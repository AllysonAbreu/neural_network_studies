{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_RECEITA</th>\n",
       "      <th>DATA</th>\n",
       "      <th>COD_CONTRIBUINTE</th>\n",
       "      <th>VALOR_ARRECADADO</th>\n",
       "      <th>FONTE_DADOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1722010101</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>185560.68</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1722010101</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>8081.80</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1722010101</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>4231.39</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1722010101</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>10536.53</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1722010101</td>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>103118.27</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COD_RECEITA        DATA COD_CONTRIBUINTE  VALOR_ARRECADADO  \\\n",
       "0   1722010101  2013-01-03   886cd0eabf5a18         185560.68   \n",
       "1   1722010101  2013-01-04   886cd0eabf5a18           8081.80   \n",
       "2   1722010101  2013-01-07   886cd0eabf5a18           4231.39   \n",
       "3   1722010101  2013-01-08   886cd0eabf5a18          10536.53   \n",
       "4   1722010101  2013-01-15   886cd0eabf5a18         103118.27   \n",
       "\n",
       "            FONTE_DADOS  \n",
       "0  prefeitura municipal  \n",
       "1  prefeitura municipal  \n",
       "2  prefeitura municipal  \n",
       "3  prefeitura municipal  \n",
       "4  prefeitura municipal  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_receitas = pd.read_csv('03_dados_carga/arquivos_para_carga/dados_receitas.csv', sep=';')\n",
    "dados_receitas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receitas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção dos outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna 'DATA' para o tipo datetime\n",
    "dados_receitas['DATA'] = pd.to_datetime(dados_receitas['DATA'])\n",
    "\n",
    "# Extrair o ano, mês e dia da coluna 'DATA' como novas features\n",
    "dados_receitas['ANO'] = dados_receitas['DATA'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 51.23\n",
      "Q3: 1579.25\n",
      "IQR: 1528.02\n",
      "Limite inferior: -2240.7999999999997\n",
      "Limite superior: 3871.2799999999997\n",
      "Quantidade de registros sem outliers: 83736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'VALOR_ARRECADADO'}, xlabel='[ANO]'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aplicação de IQR - interquartile range\n",
    "Q1 = dados_receitas['VALOR_ARRECADADO'].quantile(0.25)\n",
    "Q3 = dados_receitas['VALOR_ARRECADADO'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f'Q1: {Q1}')\n",
    "print(f'Q3: {Q3}')\n",
    "print(f'IQR: {IQR}')\n",
    "\n",
    "limite_inferior = Q1 - 1.5 * IQR\n",
    "limite_superior = Q3 + 1.5 * IQR\n",
    "print(f'Limite inferior: {limite_inferior}')\n",
    "print(f'Limite superior: {limite_superior}')\n",
    "\n",
    "df_sem_outliers = dados_receitas[(dados_receitas['VALOR_ARRECADADO'] >= limite_inferior) & (dados_receitas['VALOR_ARRECADADO'] <= limite_superior)]\n",
    "df_sem_outliers = df_sem_outliers[['ANO', 'VALOR_ARRECADADO']]\n",
    "print(f'Quantidade de registros sem outliers: {df_sem_outliers.shape[0]}')\n",
    "df_sem_outliers.boxplot(by='ANO', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_outliers = dados_receitas[(dados_receitas['VALOR_ARRECADADO'] >= limite_inferior) & (dados_receitas['VALOR_ARRECADADO'] <= limite_superior)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna pela qual você deseja amostrar proporcionalmente\n",
    "coluna_amostragem = 'ANO'\n",
    "\n",
    "# Porcentagem de amostras desejadas)\n",
    "porcentagem_amostra = 0.01\n",
    "\n",
    "# Divida o DataFrame em grupos com base na coluna de amostragem\n",
    "grupos = dados_receitas.groupby(coluna_amostragem, group_keys=False, sort=False)\n",
    "\n",
    "# Inicialize listas para armazenar os DataFrames de amostra e de não amostra\n",
    "amostras = []\n",
    "nao_amostras = []\n",
    "\n",
    "# Para cada grupo, aplique o método sample com a porcentagem desejada\n",
    "for nome_grupo, grupo in grupos:\n",
    "    grupo_amostra = grupo.sample(frac=porcentagem_amostra)\n",
    "    \n",
    "    # Adicione o grupo de amostra à lista de amostras\n",
    "    amostras.append(grupo_amostra)\n",
    "    \n",
    "    # Adicione o grupo de não amostra à lista de não amostras\n",
    "    grupo_nao_amostra = grupo.drop(grupo_amostra.index)\n",
    "    nao_amostras.append(grupo_nao_amostra)\n",
    "\n",
    "# Crie um novo DataFrame contendo todas as amostras\n",
    "df_amostrado = pd.concat(amostras).sort_index()\n",
    "\n",
    "# Crie um novo DataFrame contendo todos os dados que não entraram no sample\n",
    "df_nao_amostrado = pd.concat(nao_amostras).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_RECEITA</th>\n",
       "      <th>DATA</th>\n",
       "      <th>COD_CONTRIBUINTE</th>\n",
       "      <th>VALOR_ARRECADADO</th>\n",
       "      <th>FONTE_DADOS</th>\n",
       "      <th>ANO</th>\n",
       "      <th>SMA(12)</th>\n",
       "      <th>SMA(6)</th>\n",
       "      <th>SMA(3)</th>\n",
       "      <th>SMA(2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1113050001</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>923.08</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1113050001</td>\n",
       "      <td>2013-02-07</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511.540</td>\n",
       "      <td>511.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1113050002</td>\n",
       "      <td>2013-02-21</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>5235.76</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2667.880</td>\n",
       "      <td>2667.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1113050001</td>\n",
       "      <td>2013-03-08</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>590.09</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2912.925</td>\n",
       "      <td>2912.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1724010001</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>48808.10</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24699.095</td>\n",
       "      <td>24699.095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     COD_RECEITA       DATA COD_CONTRIBUINTE  VALOR_ARRECADADO  \\\n",
       "137   1113050001 2013-01-04   886cd0eabf5a18            923.08   \n",
       "328   1113050001 2013-02-07   886cd0eabf5a18            100.00   \n",
       "393   1113050002 2013-02-21   886cd0eabf5a18           5235.76   \n",
       "528   1113050001 2013-03-08   886cd0eabf5a18            590.09   \n",
       "624   1724010001 2013-03-26   886cd0eabf5a18          48808.10   \n",
       "\n",
       "              FONTE_DADOS   ANO  SMA(12)  SMA(6)     SMA(3)     SMA(2)  \n",
       "137  prefeitura municipal  2013      NaN     NaN        NaN        NaN  \n",
       "328  prefeitura municipal  2013      NaN     NaN    511.540    511.540  \n",
       "393  prefeitura municipal  2013      NaN     NaN   2667.880   2667.880  \n",
       "528  prefeitura municipal  2013      NaN     NaN   2912.925   2912.925  \n",
       "624  prefeitura municipal  2013      NaN     NaN  24699.095  24699.095  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amostrado['SMA(12)'] = df_amostrado['VALOR_ARRECADADO'].rolling(window=12).mean()\n",
    "df_amostrado['SMA(6)'] = df_amostrado['VALOR_ARRECADADO'].rolling(window=6).mean()\n",
    "df_amostrado['SMA(3)'] = df_amostrado['VALOR_ARRECADADO'].rolling(window=2).mean()\n",
    "df_amostrado['SMA(2)'] = df_amostrado['VALOR_ARRECADADO'].rolling(window=2).mean()\n",
    "df_amostrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_RECEITA</th>\n",
       "      <th>DATA</th>\n",
       "      <th>COD_CONTRIBUINTE</th>\n",
       "      <th>VALOR_ARRECADADO</th>\n",
       "      <th>FONTE_DADOS</th>\n",
       "      <th>ANO</th>\n",
       "      <th>SMA(12)</th>\n",
       "      <th>SMA(6)</th>\n",
       "      <th>SMA(3)</th>\n",
       "      <th>SMA(2)</th>\n",
       "      <th>lag(12)</th>\n",
       "      <th>lag(6)</th>\n",
       "      <th>lag(4)</th>\n",
       "      <th>lag(3)</th>\n",
       "      <th>lag(2)</th>\n",
       "      <th>lag(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1113050001</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>923.08</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1113050001</td>\n",
       "      <td>2013-02-07</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511.540</td>\n",
       "      <td>511.540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>923.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1113050002</td>\n",
       "      <td>2013-02-21</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>5235.76</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2667.880</td>\n",
       "      <td>2667.880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>923.08</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1113050001</td>\n",
       "      <td>2013-03-08</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>590.09</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2912.925</td>\n",
       "      <td>2912.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>923.08</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5235.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1724010001</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>48808.10</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24699.095</td>\n",
       "      <td>24699.095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>923.08</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5235.76</td>\n",
       "      <td>590.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     COD_RECEITA       DATA COD_CONTRIBUINTE  VALOR_ARRECADADO  \\\n",
       "137   1113050001 2013-01-04   886cd0eabf5a18            923.08   \n",
       "328   1113050001 2013-02-07   886cd0eabf5a18            100.00   \n",
       "393   1113050002 2013-02-21   886cd0eabf5a18           5235.76   \n",
       "528   1113050001 2013-03-08   886cd0eabf5a18            590.09   \n",
       "624   1724010001 2013-03-26   886cd0eabf5a18          48808.10   \n",
       "\n",
       "              FONTE_DADOS   ANO  SMA(12)  SMA(6)     SMA(3)     SMA(2)  \\\n",
       "137  prefeitura municipal  2013      NaN     NaN        NaN        NaN   \n",
       "328  prefeitura municipal  2013      NaN     NaN    511.540    511.540   \n",
       "393  prefeitura municipal  2013      NaN     NaN   2667.880   2667.880   \n",
       "528  prefeitura municipal  2013      NaN     NaN   2912.925   2912.925   \n",
       "624  prefeitura municipal  2013      NaN     NaN  24699.095  24699.095   \n",
       "\n",
       "     lag(12)  lag(6)  lag(4)  lag(3)   lag(2)   lag(1)  \n",
       "137      NaN     NaN     NaN     NaN      NaN      NaN  \n",
       "328      NaN     NaN     NaN     NaN      NaN   923.08  \n",
       "393      NaN     NaN     NaN     NaN   923.08   100.00  \n",
       "528      NaN     NaN     NaN  923.08   100.00  5235.76  \n",
       "624      NaN     NaN  923.08  100.00  5235.76   590.09  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amostrado['lag(12)'] = df_amostrado['VALOR_ARRECADADO'].shift(12)\n",
    "df_amostrado['lag(6)'] = df_amostrado['VALOR_ARRECADADO'].shift(6)\n",
    "df_amostrado['lag(4)'] = df_amostrado['VALOR_ARRECADADO'].shift(4)\n",
    "df_amostrado['lag(3)'] = df_amostrado['VALOR_ARRECADADO'].shift(3)\n",
    "df_amostrado['lag(2)'] = df_amostrado['VALOR_ARRECADADO'].shift(2)\n",
    "df_amostrado['lag(1)'] = df_amostrado['VALOR_ARRECADADO'].shift(1)\n",
    "df_amostrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_RECEITA</th>\n",
       "      <th>DATA</th>\n",
       "      <th>COD_CONTRIBUINTE</th>\n",
       "      <th>VALOR_ARRECADADO</th>\n",
       "      <th>FONTE_DADOS</th>\n",
       "      <th>ANO</th>\n",
       "      <th>SMA(12)</th>\n",
       "      <th>SMA(6)</th>\n",
       "      <th>SMA(3)</th>\n",
       "      <th>SMA(2)</th>\n",
       "      <th>lag(12)</th>\n",
       "      <th>lag(6)</th>\n",
       "      <th>lag(4)</th>\n",
       "      <th>lag(3)</th>\n",
       "      <th>lag(2)</th>\n",
       "      <th>lag(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1220990100</td>\n",
       "      <td>2013-05-10</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>7.30</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>24851.269167</td>\n",
       "      <td>40243.668333</td>\n",
       "      <td>236.965</td>\n",
       "      <td>236.965</td>\n",
       "      <td>923.08</td>\n",
       "      <td>1924.43</td>\n",
       "      <td>247018.51</td>\n",
       "      <td>469.33</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>1722010101</td>\n",
       "      <td>2013-06-11</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>46152.90</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>28689.010833</td>\n",
       "      <td>53411.605000</td>\n",
       "      <td>23080.100</td>\n",
       "      <td>23080.100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>-32854.72</td>\n",
       "      <td>469.33</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1600990001</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>831.28</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>28321.970833</td>\n",
       "      <td>12380.400000</td>\n",
       "      <td>23492.090</td>\n",
       "      <td>23492.090</td>\n",
       "      <td>5235.76</td>\n",
       "      <td>247018.51</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.30</td>\n",
       "      <td>46152.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>1113050001</td>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>6718.14</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>28832.641667</td>\n",
       "      <td>13421.868333</td>\n",
       "      <td>3774.710</td>\n",
       "      <td>3774.710</td>\n",
       "      <td>590.09</td>\n",
       "      <td>469.33</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.30</td>\n",
       "      <td>46152.90</td>\n",
       "      <td>831.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>1325000001</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>886cd0eabf5a18</td>\n",
       "      <td>0.95</td>\n",
       "      <td>prefeitura municipal</td>\n",
       "      <td>2013</td>\n",
       "      <td>24765.379167</td>\n",
       "      <td>9029.533333</td>\n",
       "      <td>3359.545</td>\n",
       "      <td>3359.545</td>\n",
       "      <td>48808.10</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>7.30</td>\n",
       "      <td>46152.90</td>\n",
       "      <td>831.28</td>\n",
       "      <td>6718.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      COD_RECEITA       DATA COD_CONTRIBUINTE  VALOR_ARRECADADO  \\\n",
       "1406   1220990100 2013-05-10   886cd0eabf5a18              7.30   \n",
       "1508   1722010101 2013-06-11   886cd0eabf5a18          46152.90   \n",
       "1583   1600990001 2013-06-06   886cd0eabf5a18            831.28   \n",
       "1619   1113050001 2013-06-27   886cd0eabf5a18           6718.14   \n",
       "1669   1325000001 2013-06-28   886cd0eabf5a18              0.95   \n",
       "\n",
       "               FONTE_DADOS   ANO       SMA(12)        SMA(6)     SMA(3)  \\\n",
       "1406  prefeitura municipal  2013  24851.269167  40243.668333    236.965   \n",
       "1508  prefeitura municipal  2013  28689.010833  53411.605000  23080.100   \n",
       "1583  prefeitura municipal  2013  28321.970833  12380.400000  23492.090   \n",
       "1619  prefeitura municipal  2013  28832.641667  13421.868333   3774.710   \n",
       "1669  prefeitura municipal  2013  24765.379167   9029.533333   3359.545   \n",
       "\n",
       "         SMA(2)   lag(12)     lag(6)     lag(4)    lag(3)    lag(2)    lag(1)  \n",
       "1406    236.965    923.08    1924.43  247018.51    469.33  26354.96    466.63  \n",
       "1508  23080.100    100.00  -32854.72     469.33  26354.96    466.63      7.30  \n",
       "1583  23492.090   5235.76  247018.51   26354.96    466.63      7.30  46152.90  \n",
       "1619   3774.710    590.09     469.33     466.63      7.30  46152.90    831.28  \n",
       "1669   3359.545  48808.10   26354.96       7.30  46152.90    831.28   6718.14  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amostrado.dropna(inplace=True)\n",
    "df_amostrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amostrado.drop(columns=['COD_RECEITA', 'COD_CONTRIBUINTE', 'FONTE_DADOS', 'ANO'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amostrado['DATA'] = pd.to_datetime(df_amostrado['DATA'])\n",
    "df_amostrado['DATA'] = df_amostrado['DATA'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df_amostrado) * 0.75)\n",
    "train_dataset, test_dataset = df_amostrado.iloc[:train_size], df_amostrado.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>VALOR_ARRECADADO</th>\n",
       "      <th>SMA(12)</th>\n",
       "      <th>SMA(6)</th>\n",
       "      <th>SMA(3)</th>\n",
       "      <th>SMA(2)</th>\n",
       "      <th>lag(12)</th>\n",
       "      <th>lag(6)</th>\n",
       "      <th>lag(4)</th>\n",
       "      <th>lag(3)</th>\n",
       "      <th>lag(2)</th>\n",
       "      <th>lag(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>734998</td>\n",
       "      <td>7.30</td>\n",
       "      <td>24851.269167</td>\n",
       "      <td>40243.668333</td>\n",
       "      <td>236.965</td>\n",
       "      <td>236.965</td>\n",
       "      <td>923.08</td>\n",
       "      <td>1924.43</td>\n",
       "      <td>247018.51</td>\n",
       "      <td>469.33</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>735030</td>\n",
       "      <td>46152.90</td>\n",
       "      <td>28689.010833</td>\n",
       "      <td>53411.605000</td>\n",
       "      <td>23080.100</td>\n",
       "      <td>23080.100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>-32854.72</td>\n",
       "      <td>469.33</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>735025</td>\n",
       "      <td>831.28</td>\n",
       "      <td>28321.970833</td>\n",
       "      <td>12380.400000</td>\n",
       "      <td>23492.090</td>\n",
       "      <td>23492.090</td>\n",
       "      <td>5235.76</td>\n",
       "      <td>247018.51</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.30</td>\n",
       "      <td>46152.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>735046</td>\n",
       "      <td>6718.14</td>\n",
       "      <td>28832.641667</td>\n",
       "      <td>13421.868333</td>\n",
       "      <td>3774.710</td>\n",
       "      <td>3774.710</td>\n",
       "      <td>590.09</td>\n",
       "      <td>469.33</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.30</td>\n",
       "      <td>46152.90</td>\n",
       "      <td>831.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>735047</td>\n",
       "      <td>0.95</td>\n",
       "      <td>24765.379167</td>\n",
       "      <td>9029.533333</td>\n",
       "      <td>3359.545</td>\n",
       "      <td>3359.545</td>\n",
       "      <td>48808.10</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>7.30</td>\n",
       "      <td>46152.90</td>\n",
       "      <td>831.28</td>\n",
       "      <td>6718.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATA  VALOR_ARRECADADO       SMA(12)        SMA(6)     SMA(3)  \\\n",
       "1406  734998              7.30  24851.269167  40243.668333    236.965   \n",
       "1508  735030          46152.90  28689.010833  53411.605000  23080.100   \n",
       "1583  735025            831.28  28321.970833  12380.400000  23492.090   \n",
       "1619  735046           6718.14  28832.641667  13421.868333   3774.710   \n",
       "1669  735047              0.95  24765.379167   9029.533333   3359.545   \n",
       "\n",
       "         SMA(2)   lag(12)     lag(6)     lag(4)    lag(3)    lag(2)    lag(1)  \n",
       "1406    236.965    923.08    1924.43  247018.51    469.33  26354.96    466.63  \n",
       "1508  23080.100    100.00  -32854.72     469.33  26354.96    466.63      7.30  \n",
       "1583  23492.090   5235.76  247018.51   26354.96    466.63      7.30  46152.90  \n",
       "1619   3774.710    590.09     469.33     466.63      7.30  46152.90    831.28  \n",
       "1669   3359.545  48808.10   26354.96       7.30  46152.90    831.28   6718.14  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of train data:  (758, 12)\n",
      "Dimension of test data:  (253, 12)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(train_dataset['VALOR_ARRECADADO'])\n",
    "plt.plot(test_dataset['VALOR_ARRECADADO'])\n",
    "plt.xlabel('Mês')\n",
    "plt.ylabel('Valor Arrecadado')\n",
    "plt.legend(['Treino', 'Teste'], loc='upper left')\n",
    "print('Dimension of train data: ', train_dataset.shape)\n",
    "print('Dimension of test data: ', test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.drop(['VALOR_ARRECADADO'], axis=1)\n",
    "y_train = train_dataset.loc[:, ['VALOR_ARRECADADO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_dataset.drop(['VALOR_ARRECADADO'], axis=1)\n",
    "y_test = test_dataset.loc[:, ['VALOR_ARRECADADO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X_train data:  (758, 11)\n",
      "Dimension of y_train data:  (758, 1)\n",
      "Dimension of X_test data:  (253, 11)\n",
      "Dimension of y_test data:  (253, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Dimension of X_train data: ', X_train.shape)\n",
    "print('Dimension of y_train data: ', y_train.shape)\n",
    "print('Dimension of X_test data: ', X_test.shape)\n",
    "print('Dimension of y_test data: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler(feature_range=(0,1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scaler = scaler_x.fit(X_train)\n",
    "output_scaler = scaler_y.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_norm = output_scaler.transform(y_train)\n",
    "train_x_norm = input_scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_norm = output_scaler.transform(y_test)\n",
    "test_x_norm = input_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of train_y_norm data:  (758, 11)\n",
      "Dimension of train_x_norm data:  (758, 1)\n",
      "Dimension of test_y_norm data:  (253, 11)\n",
      "Dimension of test_x_norm data:  (253, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Dimension of train_y_norm data: ', train_x_norm.shape)\n",
    "print('Dimension of train_x_norm data: ', train_y_norm.shape)\n",
    "print('Dimension of test_y_norm data: ', test_x_norm.shape)\n",
    "print('Dimension of test_x_norm data: ', test_y_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_x_norm.reshape((test_x_norm.shape[0], 1, test_x_norm.shape[1]))\n",
    "X_train = train_x_norm.reshape((train_x_norm.shape[0], 1, train_x_norm.shape[1]))\n",
    "y_test = test_y_norm.reshape((test_y_norm.shape[0], 1))\n",
    "y_train = train_y_norm.reshape((train_y_norm.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste no modelo com 32, 64 e 128 neurônioss para verficação do mais adequado para a aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 20ms/step - loss: 0.0028 - val_loss: 0.0115\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0098\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.8702e-04 - val_loss: 0.0076\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.8160e-04 - val_loss: 0.0051\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.2507e-04 - val_loss: 0.0032\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.8701e-04 - val_loss: 0.0018\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3596e-04 - val_loss: 8.3880e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.4079e-04 - val_loss: 5.7227e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8647e-04 - val_loss: 8.2827e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3230e-04 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9704e-04 - val_loss: 1.8169e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3374e-04 - val_loss: 1.8122e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.7298e-05 - val_loss: 1.9086e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.2957e-04 - val_loss: 6.8295e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 9.2400e-05 - val_loss: 9.0516e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.1642e-04 - val_loss: 2.0982e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 7.6824e-05 - val_loss: 2.3457e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.6370e-05 - val_loss: 1.9179e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 7.5788e-05 - val_loss: 8.9734e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 7.9818e-05 - val_loss: 0.0012\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.8961e-05 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1210e-04 - val_loss: 1.4966e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2181e-04 - val_loss: 3.6642e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.0080e-04 - val_loss: 3.0685e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0311e-04 - val_loss: 5.1827e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.5424e-05 - val_loss: 4.6372e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9928e-05 - val_loss: 7.1908e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.6050e-05 - val_loss: 5.6611e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.2269e-05 - val_loss: 1.0696e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6829e-05 - val_loss: 4.1800e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7511e-05 - val_loss: 1.2415e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.6784e-05 - val_loss: 1.7379e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3642e-05 - val_loss: 9.4741e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6281e-05 - val_loss: 4.6881e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.5912e-05 - val_loss: 9.6116e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.5612e-05 - val_loss: 7.9931e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.6260e-05 - val_loss: 6.5399e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4942e-05 - val_loss: 3.4304e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1825e-05 - val_loss: 4.7863e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2592e-05 - val_loss: 1.1157e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.9809e-05 - val_loss: 7.6389e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.2666e-05 - val_loss: 2.2093e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 7.0404e-05 - val_loss: 6.1167e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.6617e-05 - val_loss: 4.5244e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.0828e-05 - val_loss: 5.9136e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1944e-05 - val_loss: 3.2770e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.4919e-05 - val_loss: 4.5283e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1300e-05 - val_loss: 1.3983e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.0831e-05 - val_loss: 9.2098e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4454e-05 - val_loss: 2.8690e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.2933e-05 - val_loss: 6.0993e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7500e-05 - val_loss: 4.6327e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.9701e-05 - val_loss: 8.2578e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 7.2801e-05 - val_loss: 3.2939e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.3182e-05 - val_loss: 0.0012\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4099e-04 - val_loss: 9.2537e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.2404e-05 - val_loss: 5.1530e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3636e-05 - val_loss: 4.5419e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.2779e-05 - val_loss: 3.5605e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.3149e-05 - val_loss: 3.0437e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.1546e-05 - val_loss: 1.5673e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 5.3986e-05 - val_loss: 4.3569e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.1591e-05 - val_loss: 1.4733e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5051e-05 - val_loss: 2.4005e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7854e-05 - val_loss: 5.2967e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8478e-05 - val_loss: 3.7735e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4392e-05 - val_loss: 1.8324e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8105e-05 - val_loss: 2.3549e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6799e-05 - val_loss: 1.1711e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.8469e-05 - val_loss: 2.9415e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.8028e-05 - val_loss: 2.2579e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3171e-05 - val_loss: 4.2733e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.7546e-05 - val_loss: 4.7666e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.5713e-05 - val_loss: 5.2786e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.1884e-05 - val_loss: 4.3280e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.4240e-05 - val_loss: 4.0323e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.9876e-05 - val_loss: 2.6619e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.5729e-05 - val_loss: 7.1730e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.2924e-05 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.5997e-05 - val_loss: 7.6274e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.3776e-05 - val_loss: 4.5293e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2872e-05 - val_loss: 2.1157e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4376e-05 - val_loss: 5.5255e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2343e-05 - val_loss: 9.3856e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5503e-05 - val_loss: 6.4215e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.5498e-05 - val_loss: 2.8733e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.4035e-05 - val_loss: 6.9167e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0594e-05 - val_loss: 7.4319e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 5.1847e-05 - val_loss: 1.1550e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.1010e-05 - val_loss: 3.2527e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6227e-05 - val_loss: 5.3578e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.8245e-05 - val_loss: 2.6828e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.9700e-05 - val_loss: 1.5524e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.1730e-05 - val_loss: 8.0649e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6847e-05 - val_loss: 2.0237e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.5425e-05 - val_loss: 1.8871e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.3486e-05 - val_loss: 3.6441e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3622e-05 - val_loss: 1.5094e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9936e-05 - val_loss: 4.1350e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2251e-05 - val_loss: 1.8280e-04\n",
      ">Neurons=32, Score=0.008941027044784278\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 18ms/step - loss: 0.0028 - val_loss: 0.0114\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0100\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0081\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 8.8892e-04 - val_loss: 0.0058\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 5.5514e-04 - val_loss: 0.0034\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8291e-04 - val_loss: 0.0017\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3602e-04 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8462e-04 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0501e-04 - val_loss: 2.7590e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2725e-04 - val_loss: 9.1080e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.5735e-04 - val_loss: 4.7681e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0016e-04 - val_loss: 2.9813e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0684e-04 - val_loss: 0.0019\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6178e-04 - val_loss: 2.6532e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6509e-04 - val_loss: 1.7254e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.9261e-05 - val_loss: 7.0073e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.6239e-05 - val_loss: 0.0024\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.7630e-05 - val_loss: 3.5474e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1794e-04 - val_loss: 9.1263e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 6.1431e-05 - val_loss: 0.0036\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.7712e-05 - val_loss: 7.1026e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0082e-04 - val_loss: 2.0114e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 7.1196e-05 - val_loss: 9.1611e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 8.1500e-05 - val_loss: 9.8491e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.5525e-05 - val_loss: 3.8083e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.4673e-05 - val_loss: 9.8359e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.2624e-05 - val_loss: 0.0013\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 7.5896e-05 - val_loss: 1.3493e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 7.5029e-05 - val_loss: 6.0614e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.0099e-05 - val_loss: 0.0021\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.5110e-04 - val_loss: 6.6184e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 7.5505e-05 - val_loss: 2.8486e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.9848e-05 - val_loss: 2.7592e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.9834e-05 - val_loss: 1.2944e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 5.3765e-05 - val_loss: 1.0246e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6971e-05 - val_loss: 1.5484e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0864e-05 - val_loss: 4.4147e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.0862e-05 - val_loss: 4.5583e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.0277e-05 - val_loss: 4.5777e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.8410e-05 - val_loss: 9.9072e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3377e-05 - val_loss: 2.1774e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7487e-05 - val_loss: 1.2465e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9707e-05 - val_loss: 1.8018e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1506e-05 - val_loss: 1.2842e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9577e-05 - val_loss: 2.1468e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.3496e-05 - val_loss: 1.8864e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8610e-05 - val_loss: 4.0981e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0064e-05 - val_loss: 1.0870e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3065e-05 - val_loss: 1.9507e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8112e-05 - val_loss: 3.2439e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.6535e-05 - val_loss: 3.1562e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8242e-05 - val_loss: 1.1608e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.4192e-05 - val_loss: 5.7469e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.6167e-05 - val_loss: 1.6891e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0104e-05 - val_loss: 1.5677e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.3217e-05 - val_loss: 1.6989e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8917e-05 - val_loss: 1.2313e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3373e-05 - val_loss: 6.1876e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1827e-05 - val_loss: 6.0789e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2714e-05 - val_loss: 3.1988e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4093e-05 - val_loss: 3.3068e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0388e-05 - val_loss: 1.4317e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5233e-05 - val_loss: 4.4716e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.3082e-05 - val_loss: 4.4541e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.8200e-05 - val_loss: 4.3925e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2518e-05 - val_loss: 2.3626e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.0871e-05 - val_loss: 5.5909e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5274e-05 - val_loss: 3.4677e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5771e-05 - val_loss: 4.7108e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5726e-05 - val_loss: 1.5109e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.5499e-05 - val_loss: 6.9207e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.1120e-05 - val_loss: 2.5705e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9319e-05 - val_loss: 7.3486e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3334e-05 - val_loss: 1.3416e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2071e-05 - val_loss: 2.4317e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0693e-05 - val_loss: 4.3897e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7769e-05 - val_loss: 2.0348e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6394e-05 - val_loss: 6.4862e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.1108e-05 - val_loss: 5.5715e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1682e-05 - val_loss: 6.1927e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8113e-05 - val_loss: 1.9599e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0452e-05 - val_loss: 1.0739e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2826e-05 - val_loss: 2.6971e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6120e-05 - val_loss: 2.8416e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.0955e-05 - val_loss: 1.0254e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0627e-05 - val_loss: 1.2098e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2877e-05 - val_loss: 8.1711e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.1671e-05 - val_loss: 0.0012\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8685e-05 - val_loss: 2.3690e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6579e-05 - val_loss: 1.8939e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6637e-05 - val_loss: 1.0019e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7641e-05 - val_loss: 9.8615e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.8657e-05 - val_loss: 1.1828e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4732e-05 - val_loss: 7.8493e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.4909e-05 - val_loss: 6.0079e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5858e-05 - val_loss: 1.2359e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5233e-05 - val_loss: 2.6955e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.7724e-05 - val_loss: 7.9570e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.5390e-05 - val_loss: 2.3747e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9082e-05 - val_loss: 1.9374e-04\n",
      ">Neurons=32, Score=0.009863782906904817\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 17ms/step - loss: 0.0033 - val_loss: 0.0115\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0098\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0078\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.5214e-04 - val_loss: 0.0054\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.0629e-04 - val_loss: 0.0033\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7557e-04 - val_loss: 0.0019\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0223e-04 - val_loss: 0.0017\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7371e-04 - val_loss: 0.0014\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9703e-04 - val_loss: 4.5510e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.5294e-05 - val_loss: 3.1014e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1447e-04 - val_loss: 4.2296e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5389e-04 - val_loss: 2.5937e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2145e-04 - val_loss: 0.0020\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.4603e-05 - val_loss: 0.0020\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.5605e-04 - val_loss: 4.6116e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4208e-04 - val_loss: 5.5030e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0259e-04 - val_loss: 2.1637e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7582e-05 - val_loss: 3.0918e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.9749e-05 - val_loss: 1.5983e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.3133e-05 - val_loss: 4.0891e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3106e-04 - val_loss: 1.3052e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7485e-05 - val_loss: 2.3676e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.7629e-05 - val_loss: 0.0019\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.7725e-05 - val_loss: 9.0858e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.4377e-05 - val_loss: 1.6156e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.6255e-05 - val_loss: 6.6263e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.3774e-05 - val_loss: 5.2236e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.8122e-05 - val_loss: 3.9253e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.8827e-05 - val_loss: 7.8849e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.4538e-05 - val_loss: 8.4081e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.2759e-05 - val_loss: 1.8386e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6172e-05 - val_loss: 5.7749e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9724e-05 - val_loss: 3.8546e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1577e-05 - val_loss: 7.5752e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 6.9356e-05 - val_loss: 4.1618e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.5779e-05 - val_loss: 2.5218e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.3311e-05 - val_loss: 9.6635e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.2434e-05 - val_loss: 5.7202e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9938e-05 - val_loss: 1.0754e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.5218e-05 - val_loss: 7.2955e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.7737e-05 - val_loss: 6.1287e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2024e-05 - val_loss: 1.7300e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2924e-05 - val_loss: 4.0375e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.3964e-05 - val_loss: 1.0822e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0144e-05 - val_loss: 2.0856e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 9.0675e-05 - val_loss: 3.9257e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.6645e-05 - val_loss: 7.3540e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.6982e-05 - val_loss: 1.5125e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 9.5934e-05 - val_loss: 7.3567e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 6.6502e-05 - val_loss: 3.0659e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6999e-05 - val_loss: 8.6010e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7105e-05 - val_loss: 9.2266e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.2843e-05 - val_loss: 1.9394e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3009e-05 - val_loss: 1.9065e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.8221e-05 - val_loss: 6.7026e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9207e-05 - val_loss: 5.9329e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2261e-05 - val_loss: 3.6509e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8175e-05 - val_loss: 7.9527e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0931e-05 - val_loss: 8.7455e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6280e-05 - val_loss: 1.1029e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9527e-05 - val_loss: 1.1140e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.6411e-05 - val_loss: 1.6484e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9875e-05 - val_loss: 1.9749e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4425e-05 - val_loss: 2.1658e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7849e-05 - val_loss: 1.5687e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9282e-05 - val_loss: 2.8045e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.0276e-05 - val_loss: 1.8289e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.9250e-05 - val_loss: 4.8345e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2088e-05 - val_loss: 4.9383e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5724e-05 - val_loss: 2.1606e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0785e-05 - val_loss: 1.1758e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1799e-05 - val_loss: 1.6886e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1243e-05 - val_loss: 5.1920e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8894e-05 - val_loss: 2.1470e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5877e-05 - val_loss: 3.4974e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8154e-05 - val_loss: 2.3182e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6576e-05 - val_loss: 4.4780e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4064e-05 - val_loss: 1.9797e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7092e-05 - val_loss: 5.0779e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0101e-05 - val_loss: 8.5053e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8373e-05 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2222e-04 - val_loss: 5.5953e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1214e-05 - val_loss: 2.6756e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7325e-05 - val_loss: 3.2329e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4720e-05 - val_loss: 1.7445e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9437e-05 - val_loss: 5.0637e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4452e-05 - val_loss: 1.6424e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.4027e-05 - val_loss: 7.7160e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2196e-05 - val_loss: 4.6099e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7196e-05 - val_loss: 1.7270e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2922e-05 - val_loss: 7.7305e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.5315e-05 - val_loss: 1.9259e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.8279e-05 - val_loss: 3.1553e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4030e-05 - val_loss: 1.1027e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2048e-05 - val_loss: 6.4073e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.7273e-05 - val_loss: 1.8451e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6213e-05 - val_loss: 7.4865e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1739e-05 - val_loss: 3.3791e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8380e-05 - val_loss: 2.5481e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0519e-05 - val_loss: 1.9049e-04\n",
      ">Neurons=32, Score=0.007041703793220222\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 18ms/step - loss: 0.0028 - val_loss: 0.0120\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0082\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 8.4419e-04 - val_loss: 0.0062\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.7023e-04 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.8520e-04 - val_loss: 0.0029\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2078e-04 - val_loss: 0.0018\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.8061e-04 - val_loss: 0.0010\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.1821e-04 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3653e-04 - val_loss: 6.5660e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4804e-04 - val_loss: 2.2019e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3949e-04 - val_loss: 2.0924e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.4270e-04 - val_loss: 0.0017\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.6965e-05 - val_loss: 0.0027\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6921e-04 - val_loss: 1.9939e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2656e-04 - val_loss: 8.1687e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.9085e-05 - val_loss: 4.4137e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.0194e-04 - val_loss: 0.0010\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.8453e-05 - val_loss: 3.2492e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3660e-04 - val_loss: 9.2534e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.2269e-05 - val_loss: 2.7577e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.1802e-05 - val_loss: 3.2201e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.4030e-05 - val_loss: 7.5594e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.0461e-05 - val_loss: 7.2593e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1081e-04 - val_loss: 1.9308e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.1412e-05 - val_loss: 1.4963e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.2341e-05 - val_loss: 1.8696e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2584e-04 - val_loss: 2.7485e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.3725e-05 - val_loss: 3.3727e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9315e-05 - val_loss: 5.3148e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1936e-04 - val_loss: 5.6604e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.0696e-05 - val_loss: 2.5123e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.3860e-05 - val_loss: 1.4840e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.4152e-05 - val_loss: 5.7376e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 8.8462e-05 - val_loss: 4.2782e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.6658e-05 - val_loss: 4.0473e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.9835e-05 - val_loss: 1.0686e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.9357e-05 - val_loss: 5.0562e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0727e-05 - val_loss: 1.0145e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.9216e-05 - val_loss: 6.7121e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.5353e-05 - val_loss: 1.0505e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6168e-05 - val_loss: 3.5980e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0218e-04 - val_loss: 4.4637e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0134e-05 - val_loss: 3.5752e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.9799e-05 - val_loss: 9.6664e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.3252e-05 - val_loss: 5.3963e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.6734e-05 - val_loss: 4.0788e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9337e-05 - val_loss: 8.8559e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6313e-05 - val_loss: 3.0408e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8412e-05 - val_loss: 9.3458e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.3881e-05 - val_loss: 7.4714e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.5072e-05 - val_loss: 1.6045e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5146e-05 - val_loss: 2.9487e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7688e-05 - val_loss: 1.3709e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4603e-05 - val_loss: 1.3927e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7722e-05 - val_loss: 1.3244e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 5.7951e-05 - val_loss: 1.0284e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.4839e-05 - val_loss: 1.9170e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5467e-05 - val_loss: 1.3072e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.9107e-05 - val_loss: 2.7502e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.4218e-05 - val_loss: 2.8230e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.0514e-05 - val_loss: 0.0012\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9054e-05 - val_loss: 8.0708e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.5679e-05 - val_loss: 7.7938e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0710e-05 - val_loss: 1.9815e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.5490e-05 - val_loss: 1.2345e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.3102e-05 - val_loss: 2.1747e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0983e-05 - val_loss: 1.1345e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.3506e-05 - val_loss: 7.6622e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.6506e-05 - val_loss: 7.9870e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5610e-05 - val_loss: 4.7708e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9093e-05 - val_loss: 4.6804e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.7453e-05 - val_loss: 2.6258e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2898e-05 - val_loss: 8.0689e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.6644e-05 - val_loss: 2.0464e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.4051e-05 - val_loss: 5.4923e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8671e-05 - val_loss: 7.5506e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 5.2570e-05 - val_loss: 9.0773e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5519e-05 - val_loss: 3.0001e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1860e-05 - val_loss: 2.8152e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.1609e-05 - val_loss: 7.0816e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.6084e-05 - val_loss: 4.3592e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.1039e-05 - val_loss: 6.3367e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.9107e-05 - val_loss: 9.1647e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.6286e-05 - val_loss: 3.0440e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.4780e-05 - val_loss: 0.0012\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 6.8932e-05 - val_loss: 1.0219e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9333e-05 - val_loss: 2.4422e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.4283e-05 - val_loss: 8.6978e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 2.9916e-05 - val_loss: 1.1534e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5283e-05 - val_loss: 1.7221e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5849e-05 - val_loss: 7.0606e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0288e-05 - val_loss: 4.6333e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.4396e-05 - val_loss: 1.3739e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.9149e-05 - val_loss: 2.8725e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 4.9768e-05 - val_loss: 2.7674e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 3.2836e-05 - val_loss: 1.1814e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 6.9118e-05 - val_loss: 8.1919e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9911e-05 - val_loss: 3.4671e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.6873e-05 - val_loss: 1.7626e-04\n",
      ">Neurons=32, Score=0.007386451761703938\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 24ms/step - loss: 0.0028 - val_loss: 0.0110\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0094\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.4580e-04 - val_loss: 0.0072\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.0642e-04 - val_loss: 0.0050\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.3150e-04 - val_loss: 0.0028\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6407e-04 - val_loss: 0.0016\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.1456e-04 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.7409e-04 - val_loss: 3.1568e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6991e-04 - val_loss: 2.8028e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.1681e-04 - val_loss: 1.8816e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2204e-04 - val_loss: 3.4678e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 9.5412e-05 - val_loss: 0.0018\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.7416e-05 - val_loss: 0.0017\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.2328e-05 - val_loss: 0.0017\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.5026e-05 - val_loss: 6.8492e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2138e-04 - val_loss: 1.8887e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.9828e-05 - val_loss: 1.6106e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.0811e-05 - val_loss: 7.4730e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.2061e-05 - val_loss: 0.0012\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.4019e-05 - val_loss: 0.0011\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 8.5777e-05 - val_loss: 0.0014\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.4127e-05 - val_loss: 1.2338e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 5.8122e-05 - val_loss: 0.0010\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.1112e-05 - val_loss: 1.3874e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7773e-05 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7772e-05 - val_loss: 1.7434e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.2486e-05 - val_loss: 2.8840e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.6560e-05 - val_loss: 1.2931e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.1293e-05 - val_loss: 1.0941e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.4897e-05 - val_loss: 0.0019\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.8456e-05 - val_loss: 9.0069e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.0737e-05 - val_loss: 1.7128e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.7183e-05 - val_loss: 9.4538e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.6412e-05 - val_loss: 9.0795e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.7757e-05 - val_loss: 9.3043e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4060e-05 - val_loss: 5.3402e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0808e-05 - val_loss: 1.5625e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.8211e-05 - val_loss: 1.1468e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5154e-05 - val_loss: 6.2267e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.1736e-05 - val_loss: 3.4968e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.5072e-05 - val_loss: 7.6181e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3864e-05 - val_loss: 3.0309e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.3342e-05 - val_loss: 4.6496e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.5796e-05 - val_loss: 1.2533e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5077e-05 - val_loss: 7.4683e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8722e-05 - val_loss: 2.7174e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.7756e-05 - val_loss: 6.1744e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3985e-05 - val_loss: 2.4358e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7903e-05 - val_loss: 2.3913e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0807e-05 - val_loss: 5.5873e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5186e-05 - val_loss: 3.2838e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.0401e-05 - val_loss: 3.3131e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.8674e-05 - val_loss: 0.0015\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.5866e-05 - val_loss: 7.2387e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0308e-05 - val_loss: 4.0781e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.5647e-05 - val_loss: 1.1906e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1448e-05 - val_loss: 2.2159e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6528e-05 - val_loss: 2.3778e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9276e-05 - val_loss: 4.0141e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9521e-05 - val_loss: 4.5070e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2269e-05 - val_loss: 6.7183e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1251e-05 - val_loss: 8.0353e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9348e-05 - val_loss: 9.2229e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3170e-05 - val_loss: 1.6222e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5543e-05 - val_loss: 2.7459e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2157e-05 - val_loss: 1.4945e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.2922e-05 - val_loss: 1.6887e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0370e-05 - val_loss: 6.4250e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8274e-05 - val_loss: 4.5834e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5574e-05 - val_loss: 4.0119e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0806e-05 - val_loss: 1.8963e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8472e-05 - val_loss: 4.7875e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6475e-05 - val_loss: 8.9060e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1101e-05 - val_loss: 1.8030e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1223e-05 - val_loss: 8.6977e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7679e-05 - val_loss: 6.6800e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0270e-05 - val_loss: 7.2492e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7840e-05 - val_loss: 2.4604e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4973e-05 - val_loss: 4.4964e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6703e-05 - val_loss: 2.8577e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2032e-05 - val_loss: 3.2658e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5020e-05 - val_loss: 4.7746e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3947e-05 - val_loss: 2.0255e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5047e-05 - val_loss: 9.7593e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4429e-05 - val_loss: 8.0043e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.7203e-05 - val_loss: 0.0012\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3724e-05 - val_loss: 7.8024e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4928e-05 - val_loss: 7.3229e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4159e-05 - val_loss: 3.3553e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.0234e-05 - val_loss: 0.0015\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.3525e-05 - val_loss: 6.3171e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2464e-05 - val_loss: 4.9262e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7082e-05 - val_loss: 4.0816e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5800e-05 - val_loss: 5.3906e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4657e-05 - val_loss: 1.2937e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0859e-05 - val_loss: 7.8162e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3181e-05 - val_loss: 3.8158e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0021e-05 - val_loss: 3.5087e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1031e-05 - val_loss: 3.9498e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3320e-05 - val_loss: 2.2238e-04\n",
      ">Neurons=32, Score=0.01106775671360083\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 18ms/step - loss: 0.0029 - val_loss: 0.0121\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0105\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0085\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.6771e-04 - val_loss: 0.0057\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.3222e-04 - val_loss: 0.0033\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1561e-04 - val_loss: 0.0018\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7631e-04 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4947e-04 - val_loss: 3.6359e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5638e-04 - val_loss: 3.9905e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7438e-04 - val_loss: 1.7988e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3970e-04 - val_loss: 0.0014\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.3178e-05 - val_loss: 5.3703e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1588e-04 - val_loss: 3.0952e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2155e-04 - val_loss: 0.0014\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1406e-04 - val_loss: 2.8182e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3443e-05 - val_loss: 0.0011\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.1543e-05 - val_loss: 8.9517e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.5799e-05 - val_loss: 0.0029\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1730e-04 - val_loss: 0.0038\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.2026e-05 - val_loss: 4.2907e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.0189e-05 - val_loss: 9.2181e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.3894e-05 - val_loss: 4.7471e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.7982e-05 - val_loss: 5.1104e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.1735e-05 - val_loss: 1.1240e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.2891e-05 - val_loss: 1.4840e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1679e-04 - val_loss: 2.2768e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3047e-05 - val_loss: 3.2504e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.7936e-05 - val_loss: 2.0505e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.4031e-05 - val_loss: 1.4665e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.5994e-05 - val_loss: 6.4234e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.0678e-05 - val_loss: 6.2972e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2283e-05 - val_loss: 7.6437e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1463e-05 - val_loss: 1.0181e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8939e-05 - val_loss: 9.3526e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2664e-05 - val_loss: 1.5896e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0780e-04 - val_loss: 4.4028e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.8548e-05 - val_loss: 2.3745e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5022e-05 - val_loss: 3.9396e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9253e-05 - val_loss: 1.3158e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5477e-05 - val_loss: 1.6604e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2749e-05 - val_loss: 1.4756e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3195e-05 - val_loss: 5.9249e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8864e-05 - val_loss: 1.6131e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3493e-05 - val_loss: 2.0157e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6134e-05 - val_loss: 1.1728e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1728e-05 - val_loss: 4.4137e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.0281e-05 - val_loss: 2.0812e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.0934e-05 - val_loss: 2.0193e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7251e-05 - val_loss: 1.3704e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0880e-05 - val_loss: 1.8174e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2433e-05 - val_loss: 1.8163e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6092e-05 - val_loss: 4.2271e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0938e-05 - val_loss: 2.5447e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8580e-05 - val_loss: 2.7561e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2470e-05 - val_loss: 1.1243e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3831e-05 - val_loss: 8.8251e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2527e-05 - val_loss: 1.8452e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1963e-05 - val_loss: 1.4191e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9095e-05 - val_loss: 3.0902e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2648e-05 - val_loss: 4.7629e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7189e-05 - val_loss: 2.3400e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2837e-05 - val_loss: 4.6878e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7952e-05 - val_loss: 4.2162e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9495e-05 - val_loss: 1.6123e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.8632e-05 - val_loss: 3.8098e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6838e-05 - val_loss: 9.4609e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9831e-05 - val_loss: 2.9071e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4375e-05 - val_loss: 7.8649e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.3184e-05 - val_loss: 7.1971e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9643e-05 - val_loss: 2.1113e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2936e-05 - val_loss: 1.0046e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7427e-05 - val_loss: 3.2097e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4828e-05 - val_loss: 8.7877e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8562e-05 - val_loss: 8.6796e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4186e-05 - val_loss: 4.1707e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7157e-05 - val_loss: 2.9754e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0438e-05 - val_loss: 2.4758e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4077e-05 - val_loss: 3.9648e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9084e-05 - val_loss: 8.3430e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.0660e-05 - val_loss: 7.5968e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0090e-05 - val_loss: 2.6652e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2057e-05 - val_loss: 4.9181e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2704e-05 - val_loss: 3.3135e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0269e-05 - val_loss: 4.4834e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2454e-05 - val_loss: 5.6671e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.5362e-05 - val_loss: 7.3266e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.8253e-05 - val_loss: 1.5577e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3254e-05 - val_loss: 2.6460e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0837e-05 - val_loss: 7.8640e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3078e-05 - val_loss: 2.9139e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7518e-05 - val_loss: 1.7354e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7993e-05 - val_loss: 4.7828e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5352e-05 - val_loss: 4.9621e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6924e-05 - val_loss: 1.6145e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4931e-05 - val_loss: 2.0855e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0758e-05 - val_loss: 3.3330e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9469e-05 - val_loss: 1.8388e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3229e-05 - val_loss: 1.9126e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9422e-05 - val_loss: 2.2421e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4848e-05 - val_loss: 2.0758e-04\n",
      ">Neurons=32, Score=0.00969841712503694\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 19ms/step - loss: 0.0026 - val_loss: 0.0117\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0099\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0073\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7829e-04 - val_loss: 0.0045\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.5988e-04 - val_loss: 0.0025\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3903e-04 - val_loss: 0.0019\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1356e-04 - val_loss: 8.6836e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2813e-04 - val_loss: 6.6055e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8531e-04 - val_loss: 4.6772e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6947e-04 - val_loss: 2.2870e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3115e-04 - val_loss: 4.0264e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2306e-04 - val_loss: 8.1937e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.3779e-05 - val_loss: 3.7497e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.5311e-05 - val_loss: 3.6231e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.3283e-05 - val_loss: 3.7463e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0889e-04 - val_loss: 9.1270e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1224e-04 - val_loss: 1.2683e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.3967e-05 - val_loss: 1.1261e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.8446e-05 - val_loss: 0.0027\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.8581e-05 - val_loss: 1.9376e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.3203e-05 - val_loss: 0.0011\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.7398e-05 - val_loss: 4.0093e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.4883e-05 - val_loss: 8.3960e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9036e-05 - val_loss: 3.3520e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8052e-05 - val_loss: 4.7347e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.4320e-05 - val_loss: 1.1060e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.6444e-05 - val_loss: 6.0604e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.0039e-05 - val_loss: 2.2803e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.2705e-05 - val_loss: 7.8303e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.5562e-05 - val_loss: 1.5389e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.8138e-05 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.4613e-05 - val_loss: 7.8206e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.9411e-05 - val_loss: 6.9050e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.2754e-05 - val_loss: 2.9025e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.5212e-05 - val_loss: 1.5782e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5936e-05 - val_loss: 7.0090e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.3594e-05 - val_loss: 1.0041e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5389e-05 - val_loss: 4.4145e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4696e-05 - val_loss: 4.0292e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.7371e-05 - val_loss: 2.1167e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.2866e-05 - val_loss: 7.7356e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0524e-04 - val_loss: 4.3797e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.6846e-05 - val_loss: 9.9072e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9015e-05 - val_loss: 4.8764e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0820e-05 - val_loss: 1.8664e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7221e-05 - val_loss: 2.7689e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.6477e-05 - val_loss: 1.4521e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.4803e-05 - val_loss: 4.6358e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8043e-05 - val_loss: 9.9436e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.8576e-05 - val_loss: 4.6762e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9303e-05 - val_loss: 9.3356e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.4245e-05 - val_loss: 0.0010\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.5486e-05 - val_loss: 3.2939e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2943e-05 - val_loss: 6.1192e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8344e-05 - val_loss: 8.9633e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.3689e-05 - val_loss: 1.4629e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2215e-05 - val_loss: 1.2390e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8249e-05 - val_loss: 4.7565e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3345e-05 - val_loss: 5.0710e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5634e-05 - val_loss: 3.7471e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6875e-05 - val_loss: 3.2433e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0314e-05 - val_loss: 2.9657e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2389e-05 - val_loss: 4.5909e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.2570e-05 - val_loss: 1.0293e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8669e-05 - val_loss: 6.5927e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6226e-05 - val_loss: 1.9298e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.7083e-05 - val_loss: 0.0016\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.0352e-05 - val_loss: 1.3080e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3915e-05 - val_loss: 9.3869e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3040e-05 - val_loss: 1.4141e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3183e-05 - val_loss: 2.3067e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2509e-05 - val_loss: 3.5121e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1859e-05 - val_loss: 1.2137e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8909e-05 - val_loss: 3.3013e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.8697e-05 - val_loss: 7.2317e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.8027e-05 - val_loss: 2.9522e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6396e-05 - val_loss: 8.8511e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7582e-05 - val_loss: 2.4719e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.7700e-05 - val_loss: 8.6682e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6867e-05 - val_loss: 3.2702e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.0546e-05 - val_loss: 2.3745e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4095e-05 - val_loss: 7.4593e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7439e-05 - val_loss: 5.6254e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4959e-05 - val_loss: 1.9316e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0459e-05 - val_loss: 3.1087e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9017e-05 - val_loss: 1.2518e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2533e-05 - val_loss: 1.7227e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0796e-05 - val_loss: 1.0970e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1106e-05 - val_loss: 3.4303e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9167e-05 - val_loss: 4.3425e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7770e-05 - val_loss: 2.7515e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8540e-05 - val_loss: 5.5366e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.4389e-05 - val_loss: 1.7343e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0629e-05 - val_loss: 2.8012e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3803e-05 - val_loss: 2.8999e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6975e-05 - val_loss: 3.6182e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4724e-05 - val_loss: 2.3759e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5224e-05 - val_loss: 2.4218e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.8643e-05 - val_loss: 8.3866e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3950e-05 - val_loss: 1.7764e-04\n",
      ">Neurons=32, Score=0.009084648627322167\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 19ms/step - loss: 0.0027 - val_loss: 0.0113\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.7073e-04 - val_loss: 0.0076\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.3378e-04 - val_loss: 0.0055\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.8145e-04 - val_loss: 0.0036\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.4952e-04 - val_loss: 0.0021\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7773e-04 - val_loss: 9.9589e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1075e-04 - val_loss: 7.2858e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6322e-04 - val_loss: 4.1080e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8789e-04 - val_loss: 1.3766e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4969e-04 - val_loss: 5.0336e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.4571e-05 - val_loss: 9.6913e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.3569e-05 - val_loss: 0.0013\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9142e-04 - val_loss: 8.3151e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3754e-04 - val_loss: 1.2476e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.1276e-05 - val_loss: 2.9853e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.7880e-05 - val_loss: 9.6201e-05\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.4579e-05 - val_loss: 1.6565e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.2334e-05 - val_loss: 7.7777e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.5674e-05 - val_loss: 2.3978e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.0476e-05 - val_loss: 1.7057e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2867e-04 - val_loss: 4.3351e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0494e-04 - val_loss: 1.0626e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.7040e-05 - val_loss: 2.2665e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4261e-05 - val_loss: 2.3516e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1040e-05 - val_loss: 1.3699e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2295e-05 - val_loss: 7.2721e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.8376e-05 - val_loss: 1.6358e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4311e-04 - val_loss: 5.4649e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0998e-04 - val_loss: 7.7518e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.1484e-05 - val_loss: 3.5117e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1948e-04 - val_loss: 6.4362e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.2190e-05 - val_loss: 9.5058e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8446e-05 - val_loss: 5.3749e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4960e-05 - val_loss: 5.1841e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.7820e-05 - val_loss: 1.4122e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.3710e-05 - val_loss: 3.6738e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3035e-05 - val_loss: 5.5332e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.3875e-05 - val_loss: 2.7249e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5616e-05 - val_loss: 5.1174e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6516e-05 - val_loss: 1.6846e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.0867e-05 - val_loss: 5.2715e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9200e-05 - val_loss: 4.8214e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8663e-05 - val_loss: 1.0463e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4180e-05 - val_loss: 4.2117e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7683e-05 - val_loss: 6.6698e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1516e-05 - val_loss: 1.0465e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1539e-05 - val_loss: 3.3880e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5754e-05 - val_loss: 5.8479e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.6417e-05 - val_loss: 0.0012\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.7258e-05 - val_loss: 4.6641e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1374e-05 - val_loss: 1.1653e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2180e-05 - val_loss: 1.0722e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4297e-05 - val_loss: 3.9013e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8006e-05 - val_loss: 1.8178e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.5972e-05 - val_loss: 1.3160e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0787e-05 - val_loss: 1.0037e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.7468e-05 - val_loss: 4.3852e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2168e-05 - val_loss: 2.2541e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0093e-04 - val_loss: 7.1455e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9917e-05 - val_loss: 1.4231e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7138e-05 - val_loss: 4.6166e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9483e-05 - val_loss: 1.7825e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2264e-05 - val_loss: 3.9461e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.2363e-05 - val_loss: 1.6821e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.7751e-05 - val_loss: 1.0647e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0327e-04 - val_loss: 0.0017\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.7280e-05 - val_loss: 1.0475e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5066e-05 - val_loss: 6.7965e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0298e-05 - val_loss: 1.3558e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7001e-05 - val_loss: 3.1500e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.0332e-05 - val_loss: 1.6811e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4949e-05 - val_loss: 1.5548e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4355e-05 - val_loss: 6.1136e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3014e-05 - val_loss: 7.7717e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0882e-05 - val_loss: 1.3345e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3022e-05 - val_loss: 6.6876e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.5346e-05 - val_loss: 1.8519e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9682e-05 - val_loss: 1.2536e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5351e-05 - val_loss: 1.5010e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6782e-05 - val_loss: 1.3070e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7329e-05 - val_loss: 1.5706e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1038e-05 - val_loss: 6.6297e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6560e-05 - val_loss: 1.0083e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8422e-05 - val_loss: 3.3923e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6362e-05 - val_loss: 2.0508e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7230e-05 - val_loss: 7.7918e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9759e-05 - val_loss: 1.2065e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7885e-05 - val_loss: 8.9937e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7794e-05 - val_loss: 5.3654e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3509e-05 - val_loss: 2.3864e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.5181e-05 - val_loss: 2.5108e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1191e-05 - val_loss: 4.9387e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.3194e-05 - val_loss: 1.4693e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7755e-05 - val_loss: 7.5325e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5373e-05 - val_loss: 8.0852e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3559e-05 - val_loss: 8.3670e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2201e-05 - val_loss: 4.3561e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.5836e-05 - val_loss: 6.7268e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6361e-05 - val_loss: 1.6880e-04\n",
      ">Neurons=32, Score=0.011158112465636805\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 19ms/step - loss: 0.0029 - val_loss: 0.0117\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0100\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0084\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.6247e-04 - val_loss: 0.0062\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.1837e-04 - val_loss: 0.0038\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2048e-04 - val_loss: 0.0020\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2508e-04 - val_loss: 9.5982e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1055e-04 - val_loss: 3.9832e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4783e-04 - val_loss: 6.8018e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1352e-04 - val_loss: 0.0013\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6768e-04 - val_loss: 6.9724e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5957e-04 - val_loss: 3.4028e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.6100e-05 - val_loss: 4.9754e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.1847e-05 - val_loss: 5.6125e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4757e-04 - val_loss: 2.0174e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3219e-04 - val_loss: 1.6977e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.7877e-05 - val_loss: 2.1549e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.0124e-05 - val_loss: 1.6860e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.5663e-05 - val_loss: 2.3916e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.0096e-05 - val_loss: 5.4687e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.8014e-05 - val_loss: 1.3277e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.2895e-05 - val_loss: 9.9150e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3050e-05 - val_loss: 1.6947e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.8142e-05 - val_loss: 7.9938e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0475e-05 - val_loss: 1.9955e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.7163e-05 - val_loss: 2.0334e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1278e-05 - val_loss: 6.2010e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7256e-05 - val_loss: 5.3815e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4929e-05 - val_loss: 3.2527e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4594e-05 - val_loss: 2.4288e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.8087e-05 - val_loss: 7.4628e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.5144e-05 - val_loss: 9.5629e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.8309e-05 - val_loss: 1.5899e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0115e-05 - val_loss: 1.5188e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.6613e-05 - val_loss: 8.3967e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.1673e-05 - val_loss: 3.4148e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.6153e-05 - val_loss: 1.5584e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2221e-05 - val_loss: 3.3577e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8407e-05 - val_loss: 1.3635e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2536e-05 - val_loss: 1.1400e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7097e-05 - val_loss: 7.5972e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.6852e-05 - val_loss: 2.7081e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7672e-05 - val_loss: 6.4955e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0534e-05 - val_loss: 1.4048e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6793e-05 - val_loss: 9.4974e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.4965e-05 - val_loss: 4.9032e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2134e-05 - val_loss: 2.0247e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9008e-05 - val_loss: 7.7447e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3122e-05 - val_loss: 3.4621e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7680e-05 - val_loss: 3.0196e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1598e-05 - val_loss: 1.6704e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1491e-05 - val_loss: 3.1204e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.4636e-05 - val_loss: 6.0782e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7495e-05 - val_loss: 5.5573e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4344e-05 - val_loss: 3.6404e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1077e-05 - val_loss: 5.5521e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8224e-05 - val_loss: 1.3012e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8529e-05 - val_loss: 1.7280e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7631e-05 - val_loss: 1.4323e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1997e-05 - val_loss: 4.0380e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8873e-05 - val_loss: 2.3934e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3606e-05 - val_loss: 9.8674e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8670e-05 - val_loss: 3.3175e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6121e-05 - val_loss: 3.0261e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2499e-05 - val_loss: 1.0169e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.8571e-05 - val_loss: 1.7826e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1595e-05 - val_loss: 5.6320e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0770e-05 - val_loss: 4.5291e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8844e-05 - val_loss: 1.2399e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2862e-05 - val_loss: 8.7456e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7011e-05 - val_loss: 2.9528e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4949e-05 - val_loss: 3.9499e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2581e-05 - val_loss: 3.2928e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8416e-05 - val_loss: 3.4731e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4533e-05 - val_loss: 8.0620e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.8011e-05 - val_loss: 1.2607e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9869e-05 - val_loss: 2.2452e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5611e-05 - val_loss: 1.3954e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0372e-05 - val_loss: 3.5786e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4651e-05 - val_loss: 4.8298e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5980e-05 - val_loss: 9.8061e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9653e-05 - val_loss: 4.7654e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9442e-05 - val_loss: 1.1972e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3911e-05 - val_loss: 3.1472e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9992e-05 - val_loss: 8.9431e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9784e-05 - val_loss: 1.2325e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0125e-05 - val_loss: 3.7094e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0081e-05 - val_loss: 2.6840e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0918e-05 - val_loss: 3.4707e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0529e-05 - val_loss: 3.2716e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4759e-05 - val_loss: 1.4946e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5532e-05 - val_loss: 0.0010\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9648e-05 - val_loss: 3.3600e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2671e-05 - val_loss: 5.2358e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4127e-05 - val_loss: 4.3116e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0315e-05 - val_loss: 2.2528e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8397e-05 - val_loss: 2.2113e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2800e-05 - val_loss: 9.7119e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0100e-05 - val_loss: 7.2112e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2546e-05 - val_loss: 6.0880e-05\n",
      ">Neurons=32, Score=0.0036197478038957343\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 19ms/step - loss: 0.0025 - val_loss: 0.0109\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0088\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.7750e-04 - val_loss: 0.0066\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.6585e-04 - val_loss: 0.0045\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.9272e-04 - val_loss: 0.0027\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2863e-04 - val_loss: 0.0019\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9828e-04 - val_loss: 7.8675e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.1248e-04 - val_loss: 4.9446e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.7550e-04 - val_loss: 1.7104e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3333e-04 - val_loss: 1.7670e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4853e-04 - val_loss: 1.8647e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2185e-04 - val_loss: 1.4009e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3106e-04 - val_loss: 2.0832e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0725e-04 - val_loss: 1.8115e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0863e-05 - val_loss: 6.0158e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.0127e-05 - val_loss: 6.7794e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0092e-04 - val_loss: 3.8271e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.4191e-05 - val_loss: 6.3307e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.9922e-05 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.8671e-05 - val_loss: 0.0016\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.9098e-05 - val_loss: 1.7567e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1783e-05 - val_loss: 7.6233e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.6513e-05 - val_loss: 5.3527e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.7769e-05 - val_loss: 1.5972e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.5298e-05 - val_loss: 5.5520e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.2394e-05 - val_loss: 1.2314e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0635e-04 - val_loss: 3.0348e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.7210e-05 - val_loss: 5.0630e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5158e-05 - val_loss: 9.4731e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7219e-05 - val_loss: 5.2147e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2914e-05 - val_loss: 1.3333e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3166e-04 - val_loss: 0.0012\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.3633e-05 - val_loss: 1.1359e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3474e-05 - val_loss: 1.9597e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6095e-05 - val_loss: 5.5775e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9717e-05 - val_loss: 2.2299e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.0315e-05 - val_loss: 5.9921e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5906e-05 - val_loss: 3.8219e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1322e-05 - val_loss: 8.8749e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.3034e-05 - val_loss: 3.3026e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.0259e-05 - val_loss: 5.7985e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7251e-05 - val_loss: 3.6378e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.2022e-05 - val_loss: 5.0521e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.5434e-05 - val_loss: 1.5698e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.7890e-05 - val_loss: 9.1921e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2856e-05 - val_loss: 1.4473e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.7812e-05 - val_loss: 3.2303e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2846e-05 - val_loss: 1.5709e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4104e-05 - val_loss: 1.7768e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5496e-05 - val_loss: 8.4177e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2117e-05 - val_loss: 1.3811e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3747e-05 - val_loss: 2.5948e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9122e-05 - val_loss: 6.1114e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9257e-05 - val_loss: 3.6982e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6147e-05 - val_loss: 1.8172e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5473e-05 - val_loss: 3.8589e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3412e-05 - val_loss: 3.1678e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2965e-05 - val_loss: 2.5225e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5621e-05 - val_loss: 8.0517e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7082e-05 - val_loss: 9.6350e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3574e-05 - val_loss: 2.7053e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9339e-05 - val_loss: 1.1101e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7646e-05 - val_loss: 3.3562e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4913e-05 - val_loss: 7.7953e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2766e-05 - val_loss: 6.7290e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.4601e-05 - val_loss: 5.5621e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0924e-05 - val_loss: 6.2688e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6993e-05 - val_loss: 3.6087e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3761e-05 - val_loss: 1.0805e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8512e-05 - val_loss: 5.0334e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9465e-05 - val_loss: 1.6752e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0280e-05 - val_loss: 6.7233e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7860e-05 - val_loss: 2.8420e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1068e-05 - val_loss: 3.7391e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2880e-05 - val_loss: 9.1688e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5119e-05 - val_loss: 5.4020e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5352e-05 - val_loss: 6.9570e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0547e-05 - val_loss: 1.7162e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5745e-05 - val_loss: 9.3582e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7164e-05 - val_loss: 1.9905e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9283e-05 - val_loss: 3.6051e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5360e-05 - val_loss: 1.9059e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6221e-05 - val_loss: 2.9128e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.5251e-05 - val_loss: 4.1531e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1040e-05 - val_loss: 5.4968e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4813e-05 - val_loss: 1.2794e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9769e-05 - val_loss: 1.8433e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5762e-05 - val_loss: 1.4198e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0740e-05 - val_loss: 2.6943e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.1535e-05 - val_loss: 5.0129e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6321e-05 - val_loss: 1.6867e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3187e-05 - val_loss: 7.4916e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7197e-05 - val_loss: 6.3043e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0277e-04 - val_loss: 1.0678e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4811e-05 - val_loss: 2.5602e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0879e-05 - val_loss: 2.7667e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6181e-05 - val_loss: 1.7649e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9513e-05 - val_loss: 3.4140e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4350e-05 - val_loss: 3.0830e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6909e-05 - val_loss: 8.9862e-05\n",
      ">Neurons=32, Score=0.0068809473305009305\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 20ms/step - loss: 0.0023 - val_loss: 0.0103\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.6439e-04 - val_loss: 0.0072\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.4607e-04 - val_loss: 0.0044\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1069e-04 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6635e-04 - val_loss: 8.1958e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0690e-04 - val_loss: 3.8414e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0085e-04 - val_loss: 4.8743e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0635e-04 - val_loss: 0.0013\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0424e-05 - val_loss: 4.8604e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1464e-04 - val_loss: 3.4881e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2491e-04 - val_loss: 0.0017\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.4006e-05 - val_loss: 1.6330e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1647e-04 - val_loss: 3.0468e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0383e-04 - val_loss: 3.2991e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.7973e-05 - val_loss: 0.0014\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.8168e-05 - val_loss: 6.0872e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.6113e-05 - val_loss: 2.5081e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.9771e-05 - val_loss: 9.3067e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.6586e-05 - val_loss: 2.2164e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.0045e-05 - val_loss: 1.0805e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1141e-05 - val_loss: 2.4413e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.4278e-05 - val_loss: 5.6883e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.1649e-05 - val_loss: 2.1277e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4753e-05 - val_loss: 3.0199e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.2640e-05 - val_loss: 7.0493e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.1783e-05 - val_loss: 7.9841e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2804e-05 - val_loss: 8.4465e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3668e-05 - val_loss: 2.4940e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9737e-05 - val_loss: 1.2302e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7855e-05 - val_loss: 7.9868e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.1219e-05 - val_loss: 4.3254e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0182e-05 - val_loss: 7.7498e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9360e-05 - val_loss: 8.9157e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2386e-05 - val_loss: 3.8186e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6842e-05 - val_loss: 5.5948e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2136e-05 - val_loss: 1.5595e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0817e-05 - val_loss: 7.3083e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1296e-05 - val_loss: 4.7707e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5814e-05 - val_loss: 9.4964e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3926e-05 - val_loss: 5.1665e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7371e-05 - val_loss: 4.4075e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6531e-05 - val_loss: 1.4894e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2978e-05 - val_loss: 8.3848e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3102e-05 - val_loss: 1.4091e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1987e-05 - val_loss: 5.7901e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1805e-05 - val_loss: 0.0012\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8776e-05 - val_loss: 4.2262e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6604e-05 - val_loss: 0.0013\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3475e-05 - val_loss: 3.6773e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4415e-05 - val_loss: 1.4526e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2283e-05 - val_loss: 4.8163e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5186e-05 - val_loss: 2.6160e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2102e-05 - val_loss: 7.5637e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3619e-05 - val_loss: 3.4733e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3520e-05 - val_loss: 4.4842e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9431e-05 - val_loss: 4.0202e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8440e-05 - val_loss: 7.3863e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7801e-05 - val_loss: 2.8399e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9796e-05 - val_loss: 1.9990e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4434e-05 - val_loss: 2.7823e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3820e-05 - val_loss: 1.2314e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0157e-05 - val_loss: 2.7751e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4978e-05 - val_loss: 2.6334e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7004e-05 - val_loss: 7.3028e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2363e-05 - val_loss: 1.8432e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2319e-05 - val_loss: 2.8150e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9809e-05 - val_loss: 3.0725e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7887e-05 - val_loss: 3.7248e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3699e-05 - val_loss: 6.1906e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9212e-05 - val_loss: 1.2035e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7980e-05 - val_loss: 2.0453e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6764e-05 - val_loss: 5.9039e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0401e-05 - val_loss: 1.2689e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7909e-05 - val_loss: 8.8021e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8467e-05 - val_loss: 9.6277e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4931e-05 - val_loss: 4.7854e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3707e-05 - val_loss: 7.8913e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9824e-05 - val_loss: 7.5491e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0634e-05 - val_loss: 8.9609e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2712e-05 - val_loss: 2.7224e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.1417e-05 - val_loss: 8.1560e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3454e-05 - val_loss: 1.2809e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7419e-05 - val_loss: 5.3838e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5126e-05 - val_loss: 7.4812e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4039e-05 - val_loss: 1.5904e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6132e-05 - val_loss: 5.1474e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8275e-05 - val_loss: 1.5793e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4188e-05 - val_loss: 6.4134e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8635e-05 - val_loss: 1.8221e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9638e-05 - val_loss: 1.0614e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7152e-05 - val_loss: 1.3014e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8783e-05 - val_loss: 3.2569e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4849e-05 - val_loss: 5.1138e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4358e-05 - val_loss: 3.6379e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0769e-05 - val_loss: 1.3848e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1281e-05 - val_loss: 4.9426e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6452e-05 - val_loss: 2.0702e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6349e-05 - val_loss: 3.5127e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2908e-05 - val_loss: 1.1887e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1675e-05 - val_loss: 7.4970e-05\n",
      ">Neurons=64, Score=0.00346746455761604\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 20ms/step - loss: 0.0022 - val_loss: 0.0103\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.5869e-04 - val_loss: 0.0070\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.3213e-04 - val_loss: 0.0041\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1400e-04 - val_loss: 0.0018\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5683e-04 - val_loss: 0.0015\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7032e-04 - val_loss: 6.9692e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9379e-04 - val_loss: 7.1897e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2516e-04 - val_loss: 6.7184e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1291e-04 - val_loss: 2.3712e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3872e-04 - val_loss: 5.9915e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0889e-04 - val_loss: 2.3942e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.7231e-05 - val_loss: 2.9083e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.1010e-05 - val_loss: 0.0016\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.4921e-05 - val_loss: 2.5290e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5578e-05 - val_loss: 6.7232e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1136e-04 - val_loss: 5.0880e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0270e-04 - val_loss: 1.2086e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.5166e-05 - val_loss: 3.7952e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3693e-05 - val_loss: 4.7174e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5561e-05 - val_loss: 7.2560e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.7490e-05 - val_loss: 4.5291e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.0391e-05 - val_loss: 3.2911e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2769e-05 - val_loss: 4.7394e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.2312e-05 - val_loss: 4.3577e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.4520e-05 - val_loss: 4.8284e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0619e-05 - val_loss: 6.1915e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.4240e-05 - val_loss: 1.5169e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4277e-05 - val_loss: 4.5099e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8766e-05 - val_loss: 7.4478e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0017e-05 - val_loss: 5.7456e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7002e-05 - val_loss: 5.3070e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.7526e-05 - val_loss: 5.3779e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.0972e-05 - val_loss: 1.0452e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1236e-05 - val_loss: 1.1396e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8826e-05 - val_loss: 6.3863e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4978e-05 - val_loss: 7.0751e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.7574e-05 - val_loss: 9.4047e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.3763e-05 - val_loss: 1.1003e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7909e-05 - val_loss: 4.0163e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9178e-05 - val_loss: 5.9781e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.0612e-05 - val_loss: 6.5346e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9852e-05 - val_loss: 1.7655e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9844e-05 - val_loss: 1.4968e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3497e-05 - val_loss: 2.8698e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7440e-05 - val_loss: 8.5881e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9522e-05 - val_loss: 1.6441e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0692e-05 - val_loss: 2.0024e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3806e-05 - val_loss: 2.0589e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7072e-05 - val_loss: 2.4336e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9803e-05 - val_loss: 3.2647e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5225e-05 - val_loss: 3.7143e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9105e-05 - val_loss: 5.8652e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7095e-05 - val_loss: 1.9360e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5148e-05 - val_loss: 7.5001e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3296e-05 - val_loss: 4.3384e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7510e-05 - val_loss: 2.0723e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7763e-05 - val_loss: 1.6240e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9297e-05 - val_loss: 6.6837e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9494e-05 - val_loss: 4.5618e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5833e-05 - val_loss: 1.3423e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9644e-05 - val_loss: 7.6610e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8981e-05 - val_loss: 7.7228e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4818e-05 - val_loss: 4.8314e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.8601e-05 - val_loss: 1.4781e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4309e-05 - val_loss: 6.9219e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2857e-05 - val_loss: 8.5820e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8587e-05 - val_loss: 5.5170e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4406e-05 - val_loss: 3.1327e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0655e-05 - val_loss: 4.0747e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3902e-05 - val_loss: 1.9776e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5161e-05 - val_loss: 3.5485e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4109e-05 - val_loss: 2.7840e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4841e-05 - val_loss: 1.2730e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9148e-05 - val_loss: 4.7438e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8672e-05 - val_loss: 5.8030e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7107e-05 - val_loss: 2.2632e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0723e-05 - val_loss: 3.1966e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6536e-05 - val_loss: 2.1484e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5801e-05 - val_loss: 4.9540e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.9725e-05 - val_loss: 6.6342e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8449e-05 - val_loss: 1.2676e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1814e-05 - val_loss: 1.4751e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6927e-05 - val_loss: 7.2360e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1094e-05 - val_loss: 1.3275e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0521e-05 - val_loss: 1.0795e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3450e-05 - val_loss: 2.2804e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9976e-05 - val_loss: 9.1111e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5268e-05 - val_loss: 5.2463e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4004e-05 - val_loss: 4.5927e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4355e-05 - val_loss: 8.4509e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4511e-05 - val_loss: 5.2719e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2797e-05 - val_loss: 4.6747e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5967e-05 - val_loss: 3.5296e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1143e-05 - val_loss: 5.2868e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1381e-05 - val_loss: 4.9613e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.9407e-05 - val_loss: 1.2204e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4925e-05 - val_loss: 1.2335e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9272e-05 - val_loss: 2.0119e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6286e-05 - val_loss: 1.4629e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5608e-05 - val_loss: 1.3950e-04\n",
      ">Neurons=64, Score=0.006162785575725138\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 18ms/step - loss: 0.0022 - val_loss: 0.0102\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.6680e-04 - val_loss: 0.0073\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.6700e-04 - val_loss: 0.0047\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5050e-04 - val_loss: 0.0025\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3643e-04 - val_loss: 9.5700e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0629e-04 - val_loss: 2.9595e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5744e-04 - val_loss: 5.2742e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6941e-04 - val_loss: 7.4768e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1546e-04 - val_loss: 1.5344e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3971e-05 - val_loss: 1.9671e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.4080e-05 - val_loss: 3.4838e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.3638e-05 - val_loss: 1.2350e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1177e-04 - val_loss: 6.8953e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.8275e-05 - val_loss: 7.3917e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2323e-04 - val_loss: 6.9088e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.2111e-05 - val_loss: 3.5113e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0353e-04 - val_loss: 6.7082e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5924e-04 - val_loss: 3.5719e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.1900e-05 - val_loss: 1.5762e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.4736e-05 - val_loss: 3.0896e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.5850e-05 - val_loss: 1.6623e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1797e-05 - val_loss: 3.6953e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.9447e-05 - val_loss: 5.0229e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.1236e-05 - val_loss: 2.4693e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.8698e-05 - val_loss: 1.3681e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.1469e-05 - val_loss: 6.2934e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.1097e-05 - val_loss: 2.1189e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4576e-05 - val_loss: 2.5788e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5149e-05 - val_loss: 1.6448e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2236e-05 - val_loss: 2.1288e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3642e-05 - val_loss: 2.0563e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.2326e-05 - val_loss: 4.9341e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.4069e-05 - val_loss: 3.0032e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5717e-05 - val_loss: 2.8032e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7215e-05 - val_loss: 1.5750e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5269e-05 - val_loss: 6.6784e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5811e-05 - val_loss: 2.8140e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0182e-05 - val_loss: 8.6209e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8389e-05 - val_loss: 4.3960e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9766e-05 - val_loss: 5.3318e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3623e-05 - val_loss: 6.2381e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6950e-05 - val_loss: 1.1545e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.6453e-05 - val_loss: 3.5787e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1675e-05 - val_loss: 1.2427e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8581e-05 - val_loss: 4.2563e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1450e-05 - val_loss: 9.0007e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1130e-05 - val_loss: 8.0694e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0883e-05 - val_loss: 6.0679e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5181e-05 - val_loss: 2.1657e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1052e-05 - val_loss: 3.0789e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7402e-05 - val_loss: 2.5483e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7593e-05 - val_loss: 8.9538e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2288e-05 - val_loss: 7.5407e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2561e-05 - val_loss: 5.0967e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5635e-05 - val_loss: 9.2962e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1056e-05 - val_loss: 2.2320e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4113e-05 - val_loss: 1.1864e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4974e-05 - val_loss: 3.8652e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5576e-05 - val_loss: 1.7676e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.0638e-05 - val_loss: 0.0010\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3663e-05 - val_loss: 1.5742e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2177e-05 - val_loss: 2.1639e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5286e-05 - val_loss: 6.2109e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1190e-05 - val_loss: 6.9626e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2576e-05 - val_loss: 3.4599e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3484e-05 - val_loss: 1.9547e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2613e-05 - val_loss: 2.1928e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4503e-05 - val_loss: 5.2482e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7517e-05 - val_loss: 3.3946e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2613e-05 - val_loss: 4.9346e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5569e-05 - val_loss: 1.9668e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9223e-05 - val_loss: 5.1081e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5906e-05 - val_loss: 2.7010e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0317e-05 - val_loss: 1.2138e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3272e-05 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3789e-05 - val_loss: 1.5168e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6851e-05 - val_loss: 1.5929e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3386e-05 - val_loss: 2.1986e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1429e-05 - val_loss: 1.5407e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8049e-05 - val_loss: 3.8254e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9954e-05 - val_loss: 3.1116e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.9769e-05 - val_loss: 4.8581e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9704e-05 - val_loss: 5.1115e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2946e-05 - val_loss: 4.1857e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6107e-05 - val_loss: 1.1936e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5554e-05 - val_loss: 1.4746e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2426e-05 - val_loss: 1.8364e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3404e-05 - val_loss: 2.0985e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0537e-05 - val_loss: 8.1157e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0298e-05 - val_loss: 3.2894e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3307e-05 - val_loss: 5.5246e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7903e-05 - val_loss: 4.5047e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8516e-05 - val_loss: 1.5585e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2868e-05 - val_loss: 9.9283e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8238e-05 - val_loss: 8.3323e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0973e-05 - val_loss: 8.3553e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3789e-05 - val_loss: 1.5718e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6064e-05 - val_loss: 4.1807e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1989e-05 - val_loss: 1.2462e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5516e-05 - val_loss: 8.6714e-05\n",
      ">Neurons=64, Score=0.005760015483247116\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 20ms/step - loss: 0.0023 - val_loss: 0.0113\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0086\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.5647e-04 - val_loss: 0.0051\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1696e-04 - val_loss: 0.0024\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6488e-04 - val_loss: 9.2719e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8135e-04 - val_loss: 4.8266e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5078e-04 - val_loss: 6.1148e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1909e-04 - val_loss: 3.0682e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.7957e-05 - val_loss: 1.5311e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0857e-04 - val_loss: 2.3213e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2799e-04 - val_loss: 8.5221e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.8694e-05 - val_loss: 2.7070e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0231e-05 - val_loss: 5.0837e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.9024e-05 - val_loss: 5.2916e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.1193e-05 - val_loss: 1.7509e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.6280e-05 - val_loss: 1.5082e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.9862e-05 - val_loss: 0.0011\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.3438e-05 - val_loss: 7.0969e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0996e-05 - val_loss: 8.1575e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2394e-05 - val_loss: 1.6446e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0967e-05 - val_loss: 8.0203e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7892e-05 - val_loss: 1.5481e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4920e-05 - val_loss: 6.4563e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.5599e-05 - val_loss: 3.1512e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.0617e-05 - val_loss: 9.5581e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3219e-05 - val_loss: 1.0474e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2100e-05 - val_loss: 4.4381e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3550e-05 - val_loss: 1.1901e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6903e-05 - val_loss: 5.7858e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.7265e-05 - val_loss: 6.8138e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.8164e-05 - val_loss: 2.4681e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.5807e-05 - val_loss: 7.9943e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.0687e-05 - val_loss: 3.0876e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7143e-05 - val_loss: 1.0064e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4273e-05 - val_loss: 1.3028e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6267e-05 - val_loss: 1.1608e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2235e-05 - val_loss: 7.8219e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3754e-05 - val_loss: 6.5943e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6637e-05 - val_loss: 3.2320e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1554e-05 - val_loss: 6.4230e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4741e-05 - val_loss: 7.2133e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8991e-05 - val_loss: 2.7680e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6079e-05 - val_loss: 7.0676e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3111e-05 - val_loss: 7.3993e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9615e-05 - val_loss: 2.5294e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8196e-05 - val_loss: 6.6683e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0816e-05 - val_loss: 7.6356e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1607e-05 - val_loss: 7.7178e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1527e-05 - val_loss: 1.4197e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2163e-05 - val_loss: 8.2359e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7829e-05 - val_loss: 5.6729e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0607e-05 - val_loss: 3.6881e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.7484e-05 - val_loss: 3.1617e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5064e-05 - val_loss: 8.4337e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4761e-05 - val_loss: 4.9227e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7620e-05 - val_loss: 2.2384e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3581e-05 - val_loss: 2.5207e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4346e-05 - val_loss: 1.8042e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4716e-05 - val_loss: 2.5209e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2988e-05 - val_loss: 2.1549e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6110e-05 - val_loss: 8.8351e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0878e-05 - val_loss: 1.9943e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5981e-05 - val_loss: 5.5078e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9046e-05 - val_loss: 2.8427e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8371e-05 - val_loss: 1.0599e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2476e-05 - val_loss: 2.3219e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6022e-05 - val_loss: 1.9749e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3163e-05 - val_loss: 3.9594e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4927e-05 - val_loss: 3.0438e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0607e-05 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3061e-05 - val_loss: 0.0011\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3004e-05 - val_loss: 1.5393e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.6894e-06 - val_loss: 2.9619e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3542e-06 - val_loss: 1.5799e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2180e-05 - val_loss: 1.3936e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0250e-05 - val_loss: 4.7689e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.0136e-05 - val_loss: 3.2181e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3765e-05 - val_loss: 3.1161e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9644e-05 - val_loss: 2.8707e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0124e-05 - val_loss: 3.4035e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5169e-05 - val_loss: 7.1550e-06\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1068e-05 - val_loss: 4.9642e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7781e-05 - val_loss: 9.2219e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2689e-05 - val_loss: 5.0320e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8038e-05 - val_loss: 4.7757e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1177e-05 - val_loss: 6.4853e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1520e-05 - val_loss: 5.0924e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9399e-05 - val_loss: 6.6969e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4910e-05 - val_loss: 2.3613e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0358e-05 - val_loss: 3.4751e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3483e-05 - val_loss: 1.7440e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4740e-05 - val_loss: 5.0835e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0279e-05 - val_loss: 2.0529e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0178e-05 - val_loss: 1.3353e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8979e-05 - val_loss: 2.6789e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.8611e-05 - val_loss: 1.9337e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8818e-05 - val_loss: 5.2354e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1692e-05 - val_loss: 3.2429e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.6126e-05 - val_loss: 0.0010\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.0055e-05 - val_loss: 1.2538e-04\n",
      ">Neurons=64, Score=0.004728966086986475\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 18ms/step - loss: 0.0023 - val_loss: 0.0110\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0085\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0030e-04 - val_loss: 0.0059\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6914e-04 - val_loss: 0.0034\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7496e-04 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3128e-04 - val_loss: 5.7307e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4075e-04 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.7538e-05 - val_loss: 2.8592e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1653e-04 - val_loss: 0.0010\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.6140e-05 - val_loss: 1.5500e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.5887e-05 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.8849e-05 - val_loss: 2.1180e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.7357e-05 - val_loss: 9.7157e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2077e-04 - val_loss: 8.0193e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.9851e-05 - val_loss: 5.3807e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.3394e-05 - val_loss: 2.5693e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.1361e-05 - val_loss: 1.0823e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9721e-05 - val_loss: 2.3956e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.7815e-05 - val_loss: 1.2813e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5785e-05 - val_loss: 5.6827e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1604e-04 - val_loss: 3.5515e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.2004e-05 - val_loss: 2.3066e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1268e-05 - val_loss: 7.9362e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.0264e-05 - val_loss: 4.2114e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3690e-05 - val_loss: 9.1771e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.1570e-05 - val_loss: 3.3348e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7711e-05 - val_loss: 5.3764e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.6262e-05 - val_loss: 8.1372e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.1183e-05 - val_loss: 7.7999e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3510e-05 - val_loss: 1.7430e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0227e-05 - val_loss: 1.4984e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3878e-05 - val_loss: 1.4361e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8927e-05 - val_loss: 2.7263e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5945e-05 - val_loss: 5.2611e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5387e-05 - val_loss: 1.0488e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5652e-05 - val_loss: 1.4685e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.1209e-05 - val_loss: 8.5478e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2763e-05 - val_loss: 3.4117e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5508e-05 - val_loss: 8.4612e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.4154e-05 - val_loss: 1.3600e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4529e-05 - val_loss: 1.9175e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8407e-05 - val_loss: 4.5011e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4561e-05 - val_loss: 1.8499e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3688e-05 - val_loss: 1.0295e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3781e-05 - val_loss: 2.7518e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7038e-05 - val_loss: 2.8638e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9707e-05 - val_loss: 2.6519e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8126e-05 - val_loss: 2.1814e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8022e-05 - val_loss: 3.4558e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8124e-05 - val_loss: 6.1150e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8756e-05 - val_loss: 2.7313e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8244e-05 - val_loss: 1.9735e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7404e-05 - val_loss: 1.4010e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3724e-05 - val_loss: 3.7120e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4456e-05 - val_loss: 1.7942e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3259e-05 - val_loss: 3.9710e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0610e-05 - val_loss: 2.0564e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0327e-05 - val_loss: 2.9960e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.0765e-05 - val_loss: 3.1690e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.3653e-05 - val_loss: 8.8477e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1776e-05 - val_loss: 2.1761e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1627e-05 - val_loss: 6.9917e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.8175e-05 - val_loss: 7.6428e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9043e-05 - val_loss: 4.8300e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2899e-05 - val_loss: 7.7392e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2274e-05 - val_loss: 6.1468e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3616e-05 - val_loss: 2.6491e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7649e-05 - val_loss: 8.5730e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5319e-05 - val_loss: 6.6418e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3029e-05 - val_loss: 3.8859e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4235e-05 - val_loss: 7.0220e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3354e-05 - val_loss: 8.1503e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2458e-05 - val_loss: 7.0763e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5409e-05 - val_loss: 6.2703e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4950e-05 - val_loss: 5.9064e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4419e-05 - val_loss: 4.6702e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4222e-05 - val_loss: 4.7655e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5136e-05 - val_loss: 1.5907e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8342e-05 - val_loss: 1.7161e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6953e-05 - val_loss: 2.4259e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7461e-05 - val_loss: 1.4366e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1551e-05 - val_loss: 2.2437e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.9924e-05 - val_loss: 7.2539e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7912e-05 - val_loss: 8.2671e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1558e-05 - val_loss: 3.9781e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0008e-05 - val_loss: 2.9079e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.3110e-05 - val_loss: 1.4610e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6035e-05 - val_loss: 1.1834e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9657e-05 - val_loss: 1.0490e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1502e-05 - val_loss: 1.6818e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.6779e-05 - val_loss: 7.5767e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.7696e-06 - val_loss: 1.1092e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.1683e-05 - val_loss: 2.9275e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6003e-05 - val_loss: 3.3943e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0090e-05 - val_loss: 6.9499e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4079e-05 - val_loss: 2.9151e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8398e-05 - val_loss: 3.6168e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2569e-05 - val_loss: 2.7496e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0453e-05 - val_loss: 7.2172e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6527e-05 - val_loss: 1.0477e-04\n",
      ">Neurons=64, Score=0.008342442015418783\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 20ms/step - loss: 0.0023 - val_loss: 0.0098\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.1385e-04 - val_loss: 0.0069\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.8811e-04 - val_loss: 0.0043\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5632e-04 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9224e-04 - val_loss: 0.0014\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3798e-04 - val_loss: 9.3205e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9356e-04 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1386e-04 - val_loss: 0.0014\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1232e-04 - val_loss: 3.2971e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1310e-04 - val_loss: 7.7315e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.5548e-05 - val_loss: 5.4029e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.3482e-05 - val_loss: 2.7816e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1344e-04 - val_loss: 3.8958e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3287e-05 - val_loss: 6.5874e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4201e-05 - val_loss: 9.7467e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6940e-04 - val_loss: 0.0011\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2578e-04 - val_loss: 5.2302e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6994e-05 - val_loss: 2.7821e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6306e-05 - val_loss: 1.5564e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.1925e-05 - val_loss: 5.4904e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1270e-05 - val_loss: 3.9450e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0335e-05 - val_loss: 2.0137e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.9152e-05 - val_loss: 7.9909e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.4656e-05 - val_loss: 4.6465e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.8234e-05 - val_loss: 1.1674e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1264e-04 - val_loss: 7.5039e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4851e-05 - val_loss: 3.6114e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7150e-05 - val_loss: 1.3713e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8225e-05 - val_loss: 1.0534e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8143e-05 - val_loss: 3.1736e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0995e-05 - val_loss: 1.2271e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9068e-05 - val_loss: 6.6754e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8594e-05 - val_loss: 2.4816e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1593e-05 - val_loss: 7.8646e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9724e-05 - val_loss: 5.4925e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8254e-05 - val_loss: 5.8754e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2419e-05 - val_loss: 1.4212e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0782e-05 - val_loss: 2.1059e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5864e-05 - val_loss: 2.7627e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5274e-05 - val_loss: 7.4848e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3245e-05 - val_loss: 5.9994e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7789e-05 - val_loss: 2.7364e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4605e-05 - val_loss: 3.3875e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6222e-05 - val_loss: 9.1373e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9558e-05 - val_loss: 1.5883e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0965e-05 - val_loss: 4.6191e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2920e-05 - val_loss: 1.3824e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8499e-05 - val_loss: 6.4210e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.7024e-05 - val_loss: 6.0511e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7687e-05 - val_loss: 1.7761e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6812e-05 - val_loss: 1.1655e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9282e-05 - val_loss: 7.8506e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5104e-05 - val_loss: 1.1134e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9418e-05 - val_loss: 2.8179e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6852e-05 - val_loss: 2.1111e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0461e-05 - val_loss: 9.2547e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4230e-05 - val_loss: 8.5693e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7739e-05 - val_loss: 1.3515e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8453e-05 - val_loss: 1.0329e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5177e-05 - val_loss: 3.4539e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9257e-05 - val_loss: 6.4042e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0153e-05 - val_loss: 5.9258e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.9022e-05 - val_loss: 8.8049e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2954e-05 - val_loss: 1.9819e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5507e-05 - val_loss: 2.8074e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1338e-05 - val_loss: 3.5760e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9850e-05 - val_loss: 5.7609e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2566e-05 - val_loss: 2.5778e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5196e-05 - val_loss: 1.5311e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6585e-05 - val_loss: 1.4993e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2767e-05 - val_loss: 5.8713e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6168e-05 - val_loss: 6.1883e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.7412e-05 - val_loss: 1.7698e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0632e-05 - val_loss: 1.6101e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5411e-05 - val_loss: 6.6288e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.0831e-05 - val_loss: 7.4581e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9560e-05 - val_loss: 5.5934e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0764e-05 - val_loss: 6.4770e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6888e-05 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.3438e-05 - val_loss: 6.6816e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6283e-05 - val_loss: 9.8268e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2802e-05 - val_loss: 3.1855e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9423e-05 - val_loss: 2.4241e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3845e-05 - val_loss: 2.0622e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9335e-05 - val_loss: 2.4371e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4192e-05 - val_loss: 0.0012\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8088e-05 - val_loss: 1.5979e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9414e-05 - val_loss: 1.7779e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3432e-05 - val_loss: 4.8901e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6147e-05 - val_loss: 1.7863e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3929e-05 - val_loss: 2.5865e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4884e-05 - val_loss: 3.6987e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9108e-05 - val_loss: 1.2962e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1051e-05 - val_loss: 1.0157e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2783e-05 - val_loss: 1.2328e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4410e-05 - val_loss: 2.1246e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8916e-05 - val_loss: 9.5095e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.1091e-05 - val_loss: 4.8992e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3714e-05 - val_loss: 2.6968e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.8373e-06 - val_loss: 7.7788e-06\n",
      ">Neurons=64, Score=0.0009234310709871352\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 18ms/step - loss: 0.0023 - val_loss: 0.0109\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.8688e-04 - val_loss: 0.0084\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.2831e-04 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.1830e-04 - val_loss: 0.0029\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3801e-04 - val_loss: 0.0010\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9267e-04 - val_loss: 7.1439e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4429e-04 - val_loss: 0.0016\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2386e-04 - val_loss: 1.9256e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2713e-04 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.5758e-05 - val_loss: 0.0021\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3450e-04 - val_loss: 4.1526e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1306e-04 - val_loss: 1.3395e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1160e-04 - val_loss: 0.0010\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.0422e-05 - val_loss: 2.0406e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.6272e-05 - val_loss: 3.0324e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.8208e-05 - val_loss: 8.8169e-05\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.7203e-05 - val_loss: 3.4304e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7410e-05 - val_loss: 0.0015\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5178e-05 - val_loss: 2.3663e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.7127e-05 - val_loss: 1.8642e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.7715e-05 - val_loss: 8.2104e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.1929e-05 - val_loss: 8.0508e-05\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.7666e-05 - val_loss: 1.9667e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.1348e-05 - val_loss: 2.7830e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.1610e-05 - val_loss: 3.1453e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.4166e-05 - val_loss: 1.0218e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9432e-05 - val_loss: 5.3301e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3112e-05 - val_loss: 4.8950e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5695e-05 - val_loss: 8.6876e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1414e-05 - val_loss: 2.8599e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0864e-05 - val_loss: 8.2420e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5484e-05 - val_loss: 1.8189e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.7794e-05 - val_loss: 2.8322e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8945e-05 - val_loss: 7.3618e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3501e-05 - val_loss: 2.2521e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.9523e-05 - val_loss: 1.2542e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8695e-05 - val_loss: 1.0914e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7475e-05 - val_loss: 2.2708e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.8825e-05 - val_loss: 0.0020\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8670e-05 - val_loss: 7.9328e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2757e-05 - val_loss: 2.5659e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6453e-05 - val_loss: 9.0200e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9036e-05 - val_loss: 1.0545e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6834e-05 - val_loss: 3.6527e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6075e-05 - val_loss: 3.3109e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7229e-05 - val_loss: 9.0827e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3258e-05 - val_loss: 1.4613e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1881e-05 - val_loss: 1.7005e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0528e-05 - val_loss: 2.3682e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6110e-05 - val_loss: 1.2062e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3037e-05 - val_loss: 2.1341e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5268e-05 - val_loss: 1.0320e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7634e-05 - val_loss: 3.2951e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1323e-05 - val_loss: 5.9897e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3590e-05 - val_loss: 2.0184e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9252e-05 - val_loss: 5.8961e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1163e-05 - val_loss: 5.7394e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3007e-05 - val_loss: 8.9105e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1851e-05 - val_loss: 4.0183e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5003e-05 - val_loss: 5.1652e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6218e-05 - val_loss: 5.2810e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8512e-05 - val_loss: 1.7033e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6118e-05 - val_loss: 2.7830e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2872e-05 - val_loss: 8.0725e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9371e-05 - val_loss: 2.9892e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5668e-05 - val_loss: 1.9325e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.2263e-06 - val_loss: 5.0566e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0071e-05 - val_loss: 2.8061e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0885e-05 - val_loss: 3.7432e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1361e-05 - val_loss: 8.8680e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0518e-05 - val_loss: 5.3842e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5657e-05 - val_loss: 1.8135e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9421e-05 - val_loss: 9.3902e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8619e-05 - val_loss: 6.7647e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1935e-05 - val_loss: 3.8329e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4723e-05 - val_loss: 5.0792e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5146e-05 - val_loss: 9.7629e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9665e-05 - val_loss: 1.6781e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6217e-05 - val_loss: 6.7803e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9944e-05 - val_loss: 3.8825e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7567e-05 - val_loss: 3.0201e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8379e-05 - val_loss: 4.0441e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1922e-05 - val_loss: 5.1536e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7837e-05 - val_loss: 1.5294e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.1582e-06 - val_loss: 3.4432e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8533e-05 - val_loss: 6.7245e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6436e-05 - val_loss: 2.1618e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2965e-05 - val_loss: 1.4121e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6354e-05 - val_loss: 6.5707e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2419e-05 - val_loss: 4.3625e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.9204e-06 - val_loss: 6.0177e-06\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4692e-05 - val_loss: 5.2693e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8499e-05 - val_loss: 2.2224e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9603e-05 - val_loss: 3.2469e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4608e-05 - val_loss: 6.9860e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0807e-05 - val_loss: 1.8575e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4219e-05 - val_loss: 3.2175e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0402e-05 - val_loss: 4.8558e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1371e-05 - val_loss: 6.1283e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4772e-05 - val_loss: 1.0453e-04\n",
      ">Neurons=64, Score=0.004749104482471012\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 19ms/step - loss: 0.0022 - val_loss: 0.0102\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.8385e-04 - val_loss: 0.0078\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3476e-04 - val_loss: 0.0051\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.6553e-04 - val_loss: 0.0026\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6104e-04 - val_loss: 7.1719e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8123e-04 - val_loss: 2.6401e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6020e-04 - val_loss: 4.6579e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3639e-04 - val_loss: 1.7980e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0226e-05 - val_loss: 7.9956e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.7421e-05 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0534e-05 - val_loss: 4.7588e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.1606e-05 - val_loss: 2.3654e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0670e-04 - val_loss: 4.0037e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.6917e-05 - val_loss: 2.9909e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4173e-04 - val_loss: 9.8975e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.9186e-05 - val_loss: 8.0113e-05\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.2887e-05 - val_loss: 4.0801e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6234e-05 - val_loss: 1.7495e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.4273e-05 - val_loss: 6.8409e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2650e-04 - val_loss: 0.0010\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.7852e-05 - val_loss: 1.6216e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.0234e-05 - val_loss: 1.8336e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6264e-05 - val_loss: 9.0024e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9789e-05 - val_loss: 1.5314e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7310e-05 - val_loss: 2.0632e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3833e-05 - val_loss: 8.2921e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9169e-05 - val_loss: 1.6233e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5435e-05 - val_loss: 5.1978e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2252e-05 - val_loss: 6.2842e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5540e-05 - val_loss: 3.5337e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4085e-05 - val_loss: 5.0833e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8980e-05 - val_loss: 3.1179e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2534e-05 - val_loss: 2.8949e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6274e-05 - val_loss: 7.9540e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3622e-05 - val_loss: 3.5387e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0371e-05 - val_loss: 3.4021e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9036e-05 - val_loss: 1.9652e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2861e-05 - val_loss: 3.6732e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0968e-05 - val_loss: 3.4424e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5158e-05 - val_loss: 2.3193e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.8152e-05 - val_loss: 3.7660e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7664e-05 - val_loss: 3.1959e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3286e-05 - val_loss: 1.6060e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7346e-05 - val_loss: 3.5374e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2267e-05 - val_loss: 2.6528e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0398e-05 - val_loss: 5.9982e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1430e-05 - val_loss: 2.2042e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0744e-05 - val_loss: 9.9126e-06\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.0547e-05 - val_loss: 1.8196e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9792e-05 - val_loss: 1.4466e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9669e-05 - val_loss: 2.7343e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5476e-05 - val_loss: 4.2702e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4287e-05 - val_loss: 9.0183e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9505e-05 - val_loss: 3.1688e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8781e-05 - val_loss: 1.5710e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7458e-05 - val_loss: 2.2606e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2310e-05 - val_loss: 4.4382e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4878e-05 - val_loss: 3.4616e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.9238e-05 - val_loss: 6.0319e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5986e-05 - val_loss: 3.3408e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9759e-05 - val_loss: 5.0250e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7025e-05 - val_loss: 1.0443e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8343e-05 - val_loss: 2.6883e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6225e-05 - val_loss: 8.3936e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6572e-05 - val_loss: 5.9539e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0579e-05 - val_loss: 4.8268e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2495e-05 - val_loss: 5.5712e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1893e-05 - val_loss: 1.1648e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1965e-05 - val_loss: 2.8528e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9079e-05 - val_loss: 1.7459e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6485e-05 - val_loss: 2.9176e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5536e-05 - val_loss: 1.9451e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0949e-05 - val_loss: 2.4588e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0387e-05 - val_loss: 3.8072e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9736e-05 - val_loss: 1.2193e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4408e-05 - val_loss: 7.9213e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3858e-05 - val_loss: 1.0406e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9221e-05 - val_loss: 1.2318e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0485e-05 - val_loss: 9.6434e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4356e-05 - val_loss: 5.7995e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9610e-05 - val_loss: 7.4934e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7994e-05 - val_loss: 1.2183e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8368e-05 - val_loss: 9.7325e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5714e-05 - val_loss: 1.2628e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2280e-05 - val_loss: 1.7191e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0927e-05 - val_loss: 1.5983e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6397e-05 - val_loss: 7.0728e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2046e-05 - val_loss: 6.4049e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5479e-05 - val_loss: 1.8289e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1585e-05 - val_loss: 8.3198e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1648e-05 - val_loss: 1.4567e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5223e-05 - val_loss: 2.8380e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.2352e-06 - val_loss: 3.4835e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0389e-05 - val_loss: 9.0816e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3708e-05 - val_loss: 5.7312e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0395e-05 - val_loss: 2.4715e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1774e-05 - val_loss: 5.9735e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1010e-05 - val_loss: 3.8519e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9969e-05 - val_loss: 9.2242e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9070e-05 - val_loss: 3.2692e-04\n",
      ">Neurons=64, Score=0.01615096116438508\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 21ms/step - loss: 0.0021 - val_loss: 0.0111\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.8865e-04 - val_loss: 0.0085\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.1457e-04 - val_loss: 0.0056\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2940e-04 - val_loss: 0.0034\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1561e-04 - val_loss: 0.0015\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0596e-04 - val_loss: 8.1060e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4121e-04 - val_loss: 3.6808e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4471e-04 - val_loss: 0.0017\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5121e-04 - val_loss: 7.9128e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.2961e-05 - val_loss: 2.4940e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.1060e-05 - val_loss: 0.0014\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.0228e-05 - val_loss: 6.3162e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.3778e-05 - val_loss: 4.2550e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0372e-04 - val_loss: 0.0018\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.6111e-05 - val_loss: 1.9539e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.5278e-05 - val_loss: 2.0738e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4356e-05 - val_loss: 8.7822e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3178e-04 - val_loss: 6.8147e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.8015e-05 - val_loss: 4.0169e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.7605e-05 - val_loss: 1.8765e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.7738e-05 - val_loss: 1.8992e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.9614e-05 - val_loss: 1.1169e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0784e-05 - val_loss: 3.9486e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.9743e-05 - val_loss: 4.2350e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.9006e-05 - val_loss: 9.5059e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.0585e-05 - val_loss: 3.7513e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.2553e-05 - val_loss: 1.9830e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.5372e-05 - val_loss: 0.0014\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.9243e-05 - val_loss: 7.2912e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.9828e-05 - val_loss: 3.7316e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.9461e-05 - val_loss: 2.1564e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.5794e-05 - val_loss: 1.4706e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5484e-05 - val_loss: 3.3492e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1783e-05 - val_loss: 1.3248e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6609e-05 - val_loss: 1.1950e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3416e-05 - val_loss: 1.8001e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7208e-05 - val_loss: 2.2575e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6859e-05 - val_loss: 1.5186e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.6210e-05 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.5830e-05 - val_loss: 1.1335e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4068e-05 - val_loss: 9.5774e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0074e-05 - val_loss: 2.2795e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8241e-05 - val_loss: 4.8619e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.1895e-05 - val_loss: 3.9697e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0720e-05 - val_loss: 5.6420e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4426e-05 - val_loss: 6.2078e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7814e-05 - val_loss: 3.2567e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0315e-05 - val_loss: 1.1613e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1895e-05 - val_loss: 9.6233e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8383e-05 - val_loss: 3.4048e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6822e-05 - val_loss: 2.1419e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0203e-05 - val_loss: 8.3370e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9728e-05 - val_loss: 4.2753e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1330e-05 - val_loss: 2.6045e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6430e-05 - val_loss: 2.9864e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5099e-05 - val_loss: 1.9824e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.6667e-05 - val_loss: 3.6421e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3376e-05 - val_loss: 1.9433e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1802e-05 - val_loss: 1.7106e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6216e-05 - val_loss: 2.5898e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5671e-05 - val_loss: 6.6504e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4898e-05 - val_loss: 1.3817e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2268e-05 - val_loss: 1.5502e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7364e-05 - val_loss: 2.0890e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7505e-05 - val_loss: 2.6698e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7531e-05 - val_loss: 3.7338e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0465e-05 - val_loss: 1.7933e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6413e-05 - val_loss: 1.1174e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1616e-05 - val_loss: 1.1745e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0409e-05 - val_loss: 3.6242e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2378e-05 - val_loss: 1.6682e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3271e-05 - val_loss: 1.0663e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2270e-05 - val_loss: 1.6044e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0462e-05 - val_loss: 1.1304e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7356e-05 - val_loss: 7.4878e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6888e-05 - val_loss: 5.0366e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4795e-05 - val_loss: 2.4532e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5235e-05 - val_loss: 5.6887e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9797e-05 - val_loss: 5.4856e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2773e-05 - val_loss: 6.7375e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8676e-05 - val_loss: 6.0120e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0751e-05 - val_loss: 5.6089e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1422e-05 - val_loss: 6.1868e-06\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5181e-05 - val_loss: 2.2201e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5235e-05 - val_loss: 7.8530e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5399e-05 - val_loss: 1.0527e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.2917e-05 - val_loss: 4.7780e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5396e-05 - val_loss: 3.1318e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6998e-05 - val_loss: 2.2879e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0746e-05 - val_loss: 6.8450e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9498e-05 - val_loss: 5.1972e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0620e-05 - val_loss: 5.5337e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9975e-05 - val_loss: 2.6680e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3614e-05 - val_loss: 4.2196e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8056e-05 - val_loss: 2.1246e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7625e-05 - val_loss: 3.3230e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4492e-05 - val_loss: 1.7140e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0844e-05 - val_loss: 4.1710e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3713e-05 - val_loss: 2.0684e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6220e-05 - val_loss: 0.0012\n",
      ">Neurons=64, Score=0.06283638649620116\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 19ms/step - loss: 0.0021 - val_loss: 0.0100\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.5562e-04 - val_loss: 0.0073\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.8619e-04 - val_loss: 0.0045\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9101e-04 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6580e-04 - val_loss: 8.1609e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5733e-04 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4759e-04 - val_loss: 3.7635e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1120e-04 - val_loss: 7.6695e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.6175e-05 - val_loss: 2.7258e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.9304e-05 - val_loss: 5.6278e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.1001e-05 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0617e-04 - val_loss: 0.0027\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.5759e-05 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0763e-04 - val_loss: 1.6824e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.3735e-05 - val_loss: 1.7544e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1000e-05 - val_loss: 6.7327e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9740e-05 - val_loss: 5.5329e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5415e-05 - val_loss: 2.6799e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8691e-05 - val_loss: 1.4231e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.0435e-05 - val_loss: 5.9499e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.8259e-05 - val_loss: 3.1043e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.8264e-05 - val_loss: 1.2338e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0870e-05 - val_loss: 1.5729e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.2988e-05 - val_loss: 1.9682e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3980e-05 - val_loss: 6.3323e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6088e-05 - val_loss: 5.8557e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.0928e-05 - val_loss: 2.2567e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2014e-05 - val_loss: 7.8986e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0635e-05 - val_loss: 7.7189e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.1356e-05 - val_loss: 4.5319e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8324e-05 - val_loss: 1.3660e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.4595e-05 - val_loss: 1.0794e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.8165e-05 - val_loss: 3.0787e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6501e-05 - val_loss: 1.8176e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7716e-05 - val_loss: 1.1724e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3024e-05 - val_loss: 4.1651e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3424e-05 - val_loss: 9.0974e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4029e-05 - val_loss: 2.6344e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1383e-05 - val_loss: 1.2770e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7316e-05 - val_loss: 3.5193e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4543e-05 - val_loss: 8.7192e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6248e-05 - val_loss: 1.4259e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2413e-05 - val_loss: 4.8075e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1342e-05 - val_loss: 6.1923e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9747e-05 - val_loss: 1.5087e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.3173e-05 - val_loss: 4.0094e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.9945e-05 - val_loss: 3.8233e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5368e-05 - val_loss: 5.5563e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3392e-05 - val_loss: 2.3776e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6561e-05 - val_loss: 1.5532e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8624e-05 - val_loss: 2.3393e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.9837e-05 - val_loss: 0.0010\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.5793e-05 - val_loss: 2.6080e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0789e-05 - val_loss: 2.2177e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2235e-05 - val_loss: 1.4513e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.8967e-05 - val_loss: 2.5299e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3045e-05 - val_loss: 7.7687e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0549e-05 - val_loss: 4.3764e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4845e-05 - val_loss: 1.1227e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3289e-05 - val_loss: 4.5922e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8448e-05 - val_loss: 3.4749e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0311e-05 - val_loss: 2.1077e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9771e-05 - val_loss: 2.0063e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0524e-05 - val_loss: 7.0806e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7845e-05 - val_loss: 2.6128e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7038e-05 - val_loss: 8.0457e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.3250e-05 - val_loss: 0.0011\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.0429e-05 - val_loss: 2.4462e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5220e-05 - val_loss: 2.3616e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.1400e-05 - val_loss: 2.8261e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5908e-05 - val_loss: 1.0449e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8312e-05 - val_loss: 8.9407e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.6549e-05 - val_loss: 1.8714e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8846e-05 - val_loss: 6.5116e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9330e-05 - val_loss: 2.9080e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0306e-05 - val_loss: 3.0419e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2991e-05 - val_loss: 1.4783e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5036e-05 - val_loss: 1.3426e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.2286e-05 - val_loss: 3.0963e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8012e-05 - val_loss: 7.1798e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1163e-05 - val_loss: 7.0148e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2890e-05 - val_loss: 1.1786e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6111e-05 - val_loss: 2.0411e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0247e-05 - val_loss: 5.7250e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8649e-05 - val_loss: 3.1697e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2198e-05 - val_loss: 3.0768e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8868e-05 - val_loss: 7.6349e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0019e-05 - val_loss: 2.1407e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9049e-05 - val_loss: 3.5128e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7266e-05 - val_loss: 6.4469e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2049e-05 - val_loss: 6.4066e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7807e-05 - val_loss: 5.6994e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8976e-05 - val_loss: 7.9422e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6192e-05 - val_loss: 1.1087e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.1520e-05 - val_loss: 2.7326e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1299e-05 - val_loss: 3.5188e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4353e-05 - val_loss: 1.1029e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7049e-05 - val_loss: 8.2193e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9753e-05 - val_loss: 2.2048e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2786e-05 - val_loss: 3.4753e-05\n",
      ">Neurons=64, Score=0.0013081552424409892\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 23ms/step - loss: 0.0020 - val_loss: 0.0094\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.2280e-04 - val_loss: 0.0053\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4348e-04 - val_loss: 0.0020\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8630e-04 - val_loss: 5.1918e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3514e-04 - val_loss: 2.5395e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1770e-04 - val_loss: 2.8706e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.1475e-05 - val_loss: 1.9497e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.2350e-05 - val_loss: 2.6357e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.5096e-05 - val_loss: 2.1211e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.5939e-05 - val_loss: 2.2784e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.8476e-05 - val_loss: 2.0150e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.5439e-05 - val_loss: 3.1940e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.4231e-05 - val_loss: 1.3214e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.4049e-05 - val_loss: 1.9770e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.9674e-05 - val_loss: 1.2676e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.2783e-05 - val_loss: 6.5823e-05\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.4335e-05 - val_loss: 4.6177e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 6.8205e-05 - val_loss: 2.0177e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.4466e-05 - val_loss: 1.7518e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.1482e-05 - val_loss: 7.8829e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.6940e-05 - val_loss: 1.2285e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.5105e-05 - val_loss: 3.2318e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8096e-05 - val_loss: 1.6023e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.3879e-05 - val_loss: 6.3266e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.9164e-05 - val_loss: 5.4863e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.9309e-05 - val_loss: 2.7726e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0081e-05 - val_loss: 2.1124e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.9420e-05 - val_loss: 4.2825e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.6759e-05 - val_loss: 4.1984e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.3502e-05 - val_loss: 3.0361e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9562e-05 - val_loss: 4.0932e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 9.4923e-05 - val_loss: 3.5993e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.7400e-05 - val_loss: 8.4771e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.8131e-05 - val_loss: 2.9890e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.8359e-05 - val_loss: 1.2688e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 3.0696e-05 - val_loss: 4.2612e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.5472e-05 - val_loss: 7.8526e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 5.8545e-05 - val_loss: 0.0015\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 7.5837e-05 - val_loss: 2.1648e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.1295e-05 - val_loss: 2.7914e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7635e-05 - val_loss: 9.6511e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7780e-05 - val_loss: 3.1017e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.2960e-05 - val_loss: 2.2753e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2013e-05 - val_loss: 8.1293e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6572e-05 - val_loss: 4.8196e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7858e-05 - val_loss: 1.1420e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3636e-05 - val_loss: 2.9364e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0054e-05 - val_loss: 8.2151e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2770e-05 - val_loss: 1.0152e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.2138e-05 - val_loss: 6.5701e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5123e-05 - val_loss: 4.1429e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.2654e-05 - val_loss: 2.9277e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.8751e-05 - val_loss: 2.7372e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0468e-05 - val_loss: 2.6369e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.3317e-05 - val_loss: 7.9145e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.6348e-05 - val_loss: 2.3737e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0557e-05 - val_loss: 1.5945e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.6443e-05 - val_loss: 8.5945e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8683e-05 - val_loss: 2.7343e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.4729e-05 - val_loss: 9.3485e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.2195e-05 - val_loss: 1.2765e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.1826e-05 - val_loss: 6.1013e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.7168e-05 - val_loss: 1.1105e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.0904e-05 - val_loss: 2.9558e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.8410e-05 - val_loss: 3.8969e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4842e-05 - val_loss: 8.2314e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2070e-05 - val_loss: 4.8950e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8809e-05 - val_loss: 2.1397e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4480e-05 - val_loss: 5.1668e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8303e-05 - val_loss: 2.4403e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5643e-05 - val_loss: 4.5130e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3602e-05 - val_loss: 2.8053e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.9876e-05 - val_loss: 9.2412e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9606e-05 - val_loss: 4.3974e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3184e-05 - val_loss: 2.9174e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4728e-05 - val_loss: 8.1138e-06\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2412e-05 - val_loss: 2.1511e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.8321e-05 - val_loss: 1.4252e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.0063e-05 - val_loss: 4.8430e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1980e-05 - val_loss: 4.0510e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5147e-05 - val_loss: 8.7170e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2144e-05 - val_loss: 4.2337e-06\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5741e-05 - val_loss: 2.2974e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.0303e-05 - val_loss: 7.4546e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1429e-05 - val_loss: 7.7448e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3062e-05 - val_loss: 2.0894e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7838e-05 - val_loss: 1.1295e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4882e-05 - val_loss: 2.0009e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.5884e-05 - val_loss: 2.5571e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0905e-05 - val_loss: 4.0920e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2870e-05 - val_loss: 1.2252e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4049e-05 - val_loss: 1.0940e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0405e-05 - val_loss: 1.0648e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.2319e-06 - val_loss: 8.0345e-06\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.2350e-06 - val_loss: 3.4456e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0026e-05 - val_loss: 4.7974e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6226e-05 - val_loss: 7.2076e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5328e-05 - val_loss: 7.8810e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3331e-05 - val_loss: 8.9465e-06\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.8337e-05 - val_loss: 1.4026e-05\n",
      ">Neurons=128, Score=0.001824403807404451\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 23ms/step - loss: 0.0019 - val_loss: 0.0093\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8465e-04 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6017e-04 - val_loss: 0.0019\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9626e-04 - val_loss: 5.4505e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1724e-04 - val_loss: 1.6330e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3116e-04 - val_loss: 1.9488e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.0649e-05 - val_loss: 1.5729e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 6.3920e-05 - val_loss: 2.9543e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.7603e-05 - val_loss: 2.2633e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.2012e-05 - val_loss: 3.1558e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 9.9613e-05 - val_loss: 2.6043e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1578e-05 - val_loss: 1.0169e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4481e-05 - val_loss: 3.6237e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.4503e-05 - val_loss: 6.6118e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3169e-04 - val_loss: 3.4516e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0661e-04 - val_loss: 2.7777e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5887e-05 - val_loss: 2.3833e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.6066e-05 - val_loss: 1.0139e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2843e-05 - val_loss: 1.7672e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4656e-05 - val_loss: 5.9253e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8181e-05 - val_loss: 3.5540e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.0944e-05 - val_loss: 1.3950e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.3418e-05 - val_loss: 1.5098e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 1.9904e-05 - val_loss: 1.2749e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9424e-05 - val_loss: 2.2397e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6987e-05 - val_loss: 5.4414e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9987e-05 - val_loss: 9.9083e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1050e-05 - val_loss: 2.2246e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.7330e-05 - val_loss: 9.0309e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.8268e-05 - val_loss: 2.6941e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9076e-05 - val_loss: 5.4048e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9543e-05 - val_loss: 3.1148e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.3725e-05 - val_loss: 6.2949e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9239e-05 - val_loss: 4.3969e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8786e-05 - val_loss: 8.3122e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1682e-05 - val_loss: 3.8984e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4603e-05 - val_loss: 3.6435e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4698e-05 - val_loss: 7.8308e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4958e-05 - val_loss: 1.7851e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7045e-05 - val_loss: 5.1802e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3635e-05 - val_loss: 7.9977e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4334e-05 - val_loss: 3.6558e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9917e-05 - val_loss: 2.4844e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2582e-05 - val_loss: 1.6657e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2879e-05 - val_loss: 6.2280e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7725e-05 - val_loss: 5.5064e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8295e-05 - val_loss: 5.5853e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4426e-05 - val_loss: 8.4905e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1099e-05 - val_loss: 1.7008e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9683e-05 - val_loss: 1.8550e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9350e-05 - val_loss: 5.5656e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.6463e-05 - val_loss: 2.1204e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4483e-05 - val_loss: 4.4659e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7979e-05 - val_loss: 8.5749e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1629e-05 - val_loss: 2.2147e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7899e-05 - val_loss: 2.6986e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4524e-05 - val_loss: 6.6793e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8079e-05 - val_loss: 6.5958e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7278e-05 - val_loss: 6.2829e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5291e-05 - val_loss: 9.5160e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9125e-05 - val_loss: 1.0896e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.0010e-05 - val_loss: 3.6197e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1918e-05 - val_loss: 1.2199e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3903e-05 - val_loss: 1.1687e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.2697e-06 - val_loss: 2.1535e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1138e-05 - val_loss: 9.4488e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1508e-05 - val_loss: 4.0309e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3841e-05 - val_loss: 2.7610e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8893e-05 - val_loss: 4.0089e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0382e-05 - val_loss: 4.0241e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7307e-05 - val_loss: 3.3452e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4340e-05 - val_loss: 3.3877e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.9533e-05 - val_loss: 4.0469e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0088e-05 - val_loss: 4.7344e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.9287e-05 - val_loss: 8.9298e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8956e-05 - val_loss: 2.4096e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2868e-05 - val_loss: 1.2795e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1506e-05 - val_loss: 1.1696e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8170e-05 - val_loss: 2.2090e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0095e-05 - val_loss: 6.4799e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4606e-05 - val_loss: 1.9209e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0454e-05 - val_loss: 3.4780e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5021e-05 - val_loss: 8.6371e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6118e-05 - val_loss: 5.4644e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8262e-05 - val_loss: 4.6968e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3423e-05 - val_loss: 8.5446e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8259e-05 - val_loss: 6.0105e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.6893e-06 - val_loss: 1.4039e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.7569e-06 - val_loss: 1.0744e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9230e-06 - val_loss: 1.7000e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.8772e-06 - val_loss: 3.4152e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5854e-05 - val_loss: 4.5138e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4675e-05 - val_loss: 9.6801e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.2411e-05 - val_loss: 4.0462e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3598e-05 - val_loss: 3.4893e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8025e-05 - val_loss: 6.1861e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0745e-05 - val_loss: 3.4876e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.5142e-05 - val_loss: 2.0146e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8923e-05 - val_loss: 9.2964e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4111e-05 - val_loss: 3.8919e-05\n",
      ">Neurons=128, Score=0.00537899395567365\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 23ms/step - loss: 0.0019 - val_loss: 0.0093\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8594e-04 - val_loss: 0.0051\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4515e-04 - val_loss: 0.0019\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4446e-04 - val_loss: 6.2431e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0950e-04 - val_loss: 5.5735e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0874e-04 - val_loss: 2.4483e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0077e-04 - val_loss: 1.3579e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.2172e-05 - val_loss: 4.0402e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3716e-04 - val_loss: 7.6831e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3159e-04 - val_loss: 2.2894e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.5596e-05 - val_loss: 2.6391e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.1158e-05 - val_loss: 1.4311e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3486e-05 - val_loss: 1.3429e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.4996e-05 - val_loss: 1.1118e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.1909e-05 - val_loss: 9.6006e-05\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7178e-05 - val_loss: 2.3867e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9225e-05 - val_loss: 7.6694e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3217e-05 - val_loss: 3.5342e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.0058e-05 - val_loss: 3.2435e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4191e-05 - val_loss: 3.6201e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1146e-05 - val_loss: 6.4075e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1774e-05 - val_loss: 2.0167e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0219e-04 - val_loss: 4.1257e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.7727e-05 - val_loss: 2.7265e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0040e-04 - val_loss: 0.0013\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5533e-05 - val_loss: 7.6774e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4950e-05 - val_loss: 8.3723e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.3913e-05 - val_loss: 5.2315e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.8200e-05 - val_loss: 8.7796e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7453e-05 - val_loss: 7.4205e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0582e-05 - val_loss: 2.8648e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.7947e-05 - val_loss: 3.0345e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5696e-05 - val_loss: 4.2556e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9083e-05 - val_loss: 9.2909e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4413e-05 - val_loss: 2.5263e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4650e-05 - val_loss: 1.2879e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7096e-05 - val_loss: 3.0492e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7266e-05 - val_loss: 9.2998e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.0415e-05 - val_loss: 1.3289e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7465e-05 - val_loss: 5.5070e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9536e-05 - val_loss: 1.7500e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0322e-05 - val_loss: 4.4016e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8450e-05 - val_loss: 1.0254e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2383e-05 - val_loss: 1.1879e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5932e-05 - val_loss: 5.1784e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.4298e-05 - val_loss: 0.0015\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1189e-05 - val_loss: 2.3808e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5786e-05 - val_loss: 1.6038e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5580e-05 - val_loss: 1.5107e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6248e-05 - val_loss: 1.5957e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4026e-05 - val_loss: 2.7988e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7810e-05 - val_loss: 5.6812e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4007e-05 - val_loss: 2.6323e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.6272e-06 - val_loss: 1.3709e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7763e-05 - val_loss: 3.9331e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2961e-05 - val_loss: 7.9193e-06\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1988e-05 - val_loss: 1.3327e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2460e-05 - val_loss: 2.4569e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2273e-05 - val_loss: 6.9777e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9669e-05 - val_loss: 5.1287e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1866e-05 - val_loss: 2.4454e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4746e-05 - val_loss: 6.0393e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6742e-05 - val_loss: 1.1298e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2276e-05 - val_loss: 3.6240e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.7594e-05 - val_loss: 4.2503e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5686e-05 - val_loss: 7.4785e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1014e-05 - val_loss: 6.9821e-06\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.3222e-05 - val_loss: 5.6819e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8801e-05 - val_loss: 2.8592e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3109e-05 - val_loss: 2.1742e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4051e-05 - val_loss: 6.1170e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2065e-05 - val_loss: 5.2976e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6573e-05 - val_loss: 9.5204e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3787e-05 - val_loss: 4.2372e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3564e-05 - val_loss: 3.1172e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7208e-05 - val_loss: 2.0179e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3501e-05 - val_loss: 1.9859e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3520e-05 - val_loss: 0.0017\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.2074e-05 - val_loss: 7.0283e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2776e-05 - val_loss: 2.0503e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9586e-05 - val_loss: 4.9957e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1010e-05 - val_loss: 1.0864e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2901e-05 - val_loss: 5.5623e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7144e-05 - val_loss: 2.8538e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.9358e-06 - val_loss: 1.7181e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6348e-05 - val_loss: 5.7250e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4805e-05 - val_loss: 2.9693e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5737e-05 - val_loss: 6.1011e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.5730e-06 - val_loss: 2.9930e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1550e-05 - val_loss: 7.5577e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8750e-05 - val_loss: 1.8119e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.1812e-05 - val_loss: 0.0021\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3922e-05 - val_loss: 1.0913e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8527e-05 - val_loss: 7.1635e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6115e-05 - val_loss: 1.4636e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0558e-05 - val_loss: 3.2497e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.6544e-05 - val_loss: 0.0017\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.4258e-05 - val_loss: 3.3377e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8484e-05 - val_loss: 2.1990e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6084e-05 - val_loss: 9.7453e-05\n",
      ">Neurons=128, Score=0.006556422886205837\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 20ms/step - loss: 0.0020 - val_loss: 0.0094\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.6180e-04 - val_loss: 0.0051\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1610e-04 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2651e-04 - val_loss: 3.2295e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.6849e-05 - val_loss: 8.7603e-05\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.5804e-05 - val_loss: 3.2628e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.4083e-05 - val_loss: 2.9940e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.0595e-05 - val_loss: 6.0848e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.4669e-05 - val_loss: 4.4119e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.6879e-05 - val_loss: 4.2796e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.8450e-05 - val_loss: 2.6177e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.9523e-05 - val_loss: 4.9181e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6943e-05 - val_loss: 1.4117e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2779e-05 - val_loss: 1.5486e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.0442e-05 - val_loss: 1.2864e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.4187e-05 - val_loss: 5.0783e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.0848e-05 - val_loss: 4.9395e-05\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.6789e-05 - val_loss: 5.9530e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2309e-04 - val_loss: 0.0010\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.1221e-05 - val_loss: 2.2735e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8934e-05 - val_loss: 8.4630e-05\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.7277e-05 - val_loss: 3.9580e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7552e-05 - val_loss: 8.8354e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.2094e-05 - val_loss: 6.3735e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.0738e-05 - val_loss: 0.0011\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3602e-05 - val_loss: 1.4242e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2410e-05 - val_loss: 1.8442e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1283e-05 - val_loss: 6.4595e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3544e-05 - val_loss: 1.0527e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6707e-05 - val_loss: 2.0686e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7161e-05 - val_loss: 9.4669e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.1254e-05 - val_loss: 4.1835e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6769e-05 - val_loss: 3.1746e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6350e-05 - val_loss: 2.2739e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0841e-05 - val_loss: 1.4849e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9903e-05 - val_loss: 5.4731e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0652e-05 - val_loss: 2.0133e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7456e-05 - val_loss: 1.4931e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8392e-05 - val_loss: 3.6273e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9644e-05 - val_loss: 1.3006e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6539e-05 - val_loss: 1.9551e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.1606e-05 - val_loss: 8.4372e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7845e-05 - val_loss: 8.4352e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.5305e-05 - val_loss: 1.4093e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.9223e-05 - val_loss: 1.8113e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0181e-05 - val_loss: 1.5179e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4465e-05 - val_loss: 7.6771e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0967e-05 - val_loss: 3.7095e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3994e-05 - val_loss: 1.4354e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7419e-05 - val_loss: 7.2638e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1786e-05 - val_loss: 2.1993e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5537e-05 - val_loss: 9.4746e-06\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7786e-05 - val_loss: 8.3562e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7065e-05 - val_loss: 6.0431e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6397e-05 - val_loss: 1.6817e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.7520e-05 - val_loss: 0.0015\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0024e-05 - val_loss: 7.2196e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1914e-05 - val_loss: 2.4311e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7954e-05 - val_loss: 1.3319e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4303e-05 - val_loss: 3.0185e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8256e-05 - val_loss: 2.3418e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5050e-05 - val_loss: 5.4558e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1810e-05 - val_loss: 4.5475e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0324e-05 - val_loss: 6.0560e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2565e-05 - val_loss: 2.1767e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5249e-05 - val_loss: 5.3340e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0053e-05 - val_loss: 7.3254e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2912e-05 - val_loss: 0.0011\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5579e-05 - val_loss: 4.9483e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.2950e-06 - val_loss: 1.6318e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2502e-05 - val_loss: 7.0740e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9376e-05 - val_loss: 2.8530e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5525e-05 - val_loss: 7.4552e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2561e-05 - val_loss: 1.8809e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0856e-05 - val_loss: 4.6440e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.7661e-05 - val_loss: 5.8605e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7504e-05 - val_loss: 8.3263e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5136e-05 - val_loss: 1.3373e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6079e-05 - val_loss: 4.8305e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2458e-05 - val_loss: 1.3967e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8418e-05 - val_loss: 1.7543e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4077e-05 - val_loss: 1.7793e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.2646e-05 - val_loss: 1.8898e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1825e-05 - val_loss: 7.7944e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.9303e-06 - val_loss: 1.2573e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2742e-05 - val_loss: 9.5694e-06\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8746e-05 - val_loss: 2.0535e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6123e-05 - val_loss: 3.9478e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9009e-05 - val_loss: 6.5992e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2415e-05 - val_loss: 2.3101e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5918e-05 - val_loss: 8.8659e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5580e-05 - val_loss: 2.9095e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1885e-05 - val_loss: 8.0735e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8105e-05 - val_loss: 1.2594e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6247e-05 - val_loss: 5.7076e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.6052e-05 - val_loss: 4.6146e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3229e-05 - val_loss: 1.7228e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.5672e-05 - val_loss: 2.0960e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5055e-05 - val_loss: 5.0140e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.4044e-06 - val_loss: 1.7834e-05\n",
      ">Neurons=128, Score=0.00231082558457274\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 20ms/step - loss: 0.0018 - val_loss: 0.0089\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.8457e-04 - val_loss: 0.0048\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5082e-04 - val_loss: 0.0020\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6935e-04 - val_loss: 0.0013\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2751e-04 - val_loss: 1.9408e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0198e-04 - val_loss: 3.5736e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2199e-04 - val_loss: 3.4320e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.8642e-05 - val_loss: 3.6325e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0168e-05 - val_loss: 2.3364e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3445e-05 - val_loss: 1.6042e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2534e-05 - val_loss: 2.6501e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.8891e-05 - val_loss: 4.4167e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.4324e-05 - val_loss: 5.7743e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1488e-04 - val_loss: 4.2738e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3131e-05 - val_loss: 1.4371e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9467e-05 - val_loss: 1.0318e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4074e-05 - val_loss: 5.0752e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.1730e-05 - val_loss: 2.1778e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8672e-05 - val_loss: 2.7632e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4047e-05 - val_loss: 1.7319e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8727e-05 - val_loss: 2.1213e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0825e-05 - val_loss: 2.0882e-05\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7006e-05 - val_loss: 8.3289e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2919e-05 - val_loss: 3.9065e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7595e-05 - val_loss: 1.3196e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4147e-05 - val_loss: 1.3646e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.7065e-05 - val_loss: 1.6158e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8653e-05 - val_loss: 2.6131e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.8648e-05 - val_loss: 2.7734e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.6243e-05 - val_loss: 2.3026e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.7296e-05 - val_loss: 6.8811e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.1700e-05 - val_loss: 2.7242e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6351e-05 - val_loss: 7.3688e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8835e-05 - val_loss: 3.7293e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7492e-05 - val_loss: 1.9009e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1500e-05 - val_loss: 6.3270e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.1909e-05 - val_loss: 2.1556e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8081e-05 - val_loss: 4.7486e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4080e-05 - val_loss: 4.4520e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3955e-05 - val_loss: 1.7064e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.8481e-05 - val_loss: 4.5271e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.7295e-05 - val_loss: 3.2234e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2158e-05 - val_loss: 1.6955e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7678e-05 - val_loss: 8.6675e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9581e-05 - val_loss: 1.4454e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4924e-05 - val_loss: 6.2344e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1389e-05 - val_loss: 5.5611e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8706e-05 - val_loss: 8.2849e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8876e-05 - val_loss: 5.1717e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1849e-05 - val_loss: 4.3911e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0619e-04 - val_loss: 9.4445e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2227e-05 - val_loss: 3.6001e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5828e-05 - val_loss: 2.1794e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.0600e-05 - val_loss: 4.2390e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7139e-05 - val_loss: 1.3176e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.2174e-05 - val_loss: 1.9743e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4776e-05 - val_loss: 0.0017\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 8.0803e-05 - val_loss: 8.3669e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 1.0403e-04 - val_loss: 0.0025\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.3292e-05 - val_loss: 5.4506e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7878e-05 - val_loss: 7.4932e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1603e-05 - val_loss: 6.7632e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.6657e-05 - val_loss: 2.0363e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9274e-05 - val_loss: 1.0992e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3817e-05 - val_loss: 5.6260e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4364e-05 - val_loss: 4.1896e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4106e-05 - val_loss: 3.4158e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7428e-05 - val_loss: 1.0426e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3340e-05 - val_loss: 4.3119e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4317e-05 - val_loss: 5.1790e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6134e-05 - val_loss: 2.3932e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4840e-05 - val_loss: 1.5091e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5598e-05 - val_loss: 2.3782e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.8797e-05 - val_loss: 8.3215e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.1927e-05 - val_loss: 5.4377e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3480e-05 - val_loss: 5.3718e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.4892e-05 - val_loss: 3.5160e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6408e-05 - val_loss: 3.2349e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1378e-05 - val_loss: 1.0147e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0688e-05 - val_loss: 4.1499e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.6157e-05 - val_loss: 7.6745e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1491e-05 - val_loss: 2.6641e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3604e-05 - val_loss: 9.7390e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6357e-05 - val_loss: 6.7148e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0382e-05 - val_loss: 5.2698e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9869e-05 - val_loss: 1.5579e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.9158e-05 - val_loss: 1.3874e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.8299e-06 - val_loss: 2.2629e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.2410e-05 - val_loss: 1.9372e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.5949e-05 - val_loss: 1.0644e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1814e-05 - val_loss: 2.7762e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.2203e-05 - val_loss: 0.0014\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2203e-05 - val_loss: 2.4546e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6860e-05 - val_loss: 6.3196e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8915e-05 - val_loss: 1.5860e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.6620e-06 - val_loss: 2.3228e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.9717e-05 - val_loss: 2.2985e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8991e-05 - val_loss: 7.5646e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4299e-05 - val_loss: 2.1065e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9773e-05 - val_loss: 1.6476e-04\n",
      ">Neurons=128, Score=0.012302608229219913\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 8s 17ms/step - loss: 0.0018 - val_loss: 0.0093\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.5689e-04 - val_loss: 0.0051\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5789e-04 - val_loss: 0.0017\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6134e-04 - val_loss: 0.0012\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5893e-04 - val_loss: 6.9156e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3149e-04 - val_loss: 2.5077e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.5179e-05 - val_loss: 1.3010e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.1351e-05 - val_loss: 1.5257e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.3123e-05 - val_loss: 1.7906e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.1905e-05 - val_loss: 1.6899e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.1659e-05 - val_loss: 3.6253e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.5779e-05 - val_loss: 9.8286e-05\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.8367e-05 - val_loss: 9.7978e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.5199e-05 - val_loss: 2.6509e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.1132e-05 - val_loss: 1.1808e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6753e-05 - val_loss: 5.3070e-05\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5091e-05 - val_loss: 6.1597e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.7128e-05 - val_loss: 1.7572e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3732e-05 - val_loss: 7.2065e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.9935e-05 - val_loss: 1.6072e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7869e-05 - val_loss: 1.5619e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5979e-05 - val_loss: 1.3162e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4789e-05 - val_loss: 1.6102e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4354e-05 - val_loss: 2.0836e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8234e-05 - val_loss: 3.8465e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2432e-05 - val_loss: 1.1296e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1579e-05 - val_loss: 7.4322e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9835e-05 - val_loss: 3.5147e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8456e-05 - val_loss: 5.8146e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3474e-05 - val_loss: 7.1019e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7546e-05 - val_loss: 2.0626e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5009e-05 - val_loss: 4.5965e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.5117e-05 - val_loss: 1.4977e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0784e-05 - val_loss: 3.3699e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8011e-05 - val_loss: 3.0126e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5414e-05 - val_loss: 8.1514e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.9099e-05 - val_loss: 0.0023\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7278e-05 - val_loss: 1.7276e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5173e-05 - val_loss: 2.4136e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1422e-05 - val_loss: 1.6244e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7394e-05 - val_loss: 3.3261e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5382e-05 - val_loss: 5.0225e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8318e-05 - val_loss: 1.4443e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1335e-05 - val_loss: 6.9768e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4576e-05 - val_loss: 2.2715e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.2261e-05 - val_loss: 5.3419e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7551e-05 - val_loss: 1.1944e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.4124e-05 - val_loss: 3.3542e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6936e-05 - val_loss: 1.6051e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6554e-05 - val_loss: 2.9359e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2809e-05 - val_loss: 7.0044e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6364e-05 - val_loss: 3.4004e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2992e-05 - val_loss: 6.8653e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.1251e-05 - val_loss: 2.5887e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5581e-05 - val_loss: 1.8011e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2050e-05 - val_loss: 2.2080e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3559e-05 - val_loss: 4.2477e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2428e-05 - val_loss: 6.9395e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4656e-05 - val_loss: 7.4713e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2382e-05 - val_loss: 8.2196e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7310e-05 - val_loss: 2.8555e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3231e-05 - val_loss: 1.1940e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7577e-05 - val_loss: 1.6315e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6786e-05 - val_loss: 2.7935e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0888e-05 - val_loss: 1.2953e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7174e-05 - val_loss: 5.7988e-06\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4914e-05 - val_loss: 1.6865e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.7719e-05 - val_loss: 4.3131e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0065e-05 - val_loss: 4.8817e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1536e-05 - val_loss: 1.6005e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0548e-05 - val_loss: 1.2599e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6616e-05 - val_loss: 3.8560e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.6329e-05 - val_loss: 1.2717e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2133e-05 - val_loss: 1.7506e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7866e-05 - val_loss: 4.8954e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1674e-05 - val_loss: 1.9079e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5835e-05 - val_loss: 5.0681e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.2118e-05 - val_loss: 8.8275e-06\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4714e-05 - val_loss: 5.8364e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1838e-05 - val_loss: 9.5885e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1328e-05 - val_loss: 6.0386e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7435e-05 - val_loss: 4.0748e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0970e-05 - val_loss: 1.5034e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.7441e-06 - val_loss: 6.6429e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1418e-06 - val_loss: 9.1824e-06\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0397e-05 - val_loss: 2.6043e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2776e-05 - val_loss: 3.3672e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3860e-05 - val_loss: 1.1704e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4335e-05 - val_loss: 0.0020\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.2706e-05 - val_loss: 5.7207e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3881e-05 - val_loss: 1.1267e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.5262e-06 - val_loss: 3.2213e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9970e-05 - val_loss: 9.9287e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1156e-05 - val_loss: 1.0747e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6975e-05 - val_loss: 3.6650e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3831e-05 - val_loss: 5.6620e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2752e-05 - val_loss: 1.2059e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1989e-05 - val_loss: 2.4951e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8391e-05 - val_loss: 2.8760e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0600e-05 - val_loss: 9.8232e-05\n",
      ">Neurons=128, Score=0.006695355841657147\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 20ms/step - loss: 0.0018 - val_loss: 0.0089\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 8.1275e-04 - val_loss: 0.0048\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8057e-04 - val_loss: 0.0019\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4494e-04 - val_loss: 5.9801e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3031e-04 - val_loss: 9.8034e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0510e-04 - val_loss: 2.2256e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1752e-04 - val_loss: 4.6871e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.7855e-05 - val_loss: 2.0890e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7432e-05 - val_loss: 2.9714e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5291e-05 - val_loss: 4.7194e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5430e-05 - val_loss: 0.0010\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.0086e-05 - val_loss: 1.4847e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.7313e-05 - val_loss: 1.4935e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.7349e-05 - val_loss: 5.9447e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.1683e-05 - val_loss: 1.4466e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.9686e-05 - val_loss: 1.1694e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.8534e-05 - val_loss: 1.5288e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0737e-04 - val_loss: 8.5759e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.8142e-05 - val_loss: 2.5799e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.1056e-05 - val_loss: 7.3728e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9222e-05 - val_loss: 1.4163e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9086e-05 - val_loss: 1.1088e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6557e-05 - val_loss: 2.0846e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7285e-05 - val_loss: 3.1387e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3098e-05 - val_loss: 1.6948e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1435e-05 - val_loss: 9.3546e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.8428e-05 - val_loss: 3.6849e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0263e-04 - val_loss: 0.0010\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0848e-05 - val_loss: 2.5763e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9854e-05 - val_loss: 1.0360e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1224e-05 - val_loss: 2.9763e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4593e-05 - val_loss: 3.5194e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6275e-05 - val_loss: 1.0374e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2564e-05 - val_loss: 8.0564e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 3s 16ms/step - loss: 2.8341e-05 - val_loss: 4.9771e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7318e-05 - val_loss: 8.3885e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.1942e-05 - val_loss: 2.4427e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9367e-05 - val_loss: 7.7021e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0476e-05 - val_loss: 2.8900e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9893e-05 - val_loss: 5.6841e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0803e-05 - val_loss: 1.2697e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4886e-05 - val_loss: 8.6761e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3725e-05 - val_loss: 3.2474e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1868e-05 - val_loss: 1.7997e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1964e-05 - val_loss: 2.8847e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9021e-05 - val_loss: 1.4287e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8014e-05 - val_loss: 5.7617e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8223e-05 - val_loss: 6.8843e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9347e-05 - val_loss: 3.1596e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.0505e-05 - val_loss: 2.6666e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3161e-05 - val_loss: 4.7987e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.4419e-05 - val_loss: 7.2562e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1663e-05 - val_loss: 1.1567e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2337e-05 - val_loss: 1.1666e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2998e-05 - val_loss: 2.1090e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7466e-05 - val_loss: 1.5138e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4642e-05 - val_loss: 5.0255e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4232e-05 - val_loss: 3.9295e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5553e-05 - val_loss: 7.9667e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.7201e-05 - val_loss: 2.1340e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1304e-05 - val_loss: 7.5041e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5267e-05 - val_loss: 1.7866e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7942e-05 - val_loss: 9.3676e-06\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3150e-05 - val_loss: 5.3911e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2523e-05 - val_loss: 2.4347e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6959e-05 - val_loss: 1.0997e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1311e-05 - val_loss: 7.6238e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1162e-05 - val_loss: 8.2027e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7302e-05 - val_loss: 6.6528e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2534e-05 - val_loss: 6.4134e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1209e-05 - val_loss: 2.6497e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8178e-05 - val_loss: 4.6214e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.9042e-05 - val_loss: 8.0854e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2182e-05 - val_loss: 2.1559e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4579e-05 - val_loss: 6.1749e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6136e-05 - val_loss: 9.0572e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4828e-05 - val_loss: 3.3839e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2893e-05 - val_loss: 1.4859e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7492e-05 - val_loss: 3.6336e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4706e-05 - val_loss: 1.4763e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3311e-05 - val_loss: 2.8637e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9168e-05 - val_loss: 5.3225e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3977e-05 - val_loss: 1.8151e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5181e-04 - val_loss: 1.4696e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3933e-05 - val_loss: 2.8678e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8297e-05 - val_loss: 4.6341e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1746e-05 - val_loss: 2.0000e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0260e-05 - val_loss: 4.5482e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8937e-05 - val_loss: 7.9558e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9150e-06 - val_loss: 7.9613e-06\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2825e-05 - val_loss: 1.8227e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6172e-05 - val_loss: 1.2729e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9792e-05 - val_loss: 2.8608e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1445e-05 - val_loss: 9.1947e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2160e-05 - val_loss: 5.5893e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8432e-05 - val_loss: 2.4871e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4968e-05 - val_loss: 1.4155e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7722e-06 - val_loss: 7.0186e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8517e-05 - val_loss: 2.9513e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2658e-05 - val_loss: 1.4515e-05\n",
      ">Neurons=128, Score=0.0033109412470366806\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 21ms/step - loss: 0.0019 - val_loss: 0.0093\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.2685e-04 - val_loss: 0.0053\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.6233e-04 - val_loss: 0.0019\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2660e-04 - val_loss: 3.0690e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2855e-04 - val_loss: 5.2134e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1044e-04 - val_loss: 3.5038e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7420e-05 - val_loss: 4.9309e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9962e-05 - val_loss: 1.2060e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 6.7040e-05 - val_loss: 3.2278e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.3643e-05 - val_loss: 1.3135e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0564e-05 - val_loss: 6.6169e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5165e-04 - val_loss: 0.0013\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0323e-04 - val_loss: 1.5937e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.1734e-05 - val_loss: 1.8277e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.3501e-04 - val_loss: 0.0015\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.9330e-05 - val_loss: 1.5988e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.5247e-05 - val_loss: 0.0018\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3321e-05 - val_loss: 8.6557e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0464e-04 - val_loss: 1.7678e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.3807e-05 - val_loss: 3.9789e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3523e-05 - val_loss: 2.8480e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2110e-05 - val_loss: 1.7608e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8820e-05 - val_loss: 8.6644e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9445e-05 - val_loss: 1.7384e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5171e-05 - val_loss: 4.8580e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0888e-05 - val_loss: 1.8411e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.9996e-05 - val_loss: 7.5207e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.8088e-05 - val_loss: 1.4617e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.6907e-05 - val_loss: 5.0668e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5070e-05 - val_loss: 9.8272e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8087e-05 - val_loss: 5.4277e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8892e-05 - val_loss: 1.9698e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.4981e-05 - val_loss: 2.5102e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5774e-05 - val_loss: 2.2809e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0414e-05 - val_loss: 2.8508e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4845e-05 - val_loss: 2.4558e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6946e-05 - val_loss: 1.1147e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6029e-05 - val_loss: 2.0489e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5258e-05 - val_loss: 8.3648e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.4257e-05 - val_loss: 2.9153e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4129e-05 - val_loss: 7.6188e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.8802e-05 - val_loss: 3.3246e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6118e-05 - val_loss: 4.0806e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3462e-05 - val_loss: 6.2311e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5981e-05 - val_loss: 4.3089e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0063e-05 - val_loss: 7.8634e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9981e-05 - val_loss: 8.5498e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4878e-05 - val_loss: 8.3168e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5448e-05 - val_loss: 7.4116e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3210e-05 - val_loss: 2.1408e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5948e-05 - val_loss: 2.0160e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9262e-05 - val_loss: 1.9680e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.7824e-05 - val_loss: 8.0542e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8072e-05 - val_loss: 7.1528e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3270e-05 - val_loss: 8.3079e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4432e-05 - val_loss: 7.1532e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7181e-05 - val_loss: 2.2665e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.6821e-05 - val_loss: 1.7015e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8759e-05 - val_loss: 1.4243e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6768e-05 - val_loss: 3.1145e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5056e-05 - val_loss: 3.5861e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5691e-05 - val_loss: 2.3670e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7521e-05 - val_loss: 4.2594e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9216e-05 - val_loss: 2.1326e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.9427e-05 - val_loss: 0.0015\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.6472e-05 - val_loss: 7.5654e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4217e-05 - val_loss: 8.4368e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7961e-05 - val_loss: 0.0010\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5399e-05 - val_loss: 1.8080e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5299e-05 - val_loss: 4.0943e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2144e-05 - val_loss: 5.3691e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3285e-05 - val_loss: 3.6241e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1850e-05 - val_loss: 1.7613e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9230e-05 - val_loss: 2.5483e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.1436e-06 - val_loss: 1.9880e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.3771e-05 - val_loss: 2.2393e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.9616e-05 - val_loss: 2.3423e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2216e-05 - val_loss: 4.6522e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9376e-05 - val_loss: 8.2688e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.9288e-06 - val_loss: 1.2470e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.0689e-05 - val_loss: 5.5558e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.9328e-05 - val_loss: 2.5056e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.8142e-05 - val_loss: 1.6627e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0555e-05 - val_loss: 1.7338e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.7566e-06 - val_loss: 9.1414e-06\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7795e-05 - val_loss: 0.0011\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7143e-05 - val_loss: 5.1619e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3242e-05 - val_loss: 1.9335e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4250e-05 - val_loss: 2.1970e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1385e-05 - val_loss: 1.2660e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5769e-05 - val_loss: 5.3103e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3606e-05 - val_loss: 5.7482e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4459e-05 - val_loss: 2.8189e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4251e-05 - val_loss: 1.0544e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2519e-05 - val_loss: 2.9407e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0457e-05 - val_loss: 2.9718e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4588e-05 - val_loss: 6.2018e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.9945e-05 - val_loss: 2.0243e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7431e-05 - val_loss: 1.5461e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6599e-05 - val_loss: 4.9598e-04\n",
      ">Neurons=128, Score=0.02731270797085017\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 22ms/step - loss: 0.0018 - val_loss: 0.0092\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.3843e-04 - val_loss: 0.0053\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.8117e-04 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4976e-04 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6703e-04 - val_loss: 1.6396e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0204e-04 - val_loss: 1.9759e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.5397e-05 - val_loss: 2.7713e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1078e-04 - val_loss: 4.1711e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8622e-05 - val_loss: 5.2133e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2512e-04 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0117e-04 - val_loss: 1.2021e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.8843e-05 - val_loss: 5.3156e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.2780e-05 - val_loss: 1.7621e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0253e-05 - val_loss: 1.0627e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.6116e-05 - val_loss: 1.8771e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5024e-05 - val_loss: 1.5802e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7221e-05 - val_loss: 1.8012e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8522e-05 - val_loss: 3.6799e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3538e-05 - val_loss: 4.8094e-05\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5553e-05 - val_loss: 4.7316e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6981e-05 - val_loss: 5.4134e-05\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0227e-05 - val_loss: 1.3290e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7957e-05 - val_loss: 4.6048e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0735e-05 - val_loss: 5.9640e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4236e-05 - val_loss: 9.0003e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9002e-05 - val_loss: 2.6696e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3350e-05 - val_loss: 1.4400e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.7411e-05 - val_loss: 6.9748e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4974e-05 - val_loss: 1.0195e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.0772e-05 - val_loss: 2.6804e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8426e-05 - val_loss: 8.3728e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.4496e-05 - val_loss: 1.6618e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8093e-05 - val_loss: 4.2469e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8883e-05 - val_loss: 3.4007e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8076e-05 - val_loss: 3.1439e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.4059e-05 - val_loss: 9.6289e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.3966e-05 - val_loss: 6.8989e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.1701e-05 - val_loss: 3.8363e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.7559e-05 - val_loss: 8.2182e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.5278e-05 - val_loss: 1.9678e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.7366e-05 - val_loss: 1.0345e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0033e-05 - val_loss: 2.2573e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3199e-05 - val_loss: 1.8627e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1529e-05 - val_loss: 1.4239e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7571e-05 - val_loss: 9.5659e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3816e-05 - val_loss: 6.0822e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3106e-05 - val_loss: 1.5593e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 3.5737e-05 - val_loss: 3.0446e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9742e-05 - val_loss: 6.2291e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.5296e-05 - val_loss: 4.0030e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2907e-05 - val_loss: 1.1861e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8411e-05 - val_loss: 3.9501e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2403e-05 - val_loss: 3.3078e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9890e-05 - val_loss: 1.4625e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5361e-05 - val_loss: 1.9933e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0842e-05 - val_loss: 1.0912e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6828e-05 - val_loss: 4.1411e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.3254e-05 - val_loss: 1.1308e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3351e-05 - val_loss: 1.2326e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2181e-05 - val_loss: 4.9774e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8136e-05 - val_loss: 2.1859e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7126e-05 - val_loss: 2.2721e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1327e-05 - val_loss: 2.5216e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1159e-05 - val_loss: 2.9054e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9885e-05 - val_loss: 4.7426e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7116e-05 - val_loss: 2.0340e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1359e-05 - val_loss: 7.3723e-06\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7815e-05 - val_loss: 2.2638e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6871e-05 - val_loss: 3.5010e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1757e-05 - val_loss: 3.5093e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.3122e-05 - val_loss: 2.2455e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7225e-05 - val_loss: 4.3212e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1514e-05 - val_loss: 2.0995e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5262e-05 - val_loss: 7.7059e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8664e-05 - val_loss: 8.1176e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5581e-05 - val_loss: 4.8594e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5756e-05 - val_loss: 8.2487e-06\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.7503e-06 - val_loss: 4.4276e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3844e-05 - val_loss: 7.7170e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5500e-05 - val_loss: 1.0771e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3249e-05 - val_loss: 3.1226e-06\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5180e-05 - val_loss: 4.4833e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1605e-05 - val_loss: 3.4819e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2620e-05 - val_loss: 5.9198e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.8703e-05 - val_loss: 5.5972e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1851e-05 - val_loss: 8.7368e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5304e-05 - val_loss: 1.0755e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3488e-05 - val_loss: 1.0714e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2905e-05 - val_loss: 2.0113e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5418e-05 - val_loss: 2.8152e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7052e-05 - val_loss: 4.3087e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1010e-05 - val_loss: 1.6280e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0476e-06 - val_loss: 3.5904e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3184e-05 - val_loss: 2.5883e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9060e-05 - val_loss: 3.6007e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7412e-06 - val_loss: 2.9578e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8449e-05 - val_loss: 4.8344e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4156e-05 - val_loss: 2.8203e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2456e-05 - val_loss: 3.9672e-06\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.9828e-06 - val_loss: 4.4661e-05\n",
      ">Neurons=128, Score=0.0044068419811083\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 19ms/step - loss: 0.0019 - val_loss: 0.0094\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.0994e-04 - val_loss: 0.0051\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3788e-04 - val_loss: 0.0028\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9074e-04 - val_loss: 5.4294e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5542e-04 - val_loss: 2.9596e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0745e-04 - val_loss: 2.7262e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0410e-04 - val_loss: 1.0319e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7476e-05 - val_loss: 1.1710e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 7.0498e-05 - val_loss: 3.2970e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 9.6234e-05 - val_loss: 6.3898e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 9.8138e-05 - val_loss: 1.3389e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 1.0754e-04 - val_loss: 2.5174e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 8.3008e-05 - val_loss: 2.3530e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 6.8717e-05 - val_loss: 1.6648e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.5282e-05 - val_loss: 3.1299e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 6.4249e-05 - val_loss: 2.3272e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 6.5143e-05 - val_loss: 9.0597e-05\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 3.3347e-05 - val_loss: 8.4099e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 2.8308e-05 - val_loss: 7.0874e-05\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 4.1219e-05 - val_loss: 2.6400e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 4.0553e-05 - val_loss: 8.6018e-05\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 6.9318e-05 - val_loss: 1.6685e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 7.7643e-05 - val_loss: 6.5970e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 4.1600e-05 - val_loss: 3.0945e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 2.2367e-05 - val_loss: 1.9358e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 3.2743e-05 - val_loss: 3.8840e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.4178e-04 - val_loss: 0.0029\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.1719e-04 - val_loss: 6.9134e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 3.6246e-05 - val_loss: 4.7935e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 3.5778e-05 - val_loss: 2.4010e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.9269e-05 - val_loss: 2.9313e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.6617e-05 - val_loss: 1.1127e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 4.1925e-05 - val_loss: 1.4405e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 3s 19ms/step - loss: 2.9040e-05 - val_loss: 3.9547e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 3s 19ms/step - loss: 3.4720e-05 - val_loss: 6.7746e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.6391e-05 - val_loss: 5.8252e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 4.1335e-05 - val_loss: 1.0538e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 3.8477e-05 - val_loss: 3.9813e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 3.6979e-05 - val_loss: 1.1088e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 2.3103e-05 - val_loss: 2.8390e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 3s 19ms/step - loss: 4.0062e-05 - val_loss: 7.5916e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 3s 19ms/step - loss: 2.3710e-05 - val_loss: 3.2602e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 2.1773e-05 - val_loss: 5.3624e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 3.9313e-05 - val_loss: 1.5737e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.4453e-05 - val_loss: 9.6800e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 8.3382e-05 - val_loss: 5.0760e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 3s 19ms/step - loss: 3.6633e-05 - val_loss: 7.2046e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 2.1561e-05 - val_loss: 2.3948e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.7407e-05 - val_loss: 3.7935e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.8986e-05 - val_loss: 1.1175e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.6038e-05 - val_loss: 4.1195e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.9694e-05 - val_loss: 3.9481e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.6346e-05 - val_loss: 4.0953e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.4929e-05 - val_loss: 1.8418e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8800e-05 - val_loss: 9.2894e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.1572e-05 - val_loss: 1.2403e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6318e-05 - val_loss: 4.3588e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.4384e-05 - val_loss: 2.4828e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6826e-05 - val_loss: 4.1926e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.3903e-05 - val_loss: 3.5566e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.2813e-05 - val_loss: 7.5244e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9215e-05 - val_loss: 6.9971e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.5635e-05 - val_loss: 1.1744e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3498e-05 - val_loss: 1.2042e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2772e-05 - val_loss: 2.5139e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.9089e-05 - val_loss: 1.1761e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.8895e-05 - val_loss: 2.6073e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.6844e-05 - val_loss: 3.8493e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.1273e-05 - val_loss: 8.1236e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3224e-05 - val_loss: 7.3722e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.1122e-05 - val_loss: 8.3793e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1664e-05 - val_loss: 1.0438e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8311e-05 - val_loss: 4.5892e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2417e-05 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4691e-05 - val_loss: 6.6091e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3954e-05 - val_loss: 8.4330e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0001e-05 - val_loss: 2.1395e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4188e-05 - val_loss: 6.0021e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.1862e-06 - val_loss: 4.7340e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8777e-05 - val_loss: 2.9278e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1286e-05 - val_loss: 2.5181e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1087e-05 - val_loss: 2.3023e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 8.8375e-06 - val_loss: 1.9406e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.4438e-05 - val_loss: 1.5827e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.4674e-05 - val_loss: 2.6208e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6562e-05 - val_loss: 4.0013e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8793e-05 - val_loss: 8.7995e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.2286e-05 - val_loss: 4.0530e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3756e-05 - val_loss: 7.5785e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6755e-05 - val_loss: 3.0587e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.6543e-06 - val_loss: 8.7629e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.8998e-06 - val_loss: 2.0886e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3777e-05 - val_loss: 5.1984e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3691e-05 - val_loss: 2.1691e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1090e-05 - val_loss: 1.2119e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2907e-05 - val_loss: 2.6978e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5579e-05 - val_loss: 7.5309e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9783e-05 - val_loss: 1.7327e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1246e-05 - val_loss: 1.7685e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.4295e-06 - val_loss: 1.4960e-04\n",
      ">Neurons=128, Score=0.009978845628211275\n",
      "[[0.008941027044784278, 0.009863782906904817, 0.007041703793220222, 0.007386451761703938, 0.01106775671360083, 0.00969841712503694, 0.009084648627322167, 0.011158112465636805, 0.0036197478038957343, 0.0068809473305009305], [0.00346746455761604, 0.006162785575725138, 0.005760015483247116, 0.004728966086986475, 0.008342442015418783, 0.0009234310709871352, 0.004749104482471012, 0.01615096116438508, 0.06283638649620116, 0.0013081552424409892], [0.001824403807404451, 0.00537899395567365, 0.006556422886205837, 0.00231082558457274, 0.012302608229219913, 0.006695355841657147, 0.0033109412470366806, 0.02731270797085017, 0.0044068419811083, 0.009978845628211275]] [32, 64, 128]\n",
      "Param=32, Mean=0.008:, Std=0.002\n",
      "Param=64, Mean=0.011:, Std=0.018\n",
      "Param=128, Mean=0.008:, Std=0.007\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, neurons):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=4, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=4)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # resumindo a média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = mean(scores[i]), std(scores[i])\n",
    "        print(f'Param={params[i]}, Mean={m:.3f}:, Std={s:.3f}')\n",
    "    # boxplot das pontuações\n",
    "    pyplot.boxplot(scores, labels=params)\n",
    "    pyplot.savefig('figura[0].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repetindo o experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            score = score * 100.0\n",
    "            scores.append(score)\n",
    "            print(f'>Neurons={p}, Score={score}')\n",
    "        all_scores.append(scores)\n",
    "    # resumindo os resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = [32, 64, 128]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 18ms/step - loss: 0.0023 - val_loss: 0.0102\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.2152e-04 - val_loss: 0.0070\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.8377e-04 - val_loss: 0.0039\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1651e-04 - val_loss: 0.0019\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4782e-04 - val_loss: 6.2070e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0936e-04 - val_loss: 0.0010\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8343e-04 - val_loss: 6.7592e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2334e-04 - val_loss: 4.0369e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2081e-04 - val_loss: 1.5819e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.7519e-05 - val_loss: 8.4710e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.6247e-05 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.0383e-05 - val_loss: 0.0025\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.7217e-05 - val_loss: 7.7938e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0526e-04 - val_loss: 2.2633e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.8757e-05 - val_loss: 6.7173e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1077e-04 - val_loss: 4.7699e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.2274e-05 - val_loss: 1.3025e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.4786e-05 - val_loss: 7.7997e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8693e-05 - val_loss: 2.2528e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3557e-05 - val_loss: 8.3094e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9625e-05 - val_loss: 8.7500e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0158e-04 - val_loss: 7.6444e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0062e-04 - val_loss: 3.2770e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.0830e-05 - val_loss: 7.0704e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0915e-05 - val_loss: 2.3692e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.8055e-05 - val_loss: 7.8742e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5143e-05 - val_loss: 1.7812e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.8600e-05 - val_loss: 5.7293e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.7348e-05 - val_loss: 2.8800e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.8550e-05 - val_loss: 6.9986e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2272e-05 - val_loss: 5.0404e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8613e-05 - val_loss: 3.6173e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4784e-05 - val_loss: 9.0190e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3974e-05 - val_loss: 4.2384e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0757e-05 - val_loss: 2.1521e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8379e-05 - val_loss: 7.9852e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7811e-05 - val_loss: 2.8326e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.6344e-05 - val_loss: 4.5380e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0270e-05 - val_loss: 1.3089e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.7427e-05 - val_loss: 6.0914e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.8144e-05 - val_loss: 4.0651e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3819e-05 - val_loss: 6.7782e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.4243e-05 - val_loss: 5.6549e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.6056e-05 - val_loss: 3.8350e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5170e-05 - val_loss: 1.5533e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5495e-05 - val_loss: 9.5910e-06\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.9763e-05 - val_loss: 1.9278e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1558e-05 - val_loss: 2.5980e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2260e-05 - val_loss: 4.1530e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6980e-05 - val_loss: 1.8899e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1817e-05 - val_loss: 2.2175e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7669e-05 - val_loss: 1.1323e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3759e-05 - val_loss: 1.9440e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4558e-05 - val_loss: 3.8326e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5293e-05 - val_loss: 4.8142e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9412e-05 - val_loss: 1.9540e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0477e-05 - val_loss: 2.9154e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1981e-05 - val_loss: 8.1258e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0080e-05 - val_loss: 4.7142e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.9475e-05 - val_loss: 7.1358e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5422e-05 - val_loss: 1.6560e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7842e-05 - val_loss: 6.4491e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.5040e-05 - val_loss: 4.9189e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0869e-05 - val_loss: 2.3525e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4482e-05 - val_loss: 2.1356e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3185e-05 - val_loss: 7.1684e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3333e-05 - val_loss: 8.3245e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1533e-05 - val_loss: 4.4274e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1606e-05 - val_loss: 4.0252e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2327e-05 - val_loss: 1.8602e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.7943e-05 - val_loss: 1.6091e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1055e-05 - val_loss: 1.4151e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2077e-05 - val_loss: 7.4216e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0593e-05 - val_loss: 7.1857e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.6450e-05 - val_loss: 2.2310e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0937e-05 - val_loss: 1.5891e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3514e-05 - val_loss: 1.8195e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.8315e-05 - val_loss: 2.1236e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.6708e-05 - val_loss: 4.7112e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1950e-05 - val_loss: 1.0707e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6067e-05 - val_loss: 3.5828e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5332e-05 - val_loss: 1.7903e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6658e-05 - val_loss: 3.3332e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.1261e-06 - val_loss: 2.4313e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9488e-05 - val_loss: 1.5208e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4522e-05 - val_loss: 1.4047e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1829e-05 - val_loss: 1.5983e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1665e-05 - val_loss: 3.6849e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4899e-05 - val_loss: 3.3322e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.7128e-05 - val_loss: 2.0205e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.8918e-06 - val_loss: 1.3339e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7576e-05 - val_loss: 0.0010\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0913e-05 - val_loss: 1.8332e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7813e-05 - val_loss: 1.2361e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5834e-05 - val_loss: 8.7766e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7402e-05 - val_loss: 1.1431e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1610e-05 - val_loss: 7.6574e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7750e-05 - val_loss: 1.0043e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4370e-05 - val_loss: 3.7507e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4679e-05 - val_loss: 3.3034e-05\n",
      ">Neurons=60, Score=0.0016434552890132181\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 19ms/step - loss: 0.0021 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.6948e-04 - val_loss: 0.0077\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.0864e-04 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1762e-04 - val_loss: 0.0025\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6731e-04 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7406e-04 - val_loss: 2.8172e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2371e-04 - val_loss: 2.6806e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.6975e-05 - val_loss: 0.0017\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3211e-04 - val_loss: 2.7678e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2379e-04 - val_loss: 4.1211e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0583e-04 - val_loss: 3.4194e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.4273e-05 - val_loss: 8.5422e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.9384e-05 - val_loss: 0.0014\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.7548e-05 - val_loss: 2.6965e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.3599e-05 - val_loss: 6.6573e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8634e-05 - val_loss: 1.8789e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.0858e-05 - val_loss: 2.5222e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.6730e-05 - val_loss: 0.0012\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.0375e-05 - val_loss: 2.9160e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1146e-04 - val_loss: 2.3580e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.6412e-05 - val_loss: 4.7000e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.2938e-05 - val_loss: 2.0941e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.3459e-05 - val_loss: 1.0128e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.5300e-05 - val_loss: 4.6720e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5917e-05 - val_loss: 2.9765e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3534e-05 - val_loss: 3.5328e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.3362e-05 - val_loss: 3.0850e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.7866e-05 - val_loss: 5.1649e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.3987e-05 - val_loss: 8.6668e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9817e-05 - val_loss: 2.9245e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8021e-05 - val_loss: 2.0655e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.2456e-05 - val_loss: 5.1407e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9622e-05 - val_loss: 5.6697e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2470e-05 - val_loss: 3.7389e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7219e-05 - val_loss: 1.5967e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8273e-05 - val_loss: 5.1620e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1689e-05 - val_loss: 1.0479e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6017e-05 - val_loss: 1.8786e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2280e-05 - val_loss: 1.6197e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8821e-05 - val_loss: 2.3124e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1593e-05 - val_loss: 1.6516e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4644e-05 - val_loss: 5.7523e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9176e-05 - val_loss: 1.0163e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.7327e-05 - val_loss: 0.0012\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3892e-05 - val_loss: 6.3696e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1228e-05 - val_loss: 2.2591e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5435e-05 - val_loss: 6.0972e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9575e-05 - val_loss: 9.5182e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9214e-05 - val_loss: 1.6203e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0591e-05 - val_loss: 2.5203e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8806e-05 - val_loss: 1.4340e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7075e-05 - val_loss: 2.1140e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5965e-05 - val_loss: 2.2070e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3500e-05 - val_loss: 1.7662e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7224e-05 - val_loss: 6.9954e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5503e-05 - val_loss: 2.3337e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6562e-05 - val_loss: 7.0808e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9111e-05 - val_loss: 2.6349e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.8572e-05 - val_loss: 2.8673e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9704e-05 - val_loss: 3.1785e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7542e-05 - val_loss: 1.6455e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4191e-05 - val_loss: 3.6046e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9701e-05 - val_loss: 4.8547e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.9186e-05 - val_loss: 5.5300e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8331e-05 - val_loss: 3.8798e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0898e-05 - val_loss: 5.4443e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9264e-05 - val_loss: 4.7636e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1967e-05 - val_loss: 1.5344e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0249e-06 - val_loss: 1.9624e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1295e-05 - val_loss: 3.8655e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6972e-05 - val_loss: 3.3981e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6032e-05 - val_loss: 2.0206e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6381e-05 - val_loss: 9.8442e-06\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8308e-05 - val_loss: 6.4656e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7908e-05 - val_loss: 1.9637e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7085e-05 - val_loss: 4.4418e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1280e-05 - val_loss: 2.6664e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5230e-05 - val_loss: 8.2246e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8297e-05 - val_loss: 4.9524e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5267e-05 - val_loss: 4.0339e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9018e-05 - val_loss: 1.0198e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3417e-05 - val_loss: 4.5454e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0036e-05 - val_loss: 5.2039e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3589e-05 - val_loss: 2.3910e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3192e-05 - val_loss: 1.0098e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7694e-05 - val_loss: 3.2737e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6596e-05 - val_loss: 3.6050e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0375e-05 - val_loss: 4.0476e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2929e-05 - val_loss: 1.4876e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7940e-05 - val_loss: 4.4760e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3446e-05 - val_loss: 7.1172e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0010e-05 - val_loss: 5.0134e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.8909e-05 - val_loss: 1.8060e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7948e-05 - val_loss: 3.3328e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1003e-05 - val_loss: 9.8904e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1904e-05 - val_loss: 3.7265e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4220e-05 - val_loss: 1.7935e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6245e-05 - val_loss: 1.6805e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.9211e-06 - val_loss: 8.0152e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2890e-05 - val_loss: 4.7505e-04\n",
      ">Neurons=60, Score=0.02418830554233864\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 17ms/step - loss: 0.0022 - val_loss: 0.0101\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.6273e-04 - val_loss: 0.0074\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.1916e-04 - val_loss: 0.0043\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5802e-04 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9018e-04 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2171e-04 - val_loss: 8.0330e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1310e-04 - val_loss: 7.2441e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3213e-04 - val_loss: 7.4616e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.0070e-05 - val_loss: 5.3622e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1010e-04 - val_loss: 0.0026\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.5183e-04 - val_loss: 2.4921e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2229e-04 - val_loss: 1.7440e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.3253e-05 - val_loss: 1.4320e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.5030e-05 - val_loss: 6.6210e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.9392e-05 - val_loss: 0.0014\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.7480e-05 - val_loss: 3.5433e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.7511e-05 - val_loss: 2.7836e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8472e-05 - val_loss: 2.0262e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.9715e-05 - val_loss: 3.6656e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.1077e-05 - val_loss: 1.6230e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.0760e-05 - val_loss: 3.3295e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.4811e-05 - val_loss: 6.9457e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6063e-05 - val_loss: 2.4007e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2629e-05 - val_loss: 1.0480e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0273e-05 - val_loss: 6.0672e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.5209e-05 - val_loss: 1.7653e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6417e-05 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.3448e-05 - val_loss: 3.1048e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.5925e-05 - val_loss: 4.2604e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4575e-05 - val_loss: 1.0739e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8157e-05 - val_loss: 2.3374e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.9951e-05 - val_loss: 8.6537e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.0260e-05 - val_loss: 3.0695e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1680e-05 - val_loss: 2.8812e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3072e-05 - val_loss: 7.0133e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.0509e-05 - val_loss: 6.1929e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7220e-05 - val_loss: 1.4200e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.5222e-05 - val_loss: 3.7387e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6741e-05 - val_loss: 3.6380e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7415e-05 - val_loss: 1.2907e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.5166e-05 - val_loss: 0.0010\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3313e-05 - val_loss: 5.3965e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7008e-05 - val_loss: 1.3621e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4579e-05 - val_loss: 1.5489e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6977e-05 - val_loss: 5.5392e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2304e-05 - val_loss: 6.5922e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1549e-05 - val_loss: 2.4327e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4099e-05 - val_loss: 6.8587e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0650e-05 - val_loss: 1.3787e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6113e-05 - val_loss: 1.7450e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.0414e-05 - val_loss: 7.5816e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3300e-05 - val_loss: 7.4013e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2948e-05 - val_loss: 1.7916e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4557e-05 - val_loss: 7.2454e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6344e-05 - val_loss: 8.0851e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0280e-05 - val_loss: 4.0886e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3204e-05 - val_loss: 1.0502e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1667e-05 - val_loss: 1.1832e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.0782e-05 - val_loss: 2.6081e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2149e-05 - val_loss: 1.9845e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6215e-05 - val_loss: 8.2294e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3221e-05 - val_loss: 5.7942e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7236e-05 - val_loss: 1.7208e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5615e-05 - val_loss: 3.4391e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8667e-05 - val_loss: 1.2258e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0695e-05 - val_loss: 3.0777e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3029e-05 - val_loss: 2.6390e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5644e-05 - val_loss: 1.7800e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6323e-05 - val_loss: 6.5720e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9467e-05 - val_loss: 1.6937e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4704e-05 - val_loss: 4.3196e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5490e-05 - val_loss: 8.8350e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.0103e-05 - val_loss: 6.1940e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6972e-05 - val_loss: 2.4672e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8246e-05 - val_loss: 2.9355e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2078e-05 - val_loss: 6.0622e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7939e-05 - val_loss: 2.4043e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0981e-05 - val_loss: 5.5904e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2161e-05 - val_loss: 4.8557e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5212e-05 - val_loss: 1.1982e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7944e-05 - val_loss: 6.0194e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7874e-05 - val_loss: 1.5408e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3147e-05 - val_loss: 2.5610e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2775e-05 - val_loss: 8.0151e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7912e-05 - val_loss: 3.2909e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9806e-05 - val_loss: 2.1540e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4986e-05 - val_loss: 0.0011\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5405e-05 - val_loss: 1.2359e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9469e-05 - val_loss: 1.5643e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2755e-05 - val_loss: 9.6074e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3891e-05 - val_loss: 2.5216e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0621e-05 - val_loss: 2.8538e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3269e-05 - val_loss: 3.2519e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8778e-05 - val_loss: 1.4535e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0324e-05 - val_loss: 3.7257e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5068e-05 - val_loss: 3.5657e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.2633e-06 - val_loss: 2.2482e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.1011e-05 - val_loss: 4.5119e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0680e-05 - val_loss: 2.5854e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0112e-05 - val_loss: 1.5282e-05\n",
      ">Neurons=60, Score=0.0012721907296509016\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 20ms/step - loss: 0.0024 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.8286e-04 - val_loss: 0.0079\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.2156e-04 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.1749e-04 - val_loss: 0.0030\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6559e-04 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0907e-04 - val_loss: 6.3505e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4819e-04 - val_loss: 0.0014\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0476e-04 - val_loss: 0.0016\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3376e-04 - val_loss: 2.1372e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2422e-04 - val_loss: 1.6828e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.4947e-05 - val_loss: 2.3053e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.5398e-05 - val_loss: 2.8673e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.9228e-05 - val_loss: 2.7443e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.6421e-05 - val_loss: 0.0015\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.8274e-05 - val_loss: 1.6774e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.1341e-05 - val_loss: 2.2806e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.3648e-05 - val_loss: 1.3131e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.7263e-05 - val_loss: 2.4240e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.7414e-05 - val_loss: 4.0468e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.5000e-05 - val_loss: 9.2803e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8435e-05 - val_loss: 7.8229e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3598e-05 - val_loss: 6.2319e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0194e-05 - val_loss: 3.1504e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5164e-04 - val_loss: 0.0016\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6187e-04 - val_loss: 2.9086e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3770e-05 - val_loss: 2.1275e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7400e-05 - val_loss: 4.4556e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.4941e-05 - val_loss: 8.9169e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.9026e-05 - val_loss: 5.2394e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.3241e-05 - val_loss: 2.5446e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.7201e-05 - val_loss: 1.0654e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3649e-05 - val_loss: 3.1133e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5568e-05 - val_loss: 6.7978e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9641e-05 - val_loss: 5.4729e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4773e-05 - val_loss: 4.0537e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8513e-05 - val_loss: 1.7329e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.4669e-05 - val_loss: 5.8126e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6785e-05 - val_loss: 6.6221e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5541e-05 - val_loss: 4.3088e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7092e-05 - val_loss: 9.6659e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3773e-05 - val_loss: 5.1941e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4861e-05 - val_loss: 9.8699e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9588e-05 - val_loss: 7.2874e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.6013e-05 - val_loss: 1.3465e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.9115e-05 - val_loss: 5.7420e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.8510e-05 - val_loss: 7.6547e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2764e-05 - val_loss: 5.9692e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8107e-05 - val_loss: 1.2408e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7319e-05 - val_loss: 4.8148e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8723e-05 - val_loss: 2.5283e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2430e-05 - val_loss: 6.9783e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0220e-05 - val_loss: 6.0064e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7233e-05 - val_loss: 1.4142e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4771e-05 - val_loss: 1.0768e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9892e-05 - val_loss: 1.1337e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5058e-05 - val_loss: 2.8688e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4637e-05 - val_loss: 1.5192e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1890e-05 - val_loss: 4.8187e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8655e-05 - val_loss: 9.2245e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9363e-05 - val_loss: 6.2400e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3987e-05 - val_loss: 9.8359e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3050e-05 - val_loss: 4.4856e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7070e-05 - val_loss: 6.5582e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4289e-05 - val_loss: 3.0630e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.8298e-05 - val_loss: 3.4352e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4465e-05 - val_loss: 1.5612e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2733e-05 - val_loss: 3.4666e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1521e-05 - val_loss: 4.6071e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5185e-05 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2926e-05 - val_loss: 3.3379e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.8332e-05 - val_loss: 0.0015\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6717e-05 - val_loss: 8.6788e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8360e-05 - val_loss: 6.7737e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0326e-05 - val_loss: 6.2218e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5225e-05 - val_loss: 5.4057e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.2434e-05 - val_loss: 3.5331e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 1.4821e-05 - val_loss: 6.2316e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0205e-05 - val_loss: 1.1211e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.5105e-05 - val_loss: 6.4389e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9796e-05 - val_loss: 9.2151e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3372e-05 - val_loss: 7.2433e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7658e-05 - val_loss: 6.3165e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7552e-05 - val_loss: 1.8954e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0994e-05 - val_loss: 1.2955e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1749e-05 - val_loss: 1.0840e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7143e-05 - val_loss: 8.6928e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7558e-05 - val_loss: 2.0057e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3089e-05 - val_loss: 3.6931e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1759e-05 - val_loss: 1.7646e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3242e-05 - val_loss: 1.3616e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0598e-05 - val_loss: 6.2984e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6957e-05 - val_loss: 9.5210e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4786e-05 - val_loss: 1.1975e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5603e-05 - val_loss: 2.9409e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3451e-05 - val_loss: 1.5496e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7525e-05 - val_loss: 1.5612e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3504e-05 - val_loss: 4.0553e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6317e-05 - val_loss: 3.7158e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.0525e-05 - val_loss: 6.6335e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.8529e-06 - val_loss: 7.9291e-05\n",
      ">Neurons=60, Score=0.005631269596051425\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 21ms/step - loss: 0.0022 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 9.8431e-04 - val_loss: 0.0081\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.1989e-04 - val_loss: 0.0051\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.3318e-04 - val_loss: 0.0026\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0010e-04 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.8184e-04 - val_loss: 6.8990e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2748e-04 - val_loss: 3.7667e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1414e-04 - val_loss: 6.3803e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.7878e-05 - val_loss: 1.6376e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.8990e-05 - val_loss: 6.3625e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1053e-04 - val_loss: 0.0015\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8.2200e-05 - val_loss: 1.9554e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0545e-04 - val_loss: 2.6582e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.5712e-05 - val_loss: 3.3696e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.9411e-05 - val_loss: 2.5124e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.5729e-05 - val_loss: 1.9565e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.8012e-05 - val_loss: 4.2190e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5112e-05 - val_loss: 4.0814e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.2193e-05 - val_loss: 1.4573e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.9355e-05 - val_loss: 3.9990e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0192e-04 - val_loss: 2.4574e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.7113e-05 - val_loss: 3.8351e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4903e-05 - val_loss: 4.8301e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3540e-05 - val_loss: 2.8130e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.2898e-05 - val_loss: 1.8098e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.1557e-05 - val_loss: 2.4979e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9169e-05 - val_loss: 1.0649e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7524e-05 - val_loss: 3.8034e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4164e-05 - val_loss: 3.7477e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4994e-05 - val_loss: 3.4862e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6490e-05 - val_loss: 3.7804e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3105e-05 - val_loss: 3.9409e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2264e-05 - val_loss: 1.5979e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.4038e-05 - val_loss: 4.9692e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2539e-04 - val_loss: 6.5681e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1857e-05 - val_loss: 1.3607e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2901e-05 - val_loss: 5.7523e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8562e-05 - val_loss: 3.3552e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0277e-04 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.8370e-05 - val_loss: 3.0648e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7968e-05 - val_loss: 6.6146e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.5660e-05 - val_loss: 1.9443e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1206e-05 - val_loss: 1.8272e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7073e-05 - val_loss: 2.3993e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1069e-05 - val_loss: 1.1263e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8601e-05 - val_loss: 2.9367e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3643e-05 - val_loss: 8.7816e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2521e-05 - val_loss: 2.4238e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3647e-05 - val_loss: 2.8546e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4353e-05 - val_loss: 3.2749e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.6394e-05 - val_loss: 0.0018\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.7598e-05 - val_loss: 1.8289e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3128e-05 - val_loss: 9.5952e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2340e-05 - val_loss: 2.0967e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2653e-05 - val_loss: 2.9221e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3035e-05 - val_loss: 4.5830e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3315e-05 - val_loss: 2.0327e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8762e-05 - val_loss: 1.7377e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4116e-05 - val_loss: 3.0621e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.9669e-05 - val_loss: 1.6265e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9968e-05 - val_loss: 1.2983e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4375e-05 - val_loss: 0.0011\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4824e-05 - val_loss: 7.3699e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6194e-05 - val_loss: 1.1278e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1978e-05 - val_loss: 4.3522e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6645e-05 - val_loss: 1.4589e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1132e-05 - val_loss: 4.0473e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6743e-05 - val_loss: 1.6956e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3774e-05 - val_loss: 5.2248e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7393e-05 - val_loss: 7.5058e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0857e-05 - val_loss: 2.4402e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4503e-05 - val_loss: 5.7590e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2897e-05 - val_loss: 8.0051e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4574e-05 - val_loss: 1.0229e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5561e-05 - val_loss: 3.8221e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6265e-05 - val_loss: 4.3097e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3902e-05 - val_loss: 2.7541e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.7384e-05 - val_loss: 2.0286e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.2797e-05 - val_loss: 1.6854e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5189e-05 - val_loss: 4.6133e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7037e-05 - val_loss: 1.9690e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.7378e-05 - val_loss: 4.6213e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5754e-05 - val_loss: 2.1544e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3348e-05 - val_loss: 6.8760e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.5333e-05 - val_loss: 1.8159e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.5121e-05 - val_loss: 2.1839e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5785e-05 - val_loss: 4.5431e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0061e-05 - val_loss: 4.1779e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2042e-05 - val_loss: 1.3066e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0342e-05 - val_loss: 1.0146e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6327e-05 - val_loss: 6.7093e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1773e-05 - val_loss: 4.9082e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6365e-05 - val_loss: 3.3920e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3764e-05 - val_loss: 7.4743e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.3657e-05 - val_loss: 6.1114e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2384e-05 - val_loss: 8.7597e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4332e-05 - val_loss: 2.2976e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8626e-05 - val_loss: 1.5898e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2400e-05 - val_loss: 2.8712e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0996e-05 - val_loss: 9.5321e-06\n",
      ">Neurons=60, Score=0.0008353753401024733\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 22ms/step - loss: 0.0024 - val_loss: 0.0102\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.8522e-04 - val_loss: 0.0076\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 7.6757e-04 - val_loss: 0.0046\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0719e-04 - val_loss: 0.0021\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8777e-04 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0809e-04 - val_loss: 5.3509e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0503e-04 - val_loss: 1.9074e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1261e-04 - val_loss: 2.6555e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1269e-05 - val_loss: 0.0015\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.6191e-05 - val_loss: 2.6244e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.1590e-05 - val_loss: 8.1774e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.3341e-05 - val_loss: 2.0165e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.9495e-05 - val_loss: 2.5062e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.9402e-05 - val_loss: 1.9069e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2353e-04 - val_loss: 8.5539e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.4709e-05 - val_loss: 2.5516e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3281e-04 - val_loss: 0.0010\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0424e-04 - val_loss: 5.0279e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.9676e-05 - val_loss: 2.5489e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0619e-05 - val_loss: 1.3906e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.9364e-05 - val_loss: 3.8612e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.4443e-05 - val_loss: 4.7450e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.0850e-05 - val_loss: 3.4280e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0127e-04 - val_loss: 2.8741e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.9637e-05 - val_loss: 1.8258e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4506e-05 - val_loss: 7.7410e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.1458e-05 - val_loss: 3.3192e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8913e-05 - val_loss: 9.9764e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0212e-05 - val_loss: 4.4914e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0086e-05 - val_loss: 6.6040e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.9760e-05 - val_loss: 4.1430e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.8310e-05 - val_loss: 1.5275e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6931e-05 - val_loss: 1.8719e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.9046e-05 - val_loss: 4.2594e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5095e-05 - val_loss: 9.5781e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5781e-05 - val_loss: 3.0586e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8022e-05 - val_loss: 7.8808e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0540e-04 - val_loss: 6.7166e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 7.5621e-05 - val_loss: 5.4573e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.2301e-05 - val_loss: 4.2909e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.8993e-05 - val_loss: 0.0013\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.5088e-05 - val_loss: 4.9039e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4594e-05 - val_loss: 8.5936e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7150e-05 - val_loss: 3.8790e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8282e-05 - val_loss: 1.0754e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7998e-05 - val_loss: 2.8677e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.5716e-05 - val_loss: 4.5553e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0333e-05 - val_loss: 1.9005e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6560e-05 - val_loss: 3.1783e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0819e-05 - val_loss: 4.1170e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2167e-05 - val_loss: 7.6600e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1365e-05 - val_loss: 2.7769e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3438e-05 - val_loss: 6.8653e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.9431e-05 - val_loss: 1.3584e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.6535e-05 - val_loss: 1.8082e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0018e-05 - val_loss: 3.4113e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1645e-05 - val_loss: 1.7780e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8203e-05 - val_loss: 1.6701e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4179e-05 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.1388e-05 - val_loss: 5.7152e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3385e-05 - val_loss: 5.3717e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.2003e-05 - val_loss: 6.4359e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8202e-05 - val_loss: 1.1976e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4237e-05 - val_loss: 5.9867e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2256e-05 - val_loss: 6.9610e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.1974e-05 - val_loss: 5.5958e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8258e-05 - val_loss: 2.5097e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5428e-05 - val_loss: 6.8235e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.0838e-05 - val_loss: 2.7602e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9116e-05 - val_loss: 5.9198e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.6036e-05 - val_loss: 9.7067e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0415e-05 - val_loss: 1.1293e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.8697e-05 - val_loss: 1.1844e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.7959e-05 - val_loss: 4.9686e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5604e-05 - val_loss: 4.0728e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5020e-05 - val_loss: 1.7136e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.1069e-05 - val_loss: 5.4428e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.4886e-05 - val_loss: 2.4992e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6117e-05 - val_loss: 4.1759e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5184e-05 - val_loss: 9.1122e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3115e-05 - val_loss: 4.0048e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.2451e-05 - val_loss: 4.0463e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1076e-05 - val_loss: 1.5789e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2549e-05 - val_loss: 3.4159e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.2948e-05 - val_loss: 0.0010\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4447e-05 - val_loss: 1.1016e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8115e-05 - val_loss: 2.4370e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8501e-05 - val_loss: 3.2144e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4714e-05 - val_loss: 5.1905e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3536e-05 - val_loss: 2.9882e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8768e-05 - val_loss: 2.3954e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.3854e-06 - val_loss: 4.7863e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3505e-05 - val_loss: 5.6493e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4185e-05 - val_loss: 5.8728e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5263e-05 - val_loss: 2.0931e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5914e-05 - val_loss: 3.5849e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3448e-05 - val_loss: 4.0245e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8904e-05 - val_loss: 1.4502e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4533e-05 - val_loss: 1.7044e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4024e-05 - val_loss: 7.5772e-05\n",
      ">Neurons=60, Score=0.0037501198676181957\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 16ms/step - loss: 0.0023 - val_loss: 0.0108\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0080\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.1303e-04 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.7025e-04 - val_loss: 0.0027\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3219e-04 - val_loss: 0.0015\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1363e-04 - val_loss: 4.6225e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5933e-04 - val_loss: 2.3728e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3259e-04 - val_loss: 2.7039e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0119e-04 - val_loss: 1.8860e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2138e-04 - val_loss: 4.2099e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.0606e-05 - val_loss: 2.7229e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.1567e-05 - val_loss: 2.0348e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.4592e-05 - val_loss: 6.5960e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.7213e-05 - val_loss: 0.0023\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.1807e-04 - val_loss: 0.0014\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.0488e-05 - val_loss: 3.3507e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2667e-05 - val_loss: 0.0013\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.2338e-05 - val_loss: 1.5612e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.6382e-05 - val_loss: 3.1789e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.5137e-05 - val_loss: 2.1991e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.7104e-05 - val_loss: 7.5565e-05\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.7014e-05 - val_loss: 2.3875e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.6334e-05 - val_loss: 1.5890e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.9155e-05 - val_loss: 2.4711e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.7641e-05 - val_loss: 2.9334e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.6644e-05 - val_loss: 5.0367e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3705e-05 - val_loss: 1.5023e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5915e-05 - val_loss: 1.1684e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.1538e-05 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.4747e-05 - val_loss: 2.7947e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9776e-05 - val_loss: 1.0544e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.4705e-05 - val_loss: 8.9288e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.6451e-05 - val_loss: 8.3819e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.9202e-05 - val_loss: 6.2153e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8288e-05 - val_loss: 1.0565e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1276e-05 - val_loss: 9.5114e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.0390e-05 - val_loss: 1.4219e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8564e-05 - val_loss: 8.6438e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7259e-05 - val_loss: 6.8140e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.2175e-05 - val_loss: 4.7527e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.3581e-05 - val_loss: 1.0945e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3704e-05 - val_loss: 9.4880e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6764e-05 - val_loss: 6.8561e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9862e-05 - val_loss: 9.5080e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 3.2297e-05 - val_loss: 5.1833e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2369e-05 - val_loss: 1.9225e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.4311e-05 - val_loss: 1.0426e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 3s 19ms/step - loss: 2.1534e-05 - val_loss: 1.6367e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 3s 19ms/step - loss: 6.2373e-05 - val_loss: 1.8141e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 2.7709e-05 - val_loss: 6.5546e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 2.7605e-05 - val_loss: 6.3007e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.2566e-05 - val_loss: 2.3639e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6848e-05 - val_loss: 1.6164e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9426e-05 - val_loss: 4.2635e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.3906e-05 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 4.3985e-05 - val_loss: 5.3524e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4601e-05 - val_loss: 3.1815e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5199e-05 - val_loss: 9.1957e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3859e-05 - val_loss: 3.2480e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6547e-05 - val_loss: 2.9454e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2603e-05 - val_loss: 9.4916e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9305e-05 - val_loss: 2.6812e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0925e-05 - val_loss: 2.1089e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6774e-05 - val_loss: 1.2711e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7567e-05 - val_loss: 1.0256e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2958e-05 - val_loss: 5.3414e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1330e-05 - val_loss: 4.4423e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2252e-05 - val_loss: 2.5836e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5591e-05 - val_loss: 3.4380e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.5968e-05 - val_loss: 5.3321e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 3.6461e-05 - val_loss: 1.3722e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.9841e-05 - val_loss: 1.9220e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 2.4053e-05 - val_loss: 1.1795e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7717e-05 - val_loss: 7.2386e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3118e-05 - val_loss: 2.5960e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3973e-05 - val_loss: 1.7482e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.1476e-05 - val_loss: 5.9274e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9321e-05 - val_loss: 5.8397e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4366e-05 - val_loss: 2.5317e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4329e-05 - val_loss: 2.9073e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7885e-05 - val_loss: 4.6974e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.8342e-05 - val_loss: 4.6739e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3820e-05 - val_loss: 1.9375e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7191e-05 - val_loss: 4.1693e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.1370e-05 - val_loss: 2.9737e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.6806e-05 - val_loss: 3.8502e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4751e-05 - val_loss: 5.0076e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1650e-05 - val_loss: 1.3787e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5783e-05 - val_loss: 4.0293e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5455e-05 - val_loss: 5.1157e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5114e-05 - val_loss: 1.8618e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7878e-05 - val_loss: 3.3632e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1996e-05 - val_loss: 8.0158e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9474e-05 - val_loss: 4.5871e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.1964e-05 - val_loss: 1.6223e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4274e-05 - val_loss: 1.0037e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5528e-05 - val_loss: 2.7645e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4458e-05 - val_loss: 6.3565e-06\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4578e-05 - val_loss: 6.6833e-06\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7202e-05 - val_loss: 1.3375e-04\n",
      ">Neurons=60, Score=0.009562322520650923\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 14s 23ms/step - loss: 0.0024 - val_loss: 0.0109\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 0.0011 - val_loss: 0.0083\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7542e-04 - val_loss: 0.0051\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.3514e-04 - val_loss: 0.0027\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0121e-04 - val_loss: 0.0010\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0046e-04 - val_loss: 4.6593e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8400e-04 - val_loss: 4.5413e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2313e-04 - val_loss: 0.0014\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.6528e-05 - val_loss: 3.1435e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4776e-04 - val_loss: 4.5225e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1813e-04 - val_loss: 6.4900e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1155e-04 - val_loss: 7.4922e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4156e-05 - val_loss: 8.5669e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.7841e-05 - val_loss: 3.7302e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1416e-04 - val_loss: 4.3050e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.7449e-05 - val_loss: 1.8475e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4653e-05 - val_loss: 1.7385e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.1537e-05 - val_loss: 2.3581e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.0505e-05 - val_loss: 4.2346e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8759e-05 - val_loss: 1.5354e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.0149e-05 - val_loss: 1.4341e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.2632e-05 - val_loss: 2.2383e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.2733e-05 - val_loss: 2.1511e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3237e-05 - val_loss: 3.7581e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3509e-05 - val_loss: 4.9808e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4560e-05 - val_loss: 1.0027e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.1656e-05 - val_loss: 2.4644e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0976e-05 - val_loss: 2.4094e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3297e-05 - val_loss: 2.3540e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.9538e-05 - val_loss: 0.0010\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.5451e-05 - val_loss: 4.7962e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9747e-05 - val_loss: 3.0898e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2974e-05 - val_loss: 3.9104e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0491e-04 - val_loss: 8.9630e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.5415e-05 - val_loss: 5.4076e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8623e-05 - val_loss: 6.4944e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8519e-05 - val_loss: 4.8410e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8262e-05 - val_loss: 7.5750e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1815e-05 - val_loss: 1.2698e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.0671e-05 - val_loss: 2.8367e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5647e-05 - val_loss: 7.1718e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.9948e-05 - val_loss: 1.0413e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9782e-05 - val_loss: 6.9475e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7017e-05 - val_loss: 9.8968e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9101e-05 - val_loss: 5.4086e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1688e-05 - val_loss: 1.7125e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1732e-05 - val_loss: 8.0045e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2783e-05 - val_loss: 2.6664e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9446e-05 - val_loss: 2.6716e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1066e-05 - val_loss: 2.2412e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8137e-05 - val_loss: 6.5893e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.1150e-05 - val_loss: 2.4041e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3759e-05 - val_loss: 2.8006e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3833e-05 - val_loss: 5.2814e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.2953e-05 - val_loss: 3.9447e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7226e-05 - val_loss: 1.4441e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3125e-05 - val_loss: 5.1237e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.8097e-05 - val_loss: 9.6672e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6265e-05 - val_loss: 2.1432e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6433e-05 - val_loss: 3.1934e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8328e-05 - val_loss: 1.9734e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6347e-05 - val_loss: 2.1357e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4087e-05 - val_loss: 8.7868e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6155e-05 - val_loss: 2.7206e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1434e-05 - val_loss: 9.2854e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0218e-05 - val_loss: 2.0991e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.0726e-05 - val_loss: 5.7600e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3561e-05 - val_loss: 2.5047e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5050e-05 - val_loss: 1.9673e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5045e-05 - val_loss: 4.6282e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3355e-05 - val_loss: 3.0450e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1168e-05 - val_loss: 5.2433e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2533e-05 - val_loss: 0.0016\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.4913e-05 - val_loss: 3.6449e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.1461e-05 - val_loss: 1.7984e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8475e-05 - val_loss: 1.4989e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6649e-05 - val_loss: 2.5887e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9003e-05 - val_loss: 1.1295e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3344e-05 - val_loss: 5.2142e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4990e-05 - val_loss: 4.2120e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.8651e-05 - val_loss: 4.6122e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6455e-05 - val_loss: 2.8534e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3144e-05 - val_loss: 7.2595e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0788e-05 - val_loss: 1.2619e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7151e-05 - val_loss: 6.7029e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4614e-05 - val_loss: 1.6764e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1173e-05 - val_loss: 2.9194e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9932e-05 - val_loss: 2.3107e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9543e-05 - val_loss: 3.7024e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8679e-05 - val_loss: 3.4871e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1384e-05 - val_loss: 2.0146e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5928e-05 - val_loss: 3.2093e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7272e-05 - val_loss: 5.4279e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0984e-05 - val_loss: 3.3930e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6390e-05 - val_loss: 4.8406e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4249e-05 - val_loss: 4.5210e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8002e-05 - val_loss: 5.2290e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0314e-05 - val_loss: 1.0716e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6869e-05 - val_loss: 2.6426e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3657e-05 - val_loss: 2.3723e-05\n",
      ">Neurons=60, Score=0.001319621424045181\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 17ms/step - loss: 0.0022 - val_loss: 0.0104\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.6210e-04 - val_loss: 0.0074\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.0028e-04 - val_loss: 0.0040\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1908e-04 - val_loss: 0.0020\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4437e-04 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0273e-04 - val_loss: 3.7108e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2267e-04 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1767e-04 - val_loss: 3.0860e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2022e-04 - val_loss: 8.6767e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6115e-04 - val_loss: 4.4260e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1487e-04 - val_loss: 1.4161e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.2762e-05 - val_loss: 1.3426e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.1972e-05 - val_loss: 0.0012\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.0868e-05 - val_loss: 7.2830e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.4483e-05 - val_loss: 1.1835e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.3400e-05 - val_loss: 4.7916e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.8125e-05 - val_loss: 4.9042e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.6223e-05 - val_loss: 2.9119e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0888e-04 - val_loss: 0.0016\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.3799e-04 - val_loss: 1.4753e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 7.2791e-05 - val_loss: 5.4537e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5030e-05 - val_loss: 1.7432e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7958e-05 - val_loss: 7.3172e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.9443e-05 - val_loss: 4.7626e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3513e-05 - val_loss: 2.1336e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6.8366e-05 - val_loss: 3.1008e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.7149e-05 - val_loss: 6.9669e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.5535e-05 - val_loss: 2.1802e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.3434e-05 - val_loss: 1.1615e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7237e-05 - val_loss: 2.2034e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.4426e-05 - val_loss: 0.0012\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4638e-05 - val_loss: 6.1878e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5607e-05 - val_loss: 5.1522e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1432e-05 - val_loss: 4.6917e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.1038e-05 - val_loss: 1.0961e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5072e-05 - val_loss: 1.5541e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8553e-05 - val_loss: 6.8683e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.0709e-05 - val_loss: 8.5474e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.9579e-05 - val_loss: 1.0378e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4486e-05 - val_loss: 1.3829e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.6167e-05 - val_loss: 2.4427e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7599e-05 - val_loss: 5.0650e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4293e-05 - val_loss: 2.6147e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9974e-05 - val_loss: 6.2376e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9812e-05 - val_loss: 1.0998e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3624e-05 - val_loss: 5.4589e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8823e-05 - val_loss: 1.0249e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.0402e-05 - val_loss: 0.0013\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4047e-05 - val_loss: 3.6703e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7711e-05 - val_loss: 1.1296e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.9238e-05 - val_loss: 4.1840e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7235e-05 - val_loss: 6.8158e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7053e-05 - val_loss: 1.0311e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.4861e-05 - val_loss: 4.8367e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7219e-05 - val_loss: 2.0223e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.1333e-05 - val_loss: 6.5711e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.3449e-05 - val_loss: 2.9429e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8782e-05 - val_loss: 1.2627e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8936e-05 - val_loss: 1.4167e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0997e-05 - val_loss: 9.5200e-06\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9475e-05 - val_loss: 4.3526e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5034e-05 - val_loss: 7.2827e-06\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5244e-05 - val_loss: 1.0177e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5975e-05 - val_loss: 4.1505e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.9059e-05 - val_loss: 8.4038e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6972e-05 - val_loss: 1.4293e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8301e-05 - val_loss: 2.0389e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7448e-05 - val_loss: 1.3229e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7671e-05 - val_loss: 4.9240e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5736e-05 - val_loss: 7.5174e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8940e-05 - val_loss: 2.0822e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.8247e-05 - val_loss: 4.0163e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0252e-05 - val_loss: 5.7429e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.1361e-05 - val_loss: 4.0886e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3839e-05 - val_loss: 2.6913e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5010e-05 - val_loss: 1.7877e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7804e-05 - val_loss: 4.4771e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.7660e-05 - val_loss: 0.0015\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6200e-05 - val_loss: 1.6296e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8071e-05 - val_loss: 1.8836e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9720e-05 - val_loss: 7.1921e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4659e-05 - val_loss: 1.9084e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2786e-05 - val_loss: 1.0641e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6927e-05 - val_loss: 2.9449e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9763e-05 - val_loss: 2.5119e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2163e-05 - val_loss: 6.7417e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6440e-05 - val_loss: 1.2519e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1348e-05 - val_loss: 1.6630e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8602e-05 - val_loss: 9.8808e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.0115e-05 - val_loss: 9.3955e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7467e-05 - val_loss: 5.0663e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8077e-05 - val_loss: 1.4257e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6851e-05 - val_loss: 3.8528e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9529e-05 - val_loss: 2.7169e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.8062e-05 - val_loss: 7.4758e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7157e-05 - val_loss: 3.6801e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.8183e-05 - val_loss: 9.6550e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1319e-05 - val_loss: 1.1719e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8651e-05 - val_loss: 2.4416e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6715e-05 - val_loss: 4.5983e-05\n",
      ">Neurons=60, Score=0.004193113636574708\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 16ms/step - loss: 0.0022 - val_loss: 0.0110\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0087\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.8156e-04 - val_loss: 0.0060\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.3345e-04 - val_loss: 0.0036\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0705e-04 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5688e-04 - val_loss: 6.8196e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6578e-04 - val_loss: 3.2623e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.6341e-04 - val_loss: 2.8331e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0542e-04 - val_loss: 4.2181e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1962e-04 - val_loss: 0.0020\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.5420e-05 - val_loss: 6.5966e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2098e-04 - val_loss: 2.1266e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3717e-05 - val_loss: 6.6913e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1199e-04 - val_loss: 0.0015\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.1551e-05 - val_loss: 9.1028e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0836e-05 - val_loss: 6.8315e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8420e-05 - val_loss: 3.9195e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.5024e-05 - val_loss: 9.5014e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0740e-05 - val_loss: 2.1373e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.8714e-05 - val_loss: 3.0940e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.6818e-05 - val_loss: 1.9901e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.1876e-05 - val_loss: 6.2348e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.9755e-05 - val_loss: 2.9522e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.1458e-05 - val_loss: 7.9921e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.2955e-05 - val_loss: 3.8166e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5089e-05 - val_loss: 8.8560e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3113e-05 - val_loss: 6.9405e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.0166e-04 - val_loss: 0.0012\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2535e-04 - val_loss: 3.2029e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.6912e-05 - val_loss: 4.4627e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6229e-05 - val_loss: 1.0175e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6068e-05 - val_loss: 7.7702e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9448e-05 - val_loss: 2.3485e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7772e-05 - val_loss: 1.6807e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8778e-05 - val_loss: 7.3307e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0245e-05 - val_loss: 1.4375e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5183e-05 - val_loss: 4.8525e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0044e-05 - val_loss: 8.6140e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4179e-05 - val_loss: 2.2440e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4849e-05 - val_loss: 5.4008e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3493e-05 - val_loss: 8.5607e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3608e-05 - val_loss: 5.5850e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4021e-05 - val_loss: 8.4218e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.2793e-05 - val_loss: 1.5498e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.6647e-05 - val_loss: 2.2157e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5601e-05 - val_loss: 2.9875e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9245e-05 - val_loss: 5.6652e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0222e-05 - val_loss: 2.3265e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4281e-05 - val_loss: 2.1314e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9387e-05 - val_loss: 5.5622e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7848e-05 - val_loss: 1.9764e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9754e-05 - val_loss: 1.2873e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8454e-05 - val_loss: 8.3937e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1691e-05 - val_loss: 1.1313e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8786e-05 - val_loss: 1.3747e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.4839e-05 - val_loss: 5.2313e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.7878e-05 - val_loss: 3.9401e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6325e-05 - val_loss: 2.2046e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0411e-05 - val_loss: 6.5213e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5048e-05 - val_loss: 2.9611e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0158e-05 - val_loss: 3.7657e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2144e-05 - val_loss: 3.4702e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.8219e-05 - val_loss: 4.6663e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3515e-05 - val_loss: 2.8587e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.0487e-05 - val_loss: 2.6631e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4516e-05 - val_loss: 2.6571e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7060e-05 - val_loss: 3.8384e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7367e-05 - val_loss: 7.7273e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 5.1869e-05 - val_loss: 9.6686e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4341e-05 - val_loss: 9.8233e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4913e-05 - val_loss: 2.1930e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0441e-05 - val_loss: 1.3273e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1660e-05 - val_loss: 2.4419e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3679e-05 - val_loss: 7.4376e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3592e-05 - val_loss: 3.6658e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1345e-05 - val_loss: 6.4182e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4118e-05 - val_loss: 2.3068e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4811e-05 - val_loss: 1.2124e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3903e-05 - val_loss: 1.9505e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.5177e-05 - val_loss: 4.2790e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1848e-05 - val_loss: 1.8865e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2842e-05 - val_loss: 5.3031e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1722e-05 - val_loss: 8.8870e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.5813e-05 - val_loss: 4.3006e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1.4575e-05 - val_loss: 5.9141e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3.7873e-05 - val_loss: 2.0693e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.0643e-05 - val_loss: 3.6501e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4739e-05 - val_loss: 1.2591e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2154e-05 - val_loss: 1.2845e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3171e-05 - val_loss: 4.8728e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5245e-05 - val_loss: 3.1129e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5013e-05 - val_loss: 1.0769e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0717e-05 - val_loss: 2.0454e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2214e-05 - val_loss: 1.2162e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4681e-05 - val_loss: 2.4818e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.4129e-05 - val_loss: 7.8996e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7726e-05 - val_loss: 5.6780e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1497e-05 - val_loss: 3.7638e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6611e-05 - val_loss: 6.6865e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6835e-05 - val_loss: 1.4918e-04\n",
      ">Neurons=60, Score=0.00997807364910841\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 8s 16ms/step - loss: 0.0022 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0080\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.3456e-04 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7090e-04 - val_loss: 0.0019\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8210e-04 - val_loss: 0.0010\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7508e-04 - val_loss: 9.7781e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5923e-04 - val_loss: 0.0013\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.4037e-05 - val_loss: 5.9750e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.8591e-05 - val_loss: 2.6880e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.9614e-05 - val_loss: 1.3063e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2601e-04 - val_loss: 3.8653e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3217e-04 - val_loss: 7.4164e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.7513e-05 - val_loss: 0.0015\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.9113e-05 - val_loss: 2.3473e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.0104e-05 - val_loss: 1.2487e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.8871e-05 - val_loss: 7.3017e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0520e-05 - val_loss: 8.3397e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.9672e-05 - val_loss: 7.4041e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4839e-05 - val_loss: 1.3648e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2240e-05 - val_loss: 5.7483e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.4920e-05 - val_loss: 2.4419e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.6257e-05 - val_loss: 3.3239e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8072e-05 - val_loss: 3.9991e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1953e-04 - val_loss: 4.9141e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.8469e-05 - val_loss: 6.7575e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0473e-05 - val_loss: 3.9686e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.8099e-05 - val_loss: 1.6070e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4457e-05 - val_loss: 6.2531e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9776e-05 - val_loss: 9.0529e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6322e-05 - val_loss: 1.6575e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4323e-05 - val_loss: 1.3208e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8705e-05 - val_loss: 7.6331e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8911e-05 - val_loss: 4.5374e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3259e-05 - val_loss: 5.8710e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.4974e-05 - val_loss: 1.4738e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7446e-05 - val_loss: 7.6178e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0076e-05 - val_loss: 2.9450e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6768e-05 - val_loss: 5.7405e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.8844e-05 - val_loss: 7.9361e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.8423e-05 - val_loss: 1.2688e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0564e-05 - val_loss: 9.4038e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8575e-05 - val_loss: 2.5845e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5639e-05 - val_loss: 1.3260e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4372e-05 - val_loss: 2.3273e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5771e-05 - val_loss: 2.3145e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8291e-05 - val_loss: 9.2338e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.1777e-05 - val_loss: 0.0010\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7195e-05 - val_loss: 2.7511e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4209e-05 - val_loss: 5.6510e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6931e-05 - val_loss: 3.4436e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.1336e-05 - val_loss: 5.4393e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6124e-05 - val_loss: 2.9173e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0556e-05 - val_loss: 3.7099e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6180e-05 - val_loss: 4.5878e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5512e-05 - val_loss: 2.5077e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0108e-05 - val_loss: 4.3893e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.9805e-05 - val_loss: 0.0011\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6746e-05 - val_loss: 2.9100e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5679e-05 - val_loss: 2.3229e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3827e-05 - val_loss: 3.9391e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.5312e-05 - val_loss: 6.7769e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.0384e-05 - val_loss: 1.4747e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9545e-05 - val_loss: 3.1494e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2057e-05 - val_loss: 1.9243e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2522e-05 - val_loss: 3.1223e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5988e-05 - val_loss: 7.5401e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9988e-05 - val_loss: 1.2022e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3382e-05 - val_loss: 3.2127e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2031e-05 - val_loss: 2.9380e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2590e-05 - val_loss: 4.6367e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1823e-05 - val_loss: 5.8586e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.1055e-05 - val_loss: 4.4287e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4865e-05 - val_loss: 9.9615e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3055e-05 - val_loss: 6.9241e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3301e-05 - val_loss: 5.3525e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2570e-05 - val_loss: 4.9813e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6878e-05 - val_loss: 8.7457e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5554e-05 - val_loss: 9.3197e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9203e-05 - val_loss: 8.8175e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4637e-05 - val_loss: 2.3361e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5958e-05 - val_loss: 1.7002e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3770e-05 - val_loss: 1.3456e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.3729e-05 - val_loss: 1.0985e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.9016e-05 - val_loss: 1.1587e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.6537e-05 - val_loss: 9.9672e-06\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.1872e-05 - val_loss: 1.8982e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7269e-05 - val_loss: 4.9194e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.4165e-05 - val_loss: 2.4982e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1840e-05 - val_loss: 5.1879e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.0689e-05 - val_loss: 4.6285e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7961e-05 - val_loss: 2.0650e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.8844e-05 - val_loss: 5.1035e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.7119e-06 - val_loss: 3.0960e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8677e-05 - val_loss: 3.7210e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6988e-05 - val_loss: 4.3246e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0452e-05 - val_loss: 2.8289e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8410e-05 - val_loss: 4.0807e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.8029e-05 - val_loss: 3.7204e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.0411e-06 - val_loss: 6.1271e-06\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6565e-05 - val_loss: 6.2467e-05\n",
      ">Neurons=65, Score=0.005715840597986244\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 20ms/step - loss: 0.0023 - val_loss: 0.0109\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 0.0074\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.2186e-04 - val_loss: 0.0042\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4103e-04 - val_loss: 0.0019\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4078e-04 - val_loss: 7.0035e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3986e-04 - val_loss: 2.5689e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2684e-04 - val_loss: 3.1514e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3248e-04 - val_loss: 6.4821e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2649e-04 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2818e-04 - val_loss: 6.5481e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0670e-04 - val_loss: 2.8230e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.5034e-05 - val_loss: 2.7922e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.5407e-05 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2617e-05 - val_loss: 1.9384e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.0553e-05 - val_loss: 3.6028e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.0890e-05 - val_loss: 5.8338e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.8868e-05 - val_loss: 1.7575e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.5258e-05 - val_loss: 0.0017\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3132e-04 - val_loss: 0.0011\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.0854e-05 - val_loss: 1.9643e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0626e-05 - val_loss: 4.4742e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.9207e-05 - val_loss: 1.8880e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.1565e-05 - val_loss: 4.9664e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7009e-05 - val_loss: 2.6995e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2238e-05 - val_loss: 3.2008e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.6803e-05 - val_loss: 5.5824e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.8727e-05 - val_loss: 2.0089e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.9631e-05 - val_loss: 3.7983e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7054e-04 - val_loss: 0.0019\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2852e-04 - val_loss: 2.0381e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2972e-05 - val_loss: 2.2720e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.3652e-05 - val_loss: 7.4677e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.3095e-05 - val_loss: 6.3478e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.0125e-05 - val_loss: 4.0086e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 3.4605e-05 - val_loss: 1.3325e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.5161e-05 - val_loss: 3.1956e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5068e-05 - val_loss: 3.6931e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6596e-05 - val_loss: 4.5125e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4566e-05 - val_loss: 2.9249e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8243e-05 - val_loss: 2.7018e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4953e-05 - val_loss: 2.7417e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4943e-05 - val_loss: 8.8261e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3231e-05 - val_loss: 5.3370e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4567e-05 - val_loss: 3.1831e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3984e-05 - val_loss: 1.2877e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1084e-05 - val_loss: 1.2436e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4.9951e-05 - val_loss: 2.7548e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.6992e-05 - val_loss: 6.5612e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.9469e-05 - val_loss: 1.1973e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6580e-05 - val_loss: 2.9789e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1496e-05 - val_loss: 3.1790e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4649e-05 - val_loss: 3.0096e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.6609e-05 - val_loss: 2.6187e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.2807e-05 - val_loss: 3.9977e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4235e-05 - val_loss: 1.5551e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1538e-05 - val_loss: 3.2857e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8996e-05 - val_loss: 2.6216e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0147e-05 - val_loss: 3.6518e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3616e-05 - val_loss: 4.5918e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3491e-05 - val_loss: 1.7697e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6874e-05 - val_loss: 1.7683e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0027e-05 - val_loss: 5.3556e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1681e-05 - val_loss: 1.7095e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1726e-05 - val_loss: 7.0709e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8626e-05 - val_loss: 4.6938e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0367e-05 - val_loss: 5.1331e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0694e-05 - val_loss: 4.3022e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3954e-05 - val_loss: 2.9984e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4323e-05 - val_loss: 8.9880e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.0228e-05 - val_loss: 4.0564e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3785e-05 - val_loss: 1.8397e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5030e-05 - val_loss: 3.3059e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7598e-05 - val_loss: 2.3293e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2189e-05 - val_loss: 8.8724e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.7254e-05 - val_loss: 7.1735e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0087e-05 - val_loss: 6.5069e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0902e-05 - val_loss: 5.8000e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1063e-05 - val_loss: 1.8577e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1558e-05 - val_loss: 7.3281e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9736e-05 - val_loss: 1.4114e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8206e-05 - val_loss: 4.1128e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.2848e-05 - val_loss: 1.9014e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7656e-05 - val_loss: 1.0639e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.0037e-06 - val_loss: 6.4529e-06\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6950e-05 - val_loss: 3.2057e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9641e-05 - val_loss: 4.3646e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5136e-05 - val_loss: 2.2730e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6708e-05 - val_loss: 3.7747e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7432e-05 - val_loss: 3.1901e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6641e-05 - val_loss: 4.5949e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3993e-05 - val_loss: 4.7464e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2703e-05 - val_loss: 1.3357e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3040e-05 - val_loss: 1.3916e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6829e-05 - val_loss: 8.9097e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9443e-05 - val_loss: 2.9090e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1269e-05 - val_loss: 1.4803e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6937e-05 - val_loss: 2.7057e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0290e-05 - val_loss: 5.5366e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1515e-05 - val_loss: 2.8140e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1717e-05 - val_loss: 3.0922e-05\n",
      ">Neurons=65, Score=0.0017861739252111875\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 8s 16ms/step - loss: 0.0023 - val_loss: 0.0102\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0072\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.2252e-04 - val_loss: 0.0044\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5730e-04 - val_loss: 0.0020\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9974e-04 - val_loss: 7.5406e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0861e-04 - val_loss: 7.2290e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6288e-04 - val_loss: 4.4140e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3130e-04 - val_loss: 6.2313e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2588e-04 - val_loss: 3.9576e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2402e-04 - val_loss: 4.3227e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.6912e-05 - val_loss: 3.2214e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.2745e-05 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1971e-04 - val_loss: 3.5021e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.1698e-05 - val_loss: 4.6637e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.7001e-05 - val_loss: 5.5741e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.7140e-05 - val_loss: 8.1516e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.9852e-05 - val_loss: 1.6559e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.6425e-05 - val_loss: 2.4643e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.3614e-05 - val_loss: 8.7787e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7947e-05 - val_loss: 2.9397e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.7079e-05 - val_loss: 3.1604e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.2620e-05 - val_loss: 7.7367e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6074e-05 - val_loss: 5.8320e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1131e-05 - val_loss: 5.3924e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1935e-05 - val_loss: 2.3989e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.4734e-05 - val_loss: 6.5751e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.3673e-05 - val_loss: 7.9244e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.0746e-05 - val_loss: 7.5395e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.0381e-05 - val_loss: 3.0301e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2391e-05 - val_loss: 9.3557e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9266e-05 - val_loss: 2.0843e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1292e-05 - val_loss: 4.7178e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.5757e-05 - val_loss: 5.4321e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3970e-05 - val_loss: 6.6797e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2.4910e-05 - val_loss: 7.6493e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0958e-05 - val_loss: 1.0857e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5662e-05 - val_loss: 4.2210e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.3357e-05 - val_loss: 5.6437e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1736e-05 - val_loss: 1.0444e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0085e-05 - val_loss: 8.7586e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9403e-05 - val_loss: 5.6428e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.3370e-05 - val_loss: 2.9478e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5069e-05 - val_loss: 6.7471e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.7217e-05 - val_loss: 0.0011\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0947e-04 - val_loss: 7.7439e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3553e-05 - val_loss: 1.3402e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8626e-05 - val_loss: 2.5169e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1520e-05 - val_loss: 2.2222e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2178e-05 - val_loss: 4.1635e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3205e-05 - val_loss: 4.1952e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3893e-05 - val_loss: 1.3557e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4050e-05 - val_loss: 7.0782e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.3137e-05 - val_loss: 2.5488e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6618e-05 - val_loss: 1.5749e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9982e-05 - val_loss: 2.6605e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1427e-05 - val_loss: 3.7232e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4017e-05 - val_loss: 7.0427e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.2349e-05 - val_loss: 7.8465e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4716e-05 - val_loss: 1.5474e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7937e-05 - val_loss: 1.0226e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3648e-05 - val_loss: 1.1218e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8870e-05 - val_loss: 2.4894e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.1201e-05 - val_loss: 2.1523e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7832e-05 - val_loss: 1.0373e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3687e-05 - val_loss: 5.7346e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5600e-05 - val_loss: 1.2540e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4849e-05 - val_loss: 1.4555e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4359e-05 - val_loss: 4.1307e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.8735e-05 - val_loss: 1.2804e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0210e-05 - val_loss: 2.9071e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.3690e-05 - val_loss: 4.5657e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2820e-05 - val_loss: 6.7609e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4028e-05 - val_loss: 1.3645e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7531e-05 - val_loss: 8.4299e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0124e-05 - val_loss: 4.1136e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6757e-05 - val_loss: 9.5672e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5384e-05 - val_loss: 3.7077e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2815e-05 - val_loss: 2.9158e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0828e-05 - val_loss: 4.7650e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4504e-05 - val_loss: 3.0106e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1263e-05 - val_loss: 5.8312e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6128e-05 - val_loss: 4.0541e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0563e-05 - val_loss: 3.8148e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5341e-05 - val_loss: 2.5634e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6661e-05 - val_loss: 2.2972e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4840e-05 - val_loss: 4.9768e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7734e-05 - val_loss: 5.7374e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4424e-05 - val_loss: 9.2345e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5283e-05 - val_loss: 4.6026e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.1277e-05 - val_loss: 2.7713e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3136e-05 - val_loss: 6.0111e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4964e-05 - val_loss: 2.2232e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.1239e-05 - val_loss: 2.3964e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.6110e-05 - val_loss: 4.5111e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.9808e-05 - val_loss: 7.1572e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2395e-05 - val_loss: 4.9321e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.6319e-06 - val_loss: 1.2466e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0202e-05 - val_loss: 3.7973e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9195e-05 - val_loss: 4.0059e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.8236e-05 - val_loss: 2.0230e-04\n",
      ">Neurons=65, Score=0.011468315642559901\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 16ms/step - loss: 0.0022 - val_loss: 0.0110\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0088\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.4811e-04 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.7275e-04 - val_loss: 0.0027\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3943e-04 - val_loss: 0.0010\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8980e-04 - val_loss: 3.2297e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2930e-04 - val_loss: 2.1607e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0618e-04 - val_loss: 6.5841e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5845e-04 - val_loss: 6.6417e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5920e-04 - val_loss: 5.4054e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.7955e-05 - val_loss: 6.9828e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.6817e-04 - val_loss: 4.1713e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.7120e-05 - val_loss: 1.3517e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8983e-04 - val_loss: 6.3938e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0353e-04 - val_loss: 3.4532e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.6714e-05 - val_loss: 1.2149e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.7805e-05 - val_loss: 5.6701e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5986e-05 - val_loss: 9.3610e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4646e-05 - val_loss: 0.0013\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.7556e-05 - val_loss: 1.5590e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.5769e-05 - val_loss: 1.9065e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.9947e-05 - val_loss: 7.7599e-05\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.3192e-05 - val_loss: 5.6902e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3106e-05 - val_loss: 2.0073e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.5626e-05 - val_loss: 5.8350e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2027e-05 - val_loss: 2.3888e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.7708e-05 - val_loss: 1.7525e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7393e-05 - val_loss: 1.9738e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.1257e-05 - val_loss: 1.0142e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3034e-05 - val_loss: 1.0306e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9490e-05 - val_loss: 3.5643e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4815e-05 - val_loss: 8.8212e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.3217e-05 - val_loss: 6.2586e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.0802e-05 - val_loss: 2.9621e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9726e-05 - val_loss: 3.1691e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7656e-05 - val_loss: 2.8593e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.5397e-05 - val_loss: 4.2472e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.2269e-05 - val_loss: 1.4854e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4080e-05 - val_loss: 1.4655e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0855e-05 - val_loss: 3.5208e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.9383e-05 - val_loss: 7.0401e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.5649e-05 - val_loss: 3.1231e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0530e-05 - val_loss: 3.5594e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7162e-05 - val_loss: 5.2053e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7668e-05 - val_loss: 2.3315e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9625e-05 - val_loss: 2.9631e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2191e-05 - val_loss: 3.0833e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6370e-05 - val_loss: 2.4314e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9830e-05 - val_loss: 9.1710e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3145e-05 - val_loss: 2.0487e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4124e-05 - val_loss: 5.7253e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.9257e-05 - val_loss: 9.4346e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2448e-05 - val_loss: 2.6906e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8175e-05 - val_loss: 2.7657e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2609e-05 - val_loss: 1.2331e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.7232e-05 - val_loss: 7.2012e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2550e-05 - val_loss: 8.5157e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.8019e-05 - val_loss: 0.0018\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.1720e-05 - val_loss: 9.6660e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6230e-05 - val_loss: 2.2322e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3966e-05 - val_loss: 2.9404e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5374e-05 - val_loss: 2.8461e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5091e-05 - val_loss: 5.1740e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.9740e-06 - val_loss: 3.9305e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5032e-05 - val_loss: 4.1984e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.6890e-06 - val_loss: 5.7082e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2524e-05 - val_loss: 5.0063e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4999e-05 - val_loss: 4.1617e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6574e-05 - val_loss: 4.3255e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5372e-05 - val_loss: 4.8726e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8937e-05 - val_loss: 7.9375e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0457e-05 - val_loss: 1.9330e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1275e-05 - val_loss: 1.3434e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0838e-05 - val_loss: 1.0607e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.9071e-05 - val_loss: 7.6593e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5574e-05 - val_loss: 2.7107e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4870e-05 - val_loss: 1.7788e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0546e-04 - val_loss: 0.0024\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.9067e-05 - val_loss: 2.5635e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4198e-05 - val_loss: 2.7321e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4781e-05 - val_loss: 1.3605e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.3059e-05 - val_loss: 1.9888e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5150e-05 - val_loss: 1.1565e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2008e-05 - val_loss: 1.5654e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3820e-05 - val_loss: 2.9691e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1609e-05 - val_loss: 1.1325e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2795e-05 - val_loss: 8.4506e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5240e-05 - val_loss: 2.7229e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9995e-05 - val_loss: 1.9320e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.6992e-05 - val_loss: 1.2146e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8873e-05 - val_loss: 1.4756e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5663e-05 - val_loss: 2.3470e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2394e-05 - val_loss: 7.3224e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9556e-05 - val_loss: 1.3022e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0602e-05 - val_loss: 2.8150e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0256e-05 - val_loss: 1.7312e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8838e-05 - val_loss: 2.4910e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8756e-05 - val_loss: 1.6329e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7846e-05 - val_loss: 7.1714e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2246e-05 - val_loss: 2.2289e-05\n",
      ">Neurons=65, Score=0.001424595666321693\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 19ms/step - loss: 0.0022 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.7358e-04 - val_loss: 0.0076\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1309e-04 - val_loss: 0.0042\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3334e-04 - val_loss: 0.0019\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5178e-04 - val_loss: 7.3305e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4059e-04 - val_loss: 3.7275e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0077e-04 - val_loss: 1.9779e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2481e-04 - val_loss: 2.6717e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.3481e-05 - val_loss: 1.0831e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4208e-04 - val_loss: 4.6839e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4168e-04 - val_loss: 2.1051e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.9135e-05 - val_loss: 2.3342e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.5795e-05 - val_loss: 2.2479e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.5033e-05 - val_loss: 1.7102e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.1729e-05 - val_loss: 7.2458e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1241e-05 - val_loss: 3.2624e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.4310e-05 - val_loss: 3.4074e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.8842e-05 - val_loss: 5.4133e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6453e-05 - val_loss: 2.4345e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3534e-04 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1464e-04 - val_loss: 1.4574e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.0634e-05 - val_loss: 1.2458e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.3680e-05 - val_loss: 2.4239e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.9479e-05 - val_loss: 2.5959e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9173e-05 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.8075e-05 - val_loss: 8.5244e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.9704e-05 - val_loss: 3.8944e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.4993e-05 - val_loss: 1.7282e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2082e-05 - val_loss: 1.6768e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8800e-05 - val_loss: 1.1236e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7549e-05 - val_loss: 8.5278e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3249e-05 - val_loss: 1.9286e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4454e-05 - val_loss: 8.6481e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4280e-05 - val_loss: 1.7132e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0800e-05 - val_loss: 7.4135e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2004e-05 - val_loss: 3.7650e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0610e-05 - val_loss: 5.1328e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4956e-05 - val_loss: 4.6307e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.5653e-05 - val_loss: 4.3900e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5604e-05 - val_loss: 5.8041e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6130e-05 - val_loss: 4.5147e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5254e-05 - val_loss: 2.4336e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5461e-05 - val_loss: 1.0528e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2936e-05 - val_loss: 7.4640e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6934e-05 - val_loss: 1.1951e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2117e-05 - val_loss: 4.0010e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4149e-05 - val_loss: 1.0284e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5131e-05 - val_loss: 1.0346e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9141e-05 - val_loss: 7.4893e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8939e-05 - val_loss: 4.1247e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.7468e-05 - val_loss: 6.0538e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.9184e-05 - val_loss: 2.6860e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5571e-05 - val_loss: 3.1832e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.6020e-05 - val_loss: 1.7205e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2281e-05 - val_loss: 5.3371e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.7146e-05 - val_loss: 4.9245e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.2775e-05 - val_loss: 0.0010\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.8905e-05 - val_loss: 9.5495e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3299e-05 - val_loss: 3.5558e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3770e-05 - val_loss: 3.8236e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5013e-05 - val_loss: 1.0215e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4636e-05 - val_loss: 2.8646e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2895e-05 - val_loss: 2.8833e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8406e-05 - val_loss: 1.4670e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0038e-05 - val_loss: 6.1785e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4742e-05 - val_loss: 6.8939e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4552e-05 - val_loss: 7.2201e-06\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4708e-05 - val_loss: 7.7626e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5454e-05 - val_loss: 1.5217e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6416e-05 - val_loss: 2.5734e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3929e-05 - val_loss: 2.4181e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.1956e-05 - val_loss: 6.9132e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.9824e-05 - val_loss: 5.9957e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8998e-05 - val_loss: 5.0358e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3335e-05 - val_loss: 9.4716e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6041e-05 - val_loss: 1.2496e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4848e-05 - val_loss: 1.5103e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0940e-05 - val_loss: 1.7998e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.8466e-05 - val_loss: 3.8208e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2200e-05 - val_loss: 6.1424e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.4208e-05 - val_loss: 0.0015\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.8772e-05 - val_loss: 5.4220e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8220e-05 - val_loss: 3.7104e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2304e-05 - val_loss: 1.1652e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2448e-05 - val_loss: 2.6729e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.2616e-05 - val_loss: 1.8923e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.2257e-05 - val_loss: 1.8549e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8911e-05 - val_loss: 9.0461e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6564e-05 - val_loss: 4.1570e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4511e-05 - val_loss: 1.0842e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.4869e-06 - val_loss: 1.3077e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7691e-05 - val_loss: 9.7226e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7162e-05 - val_loss: 2.0023e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6131e-05 - val_loss: 1.9337e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1980e-05 - val_loss: 1.5427e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1363e-05 - val_loss: 9.4419e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2558e-05 - val_loss: 2.8115e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5710e-05 - val_loss: 2.0523e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1197e-05 - val_loss: 1.2196e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0942e-05 - val_loss: 1.1941e-04\n",
      ">Neurons=65, Score=0.00995320369838737\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 19ms/step - loss: 0.0022 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.9403e-04 - val_loss: 0.0078\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.0328e-04 - val_loss: 0.0052\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.8575e-04 - val_loss: 0.0028\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3490e-04 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6120e-04 - val_loss: 0.0010\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5002e-04 - val_loss: 2.2649e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0157e-04 - val_loss: 1.9808e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0499e-04 - val_loss: 7.2789e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.1786e-05 - val_loss: 0.0016\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.6076e-05 - val_loss: 3.4886e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1196e-05 - val_loss: 5.7841e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.9724e-05 - val_loss: 3.2103e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1485e-04 - val_loss: 4.7570e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.9433e-05 - val_loss: 0.0016\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.2816e-05 - val_loss: 4.9515e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.9002e-05 - val_loss: 2.2867e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.7707e-05 - val_loss: 3.2508e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.5344e-05 - val_loss: 2.2868e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2312e-05 - val_loss: 8.9752e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1597e-05 - val_loss: 1.0304e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.9612e-05 - val_loss: 2.7746e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.9622e-05 - val_loss: 4.9859e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.5815e-05 - val_loss: 8.4943e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.3372e-05 - val_loss: 7.1990e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1104e-05 - val_loss: 1.7763e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0045e-05 - val_loss: 2.7160e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8521e-05 - val_loss: 7.9014e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8687e-05 - val_loss: 5.4286e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6319e-05 - val_loss: 1.6215e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.0672e-05 - val_loss: 2.8409e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.3893e-05 - val_loss: 2.8258e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.9169e-05 - val_loss: 1.3569e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1790e-05 - val_loss: 2.7217e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0899e-05 - val_loss: 5.8634e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8116e-05 - val_loss: 1.1661e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8852e-05 - val_loss: 2.9866e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2921e-05 - val_loss: 1.4844e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4340e-05 - val_loss: 3.4844e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.1317e-05 - val_loss: 1.4453e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.2353e-05 - val_loss: 1.4357e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0420e-05 - val_loss: 2.9281e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7594e-05 - val_loss: 7.2941e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1828e-05 - val_loss: 7.3917e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0367e-05 - val_loss: 7.9310e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1580e-05 - val_loss: 1.9544e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1157e-05 - val_loss: 8.8457e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5088e-05 - val_loss: 1.3800e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7893e-05 - val_loss: 7.1276e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9842e-05 - val_loss: 3.1620e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2221e-05 - val_loss: 1.5533e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8582e-05 - val_loss: 3.4656e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.1031e-05 - val_loss: 1.9096e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6305e-05 - val_loss: 1.0642e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2420e-05 - val_loss: 5.8876e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1419e-05 - val_loss: 1.6674e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0027e-05 - val_loss: 7.6538e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6957e-05 - val_loss: 8.6836e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4116e-05 - val_loss: 7.7788e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2792e-05 - val_loss: 1.7501e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6478e-05 - val_loss: 5.0824e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.6278e-05 - val_loss: 4.1291e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6885e-05 - val_loss: 1.8342e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2342e-05 - val_loss: 1.6993e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9767e-05 - val_loss: 3.0200e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2090e-05 - val_loss: 1.7316e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4675e-05 - val_loss: 3.0139e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.9848e-05 - val_loss: 8.3085e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.0445e-05 - val_loss: 4.7537e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2657e-05 - val_loss: 2.5050e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3037e-05 - val_loss: 8.5920e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.3404e-05 - val_loss: 1.1396e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 8.7324e-06 - val_loss: 1.9967e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6277e-05 - val_loss: 1.4421e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5381e-05 - val_loss: 3.5698e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.4857e-05 - val_loss: 4.5281e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9209e-05 - val_loss: 6.6519e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.3924e-06 - val_loss: 1.5186e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7478e-05 - val_loss: 1.5865e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8625e-05 - val_loss: 0.0016\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4813e-05 - val_loss: 7.4611e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2673e-05 - val_loss: 9.8533e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3341e-05 - val_loss: 7.2626e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4779e-05 - val_loss: 1.0313e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4341e-05 - val_loss: 1.3191e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3609e-05 - val_loss: 6.0598e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6179e-05 - val_loss: 2.9933e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8371e-05 - val_loss: 3.9709e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7149e-05 - val_loss: 9.6561e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5278e-05 - val_loss: 3.6600e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1716e-05 - val_loss: 8.4661e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.7994e-05 - val_loss: 5.0087e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1129e-05 - val_loss: 1.0299e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2718e-05 - val_loss: 2.7399e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2583e-05 - val_loss: 1.6672e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9788e-05 - val_loss: 2.8503e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6426e-06 - val_loss: 1.9068e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4865e-05 - val_loss: 3.2274e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0046e-05 - val_loss: 3.7826e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5509e-05 - val_loss: 1.0660e-04\n",
      ">Neurons=65, Score=0.00741600088076666\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 19ms/step - loss: 0.0022 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0077\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.9375e-04 - val_loss: 0.0047\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.9103e-04 - val_loss: 0.0024\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0553e-04 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1067e-04 - val_loss: 8.1870e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5806e-04 - val_loss: 3.9443e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0955e-04 - val_loss: 5.2896e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.6010e-05 - val_loss: 6.8908e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0524e-04 - val_loss: 8.3307e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1157e-05 - val_loss: 1.9520e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0348e-04 - val_loss: 3.3407e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.9256e-05 - val_loss: 1.5725e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.4340e-05 - val_loss: 6.4579e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4372e-04 - val_loss: 6.0303e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0268e-04 - val_loss: 1.1662e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.7573e-05 - val_loss: 8.3205e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.0241e-05 - val_loss: 2.1572e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.1672e-05 - val_loss: 3.6143e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.2742e-05 - val_loss: 3.8126e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.4782e-05 - val_loss: 9.5872e-05\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.0352e-05 - val_loss: 3.7997e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0178e-04 - val_loss: 5.6917e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.9396e-05 - val_loss: 4.8842e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.3760e-05 - val_loss: 7.9501e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9837e-05 - val_loss: 9.6666e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4903e-05 - val_loss: 5.7588e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8692e-05 - val_loss: 3.7463e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6174e-05 - val_loss: 3.2714e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4706e-05 - val_loss: 1.6900e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2568e-05 - val_loss: 9.9627e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2471e-05 - val_loss: 8.4174e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8945e-05 - val_loss: 1.4541e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7145e-05 - val_loss: 3.5205e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0383e-05 - val_loss: 4.2653e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5261e-05 - val_loss: 1.2616e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.2453e-05 - val_loss: 0.0012\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.7403e-05 - val_loss: 6.0510e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9959e-05 - val_loss: 2.1115e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7136e-05 - val_loss: 9.0886e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3434e-05 - val_loss: 8.3486e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5966e-05 - val_loss: 3.6869e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.6801e-05 - val_loss: 2.6203e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.4761e-05 - val_loss: 6.7252e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6587e-05 - val_loss: 4.7913e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.6768e-05 - val_loss: 6.4581e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9407e-05 - val_loss: 9.7567e-06\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.6566e-05 - val_loss: 6.8199e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9194e-05 - val_loss: 1.0186e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0070e-05 - val_loss: 1.8212e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.1972e-05 - val_loss: 9.9793e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.8676e-05 - val_loss: 4.9879e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.9928e-05 - val_loss: 3.5887e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2301e-05 - val_loss: 2.0646e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.8918e-05 - val_loss: 8.2344e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1938e-05 - val_loss: 1.9134e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.4929e-05 - val_loss: 1.6290e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2097e-05 - val_loss: 1.0487e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9971e-05 - val_loss: 3.0667e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8620e-05 - val_loss: 2.5276e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6830e-05 - val_loss: 5.3326e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.1385e-05 - val_loss: 8.8159e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.6449e-05 - val_loss: 5.5393e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0334e-05 - val_loss: 5.1472e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5108e-05 - val_loss: 7.8543e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4349e-05 - val_loss: 1.9601e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8537e-05 - val_loss: 2.1899e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2677e-05 - val_loss: 3.5298e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6655e-05 - val_loss: 7.6825e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2433e-05 - val_loss: 1.2948e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2700e-05 - val_loss: 5.9716e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1202e-05 - val_loss: 1.2637e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2630e-05 - val_loss: 1.6165e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8626e-05 - val_loss: 2.5980e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3927e-05 - val_loss: 2.3744e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7716e-05 - val_loss: 2.1752e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9794e-05 - val_loss: 3.9749e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.6379e-05 - val_loss: 1.1801e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0277e-05 - val_loss: 3.0522e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2647e-05 - val_loss: 7.2959e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5459e-05 - val_loss: 1.1170e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.6738e-05 - val_loss: 8.0152e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7268e-05 - val_loss: 4.6132e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4326e-05 - val_loss: 6.7699e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9538e-05 - val_loss: 3.8863e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6288e-05 - val_loss: 1.0279e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1986e-05 - val_loss: 5.6924e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8901e-05 - val_loss: 1.2363e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4251e-05 - val_loss: 9.3647e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8696e-05 - val_loss: 6.0616e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8083e-05 - val_loss: 5.3679e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9668e-05 - val_loss: 6.5970e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.0651e-06 - val_loss: 4.7881e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2055e-05 - val_loss: 7.6572e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6178e-05 - val_loss: 2.5711e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0754e-05 - val_loss: 1.9141e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8920e-05 - val_loss: 2.1689e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2356e-05 - val_loss: 2.2638e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3470e-05 - val_loss: 4.6271e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3114e-05 - val_loss: 4.6919e-05\n",
      ">Neurons=65, Score=0.002591567135823425\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 12s 18ms/step - loss: 0.0023 - val_loss: 0.0103\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.7837e-04 - val_loss: 0.0078\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.5339e-04 - val_loss: 0.0052\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.7804e-04 - val_loss: 0.0026\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1709e-04 - val_loss: 9.7189e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9066e-04 - val_loss: 3.8851e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5823e-04 - val_loss: 9.0612e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3513e-04 - val_loss: 4.4633e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2432e-04 - val_loss: 2.1691e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2052e-04 - val_loss: 2.2760e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.0420e-05 - val_loss: 4.5349e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3057e-04 - val_loss: 6.4013e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0536e-05 - val_loss: 3.9149e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.9073e-05 - val_loss: 3.5084e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0172e-04 - val_loss: 1.3287e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.5507e-05 - val_loss: 2.7856e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.8780e-05 - val_loss: 1.1735e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.1324e-05 - val_loss: 2.5489e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.9853e-05 - val_loss: 2.5913e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.9916e-05 - val_loss: 0.0011\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.9441e-05 - val_loss: 2.9149e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3788e-05 - val_loss: 5.6102e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3765e-05 - val_loss: 5.4857e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8876e-05 - val_loss: 2.7057e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2555e-05 - val_loss: 1.3974e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4987e-05 - val_loss: 3.5142e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1832e-05 - val_loss: 7.6375e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.1902e-05 - val_loss: 5.2920e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.7716e-05 - val_loss: 9.8774e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.6651e-05 - val_loss: 4.8784e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8994e-05 - val_loss: 7.9944e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3857e-05 - val_loss: 6.5117e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.8858e-05 - val_loss: 0.0011\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.0704e-05 - val_loss: 6.2328e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.1775e-05 - val_loss: 8.2052e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.3912e-05 - val_loss: 3.0235e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.7494e-05 - val_loss: 8.9786e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6646e-05 - val_loss: 9.3186e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5265e-05 - val_loss: 6.7321e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4796e-05 - val_loss: 1.1863e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5700e-05 - val_loss: 1.1248e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2005e-05 - val_loss: 1.5299e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0594e-05 - val_loss: 1.0763e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2580e-05 - val_loss: 6.5335e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4759e-05 - val_loss: 4.1132e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7209e-05 - val_loss: 3.4966e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.9033e-05 - val_loss: 1.8642e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3427e-05 - val_loss: 6.4257e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9407e-05 - val_loss: 3.0595e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7609e-05 - val_loss: 3.8286e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7703e-05 - val_loss: 4.6766e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0809e-05 - val_loss: 1.3576e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0810e-05 - val_loss: 1.1384e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8439e-05 - val_loss: 4.9125e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7060e-05 - val_loss: 2.9646e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4733e-05 - val_loss: 2.1547e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0161e-05 - val_loss: 1.0492e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0283e-05 - val_loss: 3.6818e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4929e-05 - val_loss: 2.5732e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5454e-05 - val_loss: 1.5879e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5888e-05 - val_loss: 6.0850e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9029e-05 - val_loss: 1.5187e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2374e-05 - val_loss: 2.1204e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3711e-05 - val_loss: 1.4024e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9017e-05 - val_loss: 3.8410e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5055e-05 - val_loss: 2.7451e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7477e-05 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.8806e-05 - val_loss: 8.1995e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6786e-05 - val_loss: 8.8801e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8029e-05 - val_loss: 3.5836e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.4756e-06 - val_loss: 9.2298e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.2733e-06 - val_loss: 7.9995e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3553e-05 - val_loss: 2.7467e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.3933e-05 - val_loss: 4.4098e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1249e-05 - val_loss: 2.4064e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.8939e-06 - val_loss: 1.9271e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3896e-05 - val_loss: 1.3820e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8378e-05 - val_loss: 2.8006e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8452e-05 - val_loss: 5.8950e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.3486e-05 - val_loss: 1.1876e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8732e-05 - val_loss: 4.3692e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9086e-05 - val_loss: 9.1659e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0759e-05 - val_loss: 3.2176e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4541e-05 - val_loss: 2.8007e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1630e-05 - val_loss: 5.7777e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8439e-05 - val_loss: 0.0012\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9914e-05 - val_loss: 1.9727e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6593e-05 - val_loss: 2.2460e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7704e-05 - val_loss: 2.2702e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8316e-05 - val_loss: 1.6516e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.6540e-06 - val_loss: 3.1101e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3972e-05 - val_loss: 1.0319e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.8487e-05 - val_loss: 2.5310e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0683e-05 - val_loss: 6.2678e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0305e-05 - val_loss: 1.2607e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0159e-05 - val_loss: 1.2540e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9930e-05 - val_loss: 4.9186e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5178e-05 - val_loss: 6.5936e-06\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0459e-05 - val_loss: 5.1477e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4679e-05 - val_loss: 1.0031e-04\n",
      ">Neurons=65, Score=0.00869685027282685\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 8s 16ms/step - loss: 0.0022 - val_loss: 0.0108\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0083\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.9725e-04 - val_loss: 0.0052\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5722e-04 - val_loss: 0.0029\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5821e-04 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4885e-04 - val_loss: 0.0014\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5311e-04 - val_loss: 2.3775e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3941e-04 - val_loss: 0.0013\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1514e-04 - val_loss: 0.0019\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5217e-04 - val_loss: 8.6512e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3415e-04 - val_loss: 3.8341e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0296e-04 - val_loss: 5.4681e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.5636e-05 - val_loss: 2.5350e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5430e-04 - val_loss: 4.0707e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0456e-04 - val_loss: 4.9657e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.0772e-05 - val_loss: 6.7114e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8392e-05 - val_loss: 6.0412e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.6554e-05 - val_loss: 3.2125e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.7956e-05 - val_loss: 3.9158e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2479e-04 - val_loss: 2.3531e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.0415e-05 - val_loss: 2.8617e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.1351e-05 - val_loss: 2.2553e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.6520e-05 - val_loss: 2.9371e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.4057e-05 - val_loss: 1.6696e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6831e-05 - val_loss: 1.6710e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.0239e-05 - val_loss: 1.4479e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.2732e-05 - val_loss: 6.7610e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9848e-05 - val_loss: 8.2824e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4712e-05 - val_loss: 8.6983e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6893e-05 - val_loss: 1.2992e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2455e-05 - val_loss: 1.3254e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1998e-05 - val_loss: 1.8669e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.0746e-05 - val_loss: 4.8768e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.5120e-05 - val_loss: 4.7091e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5123e-05 - val_loss: 4.3847e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7432e-05 - val_loss: 3.4293e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4355e-05 - val_loss: 3.4616e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2268e-05 - val_loss: 1.1927e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1023e-05 - val_loss: 2.0417e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3439e-05 - val_loss: 3.7325e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6395e-05 - val_loss: 5.0608e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.1142e-05 - val_loss: 2.9806e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.9078e-05 - val_loss: 4.2331e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1901e-05 - val_loss: 1.9527e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6996e-05 - val_loss: 1.6231e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.7473e-05 - val_loss: 9.2469e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.9688e-05 - val_loss: 2.5513e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2724e-05 - val_loss: 3.2107e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4812e-05 - val_loss: 8.6501e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8020e-05 - val_loss: 3.2644e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4267e-05 - val_loss: 9.0175e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7285e-05 - val_loss: 2.2927e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7104e-05 - val_loss: 9.9925e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.2194e-05 - val_loss: 1.5931e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3336e-05 - val_loss: 5.6680e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7108e-05 - val_loss: 3.3218e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6465e-05 - val_loss: 1.5816e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7493e-05 - val_loss: 5.7590e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.3765e-05 - val_loss: 6.7215e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.1601e-05 - val_loss: 4.4503e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7751e-05 - val_loss: 2.9134e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5340e-05 - val_loss: 2.1062e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0111e-05 - val_loss: 3.4025e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3454e-05 - val_loss: 2.5037e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0151e-05 - val_loss: 1.6263e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2113e-05 - val_loss: 3.0721e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.8385e-05 - val_loss: 2.2572e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0931e-05 - val_loss: 4.4099e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4864e-05 - val_loss: 6.8761e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.2987e-05 - val_loss: 2.5841e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5157e-05 - val_loss: 4.2162e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6694e-05 - val_loss: 2.0799e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6371e-05 - val_loss: 8.5322e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8742e-05 - val_loss: 9.3343e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.6144e-05 - val_loss: 3.6248e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7412e-05 - val_loss: 3.4620e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6456e-05 - val_loss: 3.8836e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8534e-05 - val_loss: 8.1243e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6290e-05 - val_loss: 1.4455e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3571e-05 - val_loss: 1.0831e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.4633e-05 - val_loss: 8.2932e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3409e-05 - val_loss: 2.6595e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8181e-05 - val_loss: 1.8829e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7394e-05 - val_loss: 2.3445e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2705e-05 - val_loss: 1.9209e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4048e-05 - val_loss: 4.9171e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0535e-05 - val_loss: 1.7859e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2926e-05 - val_loss: 6.3400e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3478e-05 - val_loss: 1.2054e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7315e-05 - val_loss: 4.4246e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0649e-05 - val_loss: 3.4363e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1024e-05 - val_loss: 4.4284e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6732e-05 - val_loss: 1.9651e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0100e-05 - val_loss: 7.4917e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9620e-05 - val_loss: 9.9245e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5507e-05 - val_loss: 8.9714e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4797e-05 - val_loss: 2.0214e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6486e-05 - val_loss: 8.2570e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.5333e-05 - val_loss: 4.4429e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0336e-05 - val_loss: 4.8674e-05\n",
      ">Neurons=65, Score=0.0035659788409247994\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 18ms/step - loss: 0.0021 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0082\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.5119e-04 - val_loss: 0.0053\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.3122e-04 - val_loss: 0.0026\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1917e-04 - val_loss: 0.0010\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9677e-04 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3078e-04 - val_loss: 3.6904e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5530e-04 - val_loss: 7.0026e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1046e-04 - val_loss: 6.5068e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.8961e-05 - val_loss: 3.5266e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.9241e-05 - val_loss: 4.0236e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.2848e-05 - val_loss: 6.7350e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1951e-04 - val_loss: 4.5039e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5571e-04 - val_loss: 3.2414e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8059e-05 - val_loss: 1.2796e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.9052e-05 - val_loss: 2.2118e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.9791e-05 - val_loss: 3.0748e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.3688e-05 - val_loss: 9.6636e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5122e-05 - val_loss: 1.8172e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2552e-05 - val_loss: 9.9077e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.4977e-05 - val_loss: 1.5876e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.9200e-05 - val_loss: 5.4367e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6406e-05 - val_loss: 1.0689e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.4144e-05 - val_loss: 2.4796e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.1646e-05 - val_loss: 6.8287e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3747e-05 - val_loss: 6.9171e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2058e-05 - val_loss: 7.5568e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7483e-05 - val_loss: 4.0243e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.9709e-05 - val_loss: 9.9045e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.1086e-05 - val_loss: 1.2723e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.5150e-05 - val_loss: 2.5583e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5081e-05 - val_loss: 1.2918e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3113e-05 - val_loss: 7.8925e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.5977e-05 - val_loss: 6.7461e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3934e-05 - val_loss: 8.4322e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.5018e-05 - val_loss: 0.0016\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.4437e-05 - val_loss: 2.3541e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.3457e-05 - val_loss: 6.4536e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0326e-05 - val_loss: 1.5745e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2764e-05 - val_loss: 7.5493e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.2961e-05 - val_loss: 8.5820e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7209e-05 - val_loss: 2.5601e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6585e-05 - val_loss: 2.3170e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1518e-05 - val_loss: 7.3478e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7672e-05 - val_loss: 4.0401e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.2926e-05 - val_loss: 4.1040e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4105e-05 - val_loss: 2.5315e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9471e-05 - val_loss: 2.7086e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.8387e-05 - val_loss: 1.8165e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6007e-05 - val_loss: 3.9200e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9062e-05 - val_loss: 2.9055e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.3215e-05 - val_loss: 2.2468e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9290e-05 - val_loss: 3.4457e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0366e-05 - val_loss: 5.1046e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3548e-05 - val_loss: 2.0060e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.2395e-05 - val_loss: 1.1689e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3616e-05 - val_loss: 1.4485e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5811e-05 - val_loss: 8.8922e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.8282e-05 - val_loss: 9.7254e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7284e-05 - val_loss: 4.1244e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7694e-05 - val_loss: 1.1628e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3156e-05 - val_loss: 1.4375e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5425e-05 - val_loss: 8.3414e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0263e-05 - val_loss: 4.9270e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6131e-05 - val_loss: 2.4257e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.0656e-05 - val_loss: 2.4783e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4812e-05 - val_loss: 4.8089e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.0807e-05 - val_loss: 3.5800e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3076e-05 - val_loss: 8.5641e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6797e-05 - val_loss: 2.5676e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.3858e-05 - val_loss: 1.1277e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7817e-05 - val_loss: 5.9578e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7816e-05 - val_loss: 6.3989e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.9490e-05 - val_loss: 4.5946e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4415e-05 - val_loss: 4.6268e-06\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4158e-05 - val_loss: 2.0916e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6426e-05 - val_loss: 3.0458e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2000e-05 - val_loss: 0.0017\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6817e-05 - val_loss: 8.0391e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7491e-05 - val_loss: 2.3509e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0525e-05 - val_loss: 8.5599e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.8952e-05 - val_loss: 8.2010e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4244e-05 - val_loss: 4.0767e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2359e-05 - val_loss: 8.1998e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6927e-05 - val_loss: 2.2788e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9532e-05 - val_loss: 5.8705e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1457e-05 - val_loss: 1.1865e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1097e-05 - val_loss: 3.1894e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9388e-05 - val_loss: 6.6112e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7450e-05 - val_loss: 3.3850e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4588e-05 - val_loss: 2.1684e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.0606e-05 - val_loss: 8.2290e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5690e-05 - val_loss: 3.4522e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4891e-05 - val_loss: 1.7265e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3506e-05 - val_loss: 3.9269e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8422e-05 - val_loss: 1.2203e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8872e-05 - val_loss: 2.9355e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4799e-05 - val_loss: 7.3808e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4024e-05 - val_loss: 9.9085e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1777e-05 - val_loss: 5.4472e-05\n",
      ">Neurons=65, Score=0.0016808600776130334\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 20ms/step - loss: 0.0020 - val_loss: 0.0102\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.5494e-04 - val_loss: 0.0075\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.0325e-04 - val_loss: 0.0041\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1115e-04 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4022e-04 - val_loss: 6.1554e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5574e-04 - val_loss: 2.3835e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1554e-04 - val_loss: 4.2514e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0234e-04 - val_loss: 4.1268e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0949e-04 - val_loss: 8.1954e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5441e-04 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2693e-04 - val_loss: 5.7064e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.7143e-05 - val_loss: 5.9257e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.7450e-05 - val_loss: 1.4339e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.7978e-05 - val_loss: 1.6331e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.1491e-05 - val_loss: 8.3991e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.0650e-05 - val_loss: 1.1968e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.6466e-05 - val_loss: 1.0592e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0873e-05 - val_loss: 9.2808e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7139e-05 - val_loss: 1.7688e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.7333e-05 - val_loss: 5.5493e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.9120e-05 - val_loss: 2.6455e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.5231e-05 - val_loss: 2.7179e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.6707e-05 - val_loss: 2.0929e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9177e-05 - val_loss: 1.5762e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3799e-05 - val_loss: 2.8036e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5700e-05 - val_loss: 6.4592e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.0094e-05 - val_loss: 1.4242e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2357e-05 - val_loss: 1.0001e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.6801e-05 - val_loss: 0.0015\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.4711e-05 - val_loss: 1.2059e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8096e-05 - val_loss: 1.0462e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5233e-05 - val_loss: 2.4182e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4949e-05 - val_loss: 1.7027e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.9083e-05 - val_loss: 3.4901e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9192e-05 - val_loss: 5.7404e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0549e-05 - val_loss: 2.7253e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3454e-05 - val_loss: 9.2874e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8046e-05 - val_loss: 2.1354e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4193e-05 - val_loss: 1.3478e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5860e-05 - val_loss: 4.5017e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9824e-05 - val_loss: 7.1822e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.1668e-05 - val_loss: 0.0012\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3385e-05 - val_loss: 7.7543e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.3854e-05 - val_loss: 4.9886e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8241e-05 - val_loss: 1.0583e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6698e-05 - val_loss: 8.0597e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3036e-05 - val_loss: 1.5053e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5394e-05 - val_loss: 1.4409e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2614e-05 - val_loss: 9.5178e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1595e-05 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0838e-05 - val_loss: 5.5831e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4111e-05 - val_loss: 5.8913e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8427e-05 - val_loss: 3.7610e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.3798e-05 - val_loss: 5.9521e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2828e-05 - val_loss: 6.6531e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4855e-05 - val_loss: 1.2872e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.6691e-05 - val_loss: 3.5406e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4483e-05 - val_loss: 5.1826e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.7317e-05 - val_loss: 2.7804e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8988e-05 - val_loss: 5.8245e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0201e-05 - val_loss: 2.0809e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7579e-05 - val_loss: 1.8243e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6841e-05 - val_loss: 4.8627e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3404e-05 - val_loss: 8.0858e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9719e-05 - val_loss: 0.0014\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0783e-05 - val_loss: 2.8521e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8779e-05 - val_loss: 3.1436e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4916e-05 - val_loss: 5.1728e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.2487e-05 - val_loss: 5.4507e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.9235e-05 - val_loss: 5.6036e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7633e-05 - val_loss: 1.9645e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2150e-05 - val_loss: 2.5215e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9513e-05 - val_loss: 4.0262e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3537e-05 - val_loss: 3.6731e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7127e-05 - val_loss: 5.7915e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4265e-05 - val_loss: 8.1422e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.4913e-05 - val_loss: 7.1599e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9991e-05 - val_loss: 1.7872e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7576e-05 - val_loss: 3.4294e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2926e-05 - val_loss: 1.1736e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9176e-05 - val_loss: 6.1059e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2308e-05 - val_loss: 1.8269e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5831e-05 - val_loss: 3.1137e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9876e-05 - val_loss: 8.3465e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6754e-05 - val_loss: 3.6678e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3979e-05 - val_loss: 4.7631e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9669e-05 - val_loss: 1.7493e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7980e-05 - val_loss: 1.4592e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3344e-05 - val_loss: 1.6859e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1603e-05 - val_loss: 3.1997e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3566e-05 - val_loss: 7.0646e-06\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9734e-05 - val_loss: 1.4242e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1460e-05 - val_loss: 6.0825e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5951e-05 - val_loss: 3.0013e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5516e-05 - val_loss: 3.5507e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9024e-05 - val_loss: 1.6511e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7703e-05 - val_loss: 8.0963e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.4437e-05 - val_loss: 9.6385e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.8719e-05 - val_loss: 8.7934e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1300e-05 - val_loss: 8.9063e-05\n",
      ">Neurons=70, Score=0.006865151226520538\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 18ms/step - loss: 0.0021 - val_loss: 0.0098\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.9790e-04 - val_loss: 0.0069\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.9447e-04 - val_loss: 0.0037\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7568e-04 - val_loss: 0.0019\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4408e-04 - val_loss: 7.4282e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6386e-04 - val_loss: 3.4862e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.7097e-05 - val_loss: 2.1910e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6417e-04 - val_loss: 5.9674e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1316e-04 - val_loss: 6.4188e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1241e-04 - val_loss: 2.9884e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.1844e-04 - val_loss: 2.3690e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.0355e-05 - val_loss: 3.8377e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3532e-04 - val_loss: 8.1229e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.9691e-05 - val_loss: 6.8683e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8548e-05 - val_loss: 2.7658e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.4125e-05 - val_loss: 6.2433e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.7575e-05 - val_loss: 4.4625e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6540e-05 - val_loss: 9.9281e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0648e-05 - val_loss: 8.9755e-05\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6322e-05 - val_loss: 8.9078e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0107e-05 - val_loss: 5.2008e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3168e-05 - val_loss: 8.7279e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.6603e-05 - val_loss: 5.9750e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8520e-05 - val_loss: 1.6219e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.6052e-05 - val_loss: 2.4874e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0827e-05 - val_loss: 3.3049e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.3393e-05 - val_loss: 0.0011\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0034e-05 - val_loss: 4.5949e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1693e-05 - val_loss: 4.0287e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1289e-05 - val_loss: 5.7867e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.4007e-05 - val_loss: 1.8834e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2008e-05 - val_loss: 2.6711e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.7195e-05 - val_loss: 2.8946e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0936e-05 - val_loss: 8.7561e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7148e-05 - val_loss: 3.5667e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3053e-05 - val_loss: 5.9533e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8344e-05 - val_loss: 2.0702e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1617e-05 - val_loss: 4.7322e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.3351e-05 - val_loss: 5.0459e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2620e-05 - val_loss: 5.0987e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.2673e-05 - val_loss: 3.3331e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7655e-05 - val_loss: 3.2158e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7232e-05 - val_loss: 2.2352e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.8819e-05 - val_loss: 4.8750e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.0269e-05 - val_loss: 3.7018e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5058e-05 - val_loss: 3.8156e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3996e-05 - val_loss: 1.6029e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1080e-05 - val_loss: 8.4291e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8832e-05 - val_loss: 3.5143e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6674e-05 - val_loss: 1.2719e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2196e-05 - val_loss: 2.5556e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5144e-05 - val_loss: 6.4528e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7925e-05 - val_loss: 1.0761e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.9511e-05 - val_loss: 8.9224e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2919e-05 - val_loss: 2.4404e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3057e-05 - val_loss: 5.3639e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0360e-05 - val_loss: 2.3718e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1390e-05 - val_loss: 6.0470e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1961e-05 - val_loss: 3.6439e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2976e-05 - val_loss: 2.8943e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4333e-05 - val_loss: 4.2491e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8997e-05 - val_loss: 4.0213e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0588e-05 - val_loss: 7.8354e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4787e-05 - val_loss: 4.0761e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9875e-05 - val_loss: 3.4841e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.0896e-05 - val_loss: 2.4476e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.8964e-05 - val_loss: 4.8861e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7465e-05 - val_loss: 1.3256e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8811e-05 - val_loss: 9.8442e-06\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4227e-05 - val_loss: 4.1331e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1659e-05 - val_loss: 6.6509e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6478e-05 - val_loss: 3.1321e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.1666e-06 - val_loss: 1.2050e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0719e-05 - val_loss: 1.4699e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.1407e-05 - val_loss: 5.0837e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.3543e-05 - val_loss: 3.0675e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5119e-05 - val_loss: 7.2873e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4426e-05 - val_loss: 2.4331e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9522e-05 - val_loss: 5.0164e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9639e-05 - val_loss: 1.0152e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2303e-05 - val_loss: 1.0113e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7054e-05 - val_loss: 4.7355e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4850e-05 - val_loss: 4.9380e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5934e-05 - val_loss: 2.7590e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4499e-05 - val_loss: 1.0099e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3491e-05 - val_loss: 8.6232e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9158e-05 - val_loss: 2.8125e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7508e-05 - val_loss: 2.1010e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.6468e-05 - val_loss: 6.0567e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9167e-05 - val_loss: 2.4124e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7308e-05 - val_loss: 2.7095e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.8656e-05 - val_loss: 2.2638e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6570e-05 - val_loss: 2.6852e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9017e-05 - val_loss: 1.9810e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0913e-05 - val_loss: 2.8885e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.8495e-05 - val_loss: 1.6473e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2802e-05 - val_loss: 5.3986e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4774e-05 - val_loss: 3.6422e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6347e-05 - val_loss: 0.0012\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9572e-05 - val_loss: 2.8954e-05\n",
      ">Neurons=70, Score=0.0017201069567818195\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 19ms/step - loss: 0.0023 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0078\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6877e-04 - val_loss: 0.0041\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.0458e-04 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6007e-04 - val_loss: 7.8221e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4857e-04 - val_loss: 4.2362e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3569e-04 - val_loss: 4.8381e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.9209e-05 - val_loss: 3.2320e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3718e-04 - val_loss: 6.9010e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.1866e-04 - val_loss: 2.1296e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0803e-04 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.9058e-05 - val_loss: 7.7245e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.0262e-05 - val_loss: 1.8415e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.7992e-05 - val_loss: 2.4371e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.0467e-04 - val_loss: 0.0011\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.4324e-05 - val_loss: 6.6068e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.4163e-05 - val_loss: 1.6727e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.6400e-05 - val_loss: 4.2058e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5983e-04 - val_loss: 0.0017\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9144e-04 - val_loss: 6.0102e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.1930e-05 - val_loss: 2.7288e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0084e-05 - val_loss: 4.0392e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8639e-05 - val_loss: 1.0017e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.8948e-05 - val_loss: 4.9599e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.6503e-05 - val_loss: 7.9998e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.2779e-05 - val_loss: 2.1503e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0546e-05 - val_loss: 5.4633e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5465e-05 - val_loss: 3.9521e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.8599e-05 - val_loss: 7.4210e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6303e-05 - val_loss: 1.5561e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7790e-05 - val_loss: 0.0011\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0729e-04 - val_loss: 0.0013\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.6337e-05 - val_loss: 1.1352e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.2660e-05 - val_loss: 2.2843e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5785e-05 - val_loss: 4.3238e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8488e-05 - val_loss: 4.6142e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1212e-05 - val_loss: 1.1229e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.0085e-05 - val_loss: 1.2692e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6357e-05 - val_loss: 1.3556e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.4767e-05 - val_loss: 1.1055e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2634e-05 - val_loss: 1.3017e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.7152e-05 - val_loss: 3.3657e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9027e-05 - val_loss: 8.6501e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.6890e-05 - val_loss: 1.8061e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0697e-05 - val_loss: 1.4053e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6853e-05 - val_loss: 6.8368e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2400e-05 - val_loss: 3.9027e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9105e-05 - val_loss: 9.1578e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4123e-05 - val_loss: 4.7016e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7450e-05 - val_loss: 4.3989e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3350e-05 - val_loss: 4.3811e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9302e-05 - val_loss: 2.0931e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8226e-05 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.4914e-05 - val_loss: 3.3268e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8923e-05 - val_loss: 9.4697e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4658e-05 - val_loss: 1.3845e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3955e-05 - val_loss: 2.5156e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4533e-05 - val_loss: 1.4700e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1844e-05 - val_loss: 9.3914e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.5707e-05 - val_loss: 3.8918e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7303e-05 - val_loss: 1.0833e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8562e-05 - val_loss: 9.9810e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.6130e-05 - val_loss: 3.7086e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6905e-05 - val_loss: 5.3154e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1154e-05 - val_loss: 3.5345e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.9219e-05 - val_loss: 5.2579e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8425e-05 - val_loss: 4.1300e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 3.8801e-05 - val_loss: 3.9205e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2388e-05 - val_loss: 1.2895e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.5359e-05 - val_loss: 7.5945e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2414e-05 - val_loss: 3.5249e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.3442e-05 - val_loss: 4.1614e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7600e-05 - val_loss: 3.7071e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8984e-05 - val_loss: 7.7347e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2159e-05 - val_loss: 8.0313e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1440e-05 - val_loss: 1.9958e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5670e-05 - val_loss: 4.4969e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3244e-05 - val_loss: 5.4139e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 3.9008e-05 - val_loss: 7.5439e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.2816e-05 - val_loss: 4.8888e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.0938e-05 - val_loss: 2.8586e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.5891e-05 - val_loss: 1.8776e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8127e-05 - val_loss: 4.8726e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4313e-05 - val_loss: 4.3484e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8032e-05 - val_loss: 3.8030e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1771e-05 - val_loss: 0.0013\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.6591e-05 - val_loss: 6.5594e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4976e-05 - val_loss: 1.7380e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2015e-05 - val_loss: 2.0946e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7257e-05 - val_loss: 4.6683e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3670e-05 - val_loss: 2.7277e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0869e-05 - val_loss: 6.5689e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4568e-05 - val_loss: 3.9750e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 1.2678e-05 - val_loss: 2.2781e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8912e-05 - val_loss: 2.0149e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8779e-05 - val_loss: 5.5911e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9676e-05 - val_loss: 1.2103e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1082e-05 - val_loss: 2.7798e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7774e-05 - val_loss: 6.4268e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7418e-05 - val_loss: 2.1363e-04\n",
      ">Neurons=70, Score=0.011062935664085671\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 25ms/step - loss: 0.0021 - val_loss: 0.0103\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.9194e-04 - val_loss: 0.0075\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1784e-04 - val_loss: 0.0044\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7391e-04 - val_loss: 0.0021\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0846e-04 - val_loss: 7.1247e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9146e-04 - val_loss: 3.9327e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1269e-04 - val_loss: 3.9924e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3384e-04 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2909e-04 - val_loss: 2.5394e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0663e-04 - val_loss: 6.9545e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8832e-05 - val_loss: 5.5229e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.4986e-05 - val_loss: 0.0027\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.0989e-05 - val_loss: 1.3572e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7407e-05 - val_loss: 3.5511e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.9776e-05 - val_loss: 1.7374e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.9074e-05 - val_loss: 3.5236e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.6213e-05 - val_loss: 6.1516e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3178e-04 - val_loss: 9.4964e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1740e-04 - val_loss: 1.8919e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.8010e-05 - val_loss: 2.3756e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1598e-05 - val_loss: 5.5543e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.4818e-05 - val_loss: 5.1264e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4597e-05 - val_loss: 0.0012\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.1189e-05 - val_loss: 8.3511e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.6754e-05 - val_loss: 3.0982e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.0763e-05 - val_loss: 1.0425e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.1448e-05 - val_loss: 7.6350e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0429e-04 - val_loss: 6.1275e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.4651e-05 - val_loss: 1.1218e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1139e-05 - val_loss: 4.6941e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.6536e-05 - val_loss: 4.0650e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4641e-05 - val_loss: 6.8229e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.6560e-05 - val_loss: 5.3443e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.7006e-05 - val_loss: 7.7745e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6792e-05 - val_loss: 1.6095e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3927e-05 - val_loss: 4.6262e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5133e-05 - val_loss: 3.4480e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4139e-05 - val_loss: 6.7395e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1346e-05 - val_loss: 1.4697e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4401e-05 - val_loss: 2.1594e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3472e-05 - val_loss: 3.8190e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.1301e-05 - val_loss: 2.6560e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2367e-05 - val_loss: 5.4147e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3368e-05 - val_loss: 6.3317e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.2299e-05 - val_loss: 8.0597e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8359e-05 - val_loss: 4.9786e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7365e-05 - val_loss: 2.2859e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5679e-05 - val_loss: 7.0068e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5212e-05 - val_loss: 6.4858e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7277e-05 - val_loss: 7.4327e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9454e-05 - val_loss: 2.3197e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.0151e-05 - val_loss: 1.2997e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0018e-05 - val_loss: 2.7230e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.3238e-05 - val_loss: 2.2735e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1067e-05 - val_loss: 3.0588e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9552e-05 - val_loss: 1.1655e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4193e-05 - val_loss: 7.3267e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7638e-05 - val_loss: 4.1323e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9626e-05 - val_loss: 2.8965e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.6293e-05 - val_loss: 1.1071e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0579e-05 - val_loss: 1.3448e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0862e-05 - val_loss: 2.3114e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0907e-05 - val_loss: 1.4205e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6119e-05 - val_loss: 2.3511e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3095e-05 - val_loss: 1.3389e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5000e-05 - val_loss: 9.3531e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0229e-05 - val_loss: 7.1876e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7849e-05 - val_loss: 1.6290e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4188e-05 - val_loss: 1.8912e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5292e-05 - val_loss: 1.1523e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6460e-05 - val_loss: 2.0808e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.3756e-06 - val_loss: 1.2072e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6316e-05 - val_loss: 2.4901e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8460e-05 - val_loss: 8.5845e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2981e-05 - val_loss: 2.7133e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4660e-05 - val_loss: 6.5198e-06\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4601e-05 - val_loss: 1.6497e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9063e-05 - val_loss: 1.2227e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4551e-05 - val_loss: 3.2962e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6505e-05 - val_loss: 7.9918e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3847e-05 - val_loss: 1.2045e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0904e-05 - val_loss: 9.1824e-06\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5888e-05 - val_loss: 6.2687e-06\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0229e-05 - val_loss: 1.8280e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6661e-05 - val_loss: 5.8463e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1313e-05 - val_loss: 3.1072e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.6453e-05 - val_loss: 9.0387e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0864e-05 - val_loss: 5.4278e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0062e-05 - val_loss: 4.3264e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9006e-05 - val_loss: 6.6102e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1498e-05 - val_loss: 4.4806e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3788e-05 - val_loss: 1.3707e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.3014e-05 - val_loss: 8.6383e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.1991e-05 - val_loss: 1.0258e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6693e-05 - val_loss: 8.9952e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1234e-05 - val_loss: 4.5203e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4687e-05 - val_loss: 1.4637e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3135e-05 - val_loss: 3.8272e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7615e-05 - val_loss: 1.9179e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0389e-05 - val_loss: 4.4054e-04\n",
      ">Neurons=70, Score=0.023931957548484206\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 20ms/step - loss: 0.0022 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.9475e-04 - val_loss: 0.0075\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.2337e-04 - val_loss: 0.0042\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.2832e-04 - val_loss: 0.0020\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6491e-04 - val_loss: 8.0420e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3850e-04 - val_loss: 6.2821e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.5845e-05 - val_loss: 3.3173e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0538e-04 - val_loss: 3.8566e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.1747e-05 - val_loss: 4.8032e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.1947e-05 - val_loss: 2.6195e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3200e-04 - val_loss: 7.8266e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.3242e-05 - val_loss: 5.5711e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.2776e-05 - val_loss: 4.8817e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2837e-04 - val_loss: 0.0011\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0755e-04 - val_loss: 4.2954e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.5865e-05 - val_loss: 3.0856e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.0649e-05 - val_loss: 5.0385e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.6625e-05 - val_loss: 1.1659e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3421e-05 - val_loss: 4.5335e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9769e-05 - val_loss: 1.9667e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.4593e-05 - val_loss: 2.2845e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.9446e-05 - val_loss: 2.4774e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6026e-05 - val_loss: 2.8621e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.2546e-05 - val_loss: 5.2821e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.1100e-05 - val_loss: 5.3216e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.0242e-05 - val_loss: 2.1194e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.9714e-05 - val_loss: 2.5841e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.9882e-05 - val_loss: 2.2459e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3438e-05 - val_loss: 2.1268e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3131e-05 - val_loss: 3.6566e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.5448e-05 - val_loss: 5.3563e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3159e-05 - val_loss: 1.8388e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7537e-05 - val_loss: 7.6843e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8009e-05 - val_loss: 2.3743e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4053e-05 - val_loss: 2.4120e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3804e-05 - val_loss: 3.3951e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.9445e-05 - val_loss: 1.1446e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3778e-05 - val_loss: 2.6818e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4345e-05 - val_loss: 2.6357e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3518e-05 - val_loss: 2.8006e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9720e-05 - val_loss: 3.9208e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3875e-05 - val_loss: 5.9153e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4547e-05 - val_loss: 2.9012e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6608e-05 - val_loss: 7.2255e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.3231e-05 - val_loss: 2.3872e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.0316e-05 - val_loss: 8.0426e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9522e-05 - val_loss: 3.5478e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9631e-05 - val_loss: 1.6425e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2913e-05 - val_loss: 2.9069e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1255e-05 - val_loss: 4.2412e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5689e-05 - val_loss: 1.9179e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4113e-05 - val_loss: 6.0196e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0101e-05 - val_loss: 4.7632e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1810e-05 - val_loss: 8.3117e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1634e-05 - val_loss: 5.2989e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3268e-05 - val_loss: 3.5963e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7252e-05 - val_loss: 6.3696e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.8111e-05 - val_loss: 1.2489e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1027e-05 - val_loss: 1.2817e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.1757e-05 - val_loss: 5.5823e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8828e-05 - val_loss: 5.7803e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7015e-05 - val_loss: 1.2226e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0068e-05 - val_loss: 4.2392e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9386e-05 - val_loss: 1.8668e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9206e-05 - val_loss: 8.5951e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6239e-05 - val_loss: 3.0028e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3080e-05 - val_loss: 4.8158e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7072e-05 - val_loss: 5.0079e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8952e-05 - val_loss: 2.2249e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4221e-05 - val_loss: 3.3118e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.7459e-05 - val_loss: 1.0122e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6125e-05 - val_loss: 9.6758e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3863e-05 - val_loss: 1.6146e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.8606e-05 - val_loss: 1.3508e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8867e-05 - val_loss: 2.5815e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.6045e-05 - val_loss: 1.1553e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.2854e-06 - val_loss: 9.2143e-06\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3849e-05 - val_loss: 1.8174e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6511e-05 - val_loss: 2.6933e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0116e-05 - val_loss: 5.0444e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2689e-05 - val_loss: 2.8001e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3778e-05 - val_loss: 3.3800e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5075e-05 - val_loss: 3.2770e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4235e-05 - val_loss: 6.1233e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3440e-05 - val_loss: 6.9427e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5882e-05 - val_loss: 2.3876e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9603e-05 - val_loss: 9.1451e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0480e-05 - val_loss: 1.7363e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5300e-05 - val_loss: 1.4718e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1747e-05 - val_loss: 8.0190e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4499e-05 - val_loss: 0.0010\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7226e-05 - val_loss: 5.5401e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3826e-05 - val_loss: 3.0195e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9104e-05 - val_loss: 2.3118e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5813e-05 - val_loss: 5.4973e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3769e-05 - val_loss: 7.4852e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4595e-05 - val_loss: 1.7670e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.0621e-06 - val_loss: 7.0943e-06\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0029e-05 - val_loss: 1.7262e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.9747e-06 - val_loss: 1.4179e-05\n",
      ">Neurons=70, Score=0.0015589756003464572\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 19ms/step - loss: 0.0022 - val_loss: 0.0107\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0078\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.0384e-04 - val_loss: 0.0043\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.7269e-04 - val_loss: 0.0018\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6175e-04 - val_loss: 8.0358e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2168e-04 - val_loss: 0.0016\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1237e-04 - val_loss: 1.6897e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5949e-04 - val_loss: 9.7642e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5746e-04 - val_loss: 8.1243e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.8257e-05 - val_loss: 3.8884e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4938e-04 - val_loss: 8.3449e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1379e-04 - val_loss: 3.2623e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2127e-05 - val_loss: 6.2583e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.6163e-05 - val_loss: 4.7354e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1124e-04 - val_loss: 0.0019\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.0537e-05 - val_loss: 7.3587e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.8589e-05 - val_loss: 4.5691e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.1927e-05 - val_loss: 1.6127e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1264e-04 - val_loss: 4.5023e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.0636e-05 - val_loss: 3.7143e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0713e-05 - val_loss: 1.2869e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.9116e-05 - val_loss: 9.1234e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.4055e-05 - val_loss: 1.0650e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.6456e-05 - val_loss: 3.0222e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6236e-05 - val_loss: 7.4305e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.9690e-05 - val_loss: 2.3021e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0269e-04 - val_loss: 7.8370e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0237e-05 - val_loss: 1.7635e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1158e-05 - val_loss: 1.2687e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2858e-05 - val_loss: 4.6580e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7303e-05 - val_loss: 6.8842e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3052e-05 - val_loss: 2.4326e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.7786e-05 - val_loss: 1.7422e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8370e-05 - val_loss: 2.5627e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2943e-05 - val_loss: 7.1639e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6804e-05 - val_loss: 5.5429e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0150e-05 - val_loss: 4.2121e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4168e-05 - val_loss: 1.4251e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.0029e-05 - val_loss: 9.3502e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.0209e-05 - val_loss: 1.0670e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2310e-05 - val_loss: 5.4272e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3939e-05 - val_loss: 6.2842e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.0109e-05 - val_loss: 9.9538e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0318e-05 - val_loss: 5.3965e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5610e-05 - val_loss: 1.4190e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2640e-05 - val_loss: 6.4791e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3461e-05 - val_loss: 5.1057e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.7966e-05 - val_loss: 4.7680e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0389e-05 - val_loss: 5.8285e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1841e-05 - val_loss: 9.8212e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6362e-05 - val_loss: 1.3022e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5556e-05 - val_loss: 3.7864e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7381e-05 - val_loss: 8.1011e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.8014e-05 - val_loss: 4.9823e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9234e-05 - val_loss: 4.4201e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0971e-05 - val_loss: 3.0171e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2917e-05 - val_loss: 5.9510e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3623e-05 - val_loss: 4.5077e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7465e-05 - val_loss: 4.9635e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.5200e-05 - val_loss: 6.4430e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9101e-05 - val_loss: 8.1184e-06\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.0624e-05 - val_loss: 0.0011\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.5729e-05 - val_loss: 8.3615e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.0638e-05 - val_loss: 2.5323e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5788e-05 - val_loss: 2.3017e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2654e-05 - val_loss: 6.0556e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.0410e-05 - val_loss: 7.3663e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9221e-05 - val_loss: 1.6398e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5811e-05 - val_loss: 1.8274e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9932e-05 - val_loss: 2.9458e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.4315e-05 - val_loss: 4.5453e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8615e-05 - val_loss: 2.7990e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1692e-05 - val_loss: 1.1235e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5370e-05 - val_loss: 1.6963e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.6307e-05 - val_loss: 4.5282e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.4880e-05 - val_loss: 0.0013\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5082e-05 - val_loss: 1.0619e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.1718e-05 - val_loss: 2.7730e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8280e-05 - val_loss: 1.5422e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7554e-05 - val_loss: 1.1183e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0733e-05 - val_loss: 2.5869e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6245e-05 - val_loss: 1.4240e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3003e-05 - val_loss: 2.7955e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3094e-05 - val_loss: 3.4171e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7364e-05 - val_loss: 3.3727e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2831e-05 - val_loss: 2.3191e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3939e-05 - val_loss: 2.3859e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2973e-05 - val_loss: 8.6002e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2704e-05 - val_loss: 7.6566e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5290e-05 - val_loss: 6.8062e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6657e-05 - val_loss: 1.8811e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8746e-05 - val_loss: 2.8729e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2667e-05 - val_loss: 1.9495e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5760e-05 - val_loss: 3.4721e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.6272e-05 - val_loss: 2.7481e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3750e-05 - val_loss: 9.8912e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8411e-05 - val_loss: 4.9802e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0205e-05 - val_loss: 2.9379e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1401e-05 - val_loss: 4.0720e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3933e-05 - val_loss: 1.3253e-04\n",
      ">Neurons=70, Score=0.0064973799453582615\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 20ms/step - loss: 0.0022 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.8490e-04 - val_loss: 0.0079\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.8508e-04 - val_loss: 0.0050\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.0328e-04 - val_loss: 0.0026\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5750e-04 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9735e-04 - val_loss: 4.7153e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1031e-04 - val_loss: 2.5751e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.3221e-05 - val_loss: 0.0013\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.6397e-05 - val_loss: 2.9455e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.3751e-05 - val_loss: 2.7797e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3868e-05 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2836e-04 - val_loss: 4.6350e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.4820e-05 - val_loss: 6.7842e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5155e-04 - val_loss: 4.1220e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.3202e-05 - val_loss: 1.8420e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.5372e-05 - val_loss: 8.2116e-05\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.2493e-05 - val_loss: 3.4776e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.8529e-05 - val_loss: 4.5462e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.0770e-05 - val_loss: 0.0010\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9784e-05 - val_loss: 5.2300e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.2911e-05 - val_loss: 5.1130e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.7140e-05 - val_loss: 6.1493e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.4349e-05 - val_loss: 0.0020\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.9002e-05 - val_loss: 1.5225e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.8055e-05 - val_loss: 9.6457e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.5936e-05 - val_loss: 4.2596e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0234e-04 - val_loss: 3.8176e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9044e-05 - val_loss: 1.3784e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.0802e-05 - val_loss: 5.1151e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1495e-05 - val_loss: 2.2356e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3143e-05 - val_loss: 6.1691e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7861e-05 - val_loss: 4.6341e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.2500e-05 - val_loss: 2.6432e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2654e-04 - val_loss: 6.9518e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7000e-05 - val_loss: 3.7316e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7867e-05 - val_loss: 3.3965e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7563e-05 - val_loss: 1.5727e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6270e-05 - val_loss: 3.3714e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.7271e-05 - val_loss: 4.7818e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0614e-05 - val_loss: 1.1857e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4844e-05 - val_loss: 1.9073e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2026e-05 - val_loss: 4.4945e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6468e-05 - val_loss: 4.9373e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3306e-05 - val_loss: 7.0038e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4419e-05 - val_loss: 1.0845e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4686e-05 - val_loss: 1.8881e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5213e-05 - val_loss: 2.8989e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0939e-05 - val_loss: 6.9846e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5143e-05 - val_loss: 1.2509e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1991e-05 - val_loss: 5.3821e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6140e-05 - val_loss: 1.1153e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2867e-05 - val_loss: 6.0915e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1664e-05 - val_loss: 2.6773e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4252e-05 - val_loss: 1.0051e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.6398e-05 - val_loss: 0.0017\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.9045e-05 - val_loss: 6.1206e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7987e-05 - val_loss: 1.2124e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.5245e-06 - val_loss: 8.0382e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1667e-05 - val_loss: 2.0698e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0369e-05 - val_loss: 2.1779e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0575e-05 - val_loss: 1.0346e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7798e-05 - val_loss: 7.1580e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8236e-05 - val_loss: 3.3257e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5399e-05 - val_loss: 8.5512e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3518e-05 - val_loss: 1.4241e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5300e-05 - val_loss: 6.0731e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7706e-05 - val_loss: 3.3238e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3738e-05 - val_loss: 1.4734e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8855e-05 - val_loss: 1.2901e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2645e-05 - val_loss: 2.7469e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.4768e-05 - val_loss: 3.2031e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7816e-05 - val_loss: 5.3876e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5487e-05 - val_loss: 3.7296e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7749e-05 - val_loss: 2.6174e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9759e-05 - val_loss: 3.9958e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7534e-05 - val_loss: 2.2685e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.7273e-05 - val_loss: 1.8403e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4167e-05 - val_loss: 3.5648e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.2518e-05 - val_loss: 2.9148e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2620e-05 - val_loss: 1.4946e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5395e-05 - val_loss: 3.1694e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7772e-05 - val_loss: 1.1409e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2311e-05 - val_loss: 9.6362e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4879e-05 - val_loss: 8.5289e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9533e-05 - val_loss: 3.0499e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4324e-05 - val_loss: 1.0765e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5134e-05 - val_loss: 1.6845e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4722e-05 - val_loss: 2.5604e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7921e-05 - val_loss: 2.4904e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.7770e-05 - val_loss: 0.0013\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8841e-05 - val_loss: 8.0353e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3347e-05 - val_loss: 2.7487e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3884e-05 - val_loss: 2.4375e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2769e-05 - val_loss: 4.4086e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9293e-05 - val_loss: 2.8757e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8186e-05 - val_loss: 1.3168e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.3952e-05 - val_loss: 2.1080e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0414e-05 - val_loss: 3.2246e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1217e-05 - val_loss: 3.5475e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1745e-05 - val_loss: 3.7337e-05\n",
      ">Neurons=70, Score=0.003971258411183953\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 19ms/step - loss: 0.0022 - val_loss: 0.0098\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.9723e-04 - val_loss: 0.0065\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.3988e-04 - val_loss: 0.0033\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3191e-04 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0563e-04 - val_loss: 6.9951e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3624e-04 - val_loss: 3.2458e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5644e-04 - val_loss: 1.9601e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0410e-04 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4111e-04 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7111e-04 - val_loss: 7.6700e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0497e-04 - val_loss: 5.1131e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4213e-05 - val_loss: 4.9769e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3954e-05 - val_loss: 5.2264e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2602e-04 - val_loss: 7.0790e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4952e-04 - val_loss: 0.0016\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1568e-04 - val_loss: 2.6737e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0074e-04 - val_loss: 1.4115e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.9534e-05 - val_loss: 5.3477e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1232e-05 - val_loss: 7.3691e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.6377e-05 - val_loss: 2.1417e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7529e-05 - val_loss: 0.0012\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5333e-05 - val_loss: 2.4189e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.7376e-05 - val_loss: 1.4275e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3493e-05 - val_loss: 1.0070e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.7362e-05 - val_loss: 5.4133e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.4484e-05 - val_loss: 6.1878e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.3623e-05 - val_loss: 4.2495e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3852e-05 - val_loss: 1.1806e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4429e-05 - val_loss: 1.2463e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6689e-05 - val_loss: 4.2593e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.2594e-05 - val_loss: 4.2838e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8931e-05 - val_loss: 6.3535e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0687e-05 - val_loss: 2.9684e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8492e-05 - val_loss: 1.0175e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0767e-05 - val_loss: 3.7873e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.9718e-05 - val_loss: 0.0012\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0016e-04 - val_loss: 3.8613e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.5665e-05 - val_loss: 8.0709e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4977e-05 - val_loss: 6.1123e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4748e-05 - val_loss: 4.3727e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7123e-05 - val_loss: 1.8005e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4500e-05 - val_loss: 1.4084e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4029e-05 - val_loss: 2.7137e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4987e-05 - val_loss: 2.7139e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2131e-05 - val_loss: 3.2419e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.1783e-05 - val_loss: 1.2799e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.8546e-05 - val_loss: 2.6193e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5185e-05 - val_loss: 2.1031e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9065e-05 - val_loss: 3.3410e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7002e-05 - val_loss: 1.9096e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6486e-05 - val_loss: 2.1413e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1185e-05 - val_loss: 3.4657e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3163e-05 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.9367e-05 - val_loss: 0.0015\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.2002e-05 - val_loss: 7.5313e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5558e-05 - val_loss: 2.9457e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.4506e-05 - val_loss: 1.5796e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.0256e-05 - val_loss: 2.7136e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7718e-05 - val_loss: 2.9615e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5009e-05 - val_loss: 2.9516e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4240e-05 - val_loss: 5.5551e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6084e-05 - val_loss: 5.5621e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.9151e-05 - val_loss: 8.8692e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5199e-05 - val_loss: 9.3710e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6264e-05 - val_loss: 8.0813e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1852e-05 - val_loss: 8.7079e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6882e-05 - val_loss: 1.6198e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5922e-05 - val_loss: 3.1261e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7055e-05 - val_loss: 6.9072e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2235e-05 - val_loss: 1.7964e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8411e-05 - val_loss: 1.8575e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.8559e-05 - val_loss: 4.0783e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6843e-05 - val_loss: 2.3033e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0571e-05 - val_loss: 9.4604e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6753e-05 - val_loss: 1.6243e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.4538e-05 - val_loss: 5.1075e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8221e-05 - val_loss: 2.0467e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4456e-05 - val_loss: 2.2523e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.0344e-05 - val_loss: 3.2712e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5696e-05 - val_loss: 5.9829e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7834e-05 - val_loss: 8.2537e-06\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4371e-05 - val_loss: 1.3007e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6918e-05 - val_loss: 4.2066e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.2077e-05 - val_loss: 3.3098e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3174e-05 - val_loss: 3.7910e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2384e-05 - val_loss: 2.9528e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.1824e-05 - val_loss: 2.3418e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 3.2553e-05 - val_loss: 4.8311e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.6335e-05 - val_loss: 0.0012\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 2.8846e-05 - val_loss: 1.4167e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9658e-05 - val_loss: 2.9706e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4119e-05 - val_loss: 3.9671e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3859e-05 - val_loss: 2.8408e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7962e-05 - val_loss: 1.3095e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7175e-05 - val_loss: 4.7922e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0342e-05 - val_loss: 4.1577e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4180e-05 - val_loss: 2.2119e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7375e-05 - val_loss: 1.7149e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5486e-05 - val_loss: 3.6784e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0553e-05 - val_loss: 8.4628e-04\n",
      ">Neurons=70, Score=0.04302272282075137\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 19ms/step - loss: 0.0023 - val_loss: 0.0107\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 0.0010 - val_loss: 0.0081\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.2582e-04 - val_loss: 0.0050\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.1567e-04 - val_loss: 0.0026\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9508e-04 - val_loss: 0.0013\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9236e-04 - val_loss: 7.3453e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2415e-04 - val_loss: 3.6356e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1394e-04 - val_loss: 8.9432e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0439e-04 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.5605e-05 - val_loss: 0.0024\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.1013e-04 - val_loss: 4.2857e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.5380e-05 - val_loss: 0.0019\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.5013e-05 - val_loss: 5.2325e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0832e-04 - val_loss: 3.0976e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1248e-05 - val_loss: 2.6334e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9239e-05 - val_loss: 0.0011\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.7456e-05 - val_loss: 0.0011\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.8436e-05 - val_loss: 4.4319e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2865e-05 - val_loss: 0.0011\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4318e-05 - val_loss: 8.5911e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.0418e-05 - val_loss: 2.2528e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.4292e-05 - val_loss: 1.8558e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7641e-05 - val_loss: 4.4051e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7569e-05 - val_loss: 3.7638e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2716e-04 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0544e-04 - val_loss: 4.3324e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4370e-05 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4629e-05 - val_loss: 5.6765e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.7752e-05 - val_loss: 5.2066e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7195e-05 - val_loss: 2.8026e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.1914e-05 - val_loss: 2.7304e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.4287e-05 - val_loss: 1.4560e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0321e-05 - val_loss: 1.2584e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.0257e-05 - val_loss: 3.0758e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9804e-05 - val_loss: 5.6786e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9500e-05 - val_loss: 1.1447e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6660e-05 - val_loss: 4.2629e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2572e-05 - val_loss: 2.0622e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9503e-05 - val_loss: 3.0504e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4165e-05 - val_loss: 1.3431e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1829e-05 - val_loss: 3.3987e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.9377e-05 - val_loss: 1.1765e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.4622e-05 - val_loss: 2.4974e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0658e-05 - val_loss: 1.2235e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4589e-05 - val_loss: 1.5500e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1038e-05 - val_loss: 1.5049e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4619e-05 - val_loss: 5.5248e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6673e-05 - val_loss: 1.0586e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5870e-05 - val_loss: 1.3676e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9336e-05 - val_loss: 8.6418e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5537e-05 - val_loss: 1.1552e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1181e-05 - val_loss: 1.8948e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3809e-05 - val_loss: 6.0825e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8665e-05 - val_loss: 3.6311e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7432e-05 - val_loss: 3.0317e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4675e-05 - val_loss: 7.6627e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.6836e-05 - val_loss: 4.0714e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8522e-05 - val_loss: 6.3072e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.8676e-05 - val_loss: 1.4176e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4899e-05 - val_loss: 1.0200e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4928e-05 - val_loss: 3.2094e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7712e-05 - val_loss: 5.6920e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8275e-05 - val_loss: 1.8735e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.3919e-05 - val_loss: 2.6709e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1530e-05 - val_loss: 5.5755e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6678e-05 - val_loss: 1.5726e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6701e-05 - val_loss: 9.6121e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8936e-05 - val_loss: 1.4564e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7351e-05 - val_loss: 3.0347e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.8313e-05 - val_loss: 5.9639e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8195e-05 - val_loss: 4.1724e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6189e-05 - val_loss: 1.5500e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5927e-05 - val_loss: 7.5509e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5700e-05 - val_loss: 2.4899e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3313e-05 - val_loss: 6.5610e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.9874e-06 - val_loss: 1.7750e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6084e-05 - val_loss: 2.6061e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1947e-05 - val_loss: 3.2255e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.7848e-05 - val_loss: 0.0017\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.7242e-05 - val_loss: 4.8166e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3790e-05 - val_loss: 4.8089e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5616e-05 - val_loss: 2.3524e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5379e-05 - val_loss: 1.3505e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1960e-05 - val_loss: 1.9243e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0762e-05 - val_loss: 1.4751e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.1046e-05 - val_loss: 6.6168e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2614e-05 - val_loss: 4.0140e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3938e-05 - val_loss: 3.6705e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.3138e-05 - val_loss: 2.6803e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8254e-05 - val_loss: 8.4106e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1367e-05 - val_loss: 3.8273e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9902e-05 - val_loss: 3.1249e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8703e-05 - val_loss: 1.3929e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5643e-05 - val_loss: 3.4226e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3869e-05 - val_loss: 3.4920e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1067e-05 - val_loss: 5.0329e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0679e-05 - val_loss: 3.9280e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2589e-05 - val_loss: 5.8890e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0820e-05 - val_loss: 1.1138e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1111e-05 - val_loss: 3.3150e-05\n",
      ">Neurons=70, Score=0.0029536231522797607\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 22ms/step - loss: 0.0023 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.9049e-04 - val_loss: 0.0074\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8385e-04 - val_loss: 0.0040\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9519e-04 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7709e-04 - val_loss: 5.1748e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2552e-04 - val_loss: 4.2609e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4907e-04 - val_loss: 5.5304e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6029e-04 - val_loss: 0.0020\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.5200e-05 - val_loss: 3.0008e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0579e-04 - val_loss: 3.5750e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1207e-04 - val_loss: 2.1129e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.4635e-05 - val_loss: 0.0015\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.2809e-05 - val_loss: 1.7645e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1625e-04 - val_loss: 8.0617e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0925e-05 - val_loss: 3.8758e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3684e-05 - val_loss: 1.6814e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0865e-04 - val_loss: 2.8768e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0993e-04 - val_loss: 4.2328e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.9454e-05 - val_loss: 6.9166e-05\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9306e-05 - val_loss: 6.6213e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.0474e-05 - val_loss: 4.9987e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.5834e-05 - val_loss: 1.8977e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.7697e-05 - val_loss: 1.8661e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1808e-05 - val_loss: 1.1969e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.5818e-05 - val_loss: 7.7021e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.4341e-05 - val_loss: 7.9233e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3339e-05 - val_loss: 1.4834e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6491e-05 - val_loss: 9.5289e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7260e-05 - val_loss: 3.7708e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.7738e-05 - val_loss: 7.9723e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0078e-05 - val_loss: 1.1432e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6922e-04 - val_loss: 0.0019\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1317e-04 - val_loss: 1.2677e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3415e-05 - val_loss: 1.7494e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4675e-05 - val_loss: 2.8202e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3560e-05 - val_loss: 9.2694e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2252e-05 - val_loss: 1.9712e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7785e-05 - val_loss: 1.4756e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3647e-05 - val_loss: 5.5636e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.5645e-05 - val_loss: 8.2258e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.8680e-05 - val_loss: 5.1217e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3102e-05 - val_loss: 7.6587e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9176e-05 - val_loss: 3.8176e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3475e-05 - val_loss: 2.3982e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8256e-05 - val_loss: 3.2287e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7483e-05 - val_loss: 7.6414e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1592e-05 - val_loss: 2.5425e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5650e-05 - val_loss: 1.9875e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.8675e-05 - val_loss: 4.1546e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8319e-05 - val_loss: 5.5527e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.7267e-05 - val_loss: 2.1004e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8386e-05 - val_loss: 1.7824e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0400e-05 - val_loss: 2.9729e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8045e-05 - val_loss: 3.7149e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0345e-05 - val_loss: 9.6814e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2450e-05 - val_loss: 1.0745e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9295e-05 - val_loss: 7.0165e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.4723e-05 - val_loss: 5.5110e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.0467e-05 - val_loss: 2.3569e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3136e-05 - val_loss: 1.6126e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2016e-05 - val_loss: 2.8886e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0552e-05 - val_loss: 3.6073e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5332e-05 - val_loss: 2.6793e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5756e-05 - val_loss: 3.7512e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0991e-05 - val_loss: 1.8185e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1981e-05 - val_loss: 3.8910e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6400e-05 - val_loss: 1.7574e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4034e-05 - val_loss: 2.5349e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4553e-05 - val_loss: 3.2637e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.2396e-05 - val_loss: 3.2565e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9059e-05 - val_loss: 1.1654e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.8891e-05 - val_loss: 3.7676e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6276e-05 - val_loss: 2.5651e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9187e-05 - val_loss: 1.2934e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5807e-05 - val_loss: 5.8393e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7763e-05 - val_loss: 2.0942e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4153e-05 - val_loss: 3.3972e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1332e-05 - val_loss: 1.1603e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3871e-05 - val_loss: 6.8114e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4890e-05 - val_loss: 8.1257e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5313e-05 - val_loss: 1.4260e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9880e-05 - val_loss: 6.6375e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9029e-05 - val_loss: 2.4310e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2566e-05 - val_loss: 2.8656e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3635e-05 - val_loss: 8.7133e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0366e-05 - val_loss: 6.6045e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3439e-05 - val_loss: 7.5651e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7076e-05 - val_loss: 6.6905e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9675e-05 - val_loss: 3.7889e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2335e-05 - val_loss: 2.4297e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8658e-05 - val_loss: 6.8717e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0100e-05 - val_loss: 1.0636e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4751e-05 - val_loss: 6.2377e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0430e-05 - val_loss: 3.2508e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9239e-05 - val_loss: 2.3516e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4719e-05 - val_loss: 1.2470e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3479e-05 - val_loss: 1.6980e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3858e-05 - val_loss: 1.3451e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3384e-05 - val_loss: 7.7045e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6934e-05 - val_loss: 6.5917e-05\n",
      ">Neurons=70, Score=0.0038043901440687478\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 21ms/step - loss: 0.0022 - val_loss: 0.0104\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0081\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.2907e-04 - val_loss: 0.0046\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5280e-04 - val_loss: 0.0021\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0065e-04 - val_loss: 9.0145e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6730e-04 - val_loss: 0.0013\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1906e-04 - val_loss: 4.0683e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.4532e-05 - val_loss: 1.6500e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.4916e-05 - val_loss: 1.2355e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.4670e-05 - val_loss: 8.0609e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.6393e-05 - val_loss: 1.3805e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3369e-05 - val_loss: 9.4789e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.3024e-05 - val_loss: 4.7839e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.3665e-05 - val_loss: 5.1503e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1478e-04 - val_loss: 5.2992e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.1276e-05 - val_loss: 1.0734e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.6310e-05 - val_loss: 6.3225e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2157e-04 - val_loss: 7.6901e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.1167e-05 - val_loss: 5.8211e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7768e-05 - val_loss: 1.8444e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.7907e-05 - val_loss: 6.6741e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.1502e-05 - val_loss: 8.0362e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.2801e-05 - val_loss: 9.4205e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.4543e-05 - val_loss: 7.0354e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.4879e-05 - val_loss: 6.1737e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6193e-05 - val_loss: 7.7951e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.8498e-05 - val_loss: 1.8381e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.3951e-05 - val_loss: 1.2978e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1578e-05 - val_loss: 7.9276e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.0234e-05 - val_loss: 5.7337e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.2971e-05 - val_loss: 5.1713e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2920e-05 - val_loss: 2.0364e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8986e-05 - val_loss: 1.2712e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6313e-05 - val_loss: 1.0281e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5884e-05 - val_loss: 5.6715e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.1469e-05 - val_loss: 3.0543e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2882e-05 - val_loss: 1.6348e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3570e-05 - val_loss: 7.5323e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1665e-05 - val_loss: 1.7294e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4566e-05 - val_loss: 1.5632e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.1144e-05 - val_loss: 3.9987e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3720e-05 - val_loss: 2.3329e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2363e-05 - val_loss: 4.5760e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0445e-05 - val_loss: 3.0690e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9568e-05 - val_loss: 8.1492e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5138e-05 - val_loss: 9.3088e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1177e-05 - val_loss: 4.9900e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.9891e-05 - val_loss: 4.1145e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9218e-05 - val_loss: 7.6617e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.9221e-05 - val_loss: 1.4177e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.0274e-05 - val_loss: 4.9874e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9694e-05 - val_loss: 3.0332e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2145e-05 - val_loss: 2.9385e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4088e-05 - val_loss: 2.6265e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5640e-05 - val_loss: 3.9157e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.2788e-05 - val_loss: 8.9631e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5591e-05 - val_loss: 9.1244e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3245e-05 - val_loss: 1.5154e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8412e-05 - val_loss: 4.2394e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8218e-05 - val_loss: 8.5137e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2475e-05 - val_loss: 4.7806e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.9874e-05 - val_loss: 2.0671e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7957e-05 - val_loss: 2.1500e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.8370e-05 - val_loss: 7.8036e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3139e-05 - val_loss: 5.7710e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8435e-05 - val_loss: 4.5767e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2667e-05 - val_loss: 1.9308e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2545e-05 - val_loss: 1.0691e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.5091e-05 - val_loss: 1.5463e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.8826e-05 - val_loss: 1.1871e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.6041e-05 - val_loss: 3.3899e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3485e-05 - val_loss: 1.2928e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.8811e-06 - val_loss: 7.0758e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3206e-05 - val_loss: 2.4512e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8843e-05 - val_loss: 2.1869e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5568e-05 - val_loss: 5.9955e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4136e-05 - val_loss: 6.4567e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6469e-05 - val_loss: 2.5980e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2183e-05 - val_loss: 2.8358e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3556e-05 - val_loss: 3.3367e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.8759e-05 - val_loss: 9.5941e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.4823e-05 - val_loss: 2.8264e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4825e-05 - val_loss: 8.4026e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0993e-05 - val_loss: 6.3679e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1466e-05 - val_loss: 3.3038e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.0704e-06 - val_loss: 5.5516e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2124e-05 - val_loss: 9.5225e-06\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.0840e-05 - val_loss: 2.3351e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4245e-05 - val_loss: 4.8680e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4542e-05 - val_loss: 1.3146e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8700e-05 - val_loss: 1.5175e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9991e-05 - val_loss: 9.7120e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9630e-05 - val_loss: 2.3945e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3410e-05 - val_loss: 5.4566e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1238e-05 - val_loss: 5.9188e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.3102e-05 - val_loss: 3.1040e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.7680e-05 - val_loss: 2.8722e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1447e-05 - val_loss: 1.0489e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.8123e-05 - val_loss: 1.1448e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5082e-05 - val_loss: 1.5109e-05\n",
      ">Neurons=75, Score=0.002792458326439373\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 18ms/step - loss: 0.0021 - val_loss: 0.0104\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 0.0011 - val_loss: 0.0072\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6477e-04 - val_loss: 0.0035\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8443e-04 - val_loss: 0.0015\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6594e-04 - val_loss: 7.8038e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.9312e-04 - val_loss: 5.2943e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.1960e-04 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3626e-04 - val_loss: 6.9082e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3590e-04 - val_loss: 0.0023\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.5369e-05 - val_loss: 9.8910e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7583e-04 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2824e-04 - val_loss: 8.0447e-05\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.6627e-05 - val_loss: 8.8636e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.1612e-05 - val_loss: 5.4077e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.5578e-05 - val_loss: 5.6686e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.1248e-05 - val_loss: 1.3626e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.5067e-05 - val_loss: 1.6269e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4342e-05 - val_loss: 0.0011\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4037e-05 - val_loss: 1.4763e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.7218e-05 - val_loss: 4.4457e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.2462e-05 - val_loss: 1.6331e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9521e-05 - val_loss: 1.5838e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.5188e-05 - val_loss: 2.6581e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5153e-04 - val_loss: 0.0012\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0981e-04 - val_loss: 6.8277e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.3076e-05 - val_loss: 1.3664e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.9348e-05 - val_loss: 2.0689e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1703e-05 - val_loss: 2.3766e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.9382e-05 - val_loss: 2.9585e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.3522e-05 - val_loss: 3.6316e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.9333e-05 - val_loss: 5.2903e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6887e-05 - val_loss: 5.5953e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3043e-05 - val_loss: 2.6147e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.3910e-05 - val_loss: 6.5436e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4753e-05 - val_loss: 5.8558e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7300e-05 - val_loss: 6.3971e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1075e-05 - val_loss: 4.2739e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4956e-05 - val_loss: 3.8735e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1593e-05 - val_loss: 9.5233e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1632e-05 - val_loss: 2.3932e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3058e-05 - val_loss: 6.2381e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6423e-05 - val_loss: 3.9192e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9663e-05 - val_loss: 5.5729e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5968e-05 - val_loss: 9.1408e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9588e-05 - val_loss: 4.2233e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2448e-05 - val_loss: 6.0659e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0071e-05 - val_loss: 2.0370e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9252e-05 - val_loss: 7.6756e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1390e-05 - val_loss: 3.5854e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5361e-05 - val_loss: 6.4174e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3053e-05 - val_loss: 5.7821e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2345e-05 - val_loss: 3.7360e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1152e-05 - val_loss: 1.1109e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6234e-05 - val_loss: 6.2443e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4946e-05 - val_loss: 9.7339e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.2284e-05 - val_loss: 1.3147e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9480e-05 - val_loss: 1.3367e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7591e-05 - val_loss: 5.5595e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2562e-05 - val_loss: 1.1548e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1111e-05 - val_loss: 7.3351e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5743e-05 - val_loss: 2.8357e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0071e-05 - val_loss: 2.6019e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4450e-05 - val_loss: 2.4849e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6922e-05 - val_loss: 2.2992e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3755e-05 - val_loss: 3.4533e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8488e-05 - val_loss: 6.5493e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0392e-05 - val_loss: 3.2429e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0855e-05 - val_loss: 2.9056e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1042e-05 - val_loss: 4.5204e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8444e-05 - val_loss: 3.4600e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.7293e-05 - val_loss: 8.6772e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3897e-05 - val_loss: 1.9193e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7298e-05 - val_loss: 0.0012\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9450e-05 - val_loss: 1.7837e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7650e-05 - val_loss: 5.4141e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9419e-05 - val_loss: 7.3090e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3948e-05 - val_loss: 7.5230e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5870e-05 - val_loss: 3.5225e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4783e-05 - val_loss: 5.5029e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4063e-05 - val_loss: 1.1322e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0756e-05 - val_loss: 1.2012e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8742e-05 - val_loss: 9.4161e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4957e-05 - val_loss: 8.1638e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.8646e-05 - val_loss: 1.0967e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6360e-05 - val_loss: 9.1904e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9700e-05 - val_loss: 1.5783e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0212e-05 - val_loss: 1.0221e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2273e-05 - val_loss: 2.2150e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0049e-05 - val_loss: 6.7068e-06\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9271e-05 - val_loss: 9.3492e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8943e-05 - val_loss: 8.2372e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6542e-05 - val_loss: 5.7721e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7991e-05 - val_loss: 3.3203e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3021e-05 - val_loss: 1.8359e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3678e-05 - val_loss: 1.5330e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4697e-05 - val_loss: 1.2424e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8869e-05 - val_loss: 2.5805e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7226e-05 - val_loss: 3.4177e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1495e-05 - val_loss: 2.3569e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6593e-05 - val_loss: 1.9896e-04\n",
      ">Neurons=75, Score=0.009416597458766773\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 24ms/step - loss: 0.0021 - val_loss: 0.0104\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.9724e-04 - val_loss: 0.0076\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4228e-04 - val_loss: 0.0045\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0863e-04 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8237e-04 - val_loss: 5.3604e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4102e-04 - val_loss: 2.1197e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1801e-04 - val_loss: 5.0603e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2895e-04 - val_loss: 1.5692e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.9457e-05 - val_loss: 8.8637e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1576e-04 - val_loss: 6.9862e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0957e-04 - val_loss: 4.7209e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4378e-05 - val_loss: 2.3388e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.5884e-05 - val_loss: 1.2133e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.5042e-05 - val_loss: 5.9681e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.3264e-05 - val_loss: 3.9723e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2229e-04 - val_loss: 8.7167e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0225e-04 - val_loss: 7.7384e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2653e-05 - val_loss: 1.1727e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.6926e-05 - val_loss: 4.8433e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3970e-05 - val_loss: 1.0191e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1217e-04 - val_loss: 9.6099e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.1895e-04 - val_loss: 2.5215e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.5957e-05 - val_loss: 5.7449e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.5441e-05 - val_loss: 1.6818e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2764e-05 - val_loss: 2.3317e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.7232e-05 - val_loss: 1.1214e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.6247e-05 - val_loss: 3.7220e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.5874e-05 - val_loss: 1.7375e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7162e-05 - val_loss: 1.4934e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3244e-05 - val_loss: 6.6581e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4464e-05 - val_loss: 3.8065e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2772e-05 - val_loss: 8.0836e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0284e-05 - val_loss: 7.0043e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8514e-05 - val_loss: 5.1108e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0387e-05 - val_loss: 7.1225e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.9248e-05 - val_loss: 3.2278e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8306e-05 - val_loss: 5.2167e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.5758e-05 - val_loss: 9.2340e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2711e-05 - val_loss: 2.6458e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5384e-05 - val_loss: 1.6939e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3062e-05 - val_loss: 2.5401e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0048e-05 - val_loss: 3.3554e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.6262e-05 - val_loss: 4.5256e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 3.5210e-05 - val_loss: 1.0297e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.7382e-05 - val_loss: 2.1901e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3626e-05 - val_loss: 1.1700e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8996e-05 - val_loss: 1.5532e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3179e-05 - val_loss: 2.8860e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1578e-05 - val_loss: 3.0689e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4722e-05 - val_loss: 9.4899e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9472e-05 - val_loss: 4.1062e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9492e-05 - val_loss: 7.1634e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8062e-05 - val_loss: 6.1690e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.8917e-05 - val_loss: 0.0020\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.6368e-05 - val_loss: 7.1756e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0739e-05 - val_loss: 5.1878e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5125e-05 - val_loss: 6.6091e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2272e-05 - val_loss: 3.3782e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9547e-05 - val_loss: 2.1799e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.2896e-05 - val_loss: 1.5228e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0046e-05 - val_loss: 1.6069e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2315e-05 - val_loss: 2.3569e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6926e-05 - val_loss: 1.8082e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8139e-05 - val_loss: 1.5670e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7111e-05 - val_loss: 2.0007e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.0541e-05 - val_loss: 1.9683e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1136e-05 - val_loss: 4.9475e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2675e-05 - val_loss: 2.9840e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3535e-05 - val_loss: 2.9763e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6857e-05 - val_loss: 1.1144e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6525e-05 - val_loss: 1.5646e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.6105e-06 - val_loss: 8.2954e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5451e-05 - val_loss: 2.1447e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2104e-05 - val_loss: 1.9230e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2290e-05 - val_loss: 6.6643e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 1.6440e-05 - val_loss: 3.5255e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 2.4618e-05 - val_loss: 3.8553e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.3057e-05 - val_loss: 2.4893e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.3592e-05 - val_loss: 7.5062e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.7706e-05 - val_loss: 3.2391e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 2.7350e-05 - val_loss: 4.6370e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.7825e-05 - val_loss: 6.7111e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.7785e-05 - val_loss: 2.5621e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3928e-05 - val_loss: 2.2704e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1424e-05 - val_loss: 3.1418e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.5126e-05 - val_loss: 5.3469e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3886e-05 - val_loss: 6.2161e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.0026e-05 - val_loss: 2.7098e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.6937e-05 - val_loss: 1.4722e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.6109e-05 - val_loss: 1.0964e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.0687e-05 - val_loss: 6.3830e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1225e-05 - val_loss: 5.0742e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8454e-05 - val_loss: 2.5503e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3994e-05 - val_loss: 2.3725e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6303e-05 - val_loss: 9.6361e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.5277e-05 - val_loss: 2.1618e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4234e-05 - val_loss: 6.8834e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7625e-05 - val_loss: 5.9693e-06\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1789e-05 - val_loss: 1.3171e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 2.5719e-05 - val_loss: 1.8748e-04\n",
      ">Neurons=75, Score=0.013245521404314786\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 18s 32ms/step - loss: 0.0021 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 0.0010 - val_loss: 0.0080\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 7.3714e-04 - val_loss: 0.0051\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.5800e-04 - val_loss: 0.0025\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 3.6786e-04 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.8122e-04 - val_loss: 3.0621e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.5223e-04 - val_loss: 2.2923e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.4652e-04 - val_loss: 6.3400e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.3574e-05 - val_loss: 5.7358e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.6209e-05 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0242e-04 - val_loss: 6.7439e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.5355e-05 - val_loss: 2.5627e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0467e-04 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.0648e-05 - val_loss: 2.2481e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 7.8556e-05 - val_loss: 3.6610e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.3706e-04 - val_loss: 8.0025e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.1320e-04 - val_loss: 1.6762e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.1798e-04 - val_loss: 6.9978e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 8.1166e-05 - val_loss: 0.0010\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 3.9375e-05 - val_loss: 1.6890e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.3513e-05 - val_loss: 5.2912e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.3840e-05 - val_loss: 2.0776e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 5.6620e-05 - val_loss: 1.6157e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8254e-05 - val_loss: 7.4405e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.6327e-05 - val_loss: 1.7264e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.9435e-05 - val_loss: 5.1772e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.9644e-05 - val_loss: 2.2999e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7987e-05 - val_loss: 1.2340e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.6689e-05 - val_loss: 1.4371e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.8077e-05 - val_loss: 1.0944e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.4328e-05 - val_loss: 7.0084e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.7804e-05 - val_loss: 5.0183e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.9271e-05 - val_loss: 4.6596e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.5279e-05 - val_loss: 2.9150e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.7182e-05 - val_loss: 5.6619e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.7020e-05 - val_loss: 1.5397e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8354e-05 - val_loss: 6.0439e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8320e-05 - val_loss: 3.5826e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6705e-05 - val_loss: 2.1388e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.9307e-05 - val_loss: 5.6513e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2689e-05 - val_loss: 2.5832e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6400e-05 - val_loss: 2.0193e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0543e-05 - val_loss: 1.0182e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9746e-05 - val_loss: 1.9607e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.6862e-05 - val_loss: 6.2150e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 2.8258e-05 - val_loss: 1.2832e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.2093e-05 - val_loss: 2.4055e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 3.8874e-05 - val_loss: 6.9581e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 5.1896e-05 - val_loss: 1.4982e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 2.3156e-05 - val_loss: 2.9187e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.0442e-05 - val_loss: 2.7534e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5635e-05 - val_loss: 2.3030e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4081e-05 - val_loss: 3.5670e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0163e-05 - val_loss: 1.2831e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.9507e-05 - val_loss: 3.8669e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0413e-05 - val_loss: 1.8246e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3214e-05 - val_loss: 1.6754e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.1733e-06 - val_loss: 2.6458e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1390e-05 - val_loss: 3.1385e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4106e-05 - val_loss: 1.2200e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3802e-05 - val_loss: 6.1136e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5289e-05 - val_loss: 9.6350e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3793e-05 - val_loss: 1.2365e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.8197e-05 - val_loss: 1.6977e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9056e-05 - val_loss: 8.8140e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.5928e-05 - val_loss: 4.6918e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5487e-05 - val_loss: 1.4286e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3164e-05 - val_loss: 6.2779e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4081e-05 - val_loss: 1.3876e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3486e-05 - val_loss: 1.5243e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6849e-05 - val_loss: 8.4597e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.4480e-05 - val_loss: 5.2735e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6045e-05 - val_loss: 5.2424e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.5915e-05 - val_loss: 2.8495e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.2221e-05 - val_loss: 5.7482e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.5556e-05 - val_loss: 1.9136e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.0615e-05 - val_loss: 6.7590e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4526e-05 - val_loss: 9.9018e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4761e-05 - val_loss: 9.5648e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1771e-05 - val_loss: 3.8827e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7169e-05 - val_loss: 7.2785e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1066e-05 - val_loss: 1.2971e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5436e-05 - val_loss: 2.9564e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4982e-05 - val_loss: 8.6649e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.9919e-06 - val_loss: 5.4890e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.9773e-06 - val_loss: 8.2644e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2877e-05 - val_loss: 4.4156e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7228e-05 - val_loss: 4.6850e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7087e-05 - val_loss: 3.0058e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5327e-05 - val_loss: 1.4482e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1100e-05 - val_loss: 5.2986e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.5513e-05 - val_loss: 1.6730e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3411e-05 - val_loss: 1.8470e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6050e-05 - val_loss: 2.4295e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.8854e-06 - val_loss: 1.3370e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6574e-05 - val_loss: 4.6141e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6861e-05 - val_loss: 6.3316e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4993e-05 - val_loss: 5.3846e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7504e-05 - val_loss: 5.1103e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3280e-05 - val_loss: 1.2970e-05\n",
      ">Neurons=75, Score=0.0008165790859493427\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 20ms/step - loss: 0.0022 - val_loss: 0.0104\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0075\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.1862e-04 - val_loss: 0.0041\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9765e-04 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3385e-04 - val_loss: 7.5813e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3785e-04 - val_loss: 5.4356e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4702e-04 - val_loss: 0.0010\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0261e-04 - val_loss: 3.8219e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.9439e-05 - val_loss: 3.0155e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.8457e-05 - val_loss: 0.0018\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0859e-04 - val_loss: 2.5398e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.2679e-05 - val_loss: 1.2406e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7856e-05 - val_loss: 3.8470e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6097e-05 - val_loss: 2.3297e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.3512e-05 - val_loss: 1.8056e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.9067e-05 - val_loss: 1.0249e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.8188e-05 - val_loss: 0.0019\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3428e-05 - val_loss: 5.0463e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1473e-05 - val_loss: 1.2548e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0090e-05 - val_loss: 2.7478e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0898e-05 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7707e-05 - val_loss: 2.2980e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.5519e-05 - val_loss: 6.8428e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.7122e-05 - val_loss: 3.4095e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.1959e-05 - val_loss: 4.4169e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.3970e-05 - val_loss: 4.1608e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.6285e-05 - val_loss: 4.1161e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2677e-05 - val_loss: 1.8476e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.8391e-05 - val_loss: 2.0703e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6404e-05 - val_loss: 7.0499e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4841e-05 - val_loss: 1.8352e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8918e-05 - val_loss: 3.8585e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2145e-05 - val_loss: 1.3572e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8239e-05 - val_loss: 1.1248e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2714e-05 - val_loss: 1.4914e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3820e-05 - val_loss: 6.1860e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5030e-05 - val_loss: 6.8486e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.5768e-05 - val_loss: 8.2689e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7127e-05 - val_loss: 1.8895e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2856e-05 - val_loss: 3.0731e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6597e-05 - val_loss: 3.0048e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8324e-05 - val_loss: 8.7415e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3262e-05 - val_loss: 1.9069e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6243e-05 - val_loss: 7.6590e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8707e-05 - val_loss: 3.9524e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9387e-05 - val_loss: 9.7174e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.3089e-05 - val_loss: 3.9279e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3190e-05 - val_loss: 4.4219e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8916e-05 - val_loss: 3.2454e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8656e-05 - val_loss: 1.5364e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.0011e-05 - val_loss: 2.6897e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.4978e-05 - val_loss: 2.9240e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6140e-05 - val_loss: 9.4977e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2022e-05 - val_loss: 4.4509e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3076e-05 - val_loss: 4.8163e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8342e-05 - val_loss: 4.3993e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8145e-05 - val_loss: 1.6488e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2284e-05 - val_loss: 9.0178e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5367e-05 - val_loss: 1.4230e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6545e-05 - val_loss: 5.0898e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2524e-05 - val_loss: 3.4025e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8484e-05 - val_loss: 2.8900e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8718e-05 - val_loss: 2.8324e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5511e-05 - val_loss: 2.0468e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7436e-05 - val_loss: 5.4013e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6130e-05 - val_loss: 2.7089e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6552e-05 - val_loss: 2.3367e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8248e-05 - val_loss: 2.2129e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0330e-05 - val_loss: 2.3642e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7190e-05 - val_loss: 2.0966e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2715e-05 - val_loss: 6.5167e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0939e-05 - val_loss: 2.5345e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7546e-05 - val_loss: 7.4700e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.3662e-05 - val_loss: 5.9112e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2686e-05 - val_loss: 3.4192e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6639e-05 - val_loss: 9.3870e-06\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5498e-05 - val_loss: 9.5567e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1664e-05 - val_loss: 8.8770e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.0150e-06 - val_loss: 3.0750e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7774e-05 - val_loss: 3.3006e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2814e-05 - val_loss: 1.2114e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1215e-05 - val_loss: 3.4114e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9958e-05 - val_loss: 2.2951e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9572e-05 - val_loss: 2.0759e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9406e-05 - val_loss: 2.6424e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8033e-05 - val_loss: 2.4343e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7199e-05 - val_loss: 6.3698e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5896e-05 - val_loss: 9.3792e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8241e-05 - val_loss: 1.3858e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0849e-05 - val_loss: 9.7798e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1330e-05 - val_loss: 3.6209e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6976e-05 - val_loss: 5.7358e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7014e-05 - val_loss: 2.5067e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.7562e-06 - val_loss: 2.4933e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1949e-05 - val_loss: 5.5063e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0858e-05 - val_loss: 3.7747e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3342e-05 - val_loss: 2.2318e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1208e-05 - val_loss: 1.2134e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9922e-05 - val_loss: 6.1006e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1246e-05 - val_loss: 1.4264e-04\n",
      ">Neurons=75, Score=0.009613935253582895\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 21ms/step - loss: 0.0023 - val_loss: 0.0107\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0082\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.4714e-04 - val_loss: 0.0050\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9420e-04 - val_loss: 0.0024\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0656e-04 - val_loss: 0.0010\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4277e-04 - val_loss: 2.8341e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6544e-04 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4104e-04 - val_loss: 0.0016\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.1527e-04 - val_loss: 0.0016\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.6892e-05 - val_loss: 0.0010\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8902e-05 - val_loss: 0.0010\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.6667e-05 - val_loss: 1.6744e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8415e-05 - val_loss: 2.2513e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8840e-05 - val_loss: 0.0012\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.1910e-05 - val_loss: 7.1432e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4405e-05 - val_loss: 5.8445e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.6258e-05 - val_loss: 7.7065e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.2949e-05 - val_loss: 3.3981e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5916e-05 - val_loss: 0.0012\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5838e-05 - val_loss: 0.0021\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4125e-05 - val_loss: 4.3788e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.4894e-05 - val_loss: 4.0342e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.4874e-05 - val_loss: 1.6906e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.3523e-05 - val_loss: 3.9819e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9147e-05 - val_loss: 7.4866e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7443e-05 - val_loss: 4.9941e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8807e-05 - val_loss: 4.1892e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9120e-05 - val_loss: 3.3963e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.9678e-05 - val_loss: 1.6339e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9157e-05 - val_loss: 1.5502e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3617e-05 - val_loss: 7.8890e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5696e-05 - val_loss: 9.8335e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.6894e-05 - val_loss: 7.1797e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3452e-04 - val_loss: 0.0015\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.6645e-05 - val_loss: 1.6236e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3143e-05 - val_loss: 7.7697e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5526e-05 - val_loss: 2.3178e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.0027e-05 - val_loss: 5.5172e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.2395e-05 - val_loss: 0.0013\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.1419e-05 - val_loss: 5.2918e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4591e-05 - val_loss: 6.5722e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8382e-05 - val_loss: 1.0540e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5524e-05 - val_loss: 3.6309e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.5442e-05 - val_loss: 1.6865e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7429e-05 - val_loss: 1.1842e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8550e-05 - val_loss: 6.7425e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3097e-05 - val_loss: 3.0041e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5261e-05 - val_loss: 1.5838e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1956e-05 - val_loss: 4.8326e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6360e-05 - val_loss: 7.0576e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3711e-05 - val_loss: 2.2736e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1747e-05 - val_loss: 3.0381e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6229e-05 - val_loss: 1.4559e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9233e-05 - val_loss: 1.1870e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5710e-05 - val_loss: 3.3083e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5510e-05 - val_loss: 0.0012\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9226e-05 - val_loss: 2.0870e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.8646e-05 - val_loss: 7.8797e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9109e-05 - val_loss: 4.0059e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9494e-05 - val_loss: 7.0139e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7116e-05 - val_loss: 2.8655e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2186e-05 - val_loss: 1.4503e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2310e-05 - val_loss: 5.0716e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6292e-05 - val_loss: 2.6648e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5377e-05 - val_loss: 2.3435e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1088e-05 - val_loss: 1.2444e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5784e-05 - val_loss: 9.1207e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4652e-05 - val_loss: 2.7581e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0180e-05 - val_loss: 1.2970e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0291e-05 - val_loss: 0.0012\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3869e-05 - val_loss: 4.8210e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4054e-05 - val_loss: 5.2938e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5153e-05 - val_loss: 1.3388e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3953e-05 - val_loss: 1.0161e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3324e-05 - val_loss: 3.7275e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7035e-05 - val_loss: 1.7530e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1938e-05 - val_loss: 3.7182e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9315e-05 - val_loss: 1.5231e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9160e-05 - val_loss: 8.3805e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6250e-05 - val_loss: 1.4066e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2086e-05 - val_loss: 2.2493e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6430e-05 - val_loss: 5.0687e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1134e-05 - val_loss: 7.9017e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3707e-05 - val_loss: 3.0634e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7907e-05 - val_loss: 2.1937e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4287e-05 - val_loss: 8.0213e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1667e-05 - val_loss: 8.2144e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2631e-05 - val_loss: 3.2805e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4005e-05 - val_loss: 2.5438e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.7699e-05 - val_loss: 1.0110e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0496e-05 - val_loss: 6.9208e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9753e-05 - val_loss: 5.3903e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9341e-05 - val_loss: 4.3427e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2006e-05 - val_loss: 3.9706e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.3777e-05 - val_loss: 2.2855e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.2065e-05 - val_loss: 1.7601e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 1.1152e-05 - val_loss: 9.9071e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7026e-05 - val_loss: 9.7439e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8069e-05 - val_loss: 8.6818e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5441e-05 - val_loss: 4.2070e-04\n",
      ">Neurons=75, Score=0.021845227456651628\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 21ms/step - loss: 0.0022 - val_loss: 0.0110\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 0.0010 - val_loss: 0.0078\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.6723e-04 - val_loss: 0.0046\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.7540e-04 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1121e-04 - val_loss: 6.8973e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5991e-04 - val_loss: 2.7609e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1390e-04 - val_loss: 0.0011\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0991e-04 - val_loss: 2.5055e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1707e-04 - val_loss: 7.8749e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1083e-04 - val_loss: 3.9825e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.0568e-05 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1917e-05 - val_loss: 8.0746e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1506e-04 - val_loss: 3.2541e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.3546e-05 - val_loss: 0.0011\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1211e-04 - val_loss: 3.9807e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.7389e-05 - val_loss: 8.9958e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1441e-04 - val_loss: 6.5150e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2238e-04 - val_loss: 5.4164e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.3843e-05 - val_loss: 1.2083e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9884e-05 - val_loss: 2.5043e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2664e-05 - val_loss: 1.2014e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5482e-05 - val_loss: 3.7739e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1836e-05 - val_loss: 3.5437e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3282e-05 - val_loss: 1.9877e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2477e-04 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.3894e-05 - val_loss: 9.0555e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8083e-05 - val_loss: 2.3454e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.0849e-05 - val_loss: 4.4008e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.3731e-05 - val_loss: 3.5651e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.7620e-05 - val_loss: 2.7901e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7479e-05 - val_loss: 4.6881e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2151e-05 - val_loss: 2.9968e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9893e-05 - val_loss: 2.1686e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4683e-05 - val_loss: 7.1190e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8794e-05 - val_loss: 1.9589e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8175e-05 - val_loss: 4.2356e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8846e-05 - val_loss: 8.9634e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7754e-05 - val_loss: 9.1001e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.6223e-05 - val_loss: 2.5099e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4091e-05 - val_loss: 2.5194e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2571e-05 - val_loss: 1.4409e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2831e-05 - val_loss: 1.2773e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0385e-05 - val_loss: 5.0877e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8648e-05 - val_loss: 2.0393e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1472e-05 - val_loss: 4.1931e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5850e-05 - val_loss: 3.0939e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1653e-05 - val_loss: 1.2449e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0163e-05 - val_loss: 5.7732e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5520e-05 - val_loss: 6.7623e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8512e-05 - val_loss: 3.8728e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5813e-05 - val_loss: 1.4740e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3113e-05 - val_loss: 1.9333e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.9216e-05 - val_loss: 0.0015\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3941e-05 - val_loss: 1.3666e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8289e-05 - val_loss: 3.1055e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3623e-05 - val_loss: 2.3633e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3219e-05 - val_loss: 6.1609e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0592e-05 - val_loss: 1.0614e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9274e-05 - val_loss: 1.0525e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2015e-05 - val_loss: 1.9240e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5385e-05 - val_loss: 5.2743e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2785e-05 - val_loss: 2.6705e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6172e-05 - val_loss: 4.6942e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1290e-05 - val_loss: 7.3706e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0070e-05 - val_loss: 5.9313e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8913e-05 - val_loss: 3.6998e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3060e-05 - val_loss: 1.8570e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2713e-05 - val_loss: 2.5493e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5512e-05 - val_loss: 2.0957e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6461e-05 - val_loss: 1.0208e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8729e-05 - val_loss: 3.9615e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1385e-05 - val_loss: 1.9842e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4119e-05 - val_loss: 8.7922e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8140e-05 - val_loss: 7.2964e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2324e-05 - val_loss: 2.1346e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.6267e-05 - val_loss: 4.6888e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0525e-05 - val_loss: 1.1943e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7576e-05 - val_loss: 4.0831e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9421e-05 - val_loss: 4.6568e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8315e-05 - val_loss: 1.8487e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6785e-05 - val_loss: 3.3973e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2466e-05 - val_loss: 8.4106e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7113e-05 - val_loss: 1.8245e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6118e-05 - val_loss: 1.5174e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0037e-05 - val_loss: 3.7003e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8185e-05 - val_loss: 1.6627e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0579e-05 - val_loss: 1.3314e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5281e-05 - val_loss: 4.5167e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0177e-05 - val_loss: 2.6668e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8623e-05 - val_loss: 2.5329e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1709e-05 - val_loss: 5.7556e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9342e-05 - val_loss: 5.1339e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5817e-05 - val_loss: 2.6032e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4885e-05 - val_loss: 1.4386e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9214e-05 - val_loss: 4.4847e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0534e-05 - val_loss: 1.0957e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.7528e-05 - val_loss: 8.0635e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.8477e-05 - val_loss: 8.3888e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.4920e-05 - val_loss: 3.7048e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6585e-05 - val_loss: 5.2483e-04\n",
      ">Neurons=75, Score=0.02693254209589213\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 22ms/step - loss: 0.0023 - val_loss: 0.0104\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.2938e-04 - val_loss: 0.0073\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7686e-04 - val_loss: 0.0044\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6705e-04 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1455e-04 - val_loss: 8.4131e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5327e-04 - val_loss: 3.4012e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2348e-04 - val_loss: 2.5646e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7237e-05 - val_loss: 7.9605e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7852e-05 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3206e-04 - val_loss: 4.6458e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7678e-04 - val_loss: 0.0019\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3813e-04 - val_loss: 6.1031e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1522e-04 - val_loss: 1.4648e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4877e-04 - val_loss: 7.2778e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0628e-04 - val_loss: 1.0333e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.4543e-05 - val_loss: 7.7939e-05\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0876e-05 - val_loss: 1.3953e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8143e-05 - val_loss: 1.3172e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.6319e-05 - val_loss: 7.1438e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4089e-05 - val_loss: 2.3258e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0268e-04 - val_loss: 3.3052e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3899e-05 - val_loss: 1.6672e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.4455e-05 - val_loss: 2.6054e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.8323e-05 - val_loss: 6.5736e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5880e-05 - val_loss: 6.0183e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4044e-05 - val_loss: 1.4001e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6054e-05 - val_loss: 3.7470e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6735e-05 - val_loss: 4.6754e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7007e-05 - val_loss: 1.7261e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0516e-05 - val_loss: 2.9959e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7041e-05 - val_loss: 4.9976e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8308e-05 - val_loss: 2.5281e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8220e-05 - val_loss: 2.6048e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.9233e-05 - val_loss: 1.4234e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0190e-05 - val_loss: 2.3832e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.8895e-05 - val_loss: 4.7801e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.0901e-05 - val_loss: 6.2948e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4725e-05 - val_loss: 4.5375e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.0361e-05 - val_loss: 2.3437e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4067e-05 - val_loss: 2.8202e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7145e-05 - val_loss: 2.0408e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1668e-05 - val_loss: 5.6725e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5797e-05 - val_loss: 1.3080e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0540e-05 - val_loss: 5.4246e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0560e-05 - val_loss: 1.1938e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1875e-05 - val_loss: 1.7673e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5442e-05 - val_loss: 7.4314e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3110e-05 - val_loss: 9.3096e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5836e-05 - val_loss: 3.0646e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8095e-05 - val_loss: 9.1608e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8397e-05 - val_loss: 9.6899e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.0662e-05 - val_loss: 2.8539e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7589e-05 - val_loss: 9.7001e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6199e-05 - val_loss: 2.4462e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4645e-05 - val_loss: 4.1527e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6879e-05 - val_loss: 2.9686e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5718e-05 - val_loss: 2.7780e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2410e-05 - val_loss: 5.7231e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4287e-05 - val_loss: 1.0423e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8956e-05 - val_loss: 5.2404e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9744e-05 - val_loss: 1.8066e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1251e-05 - val_loss: 1.2204e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1053e-05 - val_loss: 5.7540e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.0652e-05 - val_loss: 7.0185e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9235e-05 - val_loss: 4.1772e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1682e-05 - val_loss: 2.9986e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5837e-05 - val_loss: 1.0159e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2510e-05 - val_loss: 6.9914e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8946e-05 - val_loss: 1.8791e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7337e-05 - val_loss: 2.4292e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1720e-05 - val_loss: 8.9365e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7185e-05 - val_loss: 1.6966e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1053e-05 - val_loss: 2.3113e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8787e-05 - val_loss: 1.2989e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8220e-05 - val_loss: 2.9685e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8302e-05 - val_loss: 4.1321e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8637e-05 - val_loss: 4.4143e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5589e-05 - val_loss: 2.6678e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3262e-05 - val_loss: 2.3508e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7684e-05 - val_loss: 5.5739e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0266e-05 - val_loss: 9.9786e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1813e-05 - val_loss: 3.6619e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4536e-05 - val_loss: 0.0010\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8118e-05 - val_loss: 2.5940e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6445e-05 - val_loss: 2.4061e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5257e-05 - val_loss: 3.3302e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9116e-05 - val_loss: 1.3476e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0310e-05 - val_loss: 3.7912e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6938e-05 - val_loss: 3.8289e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1521e-05 - val_loss: 2.0663e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.8685e-06 - val_loss: 3.3203e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7889e-06 - val_loss: 9.2793e-06\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0491e-05 - val_loss: 6.3928e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2844e-05 - val_loss: 2.3456e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6775e-05 - val_loss: 1.4359e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2753e-05 - val_loss: 9.1299e-06\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5408e-05 - val_loss: 1.0626e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.7478e-05 - val_loss: 5.3527e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0343e-05 - val_loss: 1.4732e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6374e-05 - val_loss: 1.8731e-05\n",
      ">Neurons=75, Score=0.0030230450647650287\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 25ms/step - loss: 0.0023 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0075\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6127e-04 - val_loss: 0.0038\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1773e-04 - val_loss: 0.0018\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6132e-04 - val_loss: 5.9085e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8315e-04 - val_loss: 6.6370e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3761e-04 - val_loss: 3.0205e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0363e-04 - val_loss: 5.3173e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.4363e-05 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1583e-05 - val_loss: 0.0025\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7991e-05 - val_loss: 3.9849e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3947e-04 - val_loss: 5.7821e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1605e-05 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.5344e-05 - val_loss: 3.3709e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.1141e-05 - val_loss: 3.5261e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3521e-04 - val_loss: 3.8401e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.8448e-05 - val_loss: 7.5740e-05\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.1373e-05 - val_loss: 0.0014\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2783e-05 - val_loss: 2.0054e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.0097e-05 - val_loss: 5.8701e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.7985e-05 - val_loss: 2.7891e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5803e-05 - val_loss: 7.3519e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5175e-05 - val_loss: 4.5122e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7594e-05 - val_loss: 5.1475e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.9301e-05 - val_loss: 2.1380e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1541e-04 - val_loss: 8.6814e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.1256e-05 - val_loss: 1.1799e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8733e-05 - val_loss: 9.9010e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.6462e-05 - val_loss: 7.2585e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3743e-05 - val_loss: 1.2352e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8888e-05 - val_loss: 8.1983e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5375e-05 - val_loss: 1.6064e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2143e-05 - val_loss: 5.0080e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0222e-05 - val_loss: 4.1931e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3624e-05 - val_loss: 6.9562e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8671e-05 - val_loss: 9.7626e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5091e-05 - val_loss: 1.0872e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6701e-05 - val_loss: 2.3938e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5083e-05 - val_loss: 2.8682e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.3356e-05 - val_loss: 4.9467e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8472e-05 - val_loss: 3.7512e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7418e-05 - val_loss: 4.5482e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4003e-05 - val_loss: 3.5282e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2035e-05 - val_loss: 2.2976e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9382e-05 - val_loss: 7.4293e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4622e-05 - val_loss: 4.0824e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9438e-05 - val_loss: 2.7153e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8981e-05 - val_loss: 2.3010e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8155e-05 - val_loss: 1.8261e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6646e-05 - val_loss: 1.7209e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3041e-05 - val_loss: 3.0221e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9840e-05 - val_loss: 2.0038e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3452e-05 - val_loss: 1.4381e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.5353e-05 - val_loss: 0.0016\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.8019e-05 - val_loss: 7.8227e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1042e-05 - val_loss: 4.4097e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4910e-05 - val_loss: 3.1160e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6429e-05 - val_loss: 7.9676e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0215e-05 - val_loss: 1.6933e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4598e-05 - val_loss: 1.5527e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6353e-05 - val_loss: 3.9548e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3871e-05 - val_loss: 1.7681e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8670e-05 - val_loss: 8.6318e-06\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1743e-05 - val_loss: 2.0212e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0733e-05 - val_loss: 1.7990e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6520e-05 - val_loss: 7.9224e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6155e-05 - val_loss: 3.1003e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7360e-05 - val_loss: 4.9704e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0479e-05 - val_loss: 5.3128e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9877e-05 - val_loss: 2.2702e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4207e-05 - val_loss: 7.1158e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8806e-05 - val_loss: 1.1483e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2588e-05 - val_loss: 3.7726e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1564e-05 - val_loss: 1.2921e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7300e-05 - val_loss: 1.4838e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9032e-05 - val_loss: 3.0450e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7718e-05 - val_loss: 5.1394e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1587e-05 - val_loss: 8.1547e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4859e-05 - val_loss: 2.2830e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0032e-05 - val_loss: 6.2529e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2360e-05 - val_loss: 2.5671e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3317e-05 - val_loss: 5.5909e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6748e-05 - val_loss: 5.9212e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2153e-05 - val_loss: 2.7304e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9761e-05 - val_loss: 9.7012e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0867e-05 - val_loss: 2.2207e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4979e-05 - val_loss: 4.3920e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1940e-05 - val_loss: 1.1867e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6009e-05 - val_loss: 1.7100e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4526e-05 - val_loss: 3.5489e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8372e-05 - val_loss: 3.1544e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1368e-05 - val_loss: 5.4994e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3903e-05 - val_loss: 8.5075e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4114e-05 - val_loss: 5.9080e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7157e-05 - val_loss: 7.2649e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4025e-05 - val_loss: 2.2258e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.9876e-06 - val_loss: 6.0248e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2098e-05 - val_loss: 5.3306e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4992e-05 - val_loss: 3.7293e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0479e-05 - val_loss: 1.0771e-05\n",
      ">Neurons=75, Score=0.002487978053977713\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 20ms/step - loss: 0.0021 - val_loss: 0.0107\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.0010 - val_loss: 0.0079\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.9008e-04 - val_loss: 0.0045\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5882e-04 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8339e-04 - val_loss: 5.3050e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5310e-04 - val_loss: 3.7561e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2001e-04 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1527e-04 - val_loss: 7.0925e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1330e-04 - val_loss: 4.0557e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.0256e-05 - val_loss: 6.1731e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2944e-04 - val_loss: 3.7080e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.7133e-05 - val_loss: 3.8146e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.3947e-05 - val_loss: 3.5316e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.9740e-05 - val_loss: 1.4369e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.4847e-05 - val_loss: 5.0990e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1406e-05 - val_loss: 3.1617e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5037e-05 - val_loss: 1.8613e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.9234e-05 - val_loss: 8.1867e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1333e-05 - val_loss: 4.1716e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.1461e-05 - val_loss: 8.3162e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7459e-05 - val_loss: 2.5563e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.7936e-05 - val_loss: 4.0070e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.1305e-05 - val_loss: 3.2572e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8824e-05 - val_loss: 2.6085e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6438e-05 - val_loss: 4.3709e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5382e-05 - val_loss: 3.4775e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8425e-05 - val_loss: 5.3059e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0193e-05 - val_loss: 1.9619e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9595e-05 - val_loss: 2.7534e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.9937e-05 - val_loss: 2.0541e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6341e-05 - val_loss: 0.0011\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.1031e-05 - val_loss: 1.0938e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9156e-05 - val_loss: 3.4258e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4881e-05 - val_loss: 8.2466e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4629e-05 - val_loss: 3.7435e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0387e-05 - val_loss: 6.3937e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4371e-05 - val_loss: 7.3037e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.9648e-05 - val_loss: 1.3865e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4518e-05 - val_loss: 7.8648e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2655e-05 - val_loss: 1.8867e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9671e-05 - val_loss: 1.5066e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5630e-05 - val_loss: 7.9016e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1051e-05 - val_loss: 4.7572e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6333e-05 - val_loss: 2.6255e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1206e-05 - val_loss: 1.5902e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.6461e-05 - val_loss: 0.0014\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0556e-05 - val_loss: 4.9432e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.1976e-05 - val_loss: 7.7354e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7926e-05 - val_loss: 5.0267e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2256e-05 - val_loss: 1.6824e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2260e-05 - val_loss: 6.6202e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4414e-05 - val_loss: 4.0491e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.9408e-05 - val_loss: 3.1525e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2848e-05 - val_loss: 1.9428e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0702e-05 - val_loss: 9.5675e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5524e-05 - val_loss: 2.1809e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3702e-05 - val_loss: 1.0688e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6116e-05 - val_loss: 6.1375e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9820e-05 - val_loss: 9.7644e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9448e-05 - val_loss: 9.6220e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9830e-05 - val_loss: 1.3172e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7797e-05 - val_loss: 7.6184e-06\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3542e-05 - val_loss: 2.1253e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.4571e-05 - val_loss: 1.5779e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5358e-05 - val_loss: 7.1419e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7537e-05 - val_loss: 1.9153e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8288e-05 - val_loss: 0.0014\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1527e-05 - val_loss: 2.2483e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1075e-05 - val_loss: 3.9853e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9723e-05 - val_loss: 1.7570e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9215e-05 - val_loss: 1.9915e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2598e-05 - val_loss: 1.8026e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3440e-05 - val_loss: 5.8368e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6410e-05 - val_loss: 2.5118e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3529e-05 - val_loss: 3.9330e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8321e-05 - val_loss: 5.3120e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1864e-05 - val_loss: 2.4783e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.5415e-05 - val_loss: 1.8020e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9558e-05 - val_loss: 6.7955e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7599e-05 - val_loss: 9.0162e-06\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2347e-05 - val_loss: 7.0086e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6742e-05 - val_loss: 2.2244e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4068e-05 - val_loss: 1.1739e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4305e-05 - val_loss: 1.9853e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4774e-05 - val_loss: 5.3258e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8787e-05 - val_loss: 7.5559e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0163e-05 - val_loss: 3.0339e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4976e-05 - val_loss: 1.0404e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2897e-05 - val_loss: 1.3286e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9270e-05 - val_loss: 1.1275e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4892e-05 - val_loss: 4.8074e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6880e-05 - val_loss: 5.7608e-06\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3054e-05 - val_loss: 2.7056e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0182e-05 - val_loss: 1.3811e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8805e-05 - val_loss: 1.3710e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7802e-05 - val_loss: 9.4187e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1712e-05 - val_loss: 1.8127e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5368e-05 - val_loss: 1.4725e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3395e-05 - val_loss: 1.1394e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7438e-05 - val_loss: 1.1782e-04\n",
      ">Neurons=75, Score=0.0051047220040345564\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 15s 28ms/step - loss: 0.0021 - val_loss: 0.0097\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.2812e-04 - val_loss: 0.0069\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.6097e-04 - val_loss: 0.0037\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.4682e-04 - val_loss: 0.0022\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1821e-04 - val_loss: 6.7592e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9386e-04 - val_loss: 4.3732e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5135e-04 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.7145e-05 - val_loss: 1.9258e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1404e-04 - val_loss: 3.0288e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3552e-04 - val_loss: 2.3552e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4647e-04 - val_loss: 5.5851e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.2894e-05 - val_loss: 2.8054e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.0745e-05 - val_loss: 1.8221e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.6548e-05 - val_loss: 2.3616e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5444e-05 - val_loss: 6.0087e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4647e-05 - val_loss: 2.4827e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3020e-05 - val_loss: 2.5909e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7662e-05 - val_loss: 8.7706e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.4679e-05 - val_loss: 2.7604e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0932e-05 - val_loss: 3.8340e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.0680e-05 - val_loss: 2.1987e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0248e-04 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0881e-04 - val_loss: 2.6905e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3012e-05 - val_loss: 5.5255e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7567e-05 - val_loss: 1.9605e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6546e-05 - val_loss: 2.3935e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7527e-05 - val_loss: 1.9196e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4826e-05 - val_loss: 1.0591e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3370e-05 - val_loss: 6.0645e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3036e-05 - val_loss: 1.5296e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.5697e-05 - val_loss: 1.3020e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9319e-05 - val_loss: 1.9857e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3810e-05 - val_loss: 3.9172e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7912e-05 - val_loss: 2.3798e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8137e-05 - val_loss: 4.2815e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4055e-05 - val_loss: 1.5557e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8561e-05 - val_loss: 3.2622e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5263e-05 - val_loss: 2.0827e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6081e-05 - val_loss: 3.3763e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9452e-05 - val_loss: 1.3366e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0930e-05 - val_loss: 3.4533e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9396e-05 - val_loss: 1.6176e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4613e-05 - val_loss: 1.7248e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4064e-05 - val_loss: 6.0091e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.7069e-05 - val_loss: 5.6202e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5499e-05 - val_loss: 2.5600e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8258e-05 - val_loss: 4.4958e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5830e-05 - val_loss: 6.1048e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7236e-05 - val_loss: 2.3965e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9237e-05 - val_loss: 4.3144e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1748e-05 - val_loss: 2.4362e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.6375e-05 - val_loss: 5.3365e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4162e-05 - val_loss: 2.9257e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6832e-05 - val_loss: 1.9823e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3811e-05 - val_loss: 4.0323e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1508e-05 - val_loss: 8.4169e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4153e-05 - val_loss: 2.0782e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3856e-05 - val_loss: 7.8176e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0905e-05 - val_loss: 7.0447e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6651e-05 - val_loss: 9.9564e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3271e-05 - val_loss: 1.6891e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8315e-05 - val_loss: 4.4974e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9125e-05 - val_loss: 0.0016\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.9829e-05 - val_loss: 1.3220e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3689e-05 - val_loss: 9.5991e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7536e-05 - val_loss: 2.1552e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3802e-05 - val_loss: 2.8003e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5137e-05 - val_loss: 4.2030e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3544e-05 - val_loss: 2.7132e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.1439e-05 - val_loss: 4.4635e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0099e-05 - val_loss: 2.8277e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8923e-05 - val_loss: 5.4741e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9868e-05 - val_loss: 6.0119e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8377e-05 - val_loss: 1.5794e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2553e-05 - val_loss: 1.7331e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8932e-05 - val_loss: 3.7554e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4427e-05 - val_loss: 1.9316e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2604e-05 - val_loss: 2.6808e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5381e-05 - val_loss: 3.9527e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0623e-05 - val_loss: 6.4108e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2880e-05 - val_loss: 2.0542e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8980e-05 - val_loss: 2.2348e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0426e-05 - val_loss: 7.9060e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8276e-05 - val_loss: 2.7860e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1628e-05 - val_loss: 0.0014\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5763e-05 - val_loss: 2.6763e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3464e-05 - val_loss: 3.5091e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5791e-05 - val_loss: 3.4731e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7295e-05 - val_loss: 8.2755e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7687e-05 - val_loss: 2.7164e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6524e-05 - val_loss: 1.6149e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.9520e-05 - val_loss: 5.0181e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3519e-05 - val_loss: 3.3408e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.1063e-05 - val_loss: 7.8874e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8230e-05 - val_loss: 7.4927e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8389e-05 - val_loss: 7.2776e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1008e-05 - val_loss: 3.3742e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3853e-05 - val_loss: 3.6907e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2718e-05 - val_loss: 2.6069e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5635e-05 - val_loss: 2.4103e-05\n",
      ">Neurons=80, Score=0.001385165251122089\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 16s 30ms/step - loss: 0.0020 - val_loss: 0.0097\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.8414e-04 - val_loss: 0.0064\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1251e-04 - val_loss: 0.0030\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7351e-04 - val_loss: 0.0010\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3719e-04 - val_loss: 7.6837e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2885e-04 - val_loss: 1.2553e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.4297e-04 - val_loss: 7.1600e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3263e-04 - val_loss: 4.2212e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7488e-05 - val_loss: 1.2841e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.0310e-05 - val_loss: 0.0015\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.9086e-05 - val_loss: 7.1108e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.8143e-05 - val_loss: 1.1643e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0617e-05 - val_loss: 2.4910e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8899e-05 - val_loss: 1.7179e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1530e-05 - val_loss: 5.1307e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.7172e-05 - val_loss: 2.0592e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2769e-05 - val_loss: 3.7148e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.2515e-05 - val_loss: 1.8879e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.6148e-05 - val_loss: 1.9203e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6449e-05 - val_loss: 4.1710e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.0761e-05 - val_loss: 3.0277e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.4983e-05 - val_loss: 4.5494e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0223e-05 - val_loss: 1.6479e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.3450e-05 - val_loss: 4.0791e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6176e-05 - val_loss: 1.3475e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8194e-05 - val_loss: 4.1577e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9177e-05 - val_loss: 1.1700e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2328e-05 - val_loss: 2.0477e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.9487e-05 - val_loss: 1.4346e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4902e-05 - val_loss: 7.2656e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9213e-05 - val_loss: 4.6986e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3052e-05 - val_loss: 8.9648e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7456e-05 - val_loss: 7.3996e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.6186e-05 - val_loss: 5.1521e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.8094e-05 - val_loss: 9.2806e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.4792e-05 - val_loss: 3.4104e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4343e-05 - val_loss: 2.5010e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2195e-05 - val_loss: 2.2314e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.8029e-05 - val_loss: 3.1556e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6117e-05 - val_loss: 6.2235e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1004e-05 - val_loss: 6.5190e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3434e-05 - val_loss: 1.0755e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3946e-05 - val_loss: 1.7856e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3924e-05 - val_loss: 5.0358e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5803e-05 - val_loss: 3.8482e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4697e-05 - val_loss: 2.0017e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6576e-05 - val_loss: 1.7342e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8996e-05 - val_loss: 4.5205e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7282e-05 - val_loss: 1.0574e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2149e-05 - val_loss: 1.6311e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0629e-05 - val_loss: 1.8665e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5207e-05 - val_loss: 4.5704e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1464e-05 - val_loss: 2.1783e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.2245e-05 - val_loss: 4.1934e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2875e-05 - val_loss: 4.6146e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7473e-05 - val_loss: 1.4052e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0579e-05 - val_loss: 1.1051e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6119e-05 - val_loss: 1.3461e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3726e-05 - val_loss: 1.7008e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3092e-05 - val_loss: 3.9687e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.6046e-05 - val_loss: 2.1072e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8690e-05 - val_loss: 2.6350e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0956e-05 - val_loss: 2.7438e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0605e-05 - val_loss: 1.0043e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7440e-05 - val_loss: 1.5825e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3821e-05 - val_loss: 1.5278e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5018e-05 - val_loss: 2.1064e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.1450e-06 - val_loss: 4.6852e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.6304e-06 - val_loss: 1.6448e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3464e-05 - val_loss: 2.5392e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4615e-05 - val_loss: 1.1450e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.5187e-05 - val_loss: 3.2974e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.0918e-05 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0060e-05 - val_loss: 2.6710e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0262e-05 - val_loss: 2.0044e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0822e-04 - val_loss: 3.3420e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8089e-05 - val_loss: 2.9023e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7891e-05 - val_loss: 5.8107e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0415e-05 - val_loss: 1.2214e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3557e-05 - val_loss: 1.4110e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7510e-05 - val_loss: 4.1096e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.9104e-06 - val_loss: 1.5129e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3292e-05 - val_loss: 3.1566e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.1366e-05 - val_loss: 1.5521e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.7543e-05 - val_loss: 6.2573e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.6441e-05 - val_loss: 3.4960e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.0694e-05 - val_loss: 0.0013\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.0981e-05 - val_loss: 1.8457e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4365e-05 - val_loss: 4.0530e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7827e-05 - val_loss: 3.2260e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0630e-05 - val_loss: 1.7907e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3378e-05 - val_loss: 3.1996e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9990e-05 - val_loss: 2.1467e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0339e-05 - val_loss: 9.4503e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5617e-05 - val_loss: 2.1144e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5317e-05 - val_loss: 0.0012\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7840e-05 - val_loss: 6.4074e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9876e-05 - val_loss: 6.2184e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1325e-05 - val_loss: 3.1592e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7519e-05 - val_loss: 1.2122e-04\n",
      ">Neurons=80, Score=0.006951997784199193\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 15s 28ms/step - loss: 0.0021 - val_loss: 0.0103\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.9735e-04 - val_loss: 0.0075\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.7477e-04 - val_loss: 0.0045\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2790e-04 - val_loss: 0.0021\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8400e-04 - val_loss: 6.4627e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5899e-04 - val_loss: 6.2456e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8711e-04 - val_loss: 0.0013\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2245e-04 - val_loss: 2.6584e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.9985e-05 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.1940e-05 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.2734e-05 - val_loss: 1.6635e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4014e-05 - val_loss: 1.3263e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.7286e-05 - val_loss: 3.7420e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.6777e-05 - val_loss: 8.2987e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3763e-05 - val_loss: 1.3401e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3052e-05 - val_loss: 3.8701e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2351e-04 - val_loss: 5.9843e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.8544e-05 - val_loss: 5.6283e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7783e-05 - val_loss: 3.7934e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.8922e-05 - val_loss: 1.9508e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.7930e-05 - val_loss: 1.6915e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2591e-05 - val_loss: 6.2592e-05\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.5158e-05 - val_loss: 1.3897e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2653e-05 - val_loss: 3.3431e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2789e-05 - val_loss: 3.2719e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8841e-05 - val_loss: 1.4449e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5154e-05 - val_loss: 1.7839e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6189e-05 - val_loss: 6.0638e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2547e-04 - val_loss: 0.0014\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.8907e-05 - val_loss: 4.7756e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7215e-05 - val_loss: 4.5185e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8126e-05 - val_loss: 9.9079e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1869e-05 - val_loss: 2.4492e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9045e-05 - val_loss: 7.1910e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5762e-05 - val_loss: 9.1706e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9853e-05 - val_loss: 2.6602e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3599e-05 - val_loss: 1.8641e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4357e-05 - val_loss: 1.0566e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2425e-05 - val_loss: 1.0726e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7665e-05 - val_loss: 1.3110e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1240e-05 - val_loss: 1.8161e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7812e-05 - val_loss: 5.5446e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9057e-05 - val_loss: 3.9058e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5060e-05 - val_loss: 2.3788e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7330e-05 - val_loss: 7.6550e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4532e-05 - val_loss: 2.1241e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7391e-05 - val_loss: 7.6754e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.7436e-05 - val_loss: 9.7555e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.7557e-05 - val_loss: 8.9225e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7555e-05 - val_loss: 3.5348e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0534e-05 - val_loss: 3.6060e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2844e-05 - val_loss: 3.5082e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4558e-05 - val_loss: 7.2108e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1447e-05 - val_loss: 2.4064e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.2197e-06 - val_loss: 4.6375e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.8110e-05 - val_loss: 1.2085e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3752e-05 - val_loss: 1.8274e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1922e-05 - val_loss: 2.1617e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4141e-05 - val_loss: 1.4572e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0769e-05 - val_loss: 3.3782e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7690e-05 - val_loss: 1.4314e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0101e-05 - val_loss: 8.1452e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2022e-05 - val_loss: 1.6909e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5417e-05 - val_loss: 1.1903e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9013e-05 - val_loss: 5.8202e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5572e-05 - val_loss: 3.3813e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7598e-05 - val_loss: 0.0016\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0683e-05 - val_loss: 6.2736e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6393e-05 - val_loss: 1.9246e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5231e-05 - val_loss: 7.9303e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3288e-05 - val_loss: 7.0520e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4663e-05 - val_loss: 2.6791e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3350e-05 - val_loss: 1.5999e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0590e-05 - val_loss: 9.9407e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9123e-05 - val_loss: 6.0272e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1250e-05 - val_loss: 3.2647e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3648e-05 - val_loss: 4.2013e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9751e-05 - val_loss: 5.4028e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5689e-05 - val_loss: 3.0337e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0171e-05 - val_loss: 1.5194e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1650e-05 - val_loss: 1.3481e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1405e-05 - val_loss: 2.3194e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7791e-05 - val_loss: 1.0550e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4512e-05 - val_loss: 1.7677e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0541e-05 - val_loss: 1.8218e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4190e-05 - val_loss: 1.7566e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.9717e-05 - val_loss: 3.7188e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9375e-05 - val_loss: 6.7053e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6298e-05 - val_loss: 3.1225e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1499e-05 - val_loss: 1.6714e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2783e-05 - val_loss: 1.3625e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1681e-05 - val_loss: 2.3971e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7362e-05 - val_loss: 3.7304e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2352e-05 - val_loss: 2.6816e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5041e-05 - val_loss: 1.1129e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2909e-05 - val_loss: 1.5886e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6930e-05 - val_loss: 8.1736e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3224e-05 - val_loss: 4.9410e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4533e-05 - val_loss: 3.0027e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5104e-05 - val_loss: 0.0021\n",
      ">Neurons=80, Score=0.09817200480028987\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 16s 28ms/step - loss: 0.0022 - val_loss: 0.0102\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.7983e-04 - val_loss: 0.0068\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1619e-04 - val_loss: 0.0034\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7566e-04 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8033e-04 - val_loss: 7.0897e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4720e-04 - val_loss: 8.2107e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.4489e-05 - val_loss: 2.4363e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.1550e-05 - val_loss: 8.8266e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7467e-05 - val_loss: 6.9897e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.9969e-05 - val_loss: 4.0031e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.6360e-05 - val_loss: 4.7086e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.5374e-05 - val_loss: 0.0015\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.9424e-05 - val_loss: 8.5682e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6586e-05 - val_loss: 3.2228e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.7230e-05 - val_loss: 7.9029e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.9265e-05 - val_loss: 4.1607e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8116e-05 - val_loss: 5.1137e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5405e-05 - val_loss: 0.0016\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8367e-05 - val_loss: 1.3792e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2320e-05 - val_loss: 4.0660e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7689e-05 - val_loss: 9.4599e-05\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8722e-05 - val_loss: 1.3496e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3645e-04 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.9994e-05 - val_loss: 1.4236e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9500e-05 - val_loss: 1.2608e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3092e-05 - val_loss: 7.7091e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1788e-05 - val_loss: 4.2824e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1456e-05 - val_loss: 1.0826e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3302e-05 - val_loss: 4.3136e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2643e-05 - val_loss: 3.6061e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6778e-05 - val_loss: 1.6593e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7268e-05 - val_loss: 2.7567e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1749e-05 - val_loss: 8.9909e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6774e-05 - val_loss: 2.2063e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.1887e-05 - val_loss: 6.9981e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.9131e-05 - val_loss: 3.1681e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7380e-05 - val_loss: 3.1855e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.9190e-05 - val_loss: 1.1720e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7168e-05 - val_loss: 8.1521e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9595e-05 - val_loss: 1.6100e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5478e-05 - val_loss: 3.2945e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0413e-05 - val_loss: 8.6552e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9302e-05 - val_loss: 9.2136e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7695e-05 - val_loss: 5.1975e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4867e-05 - val_loss: 4.5492e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8854e-05 - val_loss: 5.7340e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4183e-05 - val_loss: 3.6250e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0645e-05 - val_loss: 2.7672e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7608e-05 - val_loss: 9.5877e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9259e-05 - val_loss: 7.2558e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9849e-05 - val_loss: 3.2308e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5305e-05 - val_loss: 1.2379e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.2457e-05 - val_loss: 0.0011\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9361e-05 - val_loss: 2.8945e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8484e-05 - val_loss: 9.2740e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3064e-05 - val_loss: 2.2182e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4903e-05 - val_loss: 1.4785e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1920e-05 - val_loss: 2.6884e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2612e-05 - val_loss: 1.0684e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4105e-05 - val_loss: 1.8416e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1337e-05 - val_loss: 1.6534e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7443e-05 - val_loss: 1.4254e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0121e-05 - val_loss: 6.3427e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2680e-05 - val_loss: 7.6591e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8865e-05 - val_loss: 3.2285e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6798e-05 - val_loss: 6.5381e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7478e-05 - val_loss: 3.1516e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4750e-05 - val_loss: 4.0696e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2733e-05 - val_loss: 3.0020e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1056e-05 - val_loss: 1.4461e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0017e-05 - val_loss: 1.2290e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0371e-05 - val_loss: 1.7848e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4727e-05 - val_loss: 5.2452e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7699e-05 - val_loss: 3.3578e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4746e-05 - val_loss: 9.9349e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7879e-05 - val_loss: 9.1063e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.7933e-05 - val_loss: 3.9739e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6900e-05 - val_loss: 1.6503e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4636e-05 - val_loss: 1.3733e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2982e-05 - val_loss: 8.4242e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5724e-05 - val_loss: 1.1998e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3962e-05 - val_loss: 1.3200e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1733e-05 - val_loss: 6.3381e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2414e-05 - val_loss: 5.9939e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6548e-05 - val_loss: 6.6809e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7679e-05 - val_loss: 1.4978e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8221e-05 - val_loss: 3.5926e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3353e-06 - val_loss: 2.9245e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2278e-05 - val_loss: 3.1297e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5237e-05 - val_loss: 6.2460e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5442e-05 - val_loss: 1.7143e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3661e-05 - val_loss: 1.0429e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2099e-05 - val_loss: 1.4649e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1315e-05 - val_loss: 6.3825e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6483e-05 - val_loss: 6.3603e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5504e-05 - val_loss: 3.4830e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6237e-05 - val_loss: 1.9717e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6784e-05 - val_loss: 5.4939e-06\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6370e-05 - val_loss: 7.6362e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0039e-06 - val_loss: 6.9907e-05\n",
      ">Neurons=80, Score=0.004223103678668849\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 15s 27ms/step - loss: 0.0023 - val_loss: 0.0108\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.4083e-04 - val_loss: 0.0075\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.1236e-04 - val_loss: 0.0044\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.4273e-04 - val_loss: 0.0020\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6821e-04 - val_loss: 7.0924e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0829e-04 - val_loss: 0.0016\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3680e-04 - val_loss: 3.7420e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1609e-04 - val_loss: 0.0023\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1678e-04 - val_loss: 8.6453e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1408e-04 - val_loss: 5.8898e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.4697e-05 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0542e-04 - val_loss: 2.4944e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0828e-04 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3422e-05 - val_loss: 8.3374e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4522e-04 - val_loss: 0.0011\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5311e-04 - val_loss: 1.7239e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1695e-04 - val_loss: 3.3080e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.2588e-05 - val_loss: 8.8631e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.8183e-05 - val_loss: 2.7605e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.7051e-05 - val_loss: 1.6969e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.4251e-05 - val_loss: 3.2000e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2434e-05 - val_loss: 3.1145e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6762e-05 - val_loss: 3.9446e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9099e-05 - val_loss: 9.8102e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9730e-05 - val_loss: 2.7087e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.0438e-05 - val_loss: 7.1567e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7254e-05 - val_loss: 2.4408e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8798e-05 - val_loss: 7.0956e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8742e-05 - val_loss: 7.8750e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7677e-05 - val_loss: 6.7072e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7224e-05 - val_loss: 5.3612e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.5333e-05 - val_loss: 6.3132e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3919e-05 - val_loss: 1.6812e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4046e-05 - val_loss: 3.8633e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5302e-05 - val_loss: 1.5468e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.4273e-05 - val_loss: 4.1954e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5048e-05 - val_loss: 8.0700e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6528e-05 - val_loss: 3.6042e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5171e-05 - val_loss: 7.2981e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1975e-05 - val_loss: 4.9499e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7393e-05 - val_loss: 2.7968e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5501e-05 - val_loss: 2.5119e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6763e-05 - val_loss: 2.9406e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8640e-05 - val_loss: 3.9486e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0138e-05 - val_loss: 3.2767e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6443e-05 - val_loss: 7.8645e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5474e-05 - val_loss: 8.2098e-06\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6727e-05 - val_loss: 2.4288e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0816e-05 - val_loss: 1.0672e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2701e-05 - val_loss: 9.0505e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.8546e-05 - val_loss: 2.3774e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2941e-05 - val_loss: 7.8172e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9312e-05 - val_loss: 1.7631e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4741e-05 - val_loss: 3.2703e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5643e-05 - val_loss: 1.7107e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0693e-05 - val_loss: 8.5818e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5356e-05 - val_loss: 1.0389e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3297e-05 - val_loss: 2.0048e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0805e-05 - val_loss: 5.8045e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9516e-05 - val_loss: 1.6300e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7455e-05 - val_loss: 9.1905e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.7220e-05 - val_loss: 5.9444e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8273e-05 - val_loss: 1.5085e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2070e-05 - val_loss: 6.1671e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4717e-05 - val_loss: 1.7162e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6625e-05 - val_loss: 3.5918e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2830e-05 - val_loss: 2.8658e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6772e-05 - val_loss: 3.1423e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2917e-05 - val_loss: 2.3764e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5566e-05 - val_loss: 7.5059e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8391e-05 - val_loss: 9.7526e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9096e-05 - val_loss: 3.8295e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.7903e-05 - val_loss: 1.4522e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4617e-05 - val_loss: 1.9650e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3897e-05 - val_loss: 4.4080e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0815e-05 - val_loss: 3.3489e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8471e-05 - val_loss: 5.6739e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3681e-05 - val_loss: 1.4405e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8554e-05 - val_loss: 2.0017e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.5936e-05 - val_loss: 0.0015\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1064e-05 - val_loss: 5.2328e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.5822e-05 - val_loss: 1.5960e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3759e-05 - val_loss: 3.1556e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.5508e-06 - val_loss: 6.1523e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2505e-05 - val_loss: 1.1429e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4456e-05 - val_loss: 2.5700e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3419e-05 - val_loss: 2.9351e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5066e-05 - val_loss: 1.1938e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7734e-05 - val_loss: 0.0020\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.9963e-05 - val_loss: 3.1435e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8710e-05 - val_loss: 4.7222e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4631e-05 - val_loss: 2.5335e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2363e-05 - val_loss: 1.5757e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1204e-05 - val_loss: 2.0025e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0320e-05 - val_loss: 2.5736e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7758e-05 - val_loss: 7.4382e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6019e-05 - val_loss: 3.8985e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.5538e-06 - val_loss: 4.4926e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8019e-05 - val_loss: 1.4924e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.0553e-06 - val_loss: 1.0477e-04\n",
      ">Neurons=80, Score=0.007184466085163876\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 15s 28ms/step - loss: 0.0022 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.8255e-04 - val_loss: 0.0079\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.2032e-04 - val_loss: 0.0045\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1055e-04 - val_loss: 0.0020\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5281e-04 - val_loss: 6.0433e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7732e-04 - val_loss: 7.0003e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0957e-04 - val_loss: 4.8241e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1674e-04 - val_loss: 2.0038e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.8152e-05 - val_loss: 2.5421e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0743e-04 - val_loss: 3.3924e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0967e-04 - val_loss: 1.1542e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.6592e-05 - val_loss: 2.3011e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.1860e-05 - val_loss: 0.0012\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5342e-05 - val_loss: 5.6512e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3048e-05 - val_loss: 2.4654e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8206e-05 - val_loss: 4.1036e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.4100e-05 - val_loss: 6.2056e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.7805e-05 - val_loss: 9.5754e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.4329e-05 - val_loss: 1.3627e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.7705e-05 - val_loss: 5.8550e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1486e-05 - val_loss: 2.4008e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3443e-05 - val_loss: 7.2274e-05\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1065e-04 - val_loss: 0.0011\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1252e-04 - val_loss: 1.9845e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4862e-05 - val_loss: 2.3700e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3843e-05 - val_loss: 1.7579e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0573e-05 - val_loss: 1.8650e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7814e-05 - val_loss: 5.3476e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4441e-05 - val_loss: 3.5447e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7244e-05 - val_loss: 9.8237e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1382e-05 - val_loss: 1.0323e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0632e-05 - val_loss: 2.5780e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6388e-05 - val_loss: 1.4841e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8301e-05 - val_loss: 4.1095e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9902e-05 - val_loss: 1.3719e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6282e-05 - val_loss: 1.7536e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3249e-05 - val_loss: 6.3108e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5510e-05 - val_loss: 2.3746e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7189e-05 - val_loss: 6.7731e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5433e-05 - val_loss: 2.1438e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4278e-05 - val_loss: 3.4458e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5314e-05 - val_loss: 3.4180e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8525e-05 - val_loss: 2.3317e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4358e-05 - val_loss: 6.1923e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8911e-05 - val_loss: 2.6268e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5111e-05 - val_loss: 2.2254e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.2941e-05 - val_loss: 2.3770e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4963e-05 - val_loss: 0.0012\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.8393e-05 - val_loss: 7.8844e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5728e-05 - val_loss: 2.4650e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6850e-05 - val_loss: 0.0010\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4099e-05 - val_loss: 5.3071e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5051e-05 - val_loss: 5.2906e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0598e-05 - val_loss: 1.6483e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9351e-05 - val_loss: 2.1884e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4267e-05 - val_loss: 5.9899e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4127e-05 - val_loss: 7.7325e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4889e-05 - val_loss: 1.8009e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4924e-05 - val_loss: 6.9504e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1875e-05 - val_loss: 3.1706e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3937e-05 - val_loss: 6.8171e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6475e-05 - val_loss: 6.4469e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2933e-05 - val_loss: 3.1110e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.1487e-05 - val_loss: 1.5540e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2615e-05 - val_loss: 2.7080e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.1777e-05 - val_loss: 8.7318e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0237e-05 - val_loss: 1.2657e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8856e-05 - val_loss: 5.6394e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5772e-05 - val_loss: 7.7019e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7526e-05 - val_loss: 1.7542e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3533e-05 - val_loss: 2.1420e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8411e-05 - val_loss: 2.6891e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4840e-05 - val_loss: 3.5176e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.9391e-06 - val_loss: 7.5899e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.7573e-06 - val_loss: 1.3528e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8886e-05 - val_loss: 4.7109e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8715e-05 - val_loss: 3.9485e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3819e-05 - val_loss: 1.0402e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7018e-05 - val_loss: 6.0427e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6311e-05 - val_loss: 5.9200e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4838e-05 - val_loss: 1.2453e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1514e-05 - val_loss: 1.6542e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6056e-05 - val_loss: 2.7644e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4517e-05 - val_loss: 2.6512e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4457e-05 - val_loss: 7.5934e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2589e-05 - val_loss: 2.4003e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2154e-05 - val_loss: 2.2597e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3973e-05 - val_loss: 6.3186e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5803e-05 - val_loss: 1.5663e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4405e-05 - val_loss: 9.4013e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7078e-05 - val_loss: 6.3690e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4560e-05 - val_loss: 1.7133e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.5804e-06 - val_loss: 5.0876e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1887e-05 - val_loss: 3.1301e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4616e-05 - val_loss: 2.5069e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6775e-05 - val_loss: 5.7645e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3654e-05 - val_loss: 2.2707e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7242e-05 - val_loss: 4.3475e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.3118e-06 - val_loss: 1.2343e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6781e-05 - val_loss: 4.8772e-04\n",
      ">Neurons=80, Score=0.024605917860753834\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 16s 32ms/step - loss: 0.0021 - val_loss: 0.0100\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 9.7402e-04 - val_loss: 0.0066\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.6313e-04 - val_loss: 0.0032\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0311e-04 - val_loss: 9.5073e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7057e-04 - val_loss: 3.7169e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4346e-04 - val_loss: 2.7368e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3694e-04 - val_loss: 1.9505e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.0874e-05 - val_loss: 3.4054e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4297e-04 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.6151e-05 - val_loss: 7.3758e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.9000e-05 - val_loss: 4.6280e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3465e-05 - val_loss: 4.5488e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0716e-05 - val_loss: 4.5393e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.1205e-05 - val_loss: 6.2435e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4618e-05 - val_loss: 0.0013\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6687e-05 - val_loss: 1.4258e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7640e-05 - val_loss: 1.4830e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0629e-05 - val_loss: 5.7246e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8251e-05 - val_loss: 8.2370e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6697e-05 - val_loss: 7.5705e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9091e-05 - val_loss: 2.0491e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.5870e-05 - val_loss: 3.4486e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8796e-05 - val_loss: 1.5109e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7616e-05 - val_loss: 5.9558e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.1196e-05 - val_loss: 2.7744e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1572e-04 - val_loss: 0.0016\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0037e-04 - val_loss: 1.1540e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6807e-05 - val_loss: 1.7983e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3573e-05 - val_loss: 1.6980e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3439e-05 - val_loss: 7.8324e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.3352e-05 - val_loss: 3.2204e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8456e-05 - val_loss: 1.6043e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1116e-05 - val_loss: 8.6392e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0129e-05 - val_loss: 5.6592e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7690e-05 - val_loss: 2.5464e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0253e-05 - val_loss: 1.4943e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7905e-05 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.3106e-05 - val_loss: 5.0064e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9087e-05 - val_loss: 2.8967e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8356e-05 - val_loss: 3.6264e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7049e-05 - val_loss: 3.5615e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2803e-05 - val_loss: 2.3523e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8504e-05 - val_loss: 3.4337e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1634e-05 - val_loss: 2.3146e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0400e-05 - val_loss: 1.3027e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3860e-05 - val_loss: 4.3830e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3880e-05 - val_loss: 2.9252e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0782e-05 - val_loss: 3.6136e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4650e-05 - val_loss: 3.4442e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5609e-05 - val_loss: 1.1808e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9136e-05 - val_loss: 5.2481e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5361e-05 - val_loss: 2.5526e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3314e-05 - val_loss: 3.0352e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2337e-05 - val_loss: 6.1298e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8307e-05 - val_loss: 1.3392e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8013e-05 - val_loss: 3.0494e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3209e-05 - val_loss: 1.9206e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5499e-05 - val_loss: 1.5853e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8462e-05 - val_loss: 4.0207e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.8596e-05 - val_loss: 9.5941e-06\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7732e-05 - val_loss: 2.0725e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5523e-05 - val_loss: 1.3719e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5924e-05 - val_loss: 4.1284e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1776e-05 - val_loss: 3.5784e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0303e-05 - val_loss: 6.6932e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9408e-05 - val_loss: 2.8441e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7387e-05 - val_loss: 4.1275e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7503e-05 - val_loss: 3.8882e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0860e-05 - val_loss: 1.2673e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.1871e-05 - val_loss: 7.5814e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4449e-05 - val_loss: 1.5971e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2799e-05 - val_loss: 3.2411e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7044e-05 - val_loss: 3.0894e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1051e-05 - val_loss: 1.0031e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8818e-05 - val_loss: 2.7906e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5194e-05 - val_loss: 1.7853e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5147e-05 - val_loss: 6.1308e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1153e-05 - val_loss: 4.1314e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1685e-05 - val_loss: 0.0012\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6308e-05 - val_loss: 1.7819e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0894e-05 - val_loss: 1.7921e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0437e-05 - val_loss: 4.2062e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4333e-05 - val_loss: 5.5744e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9231e-05 - val_loss: 4.7858e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0447e-05 - val_loss: 5.2294e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1666e-05 - val_loss: 2.4076e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4363e-05 - val_loss: 1.4858e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0261e-05 - val_loss: 1.1430e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3367e-05 - val_loss: 1.6293e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7748e-05 - val_loss: 4.1173e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9484e-05 - val_loss: 1.3612e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4977e-05 - val_loss: 0.0011\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3252e-05 - val_loss: 8.7615e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3229e-05 - val_loss: 2.8034e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2409e-05 - val_loss: 2.7828e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5395e-05 - val_loss: 7.7481e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7610e-05 - val_loss: 9.9457e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7145e-05 - val_loss: 1.3059e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5647e-05 - val_loss: 2.6800e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9308e-05 - val_loss: 2.9392e-05\n",
      ">Neurons=80, Score=0.0031352887162938714\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 16s 29ms/step - loss: 0.0021 - val_loss: 0.0103\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.2369e-04 - val_loss: 0.0068\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3713e-04 - val_loss: 0.0034\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4763e-04 - val_loss: 0.0015\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1649e-04 - val_loss: 4.8409e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3869e-04 - val_loss: 2.9934e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0970e-04 - val_loss: 1.6846e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5178e-05 - val_loss: 4.0074e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.2945e-05 - val_loss: 6.8557e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7269e-05 - val_loss: 4.8126e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1176e-04 - val_loss: 4.1870e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.2526e-05 - val_loss: 1.1599e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.8970e-05 - val_loss: 0.0013\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0402e-05 - val_loss: 3.6577e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.5085e-05 - val_loss: 1.6978e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.7440e-05 - val_loss: 4.6944e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4526e-05 - val_loss: 4.8262e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9998e-05 - val_loss: 2.1459e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0307e-05 - val_loss: 2.1195e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.9349e-05 - val_loss: 2.3757e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.0365e-05 - val_loss: 3.1182e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2450e-05 - val_loss: 1.4216e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.6084e-05 - val_loss: 1.8900e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9225e-05 - val_loss: 5.8092e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5918e-05 - val_loss: 3.7789e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.6668e-05 - val_loss: 5.6585e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.4062e-05 - val_loss: 7.8389e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.9162e-05 - val_loss: 1.5469e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2004e-05 - val_loss: 1.8399e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3032e-05 - val_loss: 2.7588e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4910e-05 - val_loss: 4.6637e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4800e-05 - val_loss: 1.1345e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1268e-05 - val_loss: 1.8536e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5000e-05 - val_loss: 0.0012\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8146e-05 - val_loss: 3.7138e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.3853e-05 - val_loss: 2.1031e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3424e-05 - val_loss: 2.0951e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9438e-05 - val_loss: 6.0321e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8563e-05 - val_loss: 6.2083e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9617e-05 - val_loss: 9.9923e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7478e-05 - val_loss: 1.3362e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7636e-05 - val_loss: 2.2685e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4443e-05 - val_loss: 4.3881e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1994e-05 - val_loss: 5.4655e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6347e-05 - val_loss: 7.4360e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.4133e-05 - val_loss: 3.5224e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0579e-05 - val_loss: 2.9552e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8381e-05 - val_loss: 1.7897e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3339e-05 - val_loss: 2.1467e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2492e-05 - val_loss: 2.9912e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0371e-05 - val_loss: 1.6845e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6914e-05 - val_loss: 1.6991e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5713e-05 - val_loss: 2.7605e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0595e-05 - val_loss: 1.5891e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0662e-05 - val_loss: 2.6546e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7528e-05 - val_loss: 6.8537e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9770e-05 - val_loss: 4.7864e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0475e-05 - val_loss: 1.8954e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2143e-05 - val_loss: 5.6947e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4006e-05 - val_loss: 7.2789e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.3537e-05 - val_loss: 9.2919e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6900e-05 - val_loss: 2.6531e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2458e-05 - val_loss: 5.9830e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0283e-05 - val_loss: 4.0415e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6775e-05 - val_loss: 1.8916e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1974e-05 - val_loss: 7.0174e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4497e-05 - val_loss: 3.2683e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1973e-05 - val_loss: 2.7694e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6776e-05 - val_loss: 2.5065e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5109e-05 - val_loss: 5.7452e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9875e-05 - val_loss: 2.6083e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.4303e-06 - val_loss: 4.6557e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1684e-05 - val_loss: 1.2236e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5159e-05 - val_loss: 5.3513e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0106e-05 - val_loss: 1.2785e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.6801e-05 - val_loss: 0.0020\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0371e-05 - val_loss: 8.4852e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0442e-05 - val_loss: 2.3915e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2990e-05 - val_loss: 3.5722e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4219e-05 - val_loss: 2.4086e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8704e-05 - val_loss: 5.6347e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.8459e-05 - val_loss: 0.0014\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0390e-05 - val_loss: 2.9386e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6402e-05 - val_loss: 1.0044e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6681e-05 - val_loss: 4.6545e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5428e-05 - val_loss: 8.6371e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0212e-05 - val_loss: 5.8568e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2940e-05 - val_loss: 3.9681e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1839e-05 - val_loss: 2.0771e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.7610e-06 - val_loss: 1.3521e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5307e-05 - val_loss: 2.8998e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1618e-05 - val_loss: 1.6112e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5775e-05 - val_loss: 6.1032e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9985e-05 - val_loss: 5.0549e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4551e-05 - val_loss: 1.6500e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3026e-05 - val_loss: 1.1085e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9998e-05 - val_loss: 2.9854e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0735e-05 - val_loss: 3.8214e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7316e-05 - val_loss: 4.9988e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3597e-05 - val_loss: 3.7800e-05\n",
      ">Neurons=80, Score=0.004616755904862657\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 15s 27ms/step - loss: 0.0021 - val_loss: 0.0099\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.4685e-04 - val_loss: 0.0065\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.5695e-04 - val_loss: 0.0029\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6830e-04 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7206e-04 - val_loss: 5.1231e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1408e-04 - val_loss: 3.4097e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.3681e-05 - val_loss: 2.0521e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.4731e-05 - val_loss: 1.1172e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.5074e-05 - val_loss: 1.5253e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.5555e-05 - val_loss: 5.9078e-05\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.6630e-05 - val_loss: 3.9849e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0685e-04 - val_loss: 2.7835e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3733e-05 - val_loss: 3.2066e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.5451e-05 - val_loss: 2.0327e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.8283e-05 - val_loss: 1.5642e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2048e-05 - val_loss: 4.3765e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9199e-05 - val_loss: 5.6480e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3290e-05 - val_loss: 1.7538e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7714e-05 - val_loss: 4.9434e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1942e-05 - val_loss: 2.8551e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.5079e-05 - val_loss: 2.8027e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.3518e-05 - val_loss: 6.3474e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.1549e-05 - val_loss: 2.4243e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3399e-05 - val_loss: 2.6364e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2978e-05 - val_loss: 2.7475e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9589e-05 - val_loss: 1.3417e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7799e-05 - val_loss: 9.7759e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.1429e-05 - val_loss: 3.0561e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6871e-05 - val_loss: 1.9335e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4270e-05 - val_loss: 8.4836e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3814e-05 - val_loss: 0.0017\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.6460e-05 - val_loss: 8.3157e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6771e-05 - val_loss: 4.6178e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8057e-05 - val_loss: 1.1583e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8281e-05 - val_loss: 6.9053e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5908e-05 - val_loss: 4.1855e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5012e-05 - val_loss: 7.5040e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4476e-05 - val_loss: 5.0574e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9425e-05 - val_loss: 3.4897e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8922e-05 - val_loss: 1.8411e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2893e-05 - val_loss: 7.7722e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9554e-05 - val_loss: 5.1871e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6284e-05 - val_loss: 7.7973e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4738e-05 - val_loss: 4.2684e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2821e-05 - val_loss: 3.3259e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4758e-05 - val_loss: 2.1327e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2139e-05 - val_loss: 5.9494e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3897e-05 - val_loss: 7.0235e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8200e-05 - val_loss: 2.2432e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6317e-05 - val_loss: 2.4819e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1700e-05 - val_loss: 1.4389e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4344e-05 - val_loss: 1.1667e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2001e-05 - val_loss: 3.8982e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2826e-05 - val_loss: 6.0930e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5661e-05 - val_loss: 3.6092e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2804e-05 - val_loss: 2.5551e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8441e-05 - val_loss: 8.7781e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7926e-05 - val_loss: 2.1883e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5421e-05 - val_loss: 1.2377e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4647e-05 - val_loss: 9.6885e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7034e-05 - val_loss: 7.2000e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2231e-05 - val_loss: 1.1392e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9022e-05 - val_loss: 2.0883e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5060e-05 - val_loss: 3.0823e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7705e-05 - val_loss: 1.7023e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4038e-05 - val_loss: 1.6682e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3970e-05 - val_loss: 2.9723e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5274e-05 - val_loss: 3.2028e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3819e-05 - val_loss: 3.6669e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4041e-05 - val_loss: 2.0634e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2602e-05 - val_loss: 1.1495e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9771e-05 - val_loss: 1.1781e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6164e-05 - val_loss: 8.1317e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3987e-05 - val_loss: 2.1752e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9909e-05 - val_loss: 5.4572e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7890e-05 - val_loss: 1.7650e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0058e-05 - val_loss: 2.4304e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1626e-05 - val_loss: 3.3500e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2825e-05 - val_loss: 2.3475e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2624e-05 - val_loss: 7.4288e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1277e-05 - val_loss: 1.4097e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5609e-05 - val_loss: 2.9476e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3057e-05 - val_loss: 0.0012\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5926e-05 - val_loss: 7.8667e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4038e-05 - val_loss: 3.9877e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6406e-05 - val_loss: 3.2144e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5353e-05 - val_loss: 5.4458e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5140e-05 - val_loss: 1.2652e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0610e-05 - val_loss: 3.3650e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6214e-05 - val_loss: 2.0181e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7481e-05 - val_loss: 1.4551e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0491e-05 - val_loss: 5.9417e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6633e-05 - val_loss: 4.0746e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8702e-05 - val_loss: 7.5605e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9497e-05 - val_loss: 1.9001e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8942e-05 - val_loss: 1.3203e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2375e-05 - val_loss: 2.6516e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8886e-05 - val_loss: 2.9217e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4392e-05 - val_loss: 3.3111e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2067e-05 - val_loss: 1.1743e-04\n",
      ">Neurons=80, Score=0.005299417534843087\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 16s 28ms/step - loss: 0.0022 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.9435e-04 - val_loss: 0.0078\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.3823e-04 - val_loss: 0.0047\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7992e-04 - val_loss: 0.0024\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8784e-04 - val_loss: 6.3682e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5505e-04 - val_loss: 2.8620e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0573e-04 - val_loss: 2.7795e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2715e-04 - val_loss: 3.0221e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.9065e-05 - val_loss: 2.0359e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.4732e-05 - val_loss: 4.4326e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.8789e-05 - val_loss: 3.8694e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.6938e-05 - val_loss: 6.8358e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.9969e-05 - val_loss: 4.2848e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.7295e-05 - val_loss: 0.0011\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0136e-04 - val_loss: 3.4467e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.6666e-05 - val_loss: 0.0011\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.7017e-05 - val_loss: 7.6687e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5255e-05 - val_loss: 7.4284e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.1603e-05 - val_loss: 4.1325e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7943e-05 - val_loss: 5.0104e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9627e-05 - val_loss: 2.5728e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2696e-05 - val_loss: 1.2881e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.8684e-05 - val_loss: 4.5581e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0934e-05 - val_loss: 3.8280e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5596e-05 - val_loss: 0.0011\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8521e-05 - val_loss: 1.3628e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0767e-05 - val_loss: 1.1925e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5522e-05 - val_loss: 9.5442e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3026e-05 - val_loss: 1.4090e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9214e-05 - val_loss: 1.0519e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5139e-05 - val_loss: 1.1397e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4198e-05 - val_loss: 4.9225e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.1195e-05 - val_loss: 1.5613e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9092e-05 - val_loss: 2.9633e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9685e-05 - val_loss: 1.0806e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1661e-05 - val_loss: 5.5468e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5543e-05 - val_loss: 7.0219e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8799e-05 - val_loss: 1.6047e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8991e-05 - val_loss: 1.1077e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5752e-05 - val_loss: 1.4985e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.1512e-05 - val_loss: 6.2109e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7289e-05 - val_loss: 4.9688e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.0544e-05 - val_loss: 0.0012\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.8817e-05 - val_loss: 3.9452e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9467e-05 - val_loss: 1.3438e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1721e-05 - val_loss: 4.3984e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9740e-05 - val_loss: 2.3824e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9187e-05 - val_loss: 9.5473e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4458e-05 - val_loss: 8.0853e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3479e-05 - val_loss: 2.9676e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2993e-05 - val_loss: 9.9639e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1912e-05 - val_loss: 4.5501e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6943e-05 - val_loss: 3.4307e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8413e-05 - val_loss: 3.6405e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1597e-05 - val_loss: 1.7483e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5797e-05 - val_loss: 6.3009e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.8058e-05 - val_loss: 8.6651e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.4636e-05 - val_loss: 1.6789e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4391e-05 - val_loss: 1.2218e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.6764e-05 - val_loss: 1.1658e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.7540e-05 - val_loss: 0.0011\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7979e-05 - val_loss: 2.7928e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2108e-05 - val_loss: 7.3358e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5509e-05 - val_loss: 6.0568e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5723e-05 - val_loss: 6.4725e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5509e-05 - val_loss: 1.1753e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6360e-05 - val_loss: 1.2816e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7109e-05 - val_loss: 5.4448e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.9192e-05 - val_loss: 8.6080e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4585e-05 - val_loss: 2.9478e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7552e-05 - val_loss: 1.3022e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8535e-05 - val_loss: 3.0714e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5139e-05 - val_loss: 5.9908e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1321e-05 - val_loss: 2.8631e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8598e-05 - val_loss: 1.2444e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6015e-05 - val_loss: 6.2663e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6683e-05 - val_loss: 5.4045e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5778e-05 - val_loss: 4.1852e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6723e-05 - val_loss: 3.1415e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1488e-05 - val_loss: 3.1809e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7928e-05 - val_loss: 5.0990e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0288e-05 - val_loss: 1.6490e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9098e-05 - val_loss: 4.3378e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3570e-05 - val_loss: 2.2779e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6556e-05 - val_loss: 1.0115e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6620e-05 - val_loss: 1.4567e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0878e-05 - val_loss: 4.1019e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3567e-05 - val_loss: 9.8827e-06\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3631e-05 - val_loss: 4.5820e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9235e-05 - val_loss: 1.0555e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5666e-05 - val_loss: 3.2080e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1037e-05 - val_loss: 2.0603e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7144e-05 - val_loss: 3.8118e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8837e-05 - val_loss: 0.0010\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8988e-05 - val_loss: 1.7253e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1742e-05 - val_loss: 5.5931e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4967e-05 - val_loss: 2.2142e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.2688e-05 - val_loss: 0.0014\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6056e-05 - val_loss: 8.2765e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5540e-05 - val_loss: 4.2581e-05\n",
      ">Neurons=80, Score=0.0020578874682541937\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 14s 25ms/step - loss: 0.0021 - val_loss: 0.0100\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.4108e-04 - val_loss: 0.0069\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.9601e-04 - val_loss: 0.0041\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1520e-04 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3977e-04 - val_loss: 8.9273e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3231e-04 - val_loss: 2.5076e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0280e-04 - val_loss: 2.6432e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.9608e-05 - val_loss: 2.9571e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.6273e-05 - val_loss: 3.2958e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0127e-04 - val_loss: 1.6211e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.4446e-05 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6318e-05 - val_loss: 1.9995e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.0184e-05 - val_loss: 3.0341e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0255e-04 - val_loss: 2.3720e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.0941e-05 - val_loss: 4.1491e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.8730e-05 - val_loss: 8.8222e-05\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7227e-05 - val_loss: 1.6970e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.7802e-05 - val_loss: 3.4145e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2789e-05 - val_loss: 1.1141e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.6664e-05 - val_loss: 2.7484e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.9135e-05 - val_loss: 2.5998e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.4131e-05 - val_loss: 1.4427e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2603e-05 - val_loss: 1.6747e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.7498e-05 - val_loss: 3.1372e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.1425e-05 - val_loss: 3.8494e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2001e-05 - val_loss: 1.2961e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.7246e-05 - val_loss: 1.6682e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9883e-05 - val_loss: 1.0004e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4832e-05 - val_loss: 5.6732e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3941e-05 - val_loss: 3.7131e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2856e-05 - val_loss: 1.3606e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3172e-05 - val_loss: 1.2327e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4395e-05 - val_loss: 1.2623e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.7716e-05 - val_loss: 2.8042e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4096e-05 - val_loss: 6.8051e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.8719e-05 - val_loss: 0.0015\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0475e-05 - val_loss: 4.7401e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2718e-05 - val_loss: 2.3034e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6201e-05 - val_loss: 1.5911e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9386e-05 - val_loss: 6.0430e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2199e-05 - val_loss: 2.4923e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1337e-05 - val_loss: 2.7113e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4323e-05 - val_loss: 1.8384e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4650e-05 - val_loss: 9.4277e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8087e-05 - val_loss: 2.1726e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6437e-05 - val_loss: 4.1109e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.8310e-05 - val_loss: 6.6536e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2902e-05 - val_loss: 4.5025e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9690e-05 - val_loss: 9.2520e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5676e-05 - val_loss: 1.5028e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2172e-05 - val_loss: 2.8257e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2492e-05 - val_loss: 3.4023e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4077e-05 - val_loss: 1.5141e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5489e-05 - val_loss: 0.0014\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0816e-05 - val_loss: 6.4937e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1109e-05 - val_loss: 7.2821e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9447e-05 - val_loss: 1.2763e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0315e-05 - val_loss: 8.8491e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0946e-05 - val_loss: 3.4232e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7224e-05 - val_loss: 2.1393e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6320e-05 - val_loss: 1.6944e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2122e-05 - val_loss: 6.5678e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1749e-05 - val_loss: 8.0475e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6065e-05 - val_loss: 1.6806e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6335e-05 - val_loss: 1.1443e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2767e-05 - val_loss: 9.4729e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8122e-05 - val_loss: 2.8392e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1698e-05 - val_loss: 5.6350e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4653e-05 - val_loss: 5.9333e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4670e-05 - val_loss: 4.7926e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0909e-05 - val_loss: 2.4888e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1030e-05 - val_loss: 3.4749e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2336e-05 - val_loss: 6.6156e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4604e-05 - val_loss: 5.7534e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.5729e-05 - val_loss: 1.5248e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4951e-05 - val_loss: 9.6517e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3266e-05 - val_loss: 3.1281e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1810e-05 - val_loss: 3.1501e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7572e-05 - val_loss: 3.1302e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9616e-05 - val_loss: 1.2894e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2176e-05 - val_loss: 5.0238e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.1163e-05 - val_loss: 0.0012\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4438e-05 - val_loss: 2.8685e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3064e-05 - val_loss: 2.2486e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8433e-05 - val_loss: 1.8722e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7466e-05 - val_loss: 3.7240e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9143e-05 - val_loss: 5.0303e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2684e-05 - val_loss: 7.6482e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0965e-05 - val_loss: 3.3620e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5469e-05 - val_loss: 5.9892e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2864e-05 - val_loss: 1.9553e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.6465e-06 - val_loss: 3.6034e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2341e-05 - val_loss: 7.1390e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6613e-05 - val_loss: 9.7024e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4943e-05 - val_loss: 1.5196e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2868e-05 - val_loss: 1.2658e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2057e-05 - val_loss: 2.1150e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0257e-05 - val_loss: 2.0199e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5500e-05 - val_loss: 2.0179e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4216e-05 - val_loss: 1.9950e-04\n",
      ">Neurons=85, Score=0.013748012133873999\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 16s 29ms/step - loss: 0.0021 - val_loss: 0.0101\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.2772e-04 - val_loss: 0.0067\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2492e-04 - val_loss: 0.0033\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.1630e-04 - val_loss: 0.0013\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0743e-04 - val_loss: 6.7604e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9427e-04 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1738e-04 - val_loss: 0.0015\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7460e-04 - val_loss: 2.2168e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.5507e-05 - val_loss: 2.5063e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.5584e-05 - val_loss: 3.3505e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.2537e-05 - val_loss: 2.0388e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.5331e-05 - val_loss: 1.2137e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.0869e-05 - val_loss: 2.4417e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1009e-04 - val_loss: 5.7932e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3682e-05 - val_loss: 5.6624e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1785e-04 - val_loss: 0.0010\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7530e-05 - val_loss: 9.4270e-05\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7230e-05 - val_loss: 3.2369e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9482e-05 - val_loss: 2.6905e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1893e-05 - val_loss: 4.0383e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.9774e-05 - val_loss: 3.6037e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1293e-05 - val_loss: 2.9962e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5948e-05 - val_loss: 2.9248e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.1216e-05 - val_loss: 2.4537e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1275e-05 - val_loss: 7.6556e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3928e-05 - val_loss: 6.5044e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2578e-05 - val_loss: 9.0804e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6927e-05 - val_loss: 2.1513e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.7050e-05 - val_loss: 1.9530e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4288e-05 - val_loss: 8.5425e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8606e-05 - val_loss: 3.7335e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2665e-05 - val_loss: 8.0804e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8890e-05 - val_loss: 3.1444e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9654e-05 - val_loss: 4.6337e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1997e-05 - val_loss: 8.8001e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6575e-05 - val_loss: 7.8317e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8202e-05 - val_loss: 3.5627e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1007e-05 - val_loss: 1.7658e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8539e-05 - val_loss: 6.1174e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3859e-05 - val_loss: 7.5972e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0074e-05 - val_loss: 4.2823e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8035e-05 - val_loss: 3.4678e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7420e-05 - val_loss: 1.7171e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3910e-05 - val_loss: 1.4266e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0690e-05 - val_loss: 9.4533e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.1934e-05 - val_loss: 2.3241e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1942e-05 - val_loss: 3.4144e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.2682e-05 - val_loss: 6.1193e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1008e-05 - val_loss: 7.6225e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5552e-05 - val_loss: 2.3772e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3181e-05 - val_loss: 3.0457e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.0072e-05 - val_loss: 8.5070e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0031e-05 - val_loss: 5.0966e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4298e-05 - val_loss: 1.2464e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5589e-05 - val_loss: 5.2580e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.4447e-05 - val_loss: 3.0089e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3289e-05 - val_loss: 2.7707e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5370e-05 - val_loss: 1.5651e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4073e-05 - val_loss: 4.4058e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5534e-05 - val_loss: 3.5769e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7136e-05 - val_loss: 1.8294e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1268e-05 - val_loss: 4.1226e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6845e-05 - val_loss: 1.1391e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5040e-05 - val_loss: 3.9901e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.4126e-05 - val_loss: 1.5587e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3285e-04 - val_loss: 2.7091e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 1.3778e-05 - val_loss: 9.1119e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.4088e-05 - val_loss: 1.4220e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.4336e-05 - val_loss: 3.2618e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5562e-05 - val_loss: 4.0531e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 3s 19ms/step - loss: 2.3435e-05 - val_loss: 3.5492e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.6573e-05 - val_loss: 2.4184e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3530e-05 - val_loss: 3.1528e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3657e-05 - val_loss: 3.2184e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7009e-05 - val_loss: 4.8352e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3741e-05 - val_loss: 9.7832e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3584e-05 - val_loss: 3.5879e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2682e-05 - val_loss: 7.7937e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0730e-05 - val_loss: 1.8588e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4398e-05 - val_loss: 4.2129e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7528e-05 - val_loss: 5.1163e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7943e-05 - val_loss: 5.7641e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3343e-05 - val_loss: 2.3812e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.3091e-06 - val_loss: 2.1102e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.5852e-05 - val_loss: 6.4888e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.2223e-05 - val_loss: 9.8307e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.4996e-05 - val_loss: 8.1602e-06\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.8670e-05 - val_loss: 7.7455e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 3.2599e-05 - val_loss: 8.1807e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 2.2699e-05 - val_loss: 3.3725e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 3.2282e-05 - val_loss: 1.5985e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.8829e-05 - val_loss: 8.2362e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 3.3938e-05 - val_loss: 1.8220e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6297e-05 - val_loss: 5.8834e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.0708e-05 - val_loss: 2.4410e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.4891e-05 - val_loss: 2.6498e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 1.3097e-05 - val_loss: 2.6400e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4195e-05 - val_loss: 4.8076e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.9214e-05 - val_loss: 5.8746e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.4588e-05 - val_loss: 9.6436e-05\n",
      ">Neurons=85, Score=0.0065471846028231084\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 19s 33ms/step - loss: 0.0021 - val_loss: 0.0102\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.6137e-04 - val_loss: 0.0067\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.1036e-04 - val_loss: 0.0033\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0137e-04 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3649e-04 - val_loss: 3.3634e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5440e-04 - val_loss: 4.1080e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1504e-04 - val_loss: 7.4696e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2973e-04 - val_loss: 4.5423e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1578e-04 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0020e-04 - val_loss: 4.2088e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.5624e-05 - val_loss: 2.1523e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.0408e-05 - val_loss: 4.0224e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.9438e-05 - val_loss: 3.2661e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3105e-05 - val_loss: 8.9931e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0052e-04 - val_loss: 4.4285e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.6101e-05 - val_loss: 4.3349e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0245e-05 - val_loss: 2.5197e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.1703e-05 - val_loss: 3.4363e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8109e-05 - val_loss: 4.6867e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2547e-05 - val_loss: 1.2481e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0472e-05 - val_loss: 9.3699e-05\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.1202e-05 - val_loss: 3.5646e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.0056e-05 - val_loss: 8.5403e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6140e-05 - val_loss: 9.0420e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 9.4448e-05 - val_loss: 4.9493e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 5.8757e-05 - val_loss: 2.7363e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5378e-05 - val_loss: 1.0291e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6159e-05 - val_loss: 7.2784e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.6478e-05 - val_loss: 7.2108e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.6164e-05 - val_loss: 1.0276e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8709e-05 - val_loss: 6.7454e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1947e-05 - val_loss: 4.5088e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.5970e-05 - val_loss: 5.0243e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7063e-05 - val_loss: 4.8815e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3165e-05 - val_loss: 2.5120e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7139e-05 - val_loss: 6.9968e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1381e-05 - val_loss: 5.5068e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2117e-05 - val_loss: 5.9742e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3734e-05 - val_loss: 3.2362e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8369e-05 - val_loss: 7.2857e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8781e-05 - val_loss: 1.9982e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8411e-05 - val_loss: 3.8707e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5329e-05 - val_loss: 6.5402e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5578e-05 - val_loss: 3.0711e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9463e-05 - val_loss: 4.5612e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1867e-05 - val_loss: 4.4459e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.3652e-05 - val_loss: 0.0015\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6973e-05 - val_loss: 3.3669e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0902e-05 - val_loss: 1.5717e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3213e-05 - val_loss: 1.1178e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.1850e-05 - val_loss: 1.9741e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 3.0695e-05 - val_loss: 3.1719e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0521e-05 - val_loss: 4.5214e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7418e-05 - val_loss: 9.6829e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3689e-05 - val_loss: 7.4335e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0996e-05 - val_loss: 3.1742e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.7018e-05 - val_loss: 4.8120e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6114e-05 - val_loss: 1.1628e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4185e-05 - val_loss: 1.2711e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.2916e-05 - val_loss: 5.5744e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.1786e-05 - val_loss: 1.2779e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0464e-05 - val_loss: 1.5447e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.8849e-05 - val_loss: 3.2798e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.7213e-05 - val_loss: 4.7274e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.9747e-05 - val_loss: 5.0675e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.9078e-05 - val_loss: 6.0947e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6665e-05 - val_loss: 3.1717e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.6916e-05 - val_loss: 9.6988e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9765e-05 - val_loss: 1.6494e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2659e-05 - val_loss: 7.1498e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8320e-05 - val_loss: 9.7288e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7301e-05 - val_loss: 5.6260e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9311e-05 - val_loss: 1.0282e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0493e-05 - val_loss: 1.4604e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7595e-05 - val_loss: 8.2904e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0142e-05 - val_loss: 8.2710e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5679e-05 - val_loss: 6.1159e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8778e-05 - val_loss: 8.7050e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7464e-05 - val_loss: 5.9786e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.4881e-06 - val_loss: 2.3950e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.6780e-06 - val_loss: 1.6361e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8320e-05 - val_loss: 3.1206e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4243e-05 - val_loss: 1.8505e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0271e-05 - val_loss: 1.1836e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2239e-05 - val_loss: 2.3589e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4507e-05 - val_loss: 5.9640e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.5895e-05 - val_loss: 3.9473e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6653e-05 - val_loss: 4.9521e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7617e-05 - val_loss: 1.0717e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0101e-05 - val_loss: 0.0016\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.2243e-05 - val_loss: 1.2312e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.1759e-05 - val_loss: 3.3640e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0464e-05 - val_loss: 1.2001e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0749e-05 - val_loss: 1.8542e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7840e-05 - val_loss: 5.2145e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3483e-05 - val_loss: 1.9181e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7055e-05 - val_loss: 3.9369e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9680e-05 - val_loss: 9.3648e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7248e-05 - val_loss: 6.6709e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9637e-05 - val_loss: 2.8623e-05\n",
      ">Neurons=85, Score=0.002277636667713523\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 17s 31ms/step - loss: 0.0022 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 0.0010 - val_loss: 0.0074\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.4714e-04 - val_loss: 0.0038\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8432e-04 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.1107e-04 - val_loss: 9.4983e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.1538e-04 - val_loss: 6.1970e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.1873e-05 - val_loss: 3.8156e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0630e-04 - val_loss: 3.5364e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0191e-04 - val_loss: 8.0272e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4029e-04 - val_loss: 6.0770e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.2350e-04 - val_loss: 5.0140e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.3077e-05 - val_loss: 3.5990e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 7.1044e-05 - val_loss: 1.3564e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.2962e-05 - val_loss: 4.3276e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.9910e-05 - val_loss: 1.8565e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.6287e-05 - val_loss: 2.5445e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4672e-05 - val_loss: 1.8251e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7774e-05 - val_loss: 1.6741e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6754e-05 - val_loss: 7.0244e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.1477e-04 - val_loss: 0.0012\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.2131e-04 - val_loss: 1.2512e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.8036e-05 - val_loss: 4.2678e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4595e-05 - val_loss: 1.3445e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6823e-05 - val_loss: 6.0219e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.6585e-05 - val_loss: 8.6101e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4642e-05 - val_loss: 4.8572e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.2321e-05 - val_loss: 9.3502e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.1368e-05 - val_loss: 1.5079e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.5606e-05 - val_loss: 1.1845e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.8546e-05 - val_loss: 2.5644e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4800e-05 - val_loss: 7.7658e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4020e-05 - val_loss: 4.0661e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.0149e-05 - val_loss: 6.7308e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0983e-05 - val_loss: 6.1496e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6811e-05 - val_loss: 8.6321e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.7792e-05 - val_loss: 1.6058e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.2817e-05 - val_loss: 9.4580e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2001e-05 - val_loss: 5.3521e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.8713e-05 - val_loss: 3.1275e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.1792e-05 - val_loss: 2.4554e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9997e-05 - val_loss: 6.1988e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4048e-05 - val_loss: 2.1925e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4105e-05 - val_loss: 9.5874e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.9725e-05 - val_loss: 2.0849e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9439e-05 - val_loss: 7.4236e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4313e-05 - val_loss: 1.3838e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8842e-05 - val_loss: 1.3300e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4496e-05 - val_loss: 5.0955e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4774e-05 - val_loss: 4.6920e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.2090e-05 - val_loss: 3.4753e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.4601e-05 - val_loss: 8.8274e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3445e-05 - val_loss: 1.7894e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.4009e-05 - val_loss: 1.2267e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.5675e-05 - val_loss: 8.5795e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8171e-05 - val_loss: 6.6008e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6134e-05 - val_loss: 2.0750e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4346e-05 - val_loss: 8.1907e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6384e-05 - val_loss: 5.2281e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.1162e-05 - val_loss: 1.4622e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4394e-05 - val_loss: 5.8537e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0146e-05 - val_loss: 1.7003e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4393e-05 - val_loss: 4.3673e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0599e-05 - val_loss: 8.4237e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2300e-05 - val_loss: 1.1099e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2403e-05 - val_loss: 4.3812e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3348e-05 - val_loss: 8.7089e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9751e-05 - val_loss: 4.0378e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1309e-05 - val_loss: 1.6452e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2771e-05 - val_loss: 1.3427e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8558e-05 - val_loss: 4.3773e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3974e-05 - val_loss: 9.1671e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3454e-05 - val_loss: 1.1520e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6222e-05 - val_loss: 1.6731e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1526e-05 - val_loss: 6.0878e-06\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.1012e-05 - val_loss: 1.3999e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.8611e-05 - val_loss: 3.7920e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 3s 18ms/step - loss: 1.6673e-05 - val_loss: 3.8770e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1763e-05 - val_loss: 1.4734e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.6006e-05 - val_loss: 7.1891e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6660e-05 - val_loss: 1.5459e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.7911e-05 - val_loss: 2.5323e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5420e-05 - val_loss: 2.2598e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0964e-05 - val_loss: 4.3912e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.5360e-05 - val_loss: 1.2771e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.5345e-05 - val_loss: 1.7838e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.2343e-05 - val_loss: 2.0733e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.9889e-05 - val_loss: 1.4174e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.6843e-05 - val_loss: 1.2358e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5521e-05 - val_loss: 2.6030e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7237e-05 - val_loss: 3.1960e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3704e-05 - val_loss: 2.3385e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4374e-05 - val_loss: 0.0011\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.7567e-05 - val_loss: 1.0043e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9358e-05 - val_loss: 2.5198e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1313e-05 - val_loss: 1.5580e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0951e-05 - val_loss: 2.0637e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.7171e-05 - val_loss: 2.4959e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.9039e-05 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.0983e-05 - val_loss: 3.7696e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.5470e-05 - val_loss: 5.5226e-04\n",
      ">Neurons=85, Score=0.026790870469994843\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 16s 29ms/step - loss: 0.0021 - val_loss: 0.0107\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.8995e-04 - val_loss: 0.0076\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.1849e-04 - val_loss: 0.0037\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.0380e-04 - val_loss: 0.0012\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7442e-04 - val_loss: 2.7488e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3162e-04 - val_loss: 2.8353e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.1353e-05 - val_loss: 6.4108e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0053e-04 - val_loss: 4.2336e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0415e-04 - val_loss: 2.4013e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5856e-04 - val_loss: 9.8115e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1552e-04 - val_loss: 3.3339e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.4521e-05 - val_loss: 2.1231e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.6533e-05 - val_loss: 7.7995e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.6322e-04 - val_loss: 0.0015\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2281e-04 - val_loss: 2.6179e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8887e-05 - val_loss: 1.4386e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.3777e-05 - val_loss: 9.4308e-05\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7819e-05 - val_loss: 2.5956e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.3384e-05 - val_loss: 4.1460e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.8792e-05 - val_loss: 3.6062e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.0702e-05 - val_loss: 1.9588e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.4368e-05 - val_loss: 5.0800e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8963e-05 - val_loss: 2.5039e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.6812e-05 - val_loss: 1.5497e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5001e-05 - val_loss: 6.8797e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3014e-05 - val_loss: 3.0842e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.7994e-05 - val_loss: 3.7722e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.5942e-05 - val_loss: 3.9824e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.4175e-05 - val_loss: 2.2457e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.1854e-05 - val_loss: 6.2806e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8925e-05 - val_loss: 1.8251e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.8310e-05 - val_loss: 1.1516e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.1492e-05 - val_loss: 1.3640e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8311e-05 - val_loss: 1.0509e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.2316e-05 - val_loss: 4.3894e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0115e-05 - val_loss: 2.4198e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1114e-05 - val_loss: 4.9476e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3646e-05 - val_loss: 4.8686e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8272e-05 - val_loss: 9.1719e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0119e-05 - val_loss: 6.0460e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.0820e-05 - val_loss: 5.9698e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1390e-05 - val_loss: 1.5522e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6977e-05 - val_loss: 7.4696e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9618e-05 - val_loss: 6.1050e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7584e-05 - val_loss: 2.0501e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3671e-05 - val_loss: 1.3275e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2235e-05 - val_loss: 3.0901e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7525e-05 - val_loss: 2.2062e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.8732e-05 - val_loss: 3.5075e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4308e-05 - val_loss: 2.0174e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3374e-05 - val_loss: 3.8492e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1415e-05 - val_loss: 1.9594e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0374e-05 - val_loss: 1.1792e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5490e-05 - val_loss: 7.2215e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.1182e-05 - val_loss: 1.5026e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8578e-05 - val_loss: 2.4247e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4955e-05 - val_loss: 6.5536e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4529e-05 - val_loss: 5.2600e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9140e-05 - val_loss: 1.0313e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2196e-05 - val_loss: 2.6674e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6464e-05 - val_loss: 5.8016e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8645e-05 - val_loss: 1.4486e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1319e-05 - val_loss: 1.3897e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7212e-05 - val_loss: 3.4787e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4001e-05 - val_loss: 1.0286e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6375e-05 - val_loss: 5.3973e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1277e-05 - val_loss: 3.1639e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4211e-05 - val_loss: 2.5794e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.4762e-05 - val_loss: 5.4112e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8261e-05 - val_loss: 1.5161e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9661e-05 - val_loss: 5.1963e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6197e-05 - val_loss: 4.5566e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4142e-05 - val_loss: 3.9029e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2032e-05 - val_loss: 2.9910e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6192e-05 - val_loss: 1.7612e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7774e-05 - val_loss: 1.4684e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4019e-05 - val_loss: 1.4241e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8166e-05 - val_loss: 4.7153e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3551e-05 - val_loss: 4.1352e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1089e-05 - val_loss: 1.7308e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1897e-05 - val_loss: 1.7368e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.1865e-05 - val_loss: 3.8850e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9439e-05 - val_loss: 1.3045e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8099e-05 - val_loss: 7.4434e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8823e-05 - val_loss: 4.4467e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3778e-05 - val_loss: 9.4008e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0298e-05 - val_loss: 5.6310e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8370e-05 - val_loss: 1.7143e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4714e-05 - val_loss: 1.4791e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.5027e-06 - val_loss: 2.5975e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5880e-05 - val_loss: 8.8453e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2364e-05 - val_loss: 2.2638e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.1871e-05 - val_loss: 4.5468e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8987e-05 - val_loss: 7.1448e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.4794e-06 - val_loss: 1.1868e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1551e-05 - val_loss: 1.1660e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4402e-05 - val_loss: 2.3197e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3883e-05 - val_loss: 2.7284e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9043e-05 - val_loss: 2.4498e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9017e-05 - val_loss: 4.5182e-04\n",
      ">Neurons=85, Score=0.021810010366607457\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 18s 30ms/step - loss: 0.0020 - val_loss: 0.0103\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 9.8915e-04 - val_loss: 0.0075\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 6.8759e-04 - val_loss: 0.0043\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.1140e-04 - val_loss: 0.0018\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 2.5479e-04 - val_loss: 5.9085e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.7206e-04 - val_loss: 8.7069e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.6288e-04 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.8318e-05 - val_loss: 0.0016\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.1125e-05 - val_loss: 4.0245e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.5393e-05 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.7555e-05 - val_loss: 2.5113e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.0047e-05 - val_loss: 2.3195e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3097e-05 - val_loss: 2.2251e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.9689e-05 - val_loss: 5.1635e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.2394e-05 - val_loss: 2.4429e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.5310e-05 - val_loss: 3.7955e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3877e-05 - val_loss: 1.0664e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.7172e-05 - val_loss: 1.2058e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2622e-05 - val_loss: 2.1611e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3401e-05 - val_loss: 2.7396e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7986e-05 - val_loss: 7.8425e-05\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.2086e-05 - val_loss: 3.1040e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2521e-05 - val_loss: 1.0607e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3795e-05 - val_loss: 1.1544e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8084e-05 - val_loss: 1.8722e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6397e-05 - val_loss: 1.8664e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.9632e-05 - val_loss: 0.0010\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.5504e-05 - val_loss: 2.9396e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.7059e-05 - val_loss: 1.2902e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1258e-05 - val_loss: 2.2536e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8523e-05 - val_loss: 7.2403e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.2950e-05 - val_loss: 6.2885e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4281e-05 - val_loss: 1.6536e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.1097e-05 - val_loss: 3.7324e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5799e-05 - val_loss: 2.5249e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4161e-05 - val_loss: 1.4601e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5546e-05 - val_loss: 9.3117e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0762e-05 - val_loss: 6.3663e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2331e-05 - val_loss: 8.3402e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9995e-05 - val_loss: 5.7558e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3770e-05 - val_loss: 0.0013\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7955e-05 - val_loss: 2.2969e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3723e-05 - val_loss: 1.0851e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1743e-05 - val_loss: 2.0635e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6668e-05 - val_loss: 1.1327e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2149e-05 - val_loss: 5.9351e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1076e-05 - val_loss: 6.2967e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.6016e-05 - val_loss: 0.0013\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4810e-05 - val_loss: 8.7459e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7046e-05 - val_loss: 8.1453e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2677e-05 - val_loss: 5.9677e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1682e-05 - val_loss: 7.7863e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5331e-05 - val_loss: 4.3408e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7956e-05 - val_loss: 9.4986e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0231e-05 - val_loss: 3.4779e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3604e-05 - val_loss: 3.7653e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.2475e-05 - val_loss: 4.2879e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0850e-05 - val_loss: 8.3173e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4584e-05 - val_loss: 7.5352e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5219e-05 - val_loss: 5.0830e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.1909e-05 - val_loss: 1.3187e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0879e-05 - val_loss: 1.0569e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9290e-05 - val_loss: 2.6105e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4710e-05 - val_loss: 1.2007e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8276e-05 - val_loss: 5.7911e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9544e-05 - val_loss: 1.9476e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6735e-05 - val_loss: 6.0337e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.9537e-05 - val_loss: 9.8287e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9510e-05 - val_loss: 5.7748e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6765e-05 - val_loss: 4.1577e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7988e-05 - val_loss: 5.4876e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1996e-05 - val_loss: 2.2597e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3716e-05 - val_loss: 1.3142e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9275e-05 - val_loss: 4.4520e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2389e-05 - val_loss: 9.2428e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6973e-05 - val_loss: 3.1359e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0508e-05 - val_loss: 2.6842e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6139e-05 - val_loss: 1.0591e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.2416e-05 - val_loss: 7.0926e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3034e-05 - val_loss: 4.2664e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.9623e-05 - val_loss: 1.1319e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4736e-05 - val_loss: 1.6503e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8796e-05 - val_loss: 5.0207e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9450e-05 - val_loss: 2.5731e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.8549e-06 - val_loss: 1.2288e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9034e-05 - val_loss: 1.1334e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8863e-05 - val_loss: 1.7509e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7466e-05 - val_loss: 4.0237e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8315e-05 - val_loss: 3.2629e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7189e-05 - val_loss: 3.9623e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1261e-05 - val_loss: 3.0944e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3424e-05 - val_loss: 6.6858e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4404e-05 - val_loss: 4.7618e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2272e-05 - val_loss: 2.1430e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4858e-05 - val_loss: 8.9422e-06\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7177e-05 - val_loss: 1.8928e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4154e-05 - val_loss: 3.8394e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4087e-05 - val_loss: 1.5363e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1006e-05 - val_loss: 3.0086e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6765e-05 - val_loss: 3.1915e-04\n",
      ">Neurons=85, Score=0.01828309177653864\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 15s 29ms/step - loss: 0.0021 - val_loss: 0.0096\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.0848e-04 - val_loss: 0.0063\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0664e-04 - val_loss: 0.0032\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3911e-04 - val_loss: 0.0013\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9646e-04 - val_loss: 9.9488e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.0249e-04 - val_loss: 5.5967e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.9103e-04 - val_loss: 0.0010\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2464e-04 - val_loss: 5.7099e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.0481e-05 - val_loss: 7.2833e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7816e-04 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.1679e-04 - val_loss: 6.2521e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9756e-05 - val_loss: 9.1071e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.1222e-05 - val_loss: 2.4830e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5218e-05 - val_loss: 8.6304e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0359e-05 - val_loss: 1.5743e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.4704e-05 - val_loss: 1.6196e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0088e-04 - val_loss: 6.6622e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.1326e-05 - val_loss: 1.1136e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1652e-05 - val_loss: 1.2661e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.8352e-05 - val_loss: 1.6669e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3155e-05 - val_loss: 1.9836e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4190e-05 - val_loss: 2.4124e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2013e-05 - val_loss: 1.3521e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7387e-05 - val_loss: 1.1133e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7909e-05 - val_loss: 2.5030e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2766e-05 - val_loss: 4.2243e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9491e-05 - val_loss: 6.9107e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7090e-05 - val_loss: 2.7451e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6989e-05 - val_loss: 2.0674e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.4012e-05 - val_loss: 7.0929e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.0194e-05 - val_loss: 9.3413e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9528e-05 - val_loss: 1.6617e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7905e-05 - val_loss: 7.2498e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6732e-05 - val_loss: 1.4016e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5145e-05 - val_loss: 4.8119e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4091e-05 - val_loss: 2.2887e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.2096e-05 - val_loss: 1.6140e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3525e-05 - val_loss: 1.5100e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4882e-05 - val_loss: 2.9548e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3426e-05 - val_loss: 1.1992e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8977e-05 - val_loss: 1.6570e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7859e-05 - val_loss: 4.1482e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1401e-05 - val_loss: 3.4520e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9518e-05 - val_loss: 3.3726e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2453e-05 - val_loss: 1.3652e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8933e-05 - val_loss: 1.6566e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8518e-05 - val_loss: 3.5633e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3499e-05 - val_loss: 4.7474e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7965e-05 - val_loss: 8.2562e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9225e-05 - val_loss: 1.2561e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4393e-05 - val_loss: 5.5877e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6663e-05 - val_loss: 5.6317e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.8568e-05 - val_loss: 2.3692e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1205e-05 - val_loss: 7.7131e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2608e-05 - val_loss: 4.5349e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2806e-05 - val_loss: 1.9853e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5957e-05 - val_loss: 4.1370e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2320e-05 - val_loss: 9.3647e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8370e-05 - val_loss: 1.5441e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.6139e-05 - val_loss: 2.4647e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0619e-05 - val_loss: 1.0750e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3407e-05 - val_loss: 6.8864e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8246e-05 - val_loss: 2.2812e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1851e-05 - val_loss: 7.8842e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6019e-05 - val_loss: 1.3001e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4385e-05 - val_loss: 1.5687e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6799e-05 - val_loss: 8.2294e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3754e-05 - val_loss: 4.4723e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9152e-05 - val_loss: 2.6541e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6766e-05 - val_loss: 0.0017\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7925e-05 - val_loss: 7.4491e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4101e-05 - val_loss: 2.3625e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3716e-05 - val_loss: 2.0592e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2401e-05 - val_loss: 1.7066e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6783e-05 - val_loss: 1.9179e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2078e-05 - val_loss: 2.6452e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7151e-05 - val_loss: 6.9615e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7456e-05 - val_loss: 3.9517e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1047e-05 - val_loss: 5.9640e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3598e-05 - val_loss: 1.0571e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7737e-05 - val_loss: 3.4974e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7006e-05 - val_loss: 9.6745e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.1284e-06 - val_loss: 1.6784e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1021e-05 - val_loss: 1.0187e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4887e-05 - val_loss: 2.8092e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4846e-05 - val_loss: 1.4374e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6269e-05 - val_loss: 2.0724e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4139e-05 - val_loss: 1.9128e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6705e-05 - val_loss: 0.0015\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9586e-05 - val_loss: 1.1014e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2339e-05 - val_loss: 5.5336e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9308e-05 - val_loss: 7.1298e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9589e-05 - val_loss: 3.6041e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4062e-05 - val_loss: 4.2542e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8564e-05 - val_loss: 1.7931e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5565e-05 - val_loss: 1.3458e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9901e-05 - val_loss: 1.8495e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.3054e-06 - val_loss: 1.0217e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6111e-05 - val_loss: 4.7361e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9049e-05 - val_loss: 2.3436e-05\n",
      ">Neurons=85, Score=0.002479226895957254\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 18s 34ms/step - loss: 0.0021 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 9.9738e-04 - val_loss: 0.0076\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.5376e-04 - val_loss: 0.0043\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.9711e-04 - val_loss: 0.0016\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0000e-04 - val_loss: 6.9588e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5485e-04 - val_loss: 2.8865e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3280e-04 - val_loss: 1.3571e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.8796e-05 - val_loss: 3.9947e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.4182e-04 - val_loss: 5.0840e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.4662e-04 - val_loss: 5.7984e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.4730e-05 - val_loss: 9.3648e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4224e-05 - val_loss: 0.0014\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.2291e-04 - val_loss: 4.0294e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0158e-04 - val_loss: 9.3284e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4038e-05 - val_loss: 7.0924e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.8788e-05 - val_loss: 9.4045e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.1124e-05 - val_loss: 6.7229e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3951e-05 - val_loss: 0.0018\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.8035e-05 - val_loss: 1.0902e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1590e-05 - val_loss: 8.4407e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5372e-05 - val_loss: 4.9939e-05\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.2209e-05 - val_loss: 7.0882e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.2258e-05 - val_loss: 6.5492e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4998e-05 - val_loss: 2.3048e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7095e-05 - val_loss: 5.9279e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5124e-05 - val_loss: 3.6864e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0547e-05 - val_loss: 1.7093e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2588e-05 - val_loss: 4.8435e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5718e-05 - val_loss: 6.3033e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2691e-05 - val_loss: 6.5489e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8951e-05 - val_loss: 2.1400e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5039e-05 - val_loss: 2.5048e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9847e-05 - val_loss: 9.4071e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.1013e-05 - val_loss: 7.6261e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3160e-05 - val_loss: 8.0636e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3891e-05 - val_loss: 1.5956e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6352e-05 - val_loss: 3.2676e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.2308e-05 - val_loss: 2.4596e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2761e-05 - val_loss: 9.1822e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1303e-05 - val_loss: 1.2001e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2856e-05 - val_loss: 4.3126e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3161e-05 - val_loss: 1.9885e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1875e-05 - val_loss: 1.0021e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9876e-05 - val_loss: 9.9841e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0053e-05 - val_loss: 2.8939e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2958e-05 - val_loss: 6.7548e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.8311e-05 - val_loss: 1.8759e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8374e-05 - val_loss: 8.6444e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0777e-05 - val_loss: 3.9959e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9449e-05 - val_loss: 5.5452e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4341e-05 - val_loss: 3.7765e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6230e-05 - val_loss: 5.8360e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6166e-05 - val_loss: 4.2856e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3384e-05 - val_loss: 1.7726e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9449e-05 - val_loss: 3.5777e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.8538e-05 - val_loss: 9.8752e-06\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9519e-05 - val_loss: 1.6325e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2195e-05 - val_loss: 4.1300e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9776e-05 - val_loss: 1.8405e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5199e-05 - val_loss: 4.9914e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.5711e-05 - val_loss: 5.1635e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3732e-05 - val_loss: 9.5220e-06\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6315e-05 - val_loss: 7.0726e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6398e-05 - val_loss: 5.5664e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8431e-05 - val_loss: 4.8065e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3562e-05 - val_loss: 9.4003e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.6879e-05 - val_loss: 3.3715e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5290e-05 - val_loss: 3.0421e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4140e-05 - val_loss: 4.2686e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3441e-05 - val_loss: 2.3072e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3870e-05 - val_loss: 5.1803e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4464e-05 - val_loss: 8.6371e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0717e-05 - val_loss: 2.1009e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0624e-05 - val_loss: 1.5054e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4757e-05 - val_loss: 3.3721e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8769e-05 - val_loss: 3.9592e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2757e-05 - val_loss: 1.2548e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9919e-05 - val_loss: 1.4832e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1280e-05 - val_loss: 1.0584e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3638e-05 - val_loss: 1.2266e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3036e-05 - val_loss: 4.1226e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2080e-05 - val_loss: 1.8884e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0189e-05 - val_loss: 1.2763e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0295e-05 - val_loss: 4.1182e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0336e-05 - val_loss: 4.2354e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6529e-05 - val_loss: 1.9305e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5625e-05 - val_loss: 7.2645e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5196e-05 - val_loss: 2.9988e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0712e-05 - val_loss: 1.0016e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2234e-05 - val_loss: 3.6405e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5601e-05 - val_loss: 7.1770e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0355e-05 - val_loss: 4.7082e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4769e-05 - val_loss: 4.2814e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8644e-05 - val_loss: 2.8668e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8222e-05 - val_loss: 5.2549e-06\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0484e-05 - val_loss: 2.8021e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9153e-05 - val_loss: 1.4031e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4673e-05 - val_loss: 7.8477e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.5942e-05 - val_loss: 0.0011\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8748e-05 - val_loss: 3.3407e-05\n",
      ">Neurons=85, Score=0.002560423126851674\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 16s 31ms/step - loss: 0.0023 - val_loss: 0.0104\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.7912e-04 - val_loss: 0.0071\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.6281e-04 - val_loss: 0.0037\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6767e-04 - val_loss: 0.0017\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1475e-04 - val_loss: 3.7352e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6129e-04 - val_loss: 5.1418e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0083e-04 - val_loss: 4.9948e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.0372e-05 - val_loss: 4.4056e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0835e-04 - val_loss: 4.5748e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.5888e-05 - val_loss: 4.0641e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.8182e-05 - val_loss: 2.4521e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.7824e-05 - val_loss: 4.4396e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.6454e-05 - val_loss: 4.1241e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.3588e-05 - val_loss: 1.9514e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1730e-05 - val_loss: 2.6823e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8031e-05 - val_loss: 2.6628e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7168e-05 - val_loss: 3.4450e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.1882e-05 - val_loss: 1.5461e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.9722e-05 - val_loss: 2.2719e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.1387e-05 - val_loss: 1.0651e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7855e-05 - val_loss: 2.8680e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.1725e-05 - val_loss: 1.5804e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7689e-05 - val_loss: 6.5025e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5513e-05 - val_loss: 1.1728e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.3304e-05 - val_loss: 3.6515e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.6102e-05 - val_loss: 1.0998e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4082e-05 - val_loss: 8.0784e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6350e-05 - val_loss: 7.8913e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9535e-05 - val_loss: 9.5250e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.4339e-05 - val_loss: 2.0706e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6077e-05 - val_loss: 6.2771e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.8466e-05 - val_loss: 3.5069e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4383e-05 - val_loss: 4.0395e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5999e-05 - val_loss: 3.7059e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.0356e-05 - val_loss: 7.6718e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2495e-05 - val_loss: 1.0433e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1197e-05 - val_loss: 2.1561e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6829e-05 - val_loss: 3.1080e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8917e-05 - val_loss: 1.7975e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6312e-05 - val_loss: 3.6538e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3353e-05 - val_loss: 1.7505e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7278e-05 - val_loss: 1.6648e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.3404e-05 - val_loss: 3.8380e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1563e-05 - val_loss: 4.3373e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9235e-05 - val_loss: 4.4123e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.3527e-05 - val_loss: 4.9274e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.6524e-05 - val_loss: 1.3020e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3027e-05 - val_loss: 1.3450e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2751e-05 - val_loss: 0.0010\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8639e-05 - val_loss: 1.0422e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.0854e-05 - val_loss: 2.7856e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1342e-05 - val_loss: 4.1266e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6959e-05 - val_loss: 1.1056e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6268e-05 - val_loss: 4.2784e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9686e-05 - val_loss: 3.0700e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2492e-05 - val_loss: 1.1539e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0613e-05 - val_loss: 1.7019e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5301e-05 - val_loss: 1.3122e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4013e-05 - val_loss: 7.1453e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6669e-05 - val_loss: 2.2467e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.8667e-05 - val_loss: 7.2927e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6439e-05 - val_loss: 3.4154e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.0116e-05 - val_loss: 3.6317e-04\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1502e-05 - val_loss: 3.8372e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6015e-05 - val_loss: 5.6871e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6282e-05 - val_loss: 1.0363e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1624e-05 - val_loss: 1.5437e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4083e-05 - val_loss: 1.6665e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1289e-05 - val_loss: 9.0622e-06\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1363e-05 - val_loss: 4.1285e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6188e-05 - val_loss: 4.1590e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6980e-05 - val_loss: 1.6393e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7777e-05 - val_loss: 1.0704e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0202e-05 - val_loss: 5.1683e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1090e-05 - val_loss: 9.4963e-06\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2710e-05 - val_loss: 5.3845e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4256e-05 - val_loss: 3.5987e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0818e-05 - val_loss: 7.2590e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1037e-05 - val_loss: 1.2968e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.7801e-06 - val_loss: 1.4530e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2011e-05 - val_loss: 1.3983e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4584e-05 - val_loss: 6.0330e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7075e-05 - val_loss: 9.0772e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2956e-05 - val_loss: 4.8960e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8516e-05 - val_loss: 6.8018e-06\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5035e-05 - val_loss: 2.1604e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1753e-05 - val_loss: 4.6413e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2708e-05 - val_loss: 0.0013\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4108e-05 - val_loss: 1.8782e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2677e-05 - val_loss: 1.0957e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0535e-05 - val_loss: 2.4910e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0919e-05 - val_loss: 2.1763e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1175e-05 - val_loss: 5.0260e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4858e-05 - val_loss: 1.0251e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1068e-04 - val_loss: 0.0033\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0199e-04 - val_loss: 1.1260e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4400e-05 - val_loss: 3.9383e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2022e-05 - val_loss: 1.4116e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4853e-05 - val_loss: 2.0600e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3864e-05 - val_loss: 3.4455e-05\n",
      ">Neurons=85, Score=0.0038965306885074824\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 17s 29ms/step - loss: 0.0021 - val_loss: 0.0096\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.7845e-04 - val_loss: 0.0065\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3573e-04 - val_loss: 0.0035\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8667e-04 - val_loss: 0.0013\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8095e-04 - val_loss: 6.2876e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3726e-04 - val_loss: 1.9745e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.2872e-04 - val_loss: 4.7935e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3932e-05 - val_loss: 5.3298e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4002e-05 - val_loss: 2.9796e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5383e-04 - val_loss: 9.9242e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0597e-04 - val_loss: 1.3371e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.7285e-05 - val_loss: 2.1478e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.6467e-05 - val_loss: 1.4550e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2938e-05 - val_loss: 1.0773e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3956e-05 - val_loss: 8.0959e-05\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3690e-05 - val_loss: 3.3797e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.9843e-05 - val_loss: 4.3624e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.5198e-05 - val_loss: 2.5031e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4094e-05 - val_loss: 9.2792e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9148e-05 - val_loss: 2.3580e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.8983e-05 - val_loss: 2.1354e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3643e-05 - val_loss: 4.3878e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9438e-05 - val_loss: 1.3431e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9882e-05 - val_loss: 5.4712e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.1678e-05 - val_loss: 3.0710e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.8784e-05 - val_loss: 7.1690e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.4940e-05 - val_loss: 0.0010\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.3745e-05 - val_loss: 3.9867e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2296e-05 - val_loss: 4.7034e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.0139e-05 - val_loss: 5.8014e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8627e-05 - val_loss: 3.4080e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7868e-05 - val_loss: 1.9969e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7671e-05 - val_loss: 3.8861e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5279e-05 - val_loss: 5.9178e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5499e-05 - val_loss: 3.3912e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5983e-05 - val_loss: 1.0865e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6339e-05 - val_loss: 1.3859e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.8111e-05 - val_loss: 1.0715e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.0615e-05 - val_loss: 1.7815e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1425e-05 - val_loss: 6.6462e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2310e-05 - val_loss: 2.6496e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.5898e-05 - val_loss: 8.7118e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1302e-05 - val_loss: 2.5495e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5526e-05 - val_loss: 3.2796e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4373e-05 - val_loss: 3.9963e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9751e-05 - val_loss: 2.1502e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.0556e-05 - val_loss: 4.5458e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5194e-05 - val_loss: 3.1191e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5928e-05 - val_loss: 1.9390e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7917e-05 - val_loss: 6.2053e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4917e-05 - val_loss: 6.7798e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6613e-05 - val_loss: 3.4009e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9104e-05 - val_loss: 1.7427e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.7906e-05 - val_loss: 1.6919e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7637e-05 - val_loss: 4.7587e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.8743e-05 - val_loss: 1.5004e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6116e-05 - val_loss: 3.7954e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0891e-05 - val_loss: 1.1322e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.0570e-05 - val_loss: 1.2647e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.2119e-05 - val_loss: 3.3330e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5196e-05 - val_loss: 1.4591e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.9552e-05 - val_loss: 8.0373e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9568e-05 - val_loss: 1.2214e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4933e-05 - val_loss: 1.6962e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6324e-05 - val_loss: 1.3669e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2786e-05 - val_loss: 4.2676e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0469e-05 - val_loss: 5.5905e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.5453e-05 - val_loss: 4.6984e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.0734e-05 - val_loss: 1.2857e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.9952e-05 - val_loss: 3.2377e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 1.9203e-05 - val_loss: 2.7647e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4787e-05 - val_loss: 1.8109e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0377e-05 - val_loss: 2.8322e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.0982e-05 - val_loss: 1.3009e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.1513e-05 - val_loss: 1.9395e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.9976e-05 - val_loss: 1.8253e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.0312e-05 - val_loss: 0.0020\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6339e-05 - val_loss: 5.0806e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.1174e-05 - val_loss: 2.2433e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.8029e-05 - val_loss: 5.5564e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3179e-05 - val_loss: 9.4376e-06\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.6746e-05 - val_loss: 3.0092e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7807e-05 - val_loss: 1.3726e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8688e-05 - val_loss: 5.0118e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7010e-05 - val_loss: 6.9792e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9979e-05 - val_loss: 2.7642e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8071e-05 - val_loss: 9.9384e-06\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8305e-05 - val_loss: 1.2881e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6816e-05 - val_loss: 1.3975e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.5190e-06 - val_loss: 2.1916e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6225e-05 - val_loss: 5.2545e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5486e-05 - val_loss: 3.2141e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2918e-05 - val_loss: 3.9716e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3524e-05 - val_loss: 8.5904e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3998e-05 - val_loss: 3.8211e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4081e-05 - val_loss: 5.9671e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2659e-05 - val_loss: 6.3868e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3862e-05 - val_loss: 4.6270e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7510e-05 - val_loss: 2.4215e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4589e-05 - val_loss: 2.5532e-04\n",
      ">Neurons=85, Score=0.012980296742171049\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 17s 31ms/step - loss: 0.0021 - val_loss: 0.0099\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 9.0886e-04 - val_loss: 0.0065\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.3190e-04 - val_loss: 0.0032\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5988e-04 - val_loss: 0.0010\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6897e-04 - val_loss: 5.4105e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3989e-04 - val_loss: 2.6591e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3369e-04 - val_loss: 4.4554e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.3270e-04 - val_loss: 5.8094e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2396e-04 - val_loss: 2.1194e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2092e-04 - val_loss: 5.6912e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3236e-04 - val_loss: 5.2535e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0912e-05 - val_loss: 2.1916e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1559e-05 - val_loss: 6.3555e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.3694e-05 - val_loss: 8.1968e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.6214e-05 - val_loss: 3.1306e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.5355e-05 - val_loss: 7.7606e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0197e-04 - val_loss: 1.3148e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.2898e-05 - val_loss: 3.1685e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.1343e-05 - val_loss: 2.0723e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4481e-05 - val_loss: 6.4751e-05\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0489e-05 - val_loss: 3.5261e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.0597e-05 - val_loss: 2.1474e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.0313e-05 - val_loss: 7.6698e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.2265e-05 - val_loss: 4.8831e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2065e-05 - val_loss: 5.7377e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8950e-05 - val_loss: 1.7773e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.1274e-05 - val_loss: 4.9224e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4408e-05 - val_loss: 2.2235e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4887e-05 - val_loss: 2.6038e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.4046e-05 - val_loss: 6.7018e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3480e-05 - val_loss: 3.9481e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.3642e-05 - val_loss: 2.4261e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0298e-05 - val_loss: 5.5346e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.2425e-05 - val_loss: 6.9047e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.7124e-05 - val_loss: 5.1747e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7759e-05 - val_loss: 9.7425e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.0651e-05 - val_loss: 5.2121e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4026e-05 - val_loss: 2.2982e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0155e-05 - val_loss: 1.0038e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9816e-05 - val_loss: 1.8123e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9884e-05 - val_loss: 3.6218e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0284e-05 - val_loss: 1.6932e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3232e-05 - val_loss: 1.1048e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2218e-05 - val_loss: 3.4366e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4188e-05 - val_loss: 2.8493e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3120e-05 - val_loss: 3.0374e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9561e-05 - val_loss: 7.5911e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3163e-05 - val_loss: 1.7519e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6180e-05 - val_loss: 0.0010\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.8857e-05 - val_loss: 1.2422e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4256e-05 - val_loss: 1.7394e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6121e-05 - val_loss: 1.8040e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2645e-05 - val_loss: 1.5912e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6913e-05 - val_loss: 3.1171e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3278e-05 - val_loss: 1.1505e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8061e-05 - val_loss: 3.4906e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5809e-05 - val_loss: 5.9867e-06\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7304e-05 - val_loss: 5.5159e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5417e-05 - val_loss: 3.2734e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2122e-05 - val_loss: 3.2643e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.5380e-05 - val_loss: 3.8845e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.6803e-05 - val_loss: 4.3043e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5633e-05 - val_loss: 2.7997e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6757e-05 - val_loss: 2.6858e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9223e-05 - val_loss: 2.4489e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1917e-05 - val_loss: 7.0690e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3684e-05 - val_loss: 3.9755e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6798e-05 - val_loss: 3.3728e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6077e-05 - val_loss: 1.8176e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7495e-05 - val_loss: 5.9113e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9628e-05 - val_loss: 2.6973e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0431e-05 - val_loss: 5.5431e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2579e-05 - val_loss: 3.8592e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3889e-05 - val_loss: 8.5957e-06\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7461e-05 - val_loss: 4.7579e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5709e-05 - val_loss: 4.9901e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8713e-05 - val_loss: 4.5951e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2410e-05 - val_loss: 6.7026e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7745e-05 - val_loss: 4.7337e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2713e-05 - val_loss: 3.1466e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.5381e-05 - val_loss: 2.4683e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3326e-05 - val_loss: 6.3357e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.2643e-05 - val_loss: 3.2196e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5697e-05 - val_loss: 9.0269e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8286e-05 - val_loss: 9.6503e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4510e-05 - val_loss: 3.2980e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9419e-05 - val_loss: 3.5874e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3860e-05 - val_loss: 3.5403e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2599e-05 - val_loss: 4.2986e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.7619e-05 - val_loss: 1.2902e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2587e-05 - val_loss: 2.4249e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.8630e-05 - val_loss: 0.0011\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9311e-05 - val_loss: 5.1604e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.8735e-06 - val_loss: 8.0324e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7777e-05 - val_loss: 1.9349e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7428e-05 - val_loss: 4.8404e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3129e-05 - val_loss: 2.7351e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6170e-05 - val_loss: 6.4539e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1288e-05 - val_loss: 1.6481e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6182e-05 - val_loss: 1.4448e-05\n",
      ">Neurons=90, Score=0.0015113044355530292\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 17s 31ms/step - loss: 0.0020 - val_loss: 0.0098\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.1316e-04 - val_loss: 0.0066\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.0128e-04 - val_loss: 0.0032\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8031e-04 - val_loss: 8.2726e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0993e-04 - val_loss: 2.3597e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3575e-04 - val_loss: 4.1217e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.3220e-04 - val_loss: 4.5418e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 9.0994e-05 - val_loss: 4.7162e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.8647e-05 - val_loss: 8.2007e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 5.5120e-05 - val_loss: 0.0010\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.8337e-05 - val_loss: 2.2510e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 3s 16ms/step - loss: 6.8610e-05 - val_loss: 1.5450e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0196e-04 - val_loss: 3.0429e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.9789e-05 - val_loss: 1.4322e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 9.3359e-05 - val_loss: 3.0813e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.0750e-05 - val_loss: 1.8363e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6942e-05 - val_loss: 1.8930e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.0991e-05 - val_loss: 9.5173e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0908e-04 - val_loss: 9.3847e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2273e-04 - val_loss: 3.2782e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.9454e-05 - val_loss: 2.2325e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0160e-05 - val_loss: 2.2894e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.3277e-05 - val_loss: 3.9342e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4343e-05 - val_loss: 4.2888e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5506e-05 - val_loss: 6.8061e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.0144e-05 - val_loss: 6.2712e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.3642e-05 - val_loss: 8.4694e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.3963e-05 - val_loss: 0.0011\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4815e-05 - val_loss: 5.6812e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4594e-05 - val_loss: 5.7475e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9466e-05 - val_loss: 1.0322e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4427e-05 - val_loss: 2.2592e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.1313e-05 - val_loss: 8.1322e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2282e-05 - val_loss: 3.2746e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8867e-05 - val_loss: 1.7847e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5640e-05 - val_loss: 1.2852e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8319e-05 - val_loss: 1.2881e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8354e-05 - val_loss: 3.3766e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4900e-05 - val_loss: 4.1840e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1176e-05 - val_loss: 4.2960e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0838e-05 - val_loss: 4.2236e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1860e-05 - val_loss: 8.9881e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8313e-05 - val_loss: 5.4097e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2102e-05 - val_loss: 3.8204e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1200e-05 - val_loss: 1.5782e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.9853e-05 - val_loss: 1.5128e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3478e-05 - val_loss: 1.1555e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2939e-05 - val_loss: 2.2307e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.6613e-05 - val_loss: 1.9525e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.7311e-05 - val_loss: 4.0226e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6175e-05 - val_loss: 5.3216e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5008e-05 - val_loss: 5.8274e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7099e-05 - val_loss: 2.6146e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.5157e-05 - val_loss: 2.8836e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6362e-05 - val_loss: 9.8820e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.9927e-05 - val_loss: 5.0213e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.9705e-05 - val_loss: 1.4808e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3740e-05 - val_loss: 4.0384e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6144e-05 - val_loss: 2.0312e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6130e-05 - val_loss: 3.6054e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.8886e-05 - val_loss: 2.2836e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7011e-05 - val_loss: 9.1624e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7043e-05 - val_loss: 1.7538e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0036e-05 - val_loss: 1.7029e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.0051e-05 - val_loss: 7.5222e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4967e-05 - val_loss: 5.9386e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2123e-05 - val_loss: 6.8784e-06\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6065e-05 - val_loss: 3.0733e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.7062e-05 - val_loss: 8.4114e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8675e-05 - val_loss: 2.9631e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6815e-05 - val_loss: 4.6671e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8499e-05 - val_loss: 7.0936e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.1552e-06 - val_loss: 3.4033e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2874e-05 - val_loss: 1.5555e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9828e-05 - val_loss: 2.0686e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4850e-05 - val_loss: 5.3279e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4481e-05 - val_loss: 1.4793e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.6887e-05 - val_loss: 6.4200e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5419e-05 - val_loss: 2.4893e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4112e-05 - val_loss: 2.9119e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3892e-05 - val_loss: 1.9702e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2124e-05 - val_loss: 0.0013\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7957e-05 - val_loss: 2.2129e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3029e-05 - val_loss: 2.1408e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1917e-05 - val_loss: 1.4854e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.6589e-06 - val_loss: 5.7030e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8978e-05 - val_loss: 7.8319e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7855e-05 - val_loss: 2.3150e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6946e-05 - val_loss: 7.6592e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.5560e-05 - val_loss: 7.1749e-06\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.9458e-05 - val_loss: 2.5800e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4880e-05 - val_loss: 5.5106e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.5497e-05 - val_loss: 2.6676e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3818e-05 - val_loss: 7.0407e-04\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5623e-05 - val_loss: 0.0012\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5656e-05 - val_loss: 6.7456e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.9223e-05 - val_loss: 7.2695e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0912e-05 - val_loss: 2.3910e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.4545e-05 - val_loss: 8.7352e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9528e-05 - val_loss: 1.6060e-05\n",
      ">Neurons=90, Score=0.0007756969353067689\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 15s 27ms/step - loss: 0.0020 - val_loss: 0.0096\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.1434e-04 - val_loss: 0.0060\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.1917e-04 - val_loss: 0.0031\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0890e-04 - val_loss: 0.0010\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8074e-04 - val_loss: 5.7926e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2725e-04 - val_loss: 2.6330e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1033e-04 - val_loss: 1.8388e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.2670e-05 - val_loss: 4.0986e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.2273e-05 - val_loss: 7.8521e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.4578e-05 - val_loss: 2.7534e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4418e-04 - val_loss: 9.0310e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1468e-04 - val_loss: 2.0365e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0016e-04 - val_loss: 2.8784e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4483e-05 - val_loss: 1.4548e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9355e-05 - val_loss: 2.3949e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.4215e-05 - val_loss: 3.0021e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.2508e-05 - val_loss: 1.8061e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.2760e-05 - val_loss: 1.0107e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9009e-05 - val_loss: 1.3001e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2834e-05 - val_loss: 1.8667e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1483e-05 - val_loss: 5.2242e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7897e-05 - val_loss: 1.2545e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.1984e-05 - val_loss: 3.0425e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.0571e-05 - val_loss: 0.0011\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.0275e-05 - val_loss: 7.5952e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9032e-05 - val_loss: 5.5129e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5740e-05 - val_loss: 1.5604e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.4744e-05 - val_loss: 2.0247e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.7506e-05 - val_loss: 4.4502e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.7745e-05 - val_loss: 6.6412e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6583e-05 - val_loss: 1.1355e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5869e-05 - val_loss: 3.9510e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5816e-05 - val_loss: 1.1796e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7215e-05 - val_loss: 1.4925e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.5289e-05 - val_loss: 1.4962e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8399e-05 - val_loss: 2.8286e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9150e-05 - val_loss: 4.3901e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.4841e-05 - val_loss: 1.0233e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8624e-05 - val_loss: 2.2605e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0760e-04 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.3956e-05 - val_loss: 8.3829e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.3036e-05 - val_loss: 1.6864e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0330e-05 - val_loss: 3.2167e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9663e-05 - val_loss: 3.8547e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.2433e-05 - val_loss: 3.1528e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8003e-05 - val_loss: 7.1292e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6838e-05 - val_loss: 2.5182e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8036e-05 - val_loss: 1.1363e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8217e-05 - val_loss: 6.4310e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2730e-05 - val_loss: 2.0494e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1890e-05 - val_loss: 2.9933e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1221e-05 - val_loss: 8.0875e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4173e-05 - val_loss: 3.9697e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6968e-05 - val_loss: 2.1791e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3286e-05 - val_loss: 6.8898e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4422e-05 - val_loss: 4.8350e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6111e-05 - val_loss: 4.5089e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2257e-05 - val_loss: 8.9427e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1102e-05 - val_loss: 8.1347e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7008e-05 - val_loss: 4.5520e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4145e-05 - val_loss: 2.2491e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7685e-05 - val_loss: 1.1736e-04\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2856e-05 - val_loss: 9.4802e-06\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6754e-05 - val_loss: 3.3073e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 3.1275e-05 - val_loss: 1.3054e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.1970e-05 - val_loss: 5.1799e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 5.1762e-05 - val_loss: 7.7518e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 3s 19ms/step - loss: 3.9808e-05 - val_loss: 7.3828e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1149e-05 - val_loss: 4.8303e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.6710e-05 - val_loss: 0.0015\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.0646e-05 - val_loss: 6.0835e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.0255e-05 - val_loss: 2.3222e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1771e-05 - val_loss: 3.4666e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3558e-05 - val_loss: 1.4766e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8770e-05 - val_loss: 3.9374e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4492e-05 - val_loss: 1.3467e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6674e-05 - val_loss: 9.3756e-06\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.5977e-06 - val_loss: 1.3970e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8826e-05 - val_loss: 3.7738e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1772e-05 - val_loss: 2.2277e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4869e-05 - val_loss: 1.8344e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7935e-05 - val_loss: 9.4319e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2660e-05 - val_loss: 3.0545e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4852e-05 - val_loss: 2.4400e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6717e-05 - val_loss: 1.5665e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.1698e-05 - val_loss: 2.1110e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3374e-05 - val_loss: 4.2411e-06\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7494e-05 - val_loss: 4.9297e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8255e-05 - val_loss: 1.9368e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8568e-05 - val_loss: 2.2710e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1979e-05 - val_loss: 6.6311e-06\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2864e-05 - val_loss: 5.8316e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.9533e-06 - val_loss: 1.3947e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1102e-06 - val_loss: 7.9763e-06\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1484e-05 - val_loss: 5.7002e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0755e-05 - val_loss: 1.4268e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.5838e-05 - val_loss: 0.0014\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0167e-05 - val_loss: 1.4545e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0812e-05 - val_loss: 7.0096e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7489e-05 - val_loss: 1.3145e-04\n",
      ">Neurons=90, Score=0.005655101631418802\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 21ms/step - loss: 0.0020 - val_loss: 0.0098\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.6317e-04 - val_loss: 0.0058\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8512e-04 - val_loss: 0.0027\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2766e-04 - val_loss: 7.5880e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3782e-04 - val_loss: 3.1393e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0118e-04 - val_loss: 3.0930e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4124e-04 - val_loss: 6.9062e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1216e-04 - val_loss: 3.2655e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.3349e-05 - val_loss: 3.3006e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9053e-05 - val_loss: 2.8186e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.9941e-05 - val_loss: 1.7677e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0784e-04 - val_loss: 3.5044e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1616e-04 - val_loss: 5.5624e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.4665e-05 - val_loss: 7.0791e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8843e-05 - val_loss: 3.2998e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5656e-04 - val_loss: 0.0014\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1793e-04 - val_loss: 9.2921e-05\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5726e-05 - val_loss: 9.5462e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5223e-05 - val_loss: 6.5454e-05\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.7031e-05 - val_loss: 2.8648e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2591e-05 - val_loss: 1.1983e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4147e-05 - val_loss: 1.9910e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2741e-05 - val_loss: 4.1680e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.6793e-05 - val_loss: 2.3630e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1061e-05 - val_loss: 1.1060e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.8668e-05 - val_loss: 5.2197e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.3239e-05 - val_loss: 2.0600e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5152e-05 - val_loss: 1.8633e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8102e-05 - val_loss: 8.3822e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2640e-05 - val_loss: 9.2334e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8306e-05 - val_loss: 1.1641e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2323e-05 - val_loss: 2.9933e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8989e-05 - val_loss: 3.8969e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.8956e-05 - val_loss: 4.0271e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1008e-05 - val_loss: 3.8694e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.1558e-05 - val_loss: 2.4104e-04\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9016e-05 - val_loss: 1.6988e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3559e-05 - val_loss: 4.6932e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9018e-05 - val_loss: 1.5591e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0250e-05 - val_loss: 4.2830e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.6380e-05 - val_loss: 5.1597e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7400e-05 - val_loss: 1.3696e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3768e-05 - val_loss: 1.8607e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8393e-05 - val_loss: 2.5862e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8816e-05 - val_loss: 8.3144e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4511e-05 - val_loss: 1.0804e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4003e-05 - val_loss: 7.7983e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.1415e-05 - val_loss: 6.7494e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6055e-05 - val_loss: 3.6985e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4704e-05 - val_loss: 4.4400e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4554e-05 - val_loss: 3.6594e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5525e-05 - val_loss: 2.0343e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.1433e-05 - val_loss: 3.2387e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7089e-05 - val_loss: 3.5559e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4799e-05 - val_loss: 2.2214e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4039e-05 - val_loss: 1.7202e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1606e-05 - val_loss: 5.6239e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6370e-05 - val_loss: 3.7103e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5892e-05 - val_loss: 1.7315e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3651e-05 - val_loss: 2.1842e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7306e-05 - val_loss: 3.5914e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8841e-05 - val_loss: 3.4193e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.5602e-05 - val_loss: 4.5206e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.4726e-05 - val_loss: 2.4537e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7352e-05 - val_loss: 5.0477e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0465e-05 - val_loss: 1.1019e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4453e-05 - val_loss: 5.7856e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2810e-05 - val_loss: 6.2697e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5400e-05 - val_loss: 2.3959e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3660e-05 - val_loss: 2.1750e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8144e-05 - val_loss: 1.9939e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4984e-05 - val_loss: 1.0536e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.8185e-05 - val_loss: 2.1030e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.8693e-05 - val_loss: 4.8688e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0418e-05 - val_loss: 5.8678e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2454e-05 - val_loss: 4.7171e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0754e-05 - val_loss: 2.5011e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4267e-05 - val_loss: 1.3109e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8143e-05 - val_loss: 4.2727e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4757e-05 - val_loss: 6.3810e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5721e-05 - val_loss: 8.3853e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.0501e-06 - val_loss: 1.0309e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2205e-05 - val_loss: 1.8431e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1278e-05 - val_loss: 3.2755e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9386e-05 - val_loss: 4.6824e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3058e-05 - val_loss: 6.1683e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1051e-05 - val_loss: 1.3633e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8136e-05 - val_loss: 4.3396e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1178e-05 - val_loss: 6.2490e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6421e-05 - val_loss: 2.6240e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6612e-05 - val_loss: 1.0882e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5566e-05 - val_loss: 8.8649e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4459e-05 - val_loss: 4.8447e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6605e-05 - val_loss: 4.3260e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6565e-05 - val_loss: 2.5232e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1479e-05 - val_loss: 2.4008e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.9999e-06 - val_loss: 7.3801e-06\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.4273e-06 - val_loss: 1.3035e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0780e-05 - val_loss: 4.4352e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.5640e-05 - val_loss: 3.8318e-04\n",
      ">Neurons=90, Score=0.01888812257675454\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 21ms/step - loss: 0.0021 - val_loss: 0.0100\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.3324e-04 - val_loss: 0.0067\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6226e-04 - val_loss: 0.0031\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.0632e-04 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5106e-04 - val_loss: 3.7804e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2201e-04 - val_loss: 8.9692e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8700e-05 - val_loss: 1.8459e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0393e-04 - val_loss: 3.5726e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.5464e-05 - val_loss: 2.8904e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.7187e-05 - val_loss: 3.6973e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7928e-05 - val_loss: 1.9557e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.6226e-05 - val_loss: 6.3365e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.3021e-05 - val_loss: 3.2512e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.6519e-05 - val_loss: 1.6546e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.4886e-05 - val_loss: 4.0713e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1363e-04 - val_loss: 7.9429e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.3940e-05 - val_loss: 6.4158e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9842e-05 - val_loss: 2.6064e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1501e-04 - val_loss: 8.6392e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.3451e-05 - val_loss: 3.4255e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2071e-05 - val_loss: 1.5731e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7547e-05 - val_loss: 2.0159e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5262e-05 - val_loss: 1.1154e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.6961e-05 - val_loss: 7.7075e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3950e-05 - val_loss: 5.4962e-05\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2410e-05 - val_loss: 5.8590e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7231e-05 - val_loss: 2.6171e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9570e-05 - val_loss: 6.1091e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.6623e-05 - val_loss: 7.7677e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9478e-05 - val_loss: 8.5074e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0662e-05 - val_loss: 5.9930e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9026e-05 - val_loss: 1.6097e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5404e-05 - val_loss: 1.0970e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3521e-05 - val_loss: 5.4335e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.5856e-05 - val_loss: 1.8390e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0200e-05 - val_loss: 1.2871e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0362e-05 - val_loss: 4.7188e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2673e-05 - val_loss: 5.3338e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3622e-05 - val_loss: 3.3036e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5478e-05 - val_loss: 7.4332e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.7833e-05 - val_loss: 1.1704e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5807e-05 - val_loss: 5.6850e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7413e-05 - val_loss: 8.5703e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7612e-05 - val_loss: 5.8839e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0427e-05 - val_loss: 1.6413e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1896e-05 - val_loss: 2.9214e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6060e-05 - val_loss: 1.1499e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2772e-05 - val_loss: 6.4872e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2385e-05 - val_loss: 1.4001e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2728e-05 - val_loss: 4.5649e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0654e-05 - val_loss: 4.0115e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3473e-05 - val_loss: 1.6464e-05\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6818e-05 - val_loss: 1.5054e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.8870e-05 - val_loss: 8.0488e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9700e-05 - val_loss: 1.4149e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2545e-05 - val_loss: 5.7692e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2875e-05 - val_loss: 3.7188e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0058e-05 - val_loss: 3.8511e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9310e-05 - val_loss: 3.3098e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.9302e-05 - val_loss: 1.0343e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.3438e-05 - val_loss: 1.8756e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1942e-05 - val_loss: 7.3767e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0143e-05 - val_loss: 3.2039e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7556e-05 - val_loss: 2.3768e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7096e-05 - val_loss: 5.7202e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9576e-05 - val_loss: 1.4851e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5955e-05 - val_loss: 8.8168e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6575e-05 - val_loss: 1.1569e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6700e-05 - val_loss: 5.6204e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6656e-05 - val_loss: 1.7022e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2798e-05 - val_loss: 5.9242e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2625e-05 - val_loss: 1.4586e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3446e-05 - val_loss: 7.7551e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3911e-05 - val_loss: 1.7248e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7279e-05 - val_loss: 1.0390e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4038e-05 - val_loss: 2.5369e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0294e-05 - val_loss: 4.0873e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3469e-05 - val_loss: 8.7876e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4907e-05 - val_loss: 6.5490e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0829e-05 - val_loss: 4.9473e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.6548e-05 - val_loss: 4.5988e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1523e-05 - val_loss: 2.8666e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0665e-05 - val_loss: 1.0048e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.3000e-05 - val_loss: 1.1627e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5143e-05 - val_loss: 9.2960e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.3777e-06 - val_loss: 4.2988e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8759e-05 - val_loss: 2.6155e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3688e-05 - val_loss: 1.6124e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.9494e-05 - val_loss: 1.7700e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7578e-05 - val_loss: 3.5433e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7290e-05 - val_loss: 1.5077e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7280e-05 - val_loss: 1.4436e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6397e-05 - val_loss: 1.1582e-04\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.7673e-06 - val_loss: 6.3589e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2624e-05 - val_loss: 1.1030e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5088e-05 - val_loss: 7.4234e-05\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.5287e-06 - val_loss: 1.3087e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9472e-05 - val_loss: 2.7409e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1958e-05 - val_loss: 4.3872e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.7206e-06 - val_loss: 1.5466e-05\n",
      ">Neurons=90, Score=0.0021488589482032694\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 9s 19ms/step - loss: 0.0020 - val_loss: 0.0092\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.4179e-04 - val_loss: 0.0057\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3016e-04 - val_loss: 0.0024\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4546e-04 - val_loss: 6.5420e-04\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3975e-04 - val_loss: 1.4349e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2757e-04 - val_loss: 8.9299e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4076e-04 - val_loss: 3.5864e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7798e-04 - val_loss: 0.0017\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4556e-04 - val_loss: 4.4835e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.5077e-05 - val_loss: 3.1856e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7123e-05 - val_loss: 2.5894e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.3577e-05 - val_loss: 4.1280e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.5969e-05 - val_loss: 9.3633e-05\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.8357e-05 - val_loss: 4.0800e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1764e-04 - val_loss: 9.2535e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.6524e-05 - val_loss: 4.2298e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.9747e-05 - val_loss: 2.5683e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1838e-05 - val_loss: 1.5403e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6619e-05 - val_loss: 1.6867e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2949e-05 - val_loss: 3.6821e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.4846e-05 - val_loss: 5.7590e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.6215e-05 - val_loss: 2.1077e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8892e-05 - val_loss: 8.3589e-05\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2881e-05 - val_loss: 5.0148e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.4586e-05 - val_loss: 8.2778e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.1498e-05 - val_loss: 1.0361e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5509e-05 - val_loss: 2.3558e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0221e-05 - val_loss: 1.2138e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.7580e-05 - val_loss: 4.0163e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0165e-05 - val_loss: 3.8449e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8297e-05 - val_loss: 1.8727e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8842e-05 - val_loss: 7.8672e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7061e-05 - val_loss: 1.6469e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6992e-05 - val_loss: 2.2820e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1115e-05 - val_loss: 1.5074e-04\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2536e-05 - val_loss: 6.9189e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5915e-05 - val_loss: 7.8586e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.6410e-05 - val_loss: 2.0864e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6301e-05 - val_loss: 1.0044e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2376e-05 - val_loss: 4.2145e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1412e-05 - val_loss: 2.1275e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2071e-05 - val_loss: 2.9576e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0399e-05 - val_loss: 2.5410e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6129e-05 - val_loss: 0.0016\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.4466e-05 - val_loss: 9.2038e-05\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9449e-05 - val_loss: 2.8396e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.9279e-05 - val_loss: 5.8195e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0536e-05 - val_loss: 7.7542e-06\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1960e-05 - val_loss: 2.0516e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.1006e-05 - val_loss: 5.7987e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4538e-05 - val_loss: 4.2772e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9044e-05 - val_loss: 1.1780e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6754e-05 - val_loss: 5.9851e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1707e-05 - val_loss: 1.2491e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4648e-05 - val_loss: 1.1225e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.9605e-06 - val_loss: 1.3471e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6292e-05 - val_loss: 9.2117e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3993e-05 - val_loss: 3.4617e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3764e-05 - val_loss: 5.0995e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4599e-05 - val_loss: 3.0804e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2679e-05 - val_loss: 3.4682e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0027e-05 - val_loss: 4.0672e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2533e-05 - val_loss: 9.6530e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1022e-05 - val_loss: 2.5616e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8898e-05 - val_loss: 1.0902e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5171e-05 - val_loss: 9.5956e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.9675e-05 - val_loss: 1.2535e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7537e-05 - val_loss: 6.1146e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1896e-05 - val_loss: 5.1945e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.2271e-05 - val_loss: 5.4829e-04\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6264e-05 - val_loss: 4.3090e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7185e-05 - val_loss: 1.4175e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6662e-05 - val_loss: 4.0017e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.5072e-05 - val_loss: 9.8306e-06\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1860e-05 - val_loss: 5.9955e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8760e-05 - val_loss: 2.1360e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5607e-05 - val_loss: 5.6656e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3103e-05 - val_loss: 5.0097e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7042e-05 - val_loss: 9.2036e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3310e-05 - val_loss: 3.3794e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1677e-05 - val_loss: 5.9465e-05\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.2296e-05 - val_loss: 1.1678e-04\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.4436e-05 - val_loss: 2.1210e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1187e-05 - val_loss: 9.3255e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8037e-05 - val_loss: 4.1236e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.7760e-05 - val_loss: 5.8079e-04\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2086e-05 - val_loss: 2.5182e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9622e-05 - val_loss: 1.6727e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7336e-05 - val_loss: 1.5419e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.2426e-05 - val_loss: 1.0211e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4132e-05 - val_loss: 3.8688e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6406e-05 - val_loss: 2.2444e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7426e-06 - val_loss: 3.5669e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3641e-05 - val_loss: 2.1385e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.1733e-05 - val_loss: 1.0288e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7503e-05 - val_loss: 2.3480e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8806e-05 - val_loss: 2.1252e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9506e-05 - val_loss: 1.0446e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0638e-05 - val_loss: 3.4161e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.4725e-05 - val_loss: 7.6229e-05\n",
      ">Neurons=90, Score=0.002968254375446122\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 22ms/step - loss: 0.0021 - val_loss: 0.0101\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.7598e-04 - val_loss: 0.0067\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.2699e-04 - val_loss: 0.0032\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4131e-04 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7320e-04 - val_loss: 3.7798e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2215e-04 - val_loss: 3.1487e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2670e-05 - val_loss: 2.1601e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.4235e-05 - val_loss: 1.5216e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0554e-04 - val_loss: 3.7001e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.2451e-05 - val_loss: 0.0015\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.0176e-05 - val_loss: 1.4629e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3398e-04 - val_loss: 4.9534e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0232e-04 - val_loss: 1.9275e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.5559e-05 - val_loss: 9.4959e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.9455e-05 - val_loss: 8.9124e-05\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1736e-05 - val_loss: 2.7355e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2541e-05 - val_loss: 1.6807e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.3358e-05 - val_loss: 3.3700e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.5669e-05 - val_loss: 5.8152e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9283e-05 - val_loss: 6.4648e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.9255e-05 - val_loss: 1.8180e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.2667e-05 - val_loss: 5.6035e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.9874e-05 - val_loss: 4.6685e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.4882e-05 - val_loss: 6.1125e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.5187e-05 - val_loss: 1.9303e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.0734e-05 - val_loss: 3.3136e-04\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5948e-05 - val_loss: 6.6785e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6222e-05 - val_loss: 1.7944e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.9231e-05 - val_loss: 6.4565e-05\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6278e-05 - val_loss: 2.3854e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6109e-05 - val_loss: 2.5062e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3644e-05 - val_loss: 1.0353e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9222e-05 - val_loss: 1.4580e-04\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.7598e-05 - val_loss: 1.1284e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4432e-05 - val_loss: 7.9775e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.9459e-05 - val_loss: 0.0017\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.1308e-04 - val_loss: 1.4193e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4438e-05 - val_loss: 7.7159e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.4540e-05 - val_loss: 1.7499e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6848e-05 - val_loss: 7.5842e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.9629e-05 - val_loss: 6.5428e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.1452e-05 - val_loss: 8.6087e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.9672e-05 - val_loss: 5.2367e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0696e-05 - val_loss: 1.7713e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1214e-05 - val_loss: 2.5831e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6118e-05 - val_loss: 5.9235e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6392e-05 - val_loss: 1.0413e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0004e-05 - val_loss: 6.2755e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0903e-05 - val_loss: 1.6381e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2872e-05 - val_loss: 4.2959e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3585e-05 - val_loss: 3.4918e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5540e-05 - val_loss: 1.0362e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.7556e-05 - val_loss: 1.6774e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0654e-05 - val_loss: 9.7788e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.0951e-05 - val_loss: 7.8778e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.5851e-05 - val_loss: 1.5790e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0507e-05 - val_loss: 7.7194e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6345e-05 - val_loss: 3.3427e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.0465e-05 - val_loss: 5.6656e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5236e-05 - val_loss: 2.5618e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3829e-05 - val_loss: 6.0140e-05\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.4149e-06 - val_loss: 2.8990e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6665e-05 - val_loss: 7.4532e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6309e-05 - val_loss: 8.3742e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3252e-05 - val_loss: 9.1366e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3142e-05 - val_loss: 3.1341e-04\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0656e-05 - val_loss: 6.4157e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.2633e-05 - val_loss: 4.9956e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9800e-05 - val_loss: 1.1116e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1878e-05 - val_loss: 2.3256e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3077e-05 - val_loss: 2.3264e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0576e-05 - val_loss: 7.4511e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9727e-05 - val_loss: 9.3097e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2057e-05 - val_loss: 8.4241e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8303e-05 - val_loss: 5.3939e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.4460e-05 - val_loss: 5.2839e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4423e-05 - val_loss: 1.0557e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.9873e-05 - val_loss: 1.8608e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6431e-05 - val_loss: 4.9133e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7732e-05 - val_loss: 4.3062e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0993e-05 - val_loss: 1.1314e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1567e-05 - val_loss: 8.5231e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.8193e-05 - val_loss: 8.3471e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2562e-05 - val_loss: 1.2778e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9632e-05 - val_loss: 2.3999e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.7301e-06 - val_loss: 2.2462e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7465e-05 - val_loss: 1.7583e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 1.9757e-05 - val_loss: 2.2895e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8222e-05 - val_loss: 8.3432e-05\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.4577e-05 - val_loss: 5.7101e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8011e-05 - val_loss: 4.6738e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.6644e-05 - val_loss: 3.0765e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3236e-05 - val_loss: 2.5692e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.1689e-06 - val_loss: 8.5647e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1595e-05 - val_loss: 4.0590e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1291e-05 - val_loss: 3.2759e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1997e-05 - val_loss: 4.0408e-04\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1220e-05 - val_loss: 4.3523e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8196e-05 - val_loss: 1.0337e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6121e-05 - val_loss: 3.2404e-05\n",
      ">Neurons=90, Score=0.001866239108494483\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 11s 20ms/step - loss: 0.0020 - val_loss: 0.0095\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.8787e-04 - val_loss: 0.0063\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.1554e-04 - val_loss: 0.0034\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6405e-04 - val_loss: 0.0010\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0435e-04 - val_loss: 6.6591e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6021e-04 - val_loss: 4.9898e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1116e-04 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0131e-04 - val_loss: 7.9207e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.0338e-05 - val_loss: 8.0195e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5877e-04 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1512e-04 - val_loss: 2.1468e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.2314e-05 - val_loss: 2.7486e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.4418e-05 - val_loss: 9.6388e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.2916e-05 - val_loss: 9.9295e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5909e-05 - val_loss: 4.2443e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.5479e-05 - val_loss: 2.5012e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0033e-04 - val_loss: 4.7329e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1140e-05 - val_loss: 9.0416e-05\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0502e-05 - val_loss: 2.7873e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0511e-05 - val_loss: 1.6132e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1278e-05 - val_loss: 2.2576e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9295e-05 - val_loss: 1.1116e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.0177e-05 - val_loss: 3.0290e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.5850e-05 - val_loss: 4.4389e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1422e-05 - val_loss: 1.9474e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6615e-05 - val_loss: 5.5596e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3115e-05 - val_loss: 1.9299e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.9663e-05 - val_loss: 7.5321e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.3109e-05 - val_loss: 8.2184e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.0128e-05 - val_loss: 1.4078e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2351e-05 - val_loss: 1.4757e-05\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9032e-05 - val_loss: 7.4358e-05\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.1918e-05 - val_loss: 6.8175e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.9835e-05 - val_loss: 4.7203e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.6160e-05 - val_loss: 8.5906e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6440e-05 - val_loss: 7.7762e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2236e-05 - val_loss: 1.1184e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3595e-05 - val_loss: 3.1569e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9454e-05 - val_loss: 3.8897e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8987e-05 - val_loss: 3.2271e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.3682e-05 - val_loss: 3.7946e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3933e-05 - val_loss: 2.2268e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4754e-05 - val_loss: 3.7688e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5340e-05 - val_loss: 1.6433e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5744e-05 - val_loss: 3.1256e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.2259e-05 - val_loss: 3.3834e-04\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.0497e-05 - val_loss: 1.3933e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3890e-05 - val_loss: 2.1246e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3136e-05 - val_loss: 5.4871e-05\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0170e-05 - val_loss: 1.9299e-05\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.7981e-05 - val_loss: 1.0668e-05\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6667e-05 - val_loss: 1.2627e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1810e-05 - val_loss: 7.0944e-05\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1535e-05 - val_loss: 1.2060e-04\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9219e-05 - val_loss: 1.3096e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6407e-05 - val_loss: 1.8738e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.9920e-05 - val_loss: 3.3238e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4834e-05 - val_loss: 3.7656e-05\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5632e-05 - val_loss: 2.0469e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8943e-05 - val_loss: 1.3527e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3436e-05 - val_loss: 1.0971e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.9216e-05 - val_loss: 3.5389e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.4780e-05 - val_loss: 1.2518e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.3407e-05 - val_loss: 3.1970e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 5.4991e-05 - val_loss: 3.3704e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1662e-05 - val_loss: 6.9391e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.0240e-05 - val_loss: 4.0968e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 1.8191e-05 - val_loss: 2.4158e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2296e-05 - val_loss: 6.4209e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2858e-05 - val_loss: 3.8943e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.4478e-05 - val_loss: 1.1267e-04\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1949e-05 - val_loss: 3.4118e-05\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1745e-05 - val_loss: 1.1150e-04\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0930e-05 - val_loss: 2.7304e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.9092e-05 - val_loss: 2.4025e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0622e-05 - val_loss: 2.6395e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.9739e-05 - val_loss: 4.4062e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6123e-05 - val_loss: 1.9797e-05\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.5286e-05 - val_loss: 2.2869e-05\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.6756e-05 - val_loss: 5.5744e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5415e-05 - val_loss: 2.4150e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1877e-05 - val_loss: 5.1743e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.3063e-06 - val_loss: 7.2864e-06\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5076e-05 - val_loss: 1.3406e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2346e-05 - val_loss: 4.0522e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.1247e-05 - val_loss: 1.0542e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7892e-05 - val_loss: 1.2900e-04\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6086e-05 - val_loss: 1.1439e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.5954e-05 - val_loss: 3.2144e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.6959e-05 - val_loss: 6.6043e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7133e-05 - val_loss: 9.6762e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1345e-05 - val_loss: 1.0080e-04\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5669e-05 - val_loss: 4.0525e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9869e-05 - val_loss: 1.2936e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2401e-05 - val_loss: 7.1322e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6756e-05 - val_loss: 1.1262e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3257e-05 - val_loss: 9.2535e-06\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7686e-05 - val_loss: 3.8286e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.9741e-05 - val_loss: 1.8824e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3911e-05 - val_loss: 6.2827e-04\n",
      ">Neurons=90, Score=0.032929074950516224\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 21ms/step - loss: 0.0020 - val_loss: 0.0097\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.3782e-04 - val_loss: 0.0062\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.1856e-04 - val_loss: 0.0029\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6348e-04 - val_loss: 0.0012\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7405e-04 - val_loss: 4.4887e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3928e-04 - val_loss: 3.4327e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2404e-04 - val_loss: 7.2325e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.7495e-05 - val_loss: 6.2025e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.7337e-05 - val_loss: 6.5428e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1237e-04 - val_loss: 3.0897e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.3947e-05 - val_loss: 2.2912e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1427e-05 - val_loss: 4.3236e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.4858e-05 - val_loss: 1.0991e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5880e-05 - val_loss: 3.2114e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1447e-05 - val_loss: 1.0539e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.1050e-05 - val_loss: 2.5630e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.5142e-05 - val_loss: 4.5293e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.6653e-05 - val_loss: 1.0592e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3151e-05 - val_loss: 3.1845e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.7561e-05 - val_loss: 2.6334e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.4701e-05 - val_loss: 6.5844e-05\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.9266e-05 - val_loss: 3.1403e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.3371e-05 - val_loss: 1.7061e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.4342e-05 - val_loss: 3.7991e-04\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5635e-05 - val_loss: 1.3182e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8844e-05 - val_loss: 2.7255e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.5033e-05 - val_loss: 2.6191e-04\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.0435e-05 - val_loss: 4.1537e-04\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.8687e-05 - val_loss: 3.8387e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4601e-05 - val_loss: 4.1467e-05\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.3958e-05 - val_loss: 1.0085e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.7384e-05 - val_loss: 2.7935e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5185e-05 - val_loss: 4.9176e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1415e-05 - val_loss: 1.4086e-04\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2777e-05 - val_loss: 3.7929e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1484e-05 - val_loss: 3.2391e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.2131e-05 - val_loss: 2.1335e-04\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2424e-05 - val_loss: 2.2975e-04\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.3833e-05 - val_loss: 5.4062e-05\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2919e-05 - val_loss: 3.0662e-05\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7679e-05 - val_loss: 8.5058e-05\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4690e-05 - val_loss: 1.5695e-04\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.9793e-05 - val_loss: 1.2211e-04\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.8454e-05 - val_loss: 5.9118e-05\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0538e-05 - val_loss: 1.1572e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5047e-05 - val_loss: 5.7574e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1679e-05 - val_loss: 4.9239e-05\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.9420e-05 - val_loss: 2.2838e-05\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8960e-05 - val_loss: 1.6547e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.1562e-05 - val_loss: 7.2405e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3428e-05 - val_loss: 7.7929e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.7395e-05 - val_loss: 1.6256e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7597e-05 - val_loss: 3.5028e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.0178e-05 - val_loss: 6.9218e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7312e-05 - val_loss: 5.0268e-05\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.4293e-05 - val_loss: 4.4699e-05\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.9910e-05 - val_loss: 4.5661e-04\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3425e-05 - val_loss: 1.0968e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.1734e-05 - val_loss: 1.1024e-04\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0249e-05 - val_loss: 8.8646e-05\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9044e-05 - val_loss: 1.8820e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1928e-05 - val_loss: 5.1346e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4531e-05 - val_loss: 4.7002e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3927e-05 - val_loss: 3.7675e-05\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5895e-05 - val_loss: 2.3374e-04\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7557e-05 - val_loss: 4.6147e-05\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2093e-05 - val_loss: 1.5191e-05\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2061e-05 - val_loss: 3.2491e-04\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.7077e-05 - val_loss: 2.3464e-04\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7236e-05 - val_loss: 2.3977e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.3892e-05 - val_loss: 7.5847e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4764e-05 - val_loss: 5.8491e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1709e-05 - val_loss: 6.5794e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1530e-05 - val_loss: 6.3657e-05\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.5546e-05 - val_loss: 4.6398e-05\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8879e-05 - val_loss: 1.1651e-05\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3089e-05 - val_loss: 2.2489e-04\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.0491e-05 - val_loss: 0.0010\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1639e-05 - val_loss: 1.3511e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1550e-05 - val_loss: 2.0039e-05\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4510e-05 - val_loss: 2.5766e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4857e-05 - val_loss: 1.6092e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6724e-05 - val_loss: 1.4784e-05\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7993e-05 - val_loss: 3.1432e-04\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.2249e-05 - val_loss: 6.4254e-05\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7756e-05 - val_loss: 3.6505e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.4771e-05 - val_loss: 2.6519e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.9959e-05 - val_loss: 1.3122e-05\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9937e-05 - val_loss: 7.0625e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.1858e-05 - val_loss: 1.6499e-05\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9651e-05 - val_loss: 7.8442e-04\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.5000e-05 - val_loss: 6.3906e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3393e-05 - val_loss: 2.8896e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1852e-05 - val_loss: 2.4102e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2496e-05 - val_loss: 3.6248e-05\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8638e-05 - val_loss: 6.8041e-06\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0887e-05 - val_loss: 1.1049e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2754e-05 - val_loss: 5.9715e-04\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4072e-05 - val_loss: 2.8965e-05\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0360e-05 - val_loss: 2.2561e-04\n",
      ">Neurons=90, Score=0.011467802687548101\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 10s 20ms/step - loss: 0.0021 - val_loss: 0.0098\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.0054e-04 - val_loss: 0.0066\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.8504e-04 - val_loss: 0.0028\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.6592e-04 - val_loss: 0.0014\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6889e-04 - val_loss: 2.0116e-04\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.4079e-05 - val_loss: 2.3570e-04\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1699e-04 - val_loss: 5.3170e-04\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1062e-04 - val_loss: 3.3832e-04\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.5716e-05 - val_loss: 2.6184e-04\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.3257e-05 - val_loss: 1.6090e-04\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.3419e-04 - val_loss: 9.8584e-04\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.0344e-04 - val_loss: 1.5286e-04\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.6771e-05 - val_loss: 3.8430e-04\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.5016e-05 - val_loss: 2.6058e-04\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8963e-05 - val_loss: 1.7177e-04\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.9412e-05 - val_loss: 2.0918e-04\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9012e-05 - val_loss: 1.5856e-04\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.2690e-05 - val_loss: 1.1101e-04\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.5873e-05 - val_loss: 4.2785e-04\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.9071e-05 - val_loss: 1.3532e-04\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4394e-05 - val_loss: 1.8736e-04\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.1079e-05 - val_loss: 1.0280e-04\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.9780e-05 - val_loss: 1.2980e-04\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.7790e-05 - val_loss: 4.3215e-05\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5691e-05 - val_loss: 3.1325e-04\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.5398e-05 - val_loss: 6.1094e-05\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.3788e-05 - val_loss: 7.9042e-05\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7863e-05 - val_loss: 1.1218e-05\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.7156e-05 - val_loss: 4.3323e-04\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.7329e-05 - val_loss: 1.4227e-04\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.5594e-05 - val_loss: 2.4841e-04\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.5699e-05 - val_loss: 1.3763e-04\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.1815e-05 - val_loss: 7.4764e-05\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0922e-05 - val_loss: 7.2274e-05\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5567e-05 - val_loss: 6.7303e-05\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0520e-05 - val_loss: 5.7577e-05\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1773e-05 - val_loss: 5.5124e-05\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4221e-05 - val_loss: 4.9356e-05\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.2952e-05 - val_loss: 6.4389e-04\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.1121e-05 - val_loss: 4.1045e-04\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3384e-05 - val_loss: 1.1297e-04\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0775e-05 - val_loss: 8.2378e-05\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6792e-05 - val_loss: 9.2466e-05\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.8833e-05 - val_loss: 1.2602e-04\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.6079e-05 - val_loss: 3.6083e-04\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8903e-05 - val_loss: 9.0908e-05\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1349e-05 - val_loss: 1.6429e-04\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5443e-05 - val_loss: 1.5613e-04\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.0264e-05 - val_loss: 1.5431e-04\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3658e-05 - val_loss: 1.6861e-04\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.3079e-05 - val_loss: 1.6744e-04\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5067e-05 - val_loss: 2.0365e-04\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.1333e-05 - val_loss: 3.2193e-04\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.2710e-05 - val_loss: 8.9590e-05\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9003e-05 - val_loss: 5.9748e-04\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2883e-05 - val_loss: 1.0649e-04\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3631e-05 - val_loss: 5.3901e-05\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6763e-05 - val_loss: 1.9055e-04\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6275e-05 - val_loss: 6.0721e-05\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.6880e-05 - val_loss: 2.3494e-04\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4722e-05 - val_loss: 4.2558e-04\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.9182e-05 - val_loss: 5.1660e-05\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4238e-05 - val_loss: 1.4601e-05\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0659e-05 - val_loss: 1.2374e-04\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.2921e-05 - val_loss: 2.6654e-05\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7151e-05 - val_loss: 8.7977e-06\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1808e-05 - val_loss: 2.1839e-04\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1235e-05 - val_loss: 3.7309e-05\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2709e-05 - val_loss: 8.3462e-05\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.9622e-05 - val_loss: 4.4125e-05\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.5193e-05 - val_loss: 4.5760e-05\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.7448e-05 - val_loss: 1.1907e-04\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0460e-05 - val_loss: 3.5812e-05\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6131e-05 - val_loss: 4.4248e-04\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.2957e-05 - val_loss: 2.6699e-04\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3237e-05 - val_loss: 1.4311e-04\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0117e-05 - val_loss: 8.6385e-05\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.9591e-05 - val_loss: 3.7116e-04\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.8131e-05 - val_loss: 1.5271e-04\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3100e-05 - val_loss: 4.9001e-04\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.1990e-05 - val_loss: 1.2145e-04\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.7691e-05 - val_loss: 4.2331e-05\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5466e-05 - val_loss: 2.7319e-04\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7823e-06 - val_loss: 2.2650e-05\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.7639e-05 - val_loss: 3.9958e-04\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.4850e-05 - val_loss: 4.0559e-05\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9157e-05 - val_loss: 7.9094e-05\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8531e-05 - val_loss: 1.2755e-04\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9310e-05 - val_loss: 8.6243e-04\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.2290e-05 - val_loss: 1.1128e-04\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.8479e-05 - val_loss: 5.4913e-05\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.1435e-05 - val_loss: 3.0538e-05\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3937e-05 - val_loss: 2.4554e-05\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3905e-05 - val_loss: 5.7716e-05\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4172e-05 - val_loss: 5.6669e-04\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4519e-05 - val_loss: 5.9260e-04\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.9162e-05 - val_loss: 5.2117e-05\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.5504e-05 - val_loss: 1.7586e-05\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8290e-05 - val_loss: 1.0404e-04\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3766e-05 - val_loss: 1.1333e-05\n",
      ">Neurons=90, Score=0.00207244938792428\n",
      "[[0.0016434552890132181, 0.02418830554233864, 0.0012721907296509016, 0.005631269596051425, 0.0008353753401024733, 0.0037501198676181957, 0.009562322520650923, 0.001319621424045181, 0.004193113636574708, 0.00997807364910841], [0.005715840597986244, 0.0017861739252111875, 0.011468315642559901, 0.001424595666321693, 0.00995320369838737, 0.00741600088076666, 0.002591567135823425, 0.00869685027282685, 0.0035659788409247994, 0.0016808600776130334], [0.006865151226520538, 0.0017201069567818195, 0.011062935664085671, 0.023931957548484206, 0.0015589756003464572, 0.0064973799453582615, 0.003971258411183953, 0.04302272282075137, 0.0029536231522797607, 0.0038043901440687478], [0.002792458326439373, 0.009416597458766773, 0.013245521404314786, 0.0008165790859493427, 0.009613935253582895, 0.021845227456651628, 0.02693254209589213, 0.0030230450647650287, 0.002487978053977713, 0.0051047220040345564], [0.001385165251122089, 0.006951997784199193, 0.09817200480028987, 0.004223103678668849, 0.007184466085163876, 0.024605917860753834, 0.0031352887162938714, 0.004616755904862657, 0.005299417534843087, 0.0020578874682541937], [0.013748012133873999, 0.0065471846028231084, 0.002277636667713523, 0.026790870469994843, 0.021810010366607457, 0.01828309177653864, 0.002479226895957254, 0.002560423126851674, 0.0038965306885074824, 0.012980296742171049], [0.0015113044355530292, 0.0007756969353067689, 0.005655101631418802, 0.01888812257675454, 0.0021488589482032694, 0.002968254375446122, 0.001866239108494483, 0.032929074950516224, 0.011467802687548101, 0.00207244938792428]] [60, 65, 70, 75, 80, 85, 90]\n",
      "Param=60, Mean=0.006:, Std=0.007\n",
      "Param=65, Mean=0.005:, Std=0.004\n",
      "Param=70, Mean=0.011:, Std=0.013\n",
      "Param=75, Mean=0.010:, Std=0.008\n",
      "Param=80, Mean=0.016:, Std=0.028\n",
      "Param=85, Mean=0.011:, Std=0.008\n",
      "Param=90, Mean=0.008:, Std=0.010\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, neurons):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=4, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=4)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # resumindo a média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = mean(scores[i]), std(scores[i])\n",
    "        print(f'Param={params[i]}, Mean={m:.3f}:, Std={s:.3f}')\n",
    "    # boxplot das pontuações\n",
    "    pyplot.boxplot(scores, labels=params)\n",
    "    pyplot.savefig('figura[0].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repetindo o experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            score = score * 100.0\n",
    "            scores.append(score)\n",
    "            print(f'>Neurons={p}, Score={score}')\n",
    "        all_scores.append(scores)\n",
    "    # resumindo os resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = [60, 65, 70, 75, 80, 85, 90]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste de modelo com tamanho do lote 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 e 12, para verificação do mais adequado para a aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "606/606 [==============================] - 9s 7ms/step - loss: 0.0014 - val_loss: 0.0082\n",
      "Epoch 2/50\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 7.3070e-04 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 3.6191e-04 - val_loss: 9.8606e-04\n",
      "Epoch 4/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 1.8412e-04 - val_loss: 0.0015\n",
      "Epoch 5/50\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 1.4029e-04 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 1.8996e-04 - val_loss: 4.3535e-04\n",
      "Epoch 7/50\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 1.7287e-04 - val_loss: 5.8636e-04\n",
      "Epoch 8/50\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 1.2379e-04 - val_loss: 3.4758e-04\n",
      "Epoch 9/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 8.6890e-05 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.8606e-04 - val_loss: 8.5779e-04\n",
      "Epoch 11/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.5261e-04 - val_loss: 3.5921e-04\n",
      "Epoch 12/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.5162e-04 - val_loss: 6.4122e-04\n",
      "Epoch 13/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.1262e-04 - val_loss: 2.0787e-04\n",
      "Epoch 14/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 9.1220e-05 - val_loss: 1.7706e-04\n",
      "Epoch 15/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 6.6795e-05 - val_loss: 7.9181e-04\n",
      "Epoch 16/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 5.0647e-05 - val_loss: 6.3025e-04\n",
      "Epoch 17/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 8.6400e-05 - val_loss: 3.1793e-04\n",
      "Epoch 18/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.1397e-04 - val_loss: 6.9345e-04\n",
      "Epoch 19/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 8.8576e-05 - val_loss: 5.1468e-04\n",
      "Epoch 20/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 8.9742e-05 - val_loss: 4.3924e-04\n",
      "Epoch 21/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 6.6032e-05 - val_loss: 3.7993e-04\n",
      "Epoch 22/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.7288e-05 - val_loss: 5.6351e-04\n",
      "Epoch 23/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.2688e-04 - val_loss: 4.8390e-04\n",
      "Epoch 24/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 7.1811e-05 - val_loss: 8.2816e-04\n",
      "Epoch 25/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 3.9716e-05 - val_loss: 6.7734e-05\n",
      "Epoch 26/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.1032e-04 - val_loss: 4.4024e-04\n",
      "Epoch 27/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 4.0837e-05 - val_loss: 3.1621e-04\n",
      "Epoch 28/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.8795e-05 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.4243e-05 - val_loss: 3.8525e-04\n",
      "Epoch 30/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 6.1944e-05 - val_loss: 1.3980e-04\n",
      "Epoch 31/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 9.5919e-05 - val_loss: 7.3093e-04\n",
      "Epoch 32/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.9731e-05 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 4.6832e-05 - val_loss: 2.9143e-04\n",
      "Epoch 34/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 4.1538e-05 - val_loss: 3.7651e-04\n",
      "Epoch 35/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 6.9725e-05 - val_loss: 3.0341e-04\n",
      "Epoch 36/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.6450e-05 - val_loss: 1.4096e-04\n",
      "Epoch 37/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 5.2309e-05 - val_loss: 1.2799e-04\n",
      "Epoch 38/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.8330e-05 - val_loss: 1.7366e-04\n",
      "Epoch 39/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 9.8976e-05 - val_loss: 2.6361e-04\n",
      "Epoch 40/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.8076e-05 - val_loss: 6.8114e-04\n",
      "Epoch 41/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.6782e-05 - val_loss: 3.4229e-04\n",
      "Epoch 42/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 6.5354e-05 - val_loss: 6.4050e-05\n",
      "Epoch 43/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.8338e-05 - val_loss: 2.2669e-05\n",
      "Epoch 44/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 4.2651e-05 - val_loss: 8.7087e-05\n",
      "Epoch 45/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 3.0388e-05 - val_loss: 2.5767e-05\n",
      "Epoch 46/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.7724e-05 - val_loss: 3.4388e-04\n",
      "Epoch 47/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 6.4474e-05 - val_loss: 6.2738e-05\n",
      "Epoch 48/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.5060e-04 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 8.3364e-05 - val_loss: 6.4029e-05\n",
      "Epoch 50/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.0921e-05 - val_loss: 4.0530e-05\n",
      ">p=1: 1, Score=0.006654581375187263\n",
      "Epoch 1/50\n",
      "606/606 [==============================] - 10s 8ms/step - loss: 0.0014 - val_loss: 0.0084\n",
      "Epoch 2/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.5450e-04 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.4474e-04 - val_loss: 0.0015\n",
      "Epoch 4/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.5517e-04 - val_loss: 8.4100e-04\n",
      "Epoch 5/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.2172e-04 - val_loss: 1.6509e-04\n",
      "Epoch 6/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 2.0339e-04 - val_loss: 9.7759e-04\n",
      "Epoch 7/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.8978e-04 - val_loss: 8.0105e-04\n",
      "Epoch 8/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.4249e-04 - val_loss: 1.0409e-04\n",
      "Epoch 9/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 5.4917e-05 - val_loss: 9.1783e-04\n",
      "Epoch 10/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 9.6176e-05 - val_loss: 1.2805e-04\n",
      "Epoch 11/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.7663e-04 - val_loss: 0.0010\n",
      "Epoch 12/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.6248e-04 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 1.2394e-04 - val_loss: 4.2459e-04\n",
      "Epoch 14/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 8.7825e-05 - val_loss: 6.8273e-04\n",
      "Epoch 15/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 6.8924e-05 - val_loss: 2.2653e-04\n",
      "Epoch 16/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 6.4414e-05 - val_loss: 4.9575e-04\n",
      "Epoch 17/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 7.7343e-05 - val_loss: 1.3997e-04\n",
      "Epoch 18/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 6.2798e-05 - val_loss: 1.9943e-04\n",
      "Epoch 19/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 7.3276e-05 - val_loss: 1.1862e-04\n",
      "Epoch 20/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 9.6305e-05 - val_loss: 1.3962e-04\n",
      "Epoch 21/50\n",
      "606/606 [==============================] - 3s 6ms/step - loss: 8.3768e-05 - val_loss: 5.7355e-04\n",
      "Epoch 22/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.8034e-05 - val_loss: 1.8644e-04\n",
      "Epoch 23/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.1584e-05 - val_loss: 1.3497e-04\n",
      "Epoch 24/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 6.7299e-05 - val_loss: 1.7415e-04\n",
      "Epoch 25/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 5.9296e-05 - val_loss: 2.3998e-04\n",
      "Epoch 26/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 9.9651e-05 - val_loss: 9.3064e-04\n",
      "Epoch 27/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 5.1193e-05 - val_loss: 1.7108e-04\n",
      "Epoch 28/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 8.6715e-05 - val_loss: 6.8361e-04\n",
      "Epoch 29/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 5.8571e-05 - val_loss: 3.9798e-04\n",
      "Epoch 30/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 7.1512e-05 - val_loss: 5.3552e-04\n",
      "Epoch 31/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 6.7016e-05 - val_loss: 3.6040e-04\n",
      "Epoch 32/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 4.5570e-05 - val_loss: 5.6803e-05\n",
      "Epoch 33/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 1.1421e-04 - val_loss: 6.9251e-04\n",
      "Epoch 34/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 4.4066e-05 - val_loss: 5.0057e-04\n",
      "Epoch 35/50\n",
      "606/606 [==============================] - 9s 15ms/step - loss: 1.0716e-04 - val_loss: 7.7676e-04\n",
      "Epoch 36/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 1.9459e-05 - val_loss: 2.2263e-04\n",
      "Epoch 37/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 9.4261e-05 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 1.6476e-04 - val_loss: 0.0017\n",
      "Epoch 39/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 6.9553e-05 - val_loss: 3.2428e-05\n",
      "Epoch 40/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 3.9324e-05 - val_loss: 2.6427e-04\n",
      "Epoch 41/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 3.7688e-05 - val_loss: 3.7794e-04\n",
      "Epoch 42/50\n",
      "606/606 [==============================] - 9s 14ms/step - loss: 3.5772e-05 - val_loss: 6.1367e-05\n",
      "Epoch 43/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 2.9715e-05 - val_loss: 6.4765e-05\n",
      "Epoch 44/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 5.3324e-05 - val_loss: 2.8377e-05\n",
      "Epoch 45/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 9.1296e-05 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 5.5630e-05 - val_loss: 7.9295e-05\n",
      "Epoch 47/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 4.8193e-05 - val_loss: 1.2155e-04\n",
      "Epoch 48/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 1.0009e-04 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "606/606 [==============================] - 8s 12ms/step - loss: 5.1716e-05 - val_loss: 7.4337e-05\n",
      "Epoch 50/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 5.3009e-05 - val_loss: 4.0854e-04\n",
      ">p=1: 2, Score=0.015223288210108876\n",
      "Epoch 1/50\n",
      "606/606 [==============================] - 16s 13ms/step - loss: 0.0014 - val_loss: 0.0082\n",
      "Epoch 2/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 7.3649e-04 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 3.1148e-04 - val_loss: 3.3644e-04\n",
      "Epoch 4/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 1.6924e-04 - val_loss: 2.4610e-04\n",
      "Epoch 5/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 1.3484e-04 - val_loss: 5.8412e-04\n",
      "Epoch 6/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 1.2559e-04 - val_loss: 1.8304e-04\n",
      "Epoch 7/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.6214e-04 - val_loss: 6.4221e-04\n",
      "Epoch 8/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.1408e-04 - val_loss: 2.2396e-04\n",
      "Epoch 9/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 7.3833e-05 - val_loss: 3.2759e-04\n",
      "Epoch 10/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 9.3143e-05 - val_loss: 2.9579e-04\n",
      "Epoch 11/50\n",
      "606/606 [==============================] - 8s 14ms/step - loss: 9.9843e-05 - val_loss: 8.4831e-04\n",
      "Epoch 12/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 1.5598e-04 - val_loss: 5.1581e-04\n",
      "Epoch 13/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 1.1993e-04 - val_loss: 6.4244e-04\n",
      "Epoch 14/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 5.5249e-05 - val_loss: 1.5990e-04\n",
      "Epoch 15/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 6.1955e-05 - val_loss: 1.5637e-04\n",
      "Epoch 16/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.0812e-04 - val_loss: 9.3881e-04\n",
      "Epoch 17/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 1.4923e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.0307e-04 - val_loss: 2.5605e-04\n",
      "Epoch 19/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.8667e-05 - val_loss: 3.4613e-05\n",
      "Epoch 20/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 5.5884e-05 - val_loss: 5.1886e-04\n",
      "Epoch 21/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.6008e-04 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 7.2894e-05 - val_loss: 1.2867e-04\n",
      "Epoch 23/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 9.8185e-05 - val_loss: 8.2291e-04\n",
      "Epoch 24/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 9.6204e-05 - val_loss: 1.6570e-04\n",
      "Epoch 25/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 5.4143e-05 - val_loss: 8.4838e-05\n",
      "Epoch 26/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.2835e-05 - val_loss: 5.6978e-05\n",
      "Epoch 27/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.4840e-05 - val_loss: 8.2098e-05\n",
      "Epoch 28/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.7994e-05 - val_loss: 1.6434e-04\n",
      "Epoch 29/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.0504e-05 - val_loss: 2.5356e-04\n",
      "Epoch 30/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.4460e-05 - val_loss: 2.2317e-04\n",
      "Epoch 31/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 6.8789e-05 - val_loss: 3.3755e-04\n",
      "Epoch 32/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 8.5607e-05 - val_loss: 4.1271e-04\n",
      "Epoch 33/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.0890e-05 - val_loss: 5.9823e-04\n",
      "Epoch 34/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.4713e-05 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.1022e-04 - val_loss: 6.0844e-05\n",
      "Epoch 36/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 2.4993e-05 - val_loss: 7.8199e-05\n",
      "Epoch 37/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 5.2043e-05 - val_loss: 6.8086e-04\n",
      "Epoch 38/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.5065e-05 - val_loss: 4.5241e-04\n",
      "Epoch 39/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 8.3081e-05 - val_loss: 1.5297e-04\n",
      "Epoch 40/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.3753e-05 - val_loss: 2.3332e-04\n",
      "Epoch 41/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 4.7006e-05 - val_loss: 6.2637e-04\n",
      "Epoch 42/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 2.5855e-05 - val_loss: 4.5687e-04\n",
      "Epoch 43/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.7195e-05 - val_loss: 8.4760e-05\n",
      "Epoch 44/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 5.7556e-05 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 4.0925e-05 - val_loss: 2.1709e-04\n",
      "Epoch 46/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 4.3411e-05 - val_loss: 3.2302e-04\n",
      "Epoch 47/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 8.8475e-05 - val_loss: 7.1528e-05\n",
      "Epoch 48/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.7989e-05 - val_loss: 2.1007e-04\n",
      "Epoch 49/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 2.4154e-05 - val_loss: 7.1916e-05\n",
      "Epoch 50/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 2.7908e-05 - val_loss: 6.6578e-05\n",
      ">p=1: 3, Score=0.009404462616657838\n",
      "Epoch 1/50\n",
      "606/606 [==============================] - 14s 12ms/step - loss: 0.0014 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 7.7577e-04 - val_loss: 0.0034\n",
      "Epoch 3/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 3.4329e-04 - val_loss: 7.0811e-04\n",
      "Epoch 4/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 2.0292e-04 - val_loss: 6.8643e-04\n",
      "Epoch 5/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.1147e-04 - val_loss: 8.7878e-04\n",
      "Epoch 6/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.1139e-04 - val_loss: 7.4393e-04\n",
      "Epoch 7/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 1.6035e-04 - val_loss: 9.4520e-04\n",
      "Epoch 8/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.3430e-04 - val_loss: 1.8522e-04\n",
      "Epoch 9/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.0711e-04 - val_loss: 1.5784e-04\n",
      "Epoch 10/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 9.2616e-05 - val_loss: 4.9070e-04\n",
      "Epoch 11/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.3496e-04 - val_loss: 6.9857e-04\n",
      "Epoch 12/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.3954e-04 - val_loss: 4.7301e-04\n",
      "Epoch 13/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.8858e-05 - val_loss: 3.3988e-04\n",
      "Epoch 14/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.5362e-04 - val_loss: 2.3954e-04\n",
      "Epoch 15/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 8.0480e-05 - val_loss: 2.7341e-04\n",
      "Epoch 16/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 6.5062e-05 - val_loss: 2.9897e-04\n",
      "Epoch 17/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.0327e-04 - val_loss: 2.0702e-04\n",
      "Epoch 18/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 8.8126e-05 - val_loss: 2.0414e-04\n",
      "Epoch 19/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.8082e-04 - val_loss: 0.0010\n",
      "Epoch 20/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.0693e-04 - val_loss: 3.8456e-04\n",
      "Epoch 21/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 8.7185e-05 - val_loss: 2.6630e-04\n",
      "Epoch 22/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 7.0227e-05 - val_loss: 1.5029e-04\n",
      "Epoch 23/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 6.8817e-05 - val_loss: 1.7835e-04\n",
      "Epoch 24/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.6249e-05 - val_loss: 6.0818e-05\n",
      "Epoch 25/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.7174e-05 - val_loss: 6.0493e-04\n",
      "Epoch 26/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.7688e-05 - val_loss: 3.1771e-04\n",
      "Epoch 27/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.5206e-05 - val_loss: 1.8232e-04\n",
      "Epoch 28/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 4.7363e-05 - val_loss: 3.8166e-04\n",
      "Epoch 29/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.0712e-04 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 9.2479e-05 - val_loss: 8.6587e-05\n",
      "Epoch 31/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.3810e-05 - val_loss: 2.2450e-04\n",
      "Epoch 32/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 6.4566e-05 - val_loss: 1.3749e-04\n",
      "Epoch 33/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 2.9621e-05 - val_loss: 1.1504e-04\n",
      "Epoch 34/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 5.5551e-05 - val_loss: 6.3993e-05\n",
      "Epoch 35/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 5.3574e-05 - val_loss: 9.5538e-04\n",
      "Epoch 36/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 6.6664e-05 - val_loss: 2.6147e-05\n",
      "Epoch 37/50\n",
      "606/606 [==============================] - 9s 14ms/step - loss: 6.7568e-05 - val_loss: 3.8015e-04\n",
      "Epoch 38/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 6.6119e-05 - val_loss: 4.0801e-04\n",
      "Epoch 39/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.2594e-05 - val_loss: 1.2735e-04\n",
      "Epoch 40/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.4919e-05 - val_loss: 1.1366e-04\n",
      "Epoch 41/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.0278e-05 - val_loss: 3.2251e-04\n",
      "Epoch 42/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.0739e-05 - val_loss: 4.5783e-04\n",
      "Epoch 43/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.1324e-05 - val_loss: 3.1097e-04\n",
      "Epoch 44/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 6.2542e-05 - val_loss: 1.4472e-04\n",
      "Epoch 45/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 2.5751e-05 - val_loss: 1.5333e-04\n",
      "Epoch 46/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 6.1595e-05 - val_loss: 2.4793e-04\n",
      "Epoch 47/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 5.0394e-05 - val_loss: 6.7953e-05\n",
      "Epoch 48/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.5477e-05 - val_loss: 5.2119e-05\n",
      "Epoch 49/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.5630e-05 - val_loss: 8.9627e-04\n",
      "Epoch 50/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.1085e-05 - val_loss: 3.4776e-05\n",
      ">p=1: 4, Score=0.004897721737506799\n",
      "Epoch 1/50\n",
      "606/606 [==============================] - 14s 12ms/step - loss: 0.0014 - val_loss: 0.0082\n",
      "Epoch 2/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 6.9974e-04 - val_loss: 0.0031\n",
      "Epoch 3/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.3684e-04 - val_loss: 4.8418e-04\n",
      "Epoch 4/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.3262e-04 - val_loss: 5.5052e-04\n",
      "Epoch 5/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 1.6763e-04 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.2512e-04 - val_loss: 1.8787e-04\n",
      "Epoch 7/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.4434e-05 - val_loss: 2.9881e-04\n",
      "Epoch 8/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.7690e-04 - val_loss: 2.4534e-04\n",
      "Epoch 9/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.4260e-04 - val_loss: 6.2895e-04\n",
      "Epoch 10/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 8.2759e-05 - val_loss: 4.6782e-04\n",
      "Epoch 11/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.6519e-05 - val_loss: 6.4247e-04\n",
      "Epoch 12/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 9.7991e-05 - val_loss: 4.8402e-04\n",
      "Epoch 13/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 6.1796e-05 - val_loss: 1.0191e-04\n",
      "Epoch 14/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 1.3149e-04 - val_loss: 2.6849e-04\n",
      "Epoch 15/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.9230e-05 - val_loss: 2.8382e-04\n",
      "Epoch 16/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 7.9199e-05 - val_loss: 4.6499e-04\n",
      "Epoch 17/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 7.3321e-05 - val_loss: 4.9528e-04\n",
      "Epoch 18/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 9.2455e-05 - val_loss: 9.5363e-04\n",
      "Epoch 19/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 9.3286e-05 - val_loss: 9.6770e-04\n",
      "Epoch 20/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 8.0619e-05 - val_loss: 6.5033e-05\n",
      "Epoch 21/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 4.4739e-05 - val_loss: 2.6002e-04\n",
      "Epoch 22/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 7.2090e-05 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 1.0683e-04 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 9.8382e-05 - val_loss: 6.4065e-04\n",
      "Epoch 25/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 4.2503e-05 - val_loss: 2.1249e-04\n",
      "Epoch 26/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 2.0522e-04 - val_loss: 2.0495e-04\n",
      "Epoch 27/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 4.5025e-05 - val_loss: 1.5001e-04\n",
      "Epoch 28/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 3.5100e-05 - val_loss: 6.9264e-05\n",
      "Epoch 29/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 6.4594e-05 - val_loss: 1.1584e-04\n",
      "Epoch 30/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 6.7293e-05 - val_loss: 9.7728e-05\n",
      "Epoch 31/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 3.0465e-05 - val_loss: 1.5707e-04\n",
      "Epoch 32/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 7.5526e-05 - val_loss: 4.9542e-04\n",
      "Epoch 33/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.1303e-04 - val_loss: 0.0016\n",
      "Epoch 34/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 7.9165e-05 - val_loss: 1.7282e-04\n",
      "Epoch 35/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 3.7449e-05 - val_loss: 1.1527e-04\n",
      "Epoch 36/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 4.6134e-05 - val_loss: 4.2013e-05\n",
      "Epoch 37/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 6.7948e-05 - val_loss: 7.1525e-04\n",
      "Epoch 38/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 4.9877e-05 - val_loss: 8.7446e-05\n",
      "Epoch 39/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 5.1148e-05 - val_loss: 1.3409e-04\n",
      "Epoch 40/50\n",
      "606/606 [==============================] - 14s 24ms/step - loss: 6.8879e-05 - val_loss: 1.1203e-04\n",
      "Epoch 41/50\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 2.4436e-05 - val_loss: 7.5275e-05\n",
      "Epoch 42/50\n",
      "606/606 [==============================] - 14s 23ms/step - loss: 4.4718e-05 - val_loss: 3.2528e-05\n",
      "Epoch 43/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 3.4578e-05 - val_loss: 2.0787e-04\n",
      "Epoch 44/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 1.0326e-04 - val_loss: 2.3041e-04\n",
      "Epoch 45/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 5.2096e-05 - val_loss: 1.7842e-05\n",
      "Epoch 46/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.3882e-05 - val_loss: 7.4505e-05\n",
      "Epoch 47/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 2.3689e-05 - val_loss: 9.3099e-05\n",
      "Epoch 48/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 7.6321e-05 - val_loss: 9.3183e-04\n",
      "Epoch 49/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 6.3942e-05 - val_loss: 4.1695e-05\n",
      "Epoch 50/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 3.4145e-05 - val_loss: 1.6635e-04\n",
      ">p=1: 5, Score=0.008669953240314499\n",
      "Epoch 1/50\n",
      "606/606 [==============================] - 15s 12ms/step - loss: 0.0014 - val_loss: 0.0083\n",
      "Epoch 2/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 7.7715e-04 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 2.8568e-04 - val_loss: 7.2023e-04\n",
      "Epoch 4/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 1.9141e-04 - val_loss: 5.2820e-04\n",
      "Epoch 5/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 1.7269e-04 - val_loss: 7.0441e-04\n",
      "Epoch 6/50\n",
      "606/606 [==============================] - 9s 14ms/step - loss: 1.2846e-04 - val_loss: 4.6354e-04\n",
      "Epoch 7/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 9.5061e-05 - val_loss: 2.0408e-04\n",
      "Epoch 8/50\n",
      "606/606 [==============================] - 9s 15ms/step - loss: 1.0012e-04 - val_loss: 5.9708e-04\n",
      "Epoch 9/50\n",
      "606/606 [==============================] - 9s 16ms/step - loss: 7.2658e-05 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 1.5558e-04 - val_loss: 6.3147e-04\n",
      "Epoch 11/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 9.8101e-05 - val_loss: 0.0020\n",
      "Epoch 12/50\n",
      "606/606 [==============================] - 8s 14ms/step - loss: 1.6213e-04 - val_loss: 2.0400e-04\n",
      "Epoch 13/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 1.0243e-04 - val_loss: 1.9103e-04\n",
      "Epoch 14/50\n",
      "606/606 [==============================] - 9s 15ms/step - loss: 8.9533e-05 - val_loss: 1.1936e-04\n",
      "Epoch 15/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 6.6286e-05 - val_loss: 2.6583e-04\n",
      "Epoch 16/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 6.9290e-05 - val_loss: 2.1960e-04\n",
      "Epoch 17/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.0493e-04 - val_loss: 4.4991e-04\n",
      "Epoch 18/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.1421e-04 - val_loss: 9.3274e-04\n",
      "Epoch 19/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 6.9137e-05 - val_loss: 1.1978e-04\n",
      "Epoch 20/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 6.4634e-05 - val_loss: 2.7943e-04\n",
      "Epoch 21/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 7.9063e-05 - val_loss: 2.9805e-04\n",
      "Epoch 22/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 6.0172e-05 - val_loss: 6.8968e-05\n",
      "Epoch 23/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 6.2650e-05 - val_loss: 1.5902e-04\n",
      "Epoch 24/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 8.9271e-05 - val_loss: 3.3313e-04\n",
      "Epoch 25/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 8.2104e-05 - val_loss: 8.1772e-04\n",
      "Epoch 26/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 3.4951e-05 - val_loss: 1.0472e-04\n",
      "Epoch 27/50\n",
      "606/606 [==============================] - 5s 7ms/step - loss: 3.9108e-05 - val_loss: 7.0199e-05\n",
      "Epoch 28/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 2.7504e-05 - val_loss: 7.2497e-05\n",
      "Epoch 29/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 2.4106e-05 - val_loss: 1.7895e-04\n",
      "Epoch 30/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 9.2696e-05 - val_loss: 3.4943e-04\n",
      "Epoch 31/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 5.5034e-05 - val_loss: 4.4371e-04\n",
      "Epoch 32/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.1355e-04 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 7.9666e-05 - val_loss: 5.4437e-05\n",
      "Epoch 34/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 4.9939e-05 - val_loss: 3.6448e-04\n",
      "Epoch 35/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 4.2053e-05 - val_loss: 2.0095e-04\n",
      "Epoch 36/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 2.0571e-05 - val_loss: 8.5854e-05\n",
      "Epoch 37/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.1430e-05 - val_loss: 1.3963e-04\n",
      "Epoch 38/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.0610e-04 - val_loss: 3.3289e-04\n",
      "Epoch 39/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 7.9527e-05 - val_loss: 2.1356e-04\n",
      "Epoch 40/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 5.5306e-05 - val_loss: 6.5432e-04\n",
      "Epoch 41/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 4.0619e-05 - val_loss: 1.8021e-04\n",
      "Epoch 42/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 3.0408e-05 - val_loss: 1.2183e-04\n",
      "Epoch 43/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 3.0407e-05 - val_loss: 2.1322e-04\n",
      "Epoch 44/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 2.1783e-05 - val_loss: 4.1457e-04\n",
      "Epoch 45/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 4.6889e-05 - val_loss: 9.3009e-05\n",
      "Epoch 46/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 5.3784e-05 - val_loss: 1.2164e-04\n",
      "Epoch 47/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 8.6236e-05 - val_loss: 5.8038e-04\n",
      "Epoch 48/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 1.7569e-05 - val_loss: 3.8329e-04\n",
      "Epoch 49/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.4330e-05 - val_loss: 3.3217e-05\n",
      "Epoch 50/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 8.2288e-05 - val_loss: 2.0572e-04\n",
      ">p=1: 6, Score=0.015825610898900777\n",
      "Epoch 1/50\n",
      "606/606 [==============================] - 14s 11ms/step - loss: 0.0014 - val_loss: 0.0084\n",
      "Epoch 2/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 6.9712e-04 - val_loss: 0.0026\n",
      "Epoch 3/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 2.7215e-04 - val_loss: 9.1130e-04\n",
      "Epoch 4/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.9136e-04 - val_loss: 4.1713e-04\n",
      "Epoch 5/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.9576e-04 - val_loss: 8.9817e-04\n",
      "Epoch 6/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.4512e-04 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 2.3420e-04 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.6421e-04 - val_loss: 3.5480e-04\n",
      "Epoch 9/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.1898e-04 - val_loss: 1.7806e-04\n",
      "Epoch 10/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.0719e-04 - val_loss: 2.5544e-04\n",
      "Epoch 11/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 8.7564e-05 - val_loss: 2.4145e-04\n",
      "Epoch 12/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 1.0218e-04 - val_loss: 4.4653e-04\n",
      "Epoch 13/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.2169e-04 - val_loss: 6.1621e-04\n",
      "Epoch 14/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.4760e-04 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 9.0588e-05 - val_loss: 8.5089e-05\n",
      "Epoch 16/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 5.8598e-05 - val_loss: 4.2061e-04\n",
      "Epoch 17/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.0003e-04 - val_loss: 0.0012\n",
      "Epoch 18/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 6.1681e-05 - val_loss: 6.7699e-05\n",
      "Epoch 19/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 4.5750e-05 - val_loss: 1.9303e-04\n",
      "Epoch 20/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.0435e-04 - val_loss: 3.0789e-04\n",
      "Epoch 21/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.0310e-05 - val_loss: 1.1768e-04\n",
      "Epoch 22/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.0989e-05 - val_loss: 5.6256e-05\n",
      "Epoch 23/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 8.5555e-05 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 7.1104e-05 - val_loss: 1.2715e-04\n",
      "Epoch 25/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.0418e-04 - val_loss: 5.3007e-04\n",
      "Epoch 26/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.8010e-05 - val_loss: 2.6036e-04\n",
      "Epoch 27/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 4.6793e-05 - val_loss: 5.7005e-05\n",
      "Epoch 28/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 2.6465e-05 - val_loss: 3.9362e-05\n",
      "Epoch 29/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 3.9523e-05 - val_loss: 8.7211e-05\n",
      "Epoch 30/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 1.0470e-04 - val_loss: 7.3168e-05\n",
      "Epoch 31/50\n",
      "606/606 [==============================] - 8s 12ms/step - loss: 8.2424e-05 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 5.8325e-05 - val_loss: 7.5444e-05\n",
      "Epoch 33/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 5.8287e-05 - val_loss: 3.7883e-04\n",
      "Epoch 34/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 4.1860e-05 - val_loss: 1.5614e-04\n",
      "Epoch 35/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 7.0155e-05 - val_loss: 9.5581e-05\n",
      "Epoch 36/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 1.0780e-04 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 5.2219e-05 - val_loss: 1.0099e-04\n",
      "Epoch 38/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 5.6922e-05 - val_loss: 1.3599e-04\n",
      "Epoch 39/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 2.9298e-05 - val_loss: 2.0175e-04\n",
      "Epoch 40/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 2.9674e-05 - val_loss: 4.7363e-05\n",
      "Epoch 41/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.9707e-05 - val_loss: 6.5284e-05\n",
      "Epoch 42/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 5.1392e-05 - val_loss: 3.2964e-04\n",
      "Epoch 43/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 6.6377e-05 - val_loss: 0.0012\n",
      "Epoch 44/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 3.6532e-05 - val_loss: 1.8295e-04\n",
      "Epoch 45/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.5242e-05 - val_loss: 3.6953e-05\n",
      "Epoch 46/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.0103e-04 - val_loss: 9.1835e-05\n",
      "Epoch 47/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 3.6844e-05 - val_loss: 1.9170e-05\n",
      "Epoch 48/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 2.8287e-05 - val_loss: 4.1352e-05\n",
      "Epoch 49/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 2.4214e-05 - val_loss: 6.1883e-05\n",
      "Epoch 50/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 3.5109e-05 - val_loss: 9.5850e-05\n",
      ">p=1: 7, Score=0.005411266829469241\n",
      "Epoch 1/50\n",
      "606/606 [==============================] - 12s 9ms/step - loss: 0.0015 - val_loss: 0.0084\n",
      "Epoch 2/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.5539e-04 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.3297e-04 - val_loss: 6.2394e-04\n",
      "Epoch 4/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.4619e-04 - val_loss: 2.5998e-04\n",
      "Epoch 5/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.5311e-04 - val_loss: 6.8825e-04\n",
      "Epoch 6/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.4030e-04 - val_loss: 4.4217e-04\n",
      "Epoch 7/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 8.4243e-05 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.2853e-04 - val_loss: 3.0183e-04\n",
      "Epoch 9/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 9.9907e-05 - val_loss: 1.3771e-04\n",
      "Epoch 10/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 1.3494e-04 - val_loss: 6.9848e-04\n",
      "Epoch 11/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 1.5079e-04 - val_loss: 5.2346e-04\n",
      "Epoch 12/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 1.2692e-04 - val_loss: 3.6360e-04\n",
      "Epoch 13/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 2.1769e-04 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.6451e-04 - val_loss: 7.4736e-04\n",
      "Epoch 15/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.2465e-05 - val_loss: 4.9365e-04\n",
      "Epoch 16/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 5.5761e-05 - val_loss: 2.6720e-04\n",
      "Epoch 17/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 4.9438e-05 - val_loss: 5.3645e-04\n",
      "Epoch 18/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 7.9097e-05 - val_loss: 4.1056e-04\n",
      "Epoch 19/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 1.9697e-04 - val_loss: 0.0013\n",
      "Epoch 20/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 9.9345e-05 - val_loss: 3.8599e-04\n",
      "Epoch 21/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 5.0873e-05 - val_loss: 1.5915e-04\n",
      "Epoch 22/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 6.4153e-05 - val_loss: 4.6609e-04\n",
      "Epoch 23/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 4.3602e-05 - val_loss: 2.4287e-04\n",
      "Epoch 24/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.8405e-05 - val_loss: 2.9425e-04\n",
      "Epoch 25/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 4.9319e-05 - val_loss: 1.0619e-04\n",
      "Epoch 26/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 6.2161e-05 - val_loss: 4.1385e-04\n",
      "Epoch 27/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 5.4749e-05 - val_loss: 3.9928e-04\n",
      "Epoch 28/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 1.2373e-04 - val_loss: 9.7768e-05\n",
      "Epoch 29/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 9.6827e-05 - val_loss: 2.1242e-04\n",
      "Epoch 30/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 4.8898e-05 - val_loss: 2.7851e-04\n",
      "Epoch 31/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 5.9956e-05 - val_loss: 2.7701e-04\n",
      "Epoch 32/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 1.9560e-05 - val_loss: 4.9199e-04\n",
      "Epoch 33/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 9.6034e-05 - val_loss: 6.7825e-05\n",
      "Epoch 34/50\n",
      "606/606 [==============================] - 6s 9ms/step - loss: 1.8426e-04 - val_loss: 0.0019\n",
      "Epoch 35/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 9.6086e-05 - val_loss: 4.5098e-05\n",
      "Epoch 36/50\n",
      "606/606 [==============================] - 5s 9ms/step - loss: 3.4538e-05 - val_loss: 1.5207e-04\n",
      "Epoch 37/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 5.9112e-05 - val_loss: 1.8451e-04\n",
      "Epoch 38/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 3.3145e-05 - val_loss: 1.1549e-04\n",
      "Epoch 39/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 5.5304e-05 - val_loss: 5.5679e-04\n",
      "Epoch 40/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 9.9784e-05 - val_loss: 5.6481e-04\n",
      "Epoch 41/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 3.7055e-05 - val_loss: 1.3819e-04\n",
      "Epoch 42/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 4.6280e-05 - val_loss: 1.7157e-04\n",
      "Epoch 43/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 3.9496e-05 - val_loss: 9.7556e-05\n",
      "Epoch 44/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 4.3133e-05 - val_loss: 1.7735e-04\n",
      "Epoch 45/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 3.1551e-05 - val_loss: 2.3971e-04\n",
      "Epoch 46/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 2.1487e-05 - val_loss: 7.4018e-05\n",
      "Epoch 47/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 8.0314e-05 - val_loss: 4.1352e-04\n",
      "Epoch 48/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 7.6767e-05 - val_loss: 7.3998e-04\n",
      "Epoch 49/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 3.5563e-05 - val_loss: 2.9036e-05\n",
      "Epoch 50/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 3.9704e-05 - val_loss: 6.1549e-05\n",
      ">p=1: 8, Score=0.010416479199193418\n",
      "Epoch 1/50\n",
      "606/606 [==============================] - 18s 15ms/step - loss: 0.0014 - val_loss: 0.0085\n",
      "Epoch 2/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 6.6063e-04 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 3.3393e-04 - val_loss: 0.0011\n",
      "Epoch 4/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 1.3464e-04 - val_loss: 5.1151e-04\n",
      "Epoch 5/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 1.5806e-04 - val_loss: 4.7459e-04\n",
      "Epoch 6/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.0886e-04 - val_loss: 4.3886e-04\n",
      "Epoch 7/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.1974e-04 - val_loss: 2.4977e-04\n",
      "Epoch 8/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 1.7387e-04 - val_loss: 8.5234e-04\n",
      "Epoch 9/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.2265e-04 - val_loss: 3.1777e-04\n",
      "Epoch 10/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 1.4288e-04 - val_loss: 3.5421e-04\n",
      "Epoch 11/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 1.1041e-04 - val_loss: 3.3877e-04\n",
      "Epoch 12/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 1.0365e-04 - val_loss: 3.6095e-04\n",
      "Epoch 13/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 7.0902e-05 - val_loss: 1.2491e-04\n",
      "Epoch 14/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 8.6968e-05 - val_loss: 4.1803e-04\n",
      "Epoch 15/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 9.2735e-05 - val_loss: 3.9143e-04\n",
      "Epoch 16/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 1.3353e-04 - val_loss: 2.8957e-04\n",
      "Epoch 17/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 5.9219e-05 - val_loss: 5.6763e-04\n",
      "Epoch 18/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 8.3061e-05 - val_loss: 1.3234e-04\n",
      "Epoch 19/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 5.8429e-05 - val_loss: 1.2984e-04\n",
      "Epoch 20/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 7.1891e-05 - val_loss: 2.8699e-04\n",
      "Epoch 21/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 6.3574e-05 - val_loss: 3.6898e-04\n",
      "Epoch 22/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 8.9791e-05 - val_loss: 2.5143e-04\n",
      "Epoch 23/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 5.6267e-05 - val_loss: 6.1532e-04\n",
      "Epoch 24/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 5.2394e-05 - val_loss: 4.1897e-05\n",
      "Epoch 25/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 3.7449e-05 - val_loss: 6.5438e-05\n",
      "Epoch 26/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 7.7984e-05 - val_loss: 2.6614e-04\n",
      "Epoch 27/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 9.9953e-05 - val_loss: 7.1211e-04\n",
      "Epoch 28/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 1.1243e-04 - val_loss: 3.6223e-04\n",
      "Epoch 29/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 3.9885e-05 - val_loss: 1.6770e-04\n",
      "Epoch 30/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 6.0678e-05 - val_loss: 2.0311e-04\n",
      "Epoch 31/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 5.1507e-05 - val_loss: 7.6468e-05\n",
      "Epoch 32/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 3.8389e-05 - val_loss: 7.5461e-05\n",
      "Epoch 33/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 8.4618e-05 - val_loss: 2.8718e-04\n",
      "Epoch 34/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 8.9212e-05 - val_loss: 8.7918e-04\n",
      "Epoch 35/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 9.6866e-05 - val_loss: 3.3259e-04\n",
      "Epoch 36/50\n",
      "606/606 [==============================] - 7s 12ms/step - loss: 3.5088e-05 - val_loss: 5.1802e-04\n",
      "Epoch 37/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 8.7366e-05 - val_loss: 2.4117e-04\n",
      "Epoch 38/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 3.2346e-05 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 6.6999e-05 - val_loss: 7.0882e-04\n",
      "Epoch 40/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 6.5784e-05 - val_loss: 8.2071e-04\n",
      "Epoch 41/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 7.4854e-05 - val_loss: 4.7735e-04\n",
      "Epoch 42/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 8.1368e-05 - val_loss: 1.7786e-04\n",
      "Epoch 43/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 4.0800e-05 - val_loss: 4.7111e-04\n",
      "Epoch 44/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 5.4153e-05 - val_loss: 5.4569e-04\n",
      "Epoch 45/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 5.6736e-05 - val_loss: 1.5294e-04\n",
      "Epoch 46/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 9.0161e-05 - val_loss: 9.0120e-04\n",
      "Epoch 47/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 4.6155e-05 - val_loss: 9.5427e-05\n",
      "Epoch 48/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 1.7865e-05 - val_loss: 4.8229e-05\n",
      "Epoch 49/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 3.9691e-05 - val_loss: 8.6437e-05\n",
      "Epoch 50/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 2.5007e-05 - val_loss: 2.7002e-04\n",
      ">p=1: 9, Score=0.021938770078122616\n",
      "Epoch 1/50\n",
      "606/606 [==============================] - 15s 10ms/step - loss: 0.0015 - val_loss: 0.0090\n",
      "Epoch 2/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 7.5341e-04 - val_loss: 0.0035\n",
      "Epoch 3/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 3.2719e-04 - val_loss: 7.0303e-04\n",
      "Epoch 4/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 1.4303e-04 - val_loss: 5.8394e-04\n",
      "Epoch 5/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.1410e-04 - val_loss: 4.2219e-04\n",
      "Epoch 6/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.1431e-04 - val_loss: 2.2979e-04\n",
      "Epoch 7/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 1.0484e-04 - val_loss: 6.6241e-04\n",
      "Epoch 8/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.0900e-04 - val_loss: 8.9746e-04\n",
      "Epoch 9/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.2521e-04 - val_loss: 3.4450e-04\n",
      "Epoch 10/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.6996e-04 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.1217e-04 - val_loss: 6.6877e-05\n",
      "Epoch 12/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 4.5603e-05 - val_loss: 1.3167e-04\n",
      "Epoch 13/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.0292e-04 - val_loss: 3.5428e-04\n",
      "Epoch 14/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 6.9654e-05 - val_loss: 1.6225e-04\n",
      "Epoch 15/50\n",
      "606/606 [==============================] - 6s 11ms/step - loss: 1.4962e-04 - val_loss: 6.5273e-04\n",
      "Epoch 16/50\n",
      "606/606 [==============================] - 7s 11ms/step - loss: 1.6987e-04 - val_loss: 4.9155e-04\n",
      "Epoch 17/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.5488e-04 - val_loss: 9.5867e-04\n",
      "Epoch 18/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.7196e-04 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "606/606 [==============================] - 6s 10ms/step - loss: 1.3077e-04 - val_loss: 7.3343e-04\n",
      "Epoch 20/50\n",
      "606/606 [==============================] - 8s 13ms/step - loss: 6.3741e-05 - val_loss: 1.4172e-04\n",
      "Epoch 21/50\n",
      "606/606 [==============================] - 10s 16ms/step - loss: 2.7385e-05 - val_loss: 4.4239e-04\n",
      "Epoch 22/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 5.2224e-05 - val_loss: 4.7329e-04\n",
      "Epoch 23/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 4.3466e-05 - val_loss: 1.1977e-04\n",
      "Epoch 24/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.3262e-04 - val_loss: 1.3743e-04\n",
      "Epoch 25/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 4.4530e-05 - val_loss: 2.3005e-04\n",
      "Epoch 26/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 9.8775e-05 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 7.5755e-05 - val_loss: 4.7972e-04\n",
      "Epoch 28/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 3.6465e-05 - val_loss: 3.8273e-05\n",
      "Epoch 29/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 4.8478e-05 - val_loss: 1.4738e-04\n",
      "Epoch 30/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 5.4362e-05 - val_loss: 2.8955e-04\n",
      "Epoch 31/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 8.0032e-05 - val_loss: 6.7890e-04\n",
      "Epoch 32/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.1263e-04 - val_loss: 4.6631e-04\n",
      "Epoch 33/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.7573e-05 - val_loss: 1.6331e-04\n",
      "Epoch 34/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.3141e-05 - val_loss: 7.9909e-05\n",
      "Epoch 35/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 3.6536e-05 - val_loss: 1.0653e-04\n",
      "Epoch 36/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 4.9519e-05 - val_loss: 1.7867e-04\n",
      "Epoch 37/50\n",
      "606/606 [==============================] - 5s 8ms/step - loss: 5.4636e-05 - val_loss: 8.3301e-04\n",
      "Epoch 38/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 6.7788e-05 - val_loss: 2.8228e-04\n",
      "Epoch 39/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 4.6327e-05 - val_loss: 2.5895e-04\n",
      "Epoch 40/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.0856e-05 - val_loss: 4.4906e-05\n",
      "Epoch 41/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 1.0701e-04 - val_loss: 4.8881e-04\n",
      "Epoch 42/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.7463e-05 - val_loss: 6.5610e-05\n",
      "Epoch 43/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 8.2085e-05 - val_loss: 2.4669e-04\n",
      "Epoch 44/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 5.6854e-05 - val_loss: 2.1309e-04\n",
      "Epoch 45/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 5.0695e-05 - val_loss: 3.7760e-04\n",
      "Epoch 46/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 5.2262e-05 - val_loss: 7.0641e-04\n",
      "Epoch 47/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 7.2231e-05 - val_loss: 4.1219e-04\n",
      "Epoch 48/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 3.1558e-05 - val_loss: 2.1739e-04\n",
      "Epoch 49/50\n",
      "606/606 [==============================] - 4s 7ms/step - loss: 3.2691e-05 - val_loss: 2.3218e-04\n",
      "Epoch 50/50\n",
      "606/606 [==============================] - 4s 6ms/step - loss: 5.3383e-05 - val_loss: 1.7083e-04\n",
      ">p=1: 10, Score=0.013794367259833962\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 10s 13ms/step - loss: 0.0015 - val_loss: 0.0085\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.8613e-04 - val_loss: 0.0048\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5007e-04 - val_loss: 0.0016\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4302e-04 - val_loss: 5.3513e-04\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 2.0202e-04 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8994e-04 - val_loss: 6.2085e-04\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0717e-04 - val_loss: 6.6509e-04\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 7.3200e-05 - val_loss: 2.6721e-04\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0274e-04 - val_loss: 3.2525e-04\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8412e-04 - val_loss: 0.0011\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0322e-04 - val_loss: 5.5389e-04\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.2400e-05 - val_loss: 1.8927e-04\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 8.1752e-05 - val_loss: 4.7276e-04\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.4530e-05 - val_loss: 1.9344e-04\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.0694e-05 - val_loss: 3.1557e-04\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 9.3603e-05 - val_loss: 6.1496e-04\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1648e-04 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3482e-04 - val_loss: 6.0835e-04\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.0732e-05 - val_loss: 2.3552e-04\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.2727e-05 - val_loss: 4.1112e-04\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.8368e-05 - val_loss: 8.1412e-04\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0358e-04 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.2955e-05 - val_loss: 2.7336e-04\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.2833e-05 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.9538e-05 - val_loss: 7.3102e-04\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2251e-05 - val_loss: 1.0524e-04\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.0154e-05 - val_loss: 1.8302e-04\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.2833e-05 - val_loss: 1.2998e-04\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.1990e-05 - val_loss: 6.2471e-04\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4109e-05 - val_loss: 1.6807e-04\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7473e-05 - val_loss: 1.8957e-04\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6884e-05 - val_loss: 1.5109e-04\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3023e-05 - val_loss: 2.2489e-04\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.8660e-05 - val_loss: 2.5675e-04\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4735e-05 - val_loss: 2.0188e-04\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.6829e-05 - val_loss: 0.0014\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.8240e-05 - val_loss: 2.0427e-04\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.6151e-05 - val_loss: 8.4012e-05\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0858e-05 - val_loss: 1.1440e-04\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0568e-05 - val_loss: 7.4967e-05\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.0095e-05 - val_loss: 1.6861e-04\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.2909e-05 - val_loss: 1.8242e-04\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2580e-04 - val_loss: 0.0023\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.9249e-05 - val_loss: 1.9908e-04\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4474e-05 - val_loss: 1.8706e-04\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9614e-05 - val_loss: 3.0163e-05\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9175e-05 - val_loss: 1.2161e-04\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0767e-05 - val_loss: 5.3751e-04\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7562e-05 - val_loss: 5.3860e-04\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8528e-05 - val_loss: 1.1960e-04\n",
      ">p=2: 1, Score=0.009924157347995788\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 11s 13ms/step - loss: 0.0016 - val_loss: 0.0082\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.8397e-04 - val_loss: 0.0036\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9578e-04 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7090e-04 - val_loss: 3.3734e-04\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4732e-04 - val_loss: 5.8863e-04\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7037e-04 - val_loss: 8.6321e-04\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8448e-04 - val_loss: 7.5802e-04\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4118e-04 - val_loss: 4.2526e-04\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.2178e-05 - val_loss: 9.5824e-04\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9645e-05 - val_loss: 3.4898e-04\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.8526e-05 - val_loss: 4.3132e-04\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 9.0176e-05 - val_loss: 9.2053e-04\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.1532e-05 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7902e-05 - val_loss: 4.8250e-04\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1563e-04 - val_loss: 9.8528e-04\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.5310e-05 - val_loss: 3.1628e-04\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2660e-04 - val_loss: 0.0018\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1334e-04 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.6844e-05 - val_loss: 3.7341e-04\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.2966e-05 - val_loss: 8.0311e-04\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.0342e-05 - val_loss: 1.8738e-04\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9149e-05 - val_loss: 6.0904e-04\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.1798e-05 - val_loss: 6.5948e-05\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1647e-04 - val_loss: 0.0019\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.5085e-05 - val_loss: 1.4063e-04\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.7265e-05 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.5690e-05 - val_loss: 1.0508e-04\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7552e-05 - val_loss: 6.4421e-05\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.3881e-05 - val_loss: 4.6654e-04\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.0282e-05 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.0373e-05 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 3s 10ms/step - loss: 5.1575e-05 - val_loss: 4.3318e-04\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 3.4500e-05 - val_loss: 5.8987e-04\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 5.4789e-05 - val_loss: 2.0829e-04\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 4.5882e-05 - val_loss: 2.1588e-04\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 7.1448e-05 - val_loss: 1.0432e-04\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 3s 10ms/step - loss: 4.8270e-05 - val_loss: 9.7395e-05\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 4.2656e-05 - val_loss: 7.3461e-05\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.2216e-05 - val_loss: 1.3239e-04\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0459e-05 - val_loss: 5.3038e-04\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.5478e-05 - val_loss: 9.3863e-05\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.1498e-05 - val_loss: 1.2438e-04\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4079e-05 - val_loss: 2.1612e-05\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0679e-04 - val_loss: 0.0030\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.3863e-05 - val_loss: 2.1666e-05\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6815e-05 - val_loss: 2.4909e-04\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6312e-05 - val_loss: 1.3088e-04\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.2623e-05 - val_loss: 8.3520e-05\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4207e-05 - val_loss: 4.7047e-05\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3918e-05 - val_loss: 2.3906e-05\n",
      ">p=2: 2, Score=0.003904810728272423\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 10s 13ms/step - loss: 0.0017 - val_loss: 0.0094\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.4038e-04 - val_loss: 0.0047\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7280e-04 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0635e-04 - val_loss: 5.9124e-04\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1066e-04 - val_loss: 5.3881e-04\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0638e-04 - val_loss: 3.7653e-04\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4257e-04 - val_loss: 5.9683e-04\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0585e-04 - val_loss: 2.9033e-04\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 9.3788e-05 - val_loss: 3.6984e-04\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6531e-04 - val_loss: 8.4043e-04\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2168e-04 - val_loss: 2.4456e-04\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.5837e-05 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.0035e-05 - val_loss: 2.6419e-04\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.2423e-05 - val_loss: 1.6614e-04\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.4303e-05 - val_loss: 3.5178e-04\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.3136e-05 - val_loss: 5.4498e-04\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1579e-05 - val_loss: 9.0503e-05\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.0580e-05 - val_loss: 3.4160e-04\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.2106e-05 - val_loss: 4.2225e-04\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.6867e-05 - val_loss: 1.0024e-04\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2079e-05 - val_loss: 4.5841e-04\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1599e-05 - val_loss: 1.0529e-04\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4466e-04 - val_loss: 0.0030\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2522e-04 - val_loss: 9.3522e-05\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3077e-05 - val_loss: 1.4806e-04\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3195e-05 - val_loss: 4.8046e-05\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6386e-05 - val_loss: 6.9337e-04\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7111e-05 - val_loss: 1.6561e-04\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0635e-05 - val_loss: 1.3229e-04\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.7716e-05 - val_loss: 1.2891e-04\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3016e-05 - val_loss: 8.1267e-05\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5581e-05 - val_loss: 1.4346e-04\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.7572e-05 - val_loss: 2.2308e-04\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1237e-05 - val_loss: 1.9194e-04\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.8714e-05 - val_loss: 3.7176e-04\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7017e-05 - val_loss: 4.3274e-04\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4077e-05 - val_loss: 5.1974e-05\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3016e-05 - val_loss: 6.3595e-05\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5159e-05 - val_loss: 8.9586e-05\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4264e-04 - val_loss: 0.0032\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0202e-04 - val_loss: 3.0661e-05\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0210e-05 - val_loss: 7.4176e-05\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2491e-05 - val_loss: 2.2980e-04\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6552e-05 - val_loss: 3.9467e-04\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8798e-05 - val_loss: 7.3847e-05\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.8740e-05 - val_loss: 1.6686e-04\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.9248e-05 - val_loss: 5.7578e-05\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6176e-05 - val_loss: 3.5876e-05\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9781e-05 - val_loss: 1.0755e-04\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9863e-05 - val_loss: 1.4492e-04\n",
      ">p=2: 3, Score=0.008580950088799\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 10s 11ms/step - loss: 0.0016 - val_loss: 0.0091\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.7026e-04 - val_loss: 0.0051\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0242e-04 - val_loss: 0.0017\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.5748e-04 - val_loss: 8.8450e-04\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9259e-04 - val_loss: 6.6347e-04\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2127e-04 - val_loss: 3.4018e-04\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5521e-04 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2872e-04 - val_loss: 3.3397e-04\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0073e-04 - val_loss: 3.8643e-04\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1431e-04 - val_loss: 4.7447e-04\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.3328e-05 - val_loss: 2.4034e-04\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.5905e-05 - val_loss: 4.7482e-04\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9684e-05 - val_loss: 5.3016e-04\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.0036e-05 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.3972e-05 - val_loss: 2.1820e-04\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7819e-05 - val_loss: 1.3431e-04\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0920e-04 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0779e-04 - val_loss: 3.8918e-04\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.5834e-05 - val_loss: 3.0607e-04\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0568e-04 - val_loss: 7.7504e-05\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5489e-05 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 5.5453e-05 - val_loss: 3.4800e-04\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5507e-05 - val_loss: 1.6082e-04\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.2171e-05 - val_loss: 8.5183e-04\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9813e-05 - val_loss: 6.1136e-05\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9964e-05 - val_loss: 1.0149e-04\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0020e-05 - val_loss: 4.9352e-04\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5633e-05 - val_loss: 1.1645e-04\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0791e-05 - val_loss: 4.8863e-04\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.0343e-05 - val_loss: 1.6633e-04\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.1815e-05 - val_loss: 1.0363e-04\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4641e-05 - val_loss: 2.0594e-04\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1207e-04 - val_loss: 2.0582e-04\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3164e-05 - val_loss: 1.8780e-04\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0527e-05 - val_loss: 5.7678e-05\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7856e-04 - val_loss: 3.8052e-04\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5788e-05 - val_loss: 1.1279e-04\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8962e-05 - val_loss: 3.1120e-05\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0436e-04 - val_loss: 0.0030\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.9712e-05 - val_loss: 3.1147e-04\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2922e-05 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6921e-05 - val_loss: 4.9859e-04\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0123e-05 - val_loss: 6.8295e-05\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0494e-05 - val_loss: 1.9491e-05\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6313e-05 - val_loss: 3.6320e-05\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9441e-05 - val_loss: 1.7645e-04\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2138e-05 - val_loss: 6.6089e-04\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4000e-05 - val_loss: 3.1168e-04\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9446e-05 - val_loss: 7.3691e-05\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4134e-05 - val_loss: 7.1371e-04\n",
      ">p=2: 4, Score=0.03764419234357774\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 11s 13ms/step - loss: 0.0016 - val_loss: 0.0085\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.4645e-04 - val_loss: 0.0039\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5622e-04 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3618e-04 - val_loss: 9.6089e-04\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5224e-04 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2379e-04 - val_loss: 8.2553e-04\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1143e-04 - val_loss: 3.3549e-04\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.4013e-05 - val_loss: 8.9642e-04\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0665e-04 - val_loss: 7.7631e-04\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5155e-04 - val_loss: 0.0011\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2235e-04 - val_loss: 4.1881e-04\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.7055e-05 - val_loss: 1.1711e-04\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.4084e-05 - val_loss: 3.0679e-04\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 4.9691e-05 - val_loss: 1.6625e-04\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.0668e-05 - val_loss: 4.9173e-04\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3364e-04 - val_loss: 0.0027\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3965e-04 - val_loss: 4.5741e-04\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.0063e-05 - val_loss: 3.1298e-04\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.6397e-05 - val_loss: 3.4899e-04\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1516e-05 - val_loss: 4.5031e-04\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9424e-05 - val_loss: 2.4908e-04\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1246e-05 - val_loss: 8.2169e-05\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9808e-05 - val_loss: 8.5293e-04\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.1465e-05 - val_loss: 9.5953e-05\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6192e-05 - val_loss: 5.5294e-05\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1427e-05 - val_loss: 2.0238e-04\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.6636e-05 - val_loss: 2.2769e-04\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 9.4815e-05 - val_loss: 0.0023\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.4992e-05 - val_loss: 1.6558e-04\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.6991e-05 - val_loss: 2.2897e-04\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.2563e-05 - val_loss: 7.7561e-04\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.1984e-05 - val_loss: 1.8366e-04\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.5825e-05 - val_loss: 2.4799e-04\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.7528e-05 - val_loss: 1.1255e-04\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.2341e-05 - val_loss: 6.4918e-05\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.2574e-05 - val_loss: 8.0868e-05\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.5460e-05 - val_loss: 8.2032e-05\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.5606e-05 - val_loss: 1.4929e-05\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.1726e-05 - val_loss: 3.0742e-04\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7141e-05 - val_loss: 1.0055e-04\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.2785e-05 - val_loss: 3.8982e-05\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.4146e-05 - val_loss: 2.3534e-04\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0411e-05 - val_loss: 1.3354e-04\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.5611e-05 - val_loss: 2.9554e-04\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7494e-05 - val_loss: 1.9007e-05\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 9.9288e-06 - val_loss: 5.6543e-05\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0756e-05 - val_loss: 2.6860e-05\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.1266e-05 - val_loss: 1.9821e-04\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8851e-05 - val_loss: 3.2140e-05\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3786e-05 - val_loss: 1.1389e-04\n",
      ">p=2: 5, Score=0.010821628529811278\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 11s 14ms/step - loss: 0.0016 - val_loss: 0.0088\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.4120e-04 - val_loss: 0.0049\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.5583e-04 - val_loss: 0.0017\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3341e-04 - val_loss: 0.0022\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3517e-04 - val_loss: 5.1008e-04\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 9.2742e-05 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.9482e-05 - val_loss: 2.1189e-04\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3545e-04 - val_loss: 8.8112e-04\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0413e-04 - val_loss: 6.7708e-04\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3361e-04 - val_loss: 7.3069e-04\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0725e-04 - val_loss: 2.7122e-04\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.7829e-05 - val_loss: 3.5783e-04\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1118e-04 - val_loss: 0.0010\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2204e-04 - val_loss: 2.4776e-04\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2257e-04 - val_loss: 8.7641e-04\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.7187e-05 - val_loss: 2.1062e-04\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.2157e-05 - val_loss: 2.5196e-04\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.9416e-05 - val_loss: 1.0425e-04\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.6293e-05 - val_loss: 2.8616e-04\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.3789e-05 - val_loss: 3.9055e-04\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3568e-05 - val_loss: 1.8987e-04\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7298e-05 - val_loss: 9.0235e-05\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.9969e-05 - val_loss: 3.1174e-04\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0379e-04 - val_loss: 0.0026\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1642e-04 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.8128e-05 - val_loss: 5.4151e-05\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.6421e-05 - val_loss: 3.7896e-04\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.3274e-05 - val_loss: 5.2976e-05\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.6340e-05 - val_loss: 1.2756e-04\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.5456e-05 - val_loss: 9.9360e-04\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.6839e-05 - val_loss: 0.0017\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6263e-05 - val_loss: 2.2437e-04\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5473e-05 - val_loss: 1.3050e-04\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3709e-05 - val_loss: 1.2228e-04\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9026e-05 - val_loss: 6.3566e-05\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.3505e-05 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.0511e-05 - val_loss: 1.1129e-04\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6047e-05 - val_loss: 7.8261e-05\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5894e-05 - val_loss: 9.7408e-04\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9163e-05 - val_loss: 3.1439e-04\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9406e-05 - val_loss: 6.6339e-04\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.7838e-05 - val_loss: 1.2666e-04\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9402e-05 - val_loss: 8.3843e-05\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6782e-05 - val_loss: 5.9665e-05\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6066e-05 - val_loss: 1.7438e-04\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9179e-05 - val_loss: 3.7173e-04\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8505e-05 - val_loss: 2.8819e-04\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.0055e-05 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2428e-05 - val_loss: 6.6852e-05\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4813e-05 - val_loss: 1.5848e-04\n",
      ">p=2: 6, Score=0.01654985098866746\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 11s 12ms/step - loss: 0.0018 - val_loss: 0.0097\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.7952e-04 - val_loss: 0.0055\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.8220e-04 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1332e-04 - val_loss: 7.0651e-04\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3378e-04 - val_loss: 1.5616e-04\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.3818e-05 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2104e-04 - val_loss: 3.8206e-04\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1314e-04 - val_loss: 0.0021\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.7286e-05 - val_loss: 3.3257e-04\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.3891e-05 - val_loss: 0.0011\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.5798e-05 - val_loss: 0.0026\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.3652e-05 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6638e-04 - val_loss: 0.0034\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4865e-04 - val_loss: 2.0068e-04\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.1178e-05 - val_loss: 2.4985e-04\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1324e-05 - val_loss: 1.3772e-04\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.4231e-05 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.4194e-05 - val_loss: 1.7617e-04\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.3202e-05 - val_loss: 2.1498e-04\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.4426e-05 - val_loss: 2.3046e-04\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1354e-04 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0511e-04 - val_loss: 2.1697e-04\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.8331e-05 - val_loss: 6.2210e-05\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.6390e-05 - val_loss: 4.8638e-04\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7965e-05 - val_loss: 6.5690e-05\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6500e-05 - val_loss: 4.7587e-05\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3930e-05 - val_loss: 4.6403e-04\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4141e-05 - val_loss: 1.1961e-04\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4896e-05 - val_loss: 5.1433e-04\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.4942e-05 - val_loss: 2.1731e-04\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1378e-05 - val_loss: 1.7193e-04\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.4136e-05 - val_loss: 5.3706e-04\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 4.3581e-05 - val_loss: 3.2128e-04\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 8.9214e-05 - val_loss: 3.6717e-04\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.9884e-05 - val_loss: 1.0607e-04\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.9664e-05 - val_loss: 3.0415e-04\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.8782e-05 - val_loss: 3.1080e-04\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.6536e-05 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6756e-05 - val_loss: 5.5646e-04\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5220e-05 - val_loss: 1.2896e-04\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6787e-05 - val_loss: 1.1972e-04\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9896e-05 - val_loss: 2.7103e-04\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4119e-05 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.6691e-05 - val_loss: 1.5453e-04\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9488e-05 - val_loss: 4.4872e-04\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.5830e-05 - val_loss: 6.4911e-05\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7087e-05 - val_loss: 1.5873e-05\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.8102e-05 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3430e-05 - val_loss: 1.6940e-04\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7221e-05 - val_loss: 7.7222e-05\n",
      ">p=2: 7, Score=0.008360658102901652\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 10s 13ms/step - loss: 0.0017 - val_loss: 0.0096\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.4015e-04 - val_loss: 0.0046\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.4702e-04 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9559e-04 - val_loss: 3.6232e-04\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2156e-04 - val_loss: 9.9986e-04\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.3848e-04 - val_loss: 3.5018e-04\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.5979e-05 - val_loss: 8.3941e-04\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.3096e-05 - val_loss: 9.6052e-04\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5982e-04 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5196e-04 - val_loss: 3.5948e-04\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.4744e-05 - val_loss: 8.3247e-04\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1793e-04 - val_loss: 6.2713e-04\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1124e-04 - val_loss: 2.2386e-04\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.2050e-05 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.7282e-05 - val_loss: 6.7052e-04\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4872e-04 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2196e-04 - val_loss: 1.3526e-04\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 6.2484e-05 - val_loss: 6.6980e-04\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.7957e-05 - val_loss: 4.2664e-04\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 7.8628e-05 - val_loss: 4.2785e-04\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 9.7305e-05 - val_loss: 9.7832e-04\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.9630e-05 - val_loss: 2.9465e-04\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.4858e-05 - val_loss: 6.4209e-05\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4079e-05 - val_loss: 1.8759e-04\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5376e-05 - val_loss: 1.1361e-04\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8376e-05 - val_loss: 4.4638e-04\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.9647e-05 - val_loss: 3.7773e-04\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8585e-05 - val_loss: 9.9957e-05\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.0758e-05 - val_loss: 1.6646e-04\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4434e-05 - val_loss: 2.9627e-04\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9108e-05 - val_loss: 1.2016e-04\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3580e-05 - val_loss: 7.4124e-05\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8482e-05 - val_loss: 1.4539e-04\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5306e-05 - val_loss: 1.3937e-04\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.1977e-05 - val_loss: 5.0126e-05\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.1736e-05 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.4157e-05 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5947e-05 - val_loss: 2.9077e-04\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0388e-05 - val_loss: 1.9097e-04\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.7243e-05 - val_loss: 8.7558e-05\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5066e-05 - val_loss: 8.7235e-04\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2083e-05 - val_loss: 2.6757e-04\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9001e-05 - val_loss: 0.0012\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6048e-05 - val_loss: 1.0826e-04\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0558e-05 - val_loss: 1.5328e-04\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1849e-05 - val_loss: 7.1433e-05\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5708e-05 - val_loss: 2.7114e-04\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6486e-05 - val_loss: 7.9227e-05\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0903e-04 - val_loss: 1.2046e-04\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7619e-05 - val_loss: 1.4668e-04\n",
      ">p=2: 8, Score=0.006532988481922075\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 10s 12ms/step - loss: 0.0017 - val_loss: 0.0090\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.1277e-04 - val_loss: 0.0048\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5126e-04 - val_loss: 0.0016\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 2.2305e-04 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1572e-04 - val_loss: 3.2553e-04\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1315e-04 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7019e-04 - val_loss: 1.9647e-04\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5519e-04 - val_loss: 9.5800e-04\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2822e-04 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1343e-05 - val_loss: 2.3920e-04\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.4535e-05 - val_loss: 3.7283e-04\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5415e-04 - val_loss: 8.0764e-04\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4970e-04 - val_loss: 7.3368e-04\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.4662e-05 - val_loss: 2.9860e-04\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.3948e-05 - val_loss: 1.2834e-04\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.4370e-05 - val_loss: 2.5434e-04\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.5142e-05 - val_loss: 5.0735e-04\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.9946e-05 - val_loss: 5.9412e-04\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.5332e-05 - val_loss: 1.9691e-04\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.2915e-05 - val_loss: 4.1221e-04\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.5347e-05 - val_loss: 8.3927e-04\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9362e-05 - val_loss: 2.8438e-04\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9800e-05 - val_loss: 2.1771e-04\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.3731e-05 - val_loss: 3.1151e-04\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.6858e-05 - val_loss: 2.6155e-04\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4864e-05 - val_loss: 1.1217e-04\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9614e-05 - val_loss: 2.6562e-05\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8964e-05 - val_loss: 4.6719e-05\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5668e-05 - val_loss: 1.3056e-04\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5985e-05 - val_loss: 9.6265e-05\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.5937e-05 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.8951e-05 - val_loss: 2.7027e-04\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.6180e-05 - val_loss: 5.1878e-04\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.4402e-05 - val_loss: 3.3356e-05\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3320e-05 - val_loss: 2.9558e-05\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 4.5048e-05 - val_loss: 1.8763e-04\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.8818e-05 - val_loss: 2.5656e-04\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5998e-05 - val_loss: 1.8858e-04\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.1188e-05 - val_loss: 1.3732e-04\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8235e-05 - val_loss: 4.2056e-04\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8689e-05 - val_loss: 3.1920e-04\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5773e-05 - val_loss: 5.1092e-05\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9921e-05 - val_loss: 8.3244e-04\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7074e-05 - val_loss: 3.4896e-04\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8905e-05 - val_loss: 2.4122e-04\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9748e-05 - val_loss: 2.0130e-04\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9134e-05 - val_loss: 2.6293e-04\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6455e-05 - val_loss: 4.2263e-04\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9757e-05 - val_loss: 4.4161e-04\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2341e-05 - val_loss: 1.4765e-04\n",
      ">p=2: 9, Score=0.008207216887967661\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 10s 14ms/step - loss: 0.0015 - val_loss: 0.0081\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.1546e-04 - val_loss: 0.0036\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.5627e-04 - val_loss: 9.8746e-04\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8167e-04 - val_loss: 4.1252e-04\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.6776e-04 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4709e-04 - val_loss: 1.1701e-04\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.3933e-05 - val_loss: 2.3622e-04\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.8448e-05 - val_loss: 0.0010\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8527e-04 - val_loss: 0.0020\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4694e-04 - val_loss: 1.1152e-04\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0911e-04 - val_loss: 9.7964e-04\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.5591e-05 - val_loss: 4.5297e-04\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.2163e-05 - val_loss: 2.7412e-04\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.5205e-05 - val_loss: 5.6346e-04\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.4237e-05 - val_loss: 4.9144e-04\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.0036e-05 - val_loss: 3.7246e-04\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.8644e-05 - val_loss: 0.0016\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7404e-05 - val_loss: 0.0022\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.3053e-05 - val_loss: 3.0414e-04\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.7797e-05 - val_loss: 4.6722e-04\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.5414e-05 - val_loss: 8.1464e-04\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.4974e-05 - val_loss: 1.0013e-04\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6155e-05 - val_loss: 1.1602e-04\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0238e-05 - val_loss: 1.8288e-04\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7269e-05 - val_loss: 6.6488e-04\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.0002e-05 - val_loss: 6.7241e-04\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.6083e-05 - val_loss: 3.1646e-04\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1593e-05 - val_loss: 3.4533e-04\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6482e-05 - val_loss: 2.0530e-04\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4232e-05 - val_loss: 3.3878e-05\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1359e-05 - val_loss: 1.6317e-04\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.0707e-05 - val_loss: 4.0535e-05\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.0123e-05 - val_loss: 1.1839e-04\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.8169e-05 - val_loss: 5.1369e-04\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.0370e-05 - val_loss: 4.1717e-04\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3623e-05 - val_loss: 3.9055e-04\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8364e-05 - val_loss: 1.2918e-04\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.1980e-05 - val_loss: 1.8451e-04\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.8730e-05 - val_loss: 8.9139e-04\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.2807e-05 - val_loss: 2.4085e-04\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.1493e-05 - val_loss: 7.7720e-04\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.0743e-05 - val_loss: 1.8834e-05\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2627e-05 - val_loss: 8.8782e-05\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.6077e-05 - val_loss: 4.2652e-05\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.3813e-05 - val_loss: 0.0017\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5441e-05 - val_loss: 7.2824e-05\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4930e-05 - val_loss: 1.2828e-04\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9911e-05 - val_loss: 4.8568e-04\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7609e-05 - val_loss: 7.3802e-05\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5669e-05 - val_loss: 5.3787e-04\n",
      ">p=2: 10, Score=0.029206194449216127\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 9s 14ms/step - loss: 0.0018 - val_loss: 0.0094\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 8.8008e-04 - val_loss: 0.0057\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 5.3785e-04 - val_loss: 0.0023\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 3.0436e-04 - val_loss: 9.5915e-04\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 1.3431e-04 - val_loss: 5.3921e-04\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 1.5553e-04 - val_loss: 7.6758e-04\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 1.0535e-04 - val_loss: 5.3704e-04\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 6.2793e-05 - val_loss: 2.9510e-04\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 9.3596e-05 - val_loss: 2.7298e-04\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 6.1603e-05 - val_loss: 5.2077e-04\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 1.1509e-04 - val_loss: 8.9817e-04\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.4509e-04 - val_loss: 3.2530e-04\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.0486e-04 - val_loss: 2.8422e-04\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.6600e-05 - val_loss: 8.6021e-05\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.4252e-05 - val_loss: 1.1841e-04\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.0413e-05 - val_loss: 8.1468e-04\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.9921e-05 - val_loss: 1.7631e-04\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.7567e-05 - val_loss: 1.4749e-04\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.2183e-05 - val_loss: 2.3871e-04\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.6585e-05 - val_loss: 9.6256e-05\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.7020e-05 - val_loss: 7.4164e-05\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.3306e-05 - val_loss: 4.0355e-04\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.8044e-05 - val_loss: 2.5709e-04\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.7155e-05 - val_loss: 2.0762e-04\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.3149e-05 - val_loss: 6.3365e-04\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.5130e-05 - val_loss: 4.2228e-04\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.9902e-05 - val_loss: 8.3474e-05\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.5922e-05 - val_loss: 7.4259e-04\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.3668e-05 - val_loss: 1.2643e-04\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 2s 7ms/step - loss: 6.8271e-05 - val_loss: 3.5160e-04\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.7054e-05 - val_loss: 8.6041e-05\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.9031e-05 - val_loss: 2.2733e-04\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.2375e-05 - val_loss: 1.3072e-04\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.7801e-05 - val_loss: 3.5830e-04\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.1317e-05 - val_loss: 1.9195e-04\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.6658e-05 - val_loss: 5.6476e-04\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.6870e-05 - val_loss: 2.2693e-05\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 2s 7ms/step - loss: 1.6850e-05 - val_loss: 3.8989e-05\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.3421e-05 - val_loss: 0.0015\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 7.1501e-05 - val_loss: 5.1076e-05\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 4.0576e-05 - val_loss: 9.5887e-04\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.7285e-05 - val_loss: 5.7812e-04\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.6518e-05 - val_loss: 2.4934e-05\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.4523e-05 - val_loss: 1.5702e-04\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.6078e-05 - val_loss: 4.9350e-04\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.3776e-05 - val_loss: 3.5066e-05\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.7896e-05 - val_loss: 3.3212e-04\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.6891e-05 - val_loss: 5.3752e-04\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.8672e-05 - val_loss: 8.3726e-05\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 2.4076e-05 - val_loss: 3.7447e-04\n",
      ">p=3: 1, Score=0.020314181165304035\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 10s 17ms/step - loss: 0.0019 - val_loss: 0.0102\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0010 - val_loss: 0.0067\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.6047e-04 - val_loss: 0.0031\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.5496e-04 - val_loss: 0.0010\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.7477e-04 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.3983e-04 - val_loss: 7.3068e-04\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.3375e-04 - val_loss: 1.3467e-04\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.1935e-04 - val_loss: 2.9667e-04\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 1.1159e-04 - val_loss: 2.6575e-04\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0275e-04 - val_loss: 1.1998e-04\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 7.9575e-05 - val_loss: 3.2249e-04\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.9547e-05 - val_loss: 8.1891e-04\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 7.5757e-05 - val_loss: 2.0038e-04\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 8.3356e-05 - val_loss: 1.3797e-04\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.3953e-05 - val_loss: 2.5533e-04\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.6162e-05 - val_loss: 3.0506e-04\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.8309e-05 - val_loss: 1.3984e-04\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.9114e-05 - val_loss: 9.6932e-04\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.0215e-04 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.2123e-04 - val_loss: 1.0872e-04\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.9622e-05 - val_loss: 1.8633e-04\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.6855e-05 - val_loss: 9.5425e-05\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.5599e-05 - val_loss: 8.9859e-05\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.5508e-05 - val_loss: 4.0721e-04\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.1096e-05 - val_loss: 1.7157e-04\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.7126e-05 - val_loss: 2.6114e-05\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.8751e-05 - val_loss: 4.7184e-04\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.4322e-05 - val_loss: 1.0658e-04\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.3106e-05 - val_loss: 2.1901e-04\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.5156e-05 - val_loss: 7.6653e-05\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.2763e-04 - val_loss: 0.0018\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.6389e-05 - val_loss: 1.0713e-04\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.5440e-05 - val_loss: 7.7018e-05\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.0887e-05 - val_loss: 2.5466e-05\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 1.8995e-05 - val_loss: 2.9973e-05\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.0739e-05 - val_loss: 2.8003e-04\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.9326e-05 - val_loss: 6.7990e-04\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.0909e-05 - val_loss: 2.9431e-05\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.1769e-05 - val_loss: 2.6356e-04\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.0865e-05 - val_loss: 6.5505e-06\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.4853e-05 - val_loss: 8.1261e-04\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.7770e-05 - val_loss: 4.6437e-05\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.9114e-05 - val_loss: 2.1807e-04\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 5.6313e-05 - val_loss: 1.0052e-04\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.6265e-05 - val_loss: 1.5430e-05\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.9611e-05 - val_loss: 3.2188e-05\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 1.3744e-05 - val_loss: 5.6717e-06\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.9276e-05 - val_loss: 2.4465e-05\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.1793e-05 - val_loss: 4.9091e-05\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.2191e-05 - val_loss: 2.6505e-05\n",
      ">p=3: 2, Score=0.0034100117773050442\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 10s 16ms/step - loss: 0.0019 - val_loss: 0.0097\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.6709e-04 - val_loss: 0.0055\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.9760e-04 - val_loss: 0.0022\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.8332e-04 - val_loss: 6.9847e-04\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.1335e-04 - val_loss: 2.1998e-04\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.5429e-04 - val_loss: 2.8933e-04\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.1136e-04 - val_loss: 2.5680e-04\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 9.0685e-05 - val_loss: 3.0152e-04\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.0956e-04 - val_loss: 3.1961e-04\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.1197e-04 - val_loss: 1.8365e-04\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.1777e-05 - val_loss: 1.6409e-04\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 9.3221e-05 - val_loss: 2.6164e-04\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.7724e-05 - val_loss: 2.3043e-04\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.5651e-05 - val_loss: 1.8436e-04\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.0732e-05 - val_loss: 1.2085e-04\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.8161e-05 - val_loss: 2.1657e-04\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.8276e-05 - val_loss: 3.2968e-04\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.4191e-05 - val_loss: 1.4071e-04\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.5687e-05 - val_loss: 1.2968e-04\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 8.2398e-05 - val_loss: 5.5036e-04\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.1152e-04 - val_loss: 6.9349e-04\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.0019e-05 - val_loss: 9.7533e-05\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.9478e-05 - val_loss: 1.8569e-04\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.8677e-05 - val_loss: 3.9153e-04\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 9.1641e-05 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.3632e-05 - val_loss: 1.1392e-04\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.4356e-05 - val_loss: 8.9035e-05\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.3099e-05 - val_loss: 7.0874e-05\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 2.8369e-05 - val_loss: 1.0643e-04\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 7.9058e-05 - val_loss: 4.6402e-04\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.1460e-05 - val_loss: 2.3255e-04\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.0910e-05 - val_loss: 4.8471e-04\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.6863e-05 - val_loss: 3.3938e-05\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.1473e-05 - val_loss: 2.4086e-05\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 9.1418e-05 - val_loss: 0.0015\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 8.4667e-05 - val_loss: 5.1993e-04\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.0404e-05 - val_loss: 7.2015e-05\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.1774e-05 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.8387e-05 - val_loss: 4.4222e-04\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.1095e-05 - val_loss: 3.6016e-05\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 4.7426e-05 - val_loss: 4.1757e-04\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 2.0499e-05 - val_loss: 3.0413e-05\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.9762e-05 - val_loss: 6.9209e-04\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 4.2939e-05 - val_loss: 1.9865e-04\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.0867e-05 - val_loss: 2.5327e-04\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.8835e-05 - val_loss: 6.6652e-04\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.5314e-05 - val_loss: 2.6478e-04\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.4616e-05 - val_loss: 5.3452e-05\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.8159e-05 - val_loss: 2.7299e-04\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.1136e-05 - val_loss: 5.2606e-05\n",
      ">p=3: 3, Score=0.003802148421527818\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 12s 17ms/step - loss: 0.0018 - val_loss: 0.0091\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 9.0778e-04 - val_loss: 0.0054\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 5.0395e-04 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.3614e-04 - val_loss: 7.7274e-04\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.7028e-04 - val_loss: 4.3544e-04\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.6603e-04 - val_loss: 1.6404e-04\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.2828e-04 - val_loss: 3.6918e-04\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 9.3589e-05 - val_loss: 8.1345e-04\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.5897e-04 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 1.6459e-04 - val_loss: 4.1571e-04\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.2338e-05 - val_loss: 2.0745e-04\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 7.3697e-05 - val_loss: 1.5178e-04\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 7.9545e-05 - val_loss: 3.0191e-04\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.8827e-05 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.5288e-05 - val_loss: 5.1274e-04\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 8.8224e-05 - val_loss: 3.9008e-04\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 9.7015e-05 - val_loss: 1.5606e-04\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.2236e-05 - val_loss: 9.1763e-05\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.6648e-05 - val_loss: 2.0101e-04\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.5796e-05 - val_loss: 6.4214e-04\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 7.7476e-05 - val_loss: 2.9073e-04\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.3663e-05 - val_loss: 9.3879e-04\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.6428e-05 - val_loss: 1.7089e-04\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.1273e-05 - val_loss: 5.4744e-04\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.2210e-05 - val_loss: 4.1834e-05\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.3472e-05 - val_loss: 2.2521e-04\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 2.2851e-05 - val_loss: 9.1386e-05\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 7.3644e-05 - val_loss: 7.6305e-04\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 4.8077e-05 - val_loss: 5.5401e-05\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 6.4214e-05 - val_loss: 4.8848e-04\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.6437e-05 - val_loss: 4.7961e-04\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.0570e-05 - val_loss: 7.6585e-05\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.3481e-05 - val_loss: 4.0062e-05\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.4496e-05 - val_loss: 6.4155e-05\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 3.6225e-05 - val_loss: 1.2963e-04\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 2.8072e-05 - val_loss: 1.6546e-04\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 2.2097e-05 - val_loss: 2.5272e-04\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.1608e-04 - val_loss: 0.0018\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.0906e-05 - val_loss: 8.2213e-05\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.3929e-05 - val_loss: 1.0996e-05\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.6118e-05 - val_loss: 1.8500e-05\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.7075e-05 - val_loss: 1.3131e-05\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 8.6808e-05 - val_loss: 1.3599e-04\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 2.5860e-05 - val_loss: 6.3798e-05\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.5857e-05 - val_loss: 1.5405e-04\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 2.4591e-05 - val_loss: 1.3926e-05\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.0404e-05 - val_loss: 4.4919e-04\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.1859e-05 - val_loss: 4.2744e-04\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.4886e-05 - val_loss: 4.4991e-04\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.0717e-05 - val_loss: 2.1225e-04\n",
      ">p=3: 4, Score=0.013468830729834735\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 11s 16ms/step - loss: 0.0019 - val_loss: 0.0092\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.6704e-04 - val_loss: 0.0046\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.6972e-04 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.4327e-04 - val_loss: 4.1669e-04\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.2167e-04 - val_loss: 1.9791e-04\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.6149e-04 - val_loss: 4.1713e-04\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.7646e-04 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.4829e-04 - val_loss: 1.3138e-04\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.1563e-05 - val_loss: 2.4159e-04\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 9.7672e-05 - val_loss: 4.4602e-04\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.7691e-05 - val_loss: 1.4377e-04\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.5940e-05 - val_loss: 8.6097e-04\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.7676e-05 - val_loss: 1.7940e-04\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.5606e-04 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.4810e-04 - val_loss: 1.0075e-04\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.1011e-05 - val_loss: 2.1090e-04\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.6244e-05 - val_loss: 1.2270e-04\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.1954e-05 - val_loss: 2.3776e-04\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.8651e-05 - val_loss: 1.0103e-04\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 5.4340e-05 - val_loss: 1.0545e-04\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 8.7251e-05 - val_loss: 8.0845e-04\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 7.3469e-05 - val_loss: 9.4282e-05\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.1554e-05 - val_loss: 2.9829e-04\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 4.5146e-05 - val_loss: 2.6806e-04\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.4358e-05 - val_loss: 3.3297e-05\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.8181e-05 - val_loss: 1.3411e-04\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.5223e-05 - val_loss: 9.6853e-05\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.6273e-05 - val_loss: 2.5963e-04\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.8688e-05 - val_loss: 9.8392e-05\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.2200e-05 - val_loss: 4.8782e-04\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.6477e-05 - val_loss: 1.8159e-04\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.0255e-05 - val_loss: 3.6322e-04\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.1772e-05 - val_loss: 1.1906e-04\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.0344e-05 - val_loss: 6.0718e-05\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.8270e-05 - val_loss: 1.0514e-04\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.7411e-05 - val_loss: 9.4254e-05\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.8651e-05 - val_loss: 9.9774e-04\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.8280e-05 - val_loss: 1.6901e-04\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.7857e-05 - val_loss: 8.3490e-05\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.0544e-05 - val_loss: 5.8025e-04\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 9.6206e-05 - val_loss: 3.6121e-04\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.3819e-05 - val_loss: 1.2234e-04\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.7965e-05 - val_loss: 4.1953e-05\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.6149e-05 - val_loss: 8.7996e-04\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.1986e-05 - val_loss: 1.8710e-05\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.8988e-05 - val_loss: 4.4940e-04\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.5417e-05 - val_loss: 6.6969e-05\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.9583e-05 - val_loss: 9.4354e-05\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.2472e-05 - val_loss: 1.9162e-04\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.6166e-05 - val_loss: 2.4392e-05\n",
      ">p=3: 5, Score=0.002925612534454558\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 10s 16ms/step - loss: 0.0018 - val_loss: 0.0092\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.5135e-04 - val_loss: 0.0049\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.7819e-04 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 2.0905e-04 - val_loss: 4.8164e-04\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 1.4128e-04 - val_loss: 2.7979e-04\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.5786e-04 - val_loss: 5.7384e-04\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.1679e-04 - val_loss: 6.4204e-04\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 7.0669e-05 - val_loss: 0.0010\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 9.2382e-05 - val_loss: 1.3043e-04\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 7.2489e-05 - val_loss: 4.8762e-04\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.3481e-05 - val_loss: 9.0510e-05\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.1753e-04 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.2050e-04 - val_loss: 1.9325e-04\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 9.7416e-05 - val_loss: 2.9498e-04\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 4.8752e-05 - val_loss: 4.1068e-04\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.1733e-05 - val_loss: 5.9484e-05\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0124e-04 - val_loss: 8.1805e-04\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.6766e-05 - val_loss: 2.4683e-04\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.7109e-05 - val_loss: 2.6057e-04\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.6823e-05 - val_loss: 3.4455e-04\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.5315e-05 - val_loss: 3.3695e-04\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.5599e-05 - val_loss: 8.0260e-04\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.7596e-05 - val_loss: 5.1492e-05\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.3923e-05 - val_loss: 1.0677e-04\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.7773e-05 - val_loss: 2.2512e-04\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.2366e-05 - val_loss: 1.0087e-04\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.8945e-05 - val_loss: 7.4854e-04\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.0654e-05 - val_loss: 8.6757e-05\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.4924e-05 - val_loss: 1.0028e-04\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.6543e-05 - val_loss: 5.5619e-05\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.3452e-05 - val_loss: 0.0010\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.2453e-05 - val_loss: 4.2835e-04\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.0520e-05 - val_loss: 8.2730e-05\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 2.6698e-05 - val_loss: 8.2669e-05\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 5.0486e-05 - val_loss: 8.0442e-05\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.3129e-05 - val_loss: 1.3546e-04\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 4.6055e-05 - val_loss: 7.2181e-04\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 5.7982e-05 - val_loss: 1.0986e-04\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 5.6103e-05 - val_loss: 7.3240e-04\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.4695e-05 - val_loss: 4.9815e-04\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.5302e-05 - val_loss: 1.2695e-04\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 3.6729e-05 - val_loss: 1.7547e-04\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 3s 12ms/step - loss: 2.1153e-05 - val_loss: 9.2570e-05\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.9211e-05 - val_loss: 2.1782e-04\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 3.4339e-05 - val_loss: 2.1302e-04\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.9574e-05 - val_loss: 1.3714e-04\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 6.7180e-05 - val_loss: 2.3255e-04\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 2.9307e-05 - val_loss: 1.5598e-04\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.7450e-05 - val_loss: 2.7767e-05\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 7.4631e-05 - val_loss: 0.0016\n",
      ">p=3: 6, Score=0.0791537924669683\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 10s 17ms/step - loss: 0.0020 - val_loss: 0.0097\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.9399e-04 - val_loss: 0.0058\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.8997e-04 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.3310e-04 - val_loss: 8.5180e-04\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.6968e-04 - val_loss: 5.9934e-04\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.0720e-04 - val_loss: 2.1290e-04\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.9256e-05 - val_loss: 8.4578e-04\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.8150e-04 - val_loss: 6.5057e-04\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.3263e-04 - val_loss: 2.5173e-04\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.0677e-05 - val_loss: 3.7608e-04\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 8.8918e-05 - val_loss: 1.6464e-04\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 6.8074e-05 - val_loss: 0.0023\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 4.7411e-05 - val_loss: 2.2566e-04\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 8.9298e-05 - val_loss: 3.5872e-04\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.1227e-04 - val_loss: 3.7093e-04\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 9.9546e-05 - val_loss: 1.5229e-04\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 7.5052e-05 - val_loss: 4.4509e-04\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 8.1018e-05 - val_loss: 6.4625e-04\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.5264e-05 - val_loss: 2.0012e-04\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 7.8392e-05 - val_loss: 7.4229e-04\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 6.9450e-05 - val_loss: 6.8574e-04\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.8293e-05 - val_loss: 2.0093e-04\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.4917e-05 - val_loss: 1.2421e-04\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.3383e-05 - val_loss: 4.1213e-04\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.9090e-05 - val_loss: 3.0743e-04\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.7593e-05 - val_loss: 2.1041e-04\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.3876e-05 - val_loss: 2.0307e-04\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.7092e-05 - val_loss: 2.5158e-04\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.5330e-05 - val_loss: 1.3569e-04\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.6593e-05 - val_loss: 5.8095e-04\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.5058e-05 - val_loss: 1.8153e-04\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.1536e-05 - val_loss: 7.7982e-05\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.0187e-05 - val_loss: 7.0806e-05\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 8.8485e-05 - val_loss: 0.0023\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0873e-04 - val_loss: 1.6779e-04\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.5903e-05 - val_loss: 5.2653e-05\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.9911e-05 - val_loss: 7.9081e-05\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.2637e-05 - val_loss: 2.3139e-04\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.9266e-05 - val_loss: 2.5661e-04\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.8191e-05 - val_loss: 5.9923e-04\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 6.3586e-05 - val_loss: 7.7440e-04\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.3132e-05 - val_loss: 3.0846e-05\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.5098e-05 - val_loss: 2.1718e-04\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.0373e-05 - val_loss: 1.7096e-04\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.0634e-05 - val_loss: 1.4949e-04\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.2680e-05 - val_loss: 4.9977e-04\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.5149e-05 - val_loss: 5.7166e-04\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 3.3650e-05 - val_loss: 2.3981e-05\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.7681e-05 - val_loss: 5.9688e-04\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.3417e-05 - val_loss: 2.4356e-05\n",
      ">p=3: 7, Score=0.003248215580242686\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 10s 17ms/step - loss: 0.0018 - val_loss: 0.0092\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.9674e-04 - val_loss: 0.0050\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.6742e-04 - val_loss: 0.0020\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.9853e-04 - val_loss: 5.6235e-04\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.7011e-04 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.7595e-05 - val_loss: 3.1598e-04\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.1022e-04 - val_loss: 5.8187e-04\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.0938e-04 - val_loss: 9.8385e-05\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.2992e-04 - val_loss: 1.7633e-04\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.7136e-05 - val_loss: 1.2164e-04\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.4952e-05 - val_loss: 7.3631e-04\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 9.7108e-05 - val_loss: 1.9853e-04\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 7.3759e-05 - val_loss: 4.4969e-04\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.2592e-05 - val_loss: 1.3161e-04\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.5655e-05 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.8141e-05 - val_loss: 7.8761e-04\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.5281e-05 - val_loss: 5.0464e-04\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.1271e-04 - val_loss: 2.7824e-04\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 4.1534e-05 - val_loss: 2.6012e-04\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.0610e-04 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 1.0773e-04 - val_loss: 3.4762e-04\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 5.2820e-05 - val_loss: 2.2694e-05\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.9140e-05 - val_loss: 5.8785e-04\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 7.1122e-05 - val_loss: 2.8781e-04\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.9383e-05 - val_loss: 3.5732e-04\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.3796e-05 - val_loss: 6.2178e-05\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.0155e-05 - val_loss: 1.1825e-04\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.4524e-05 - val_loss: 7.7344e-05\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.7444e-05 - val_loss: 4.6424e-05\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 4.3073e-05 - val_loss: 4.9872e-04\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 5.7046e-05 - val_loss: 5.8489e-04\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.4720e-05 - val_loss: 2.3458e-05\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 4.7266e-05 - val_loss: 2.3740e-04\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 2.8589e-05 - val_loss: 6.7155e-05\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 3.0971e-05 - val_loss: 8.0932e-05\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 3s 15ms/step - loss: 4.9106e-05 - val_loss: 1.3301e-04\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 2.2189e-05 - val_loss: 1.9341e-04\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.3144e-05 - val_loss: 9.6666e-05\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 3.7616e-05 - val_loss: 5.1255e-04\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.9772e-05 - val_loss: 6.2571e-05\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 8.2200e-05 - val_loss: 2.9863e-04\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 2.3964e-05 - val_loss: 2.4103e-04\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 4.3513e-05 - val_loss: 3.4607e-04\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.9545e-05 - val_loss: 1.1755e-04\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 1.9831e-05 - val_loss: 2.4600e-05\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.0277e-05 - val_loss: 6.2689e-05\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 2.4742e-05 - val_loss: 1.4351e-04\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.7121e-05 - val_loss: 1.2168e-04\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 3s 14ms/step - loss: 4.8901e-05 - val_loss: 6.4142e-04\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.1368e-05 - val_loss: 5.2370e-05\n",
      ">p=3: 8, Score=0.004298163912608288\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 10s 17ms/step - loss: 0.0018 - val_loss: 0.0093\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 8.8700e-04 - val_loss: 0.0053\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 5.6555e-04 - val_loss: 0.0023\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.2979e-04 - val_loss: 7.6122e-04\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 1.6339e-04 - val_loss: 8.3957e-04\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.0823e-04 - val_loss: 2.0397e-04\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0627e-04 - val_loss: 2.3214e-04\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 7.8303e-05 - val_loss: 3.7527e-04\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 7.4655e-05 - val_loss: 1.0571e-04\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 9.5062e-05 - val_loss: 2.5308e-04\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 1.1199e-04 - val_loss: 3.8479e-04\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 6.3894e-05 - val_loss: 1.1749e-04\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 5.9844e-05 - val_loss: 8.6935e-04\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 7.9222e-05 - val_loss: 1.5082e-04\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 7.9631e-05 - val_loss: 2.4759e-04\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 6.3084e-05 - val_loss: 2.6248e-04\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 6.4909e-05 - val_loss: 2.4165e-04\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 1.0355e-04 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 1.1006e-04 - val_loss: 4.3623e-04\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 5.2866e-05 - val_loss: 1.3188e-04\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 6.9247e-05 - val_loss: 3.8248e-04\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 6.3600e-05 - val_loss: 6.0689e-04\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 7.2801e-05 - val_loss: 1.6381e-04\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 4.6317e-05 - val_loss: 2.6561e-04\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 4.7665e-05 - val_loss: 2.5254e-04\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.0139e-05 - val_loss: 2.2200e-04\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.9652e-05 - val_loss: 3.4850e-04\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 2.5092e-05 - val_loss: 6.8131e-05\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.8143e-05 - val_loss: 2.6033e-04\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.8369e-05 - val_loss: 4.9958e-04\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.2069e-05 - val_loss: 2.7422e-05\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.3099e-05 - val_loss: 2.7045e-04\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 7.5085e-05 - val_loss: 5.1594e-04\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 8.2165e-05 - val_loss: 0.0016\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 6.4664e-05 - val_loss: 5.8537e-04\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 7.4514e-05 - val_loss: 8.4819e-04\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 4.7934e-05 - val_loss: 1.6239e-05\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 2.1818e-05 - val_loss: 8.6553e-05\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 4.1634e-05 - val_loss: 8.0643e-05\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 3.8559e-05 - val_loss: 7.6105e-04\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 1.7941e-05 - val_loss: 7.5366e-05\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 1.3863e-05 - val_loss: 5.6055e-05\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 3s 12ms/step - loss: 2.9542e-05 - val_loss: 5.0338e-04\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 4.7871e-05 - val_loss: 1.9634e-04\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.7847e-05 - val_loss: 2.3562e-05\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 1.2785e-05 - val_loss: 6.5619e-05\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 6.4168e-05 - val_loss: 7.9169e-05\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 2.3461e-05 - val_loss: 3.6848e-05\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 2.8170e-05 - val_loss: 8.3065e-05\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 2.2168e-05 - val_loss: 2.9786e-05\n",
      ">p=3: 9, Score=0.0032920775993261486\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 11s 19ms/step - loss: 0.0019 - val_loss: 0.0100\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0067\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 6.3963e-04 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 3.9088e-04 - val_loss: 0.0010\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 1.6470e-04 - val_loss: 3.1161e-04\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 1.4108e-04 - val_loss: 3.6735e-04\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.0329e-04 - val_loss: 1.9396e-04\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.5135e-04 - val_loss: 6.5959e-04\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 9.7399e-05 - val_loss: 1.1901e-04\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 7.5307e-05 - val_loss: 1.7411e-04\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 7.4473e-05 - val_loss: 7.2516e-04\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 8.1413e-05 - val_loss: 2.8252e-04\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 7.8349e-05 - val_loss: 1.1854e-04\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 7.4764e-05 - val_loss: 2.3216e-04\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 1.1380e-04 - val_loss: 5.7160e-04\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 1.2261e-04 - val_loss: 5.1386e-04\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 7.5819e-05 - val_loss: 9.6841e-05\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 5.4611e-05 - val_loss: 2.0286e-04\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 8.8721e-05 - val_loss: 5.8533e-04\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 8.7020e-05 - val_loss: 3.6778e-04\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.4909e-05 - val_loss: 1.2494e-04\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 5.8225e-05 - val_loss: 3.2680e-04\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.1305e-05 - val_loss: 2.0923e-04\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.6748e-05 - val_loss: 1.3469e-04\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 5.5365e-05 - val_loss: 7.2423e-05\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.9992e-05 - val_loss: 2.5671e-04\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 5.1468e-05 - val_loss: 4.1214e-04\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 3.4279e-05 - val_loss: 2.1931e-04\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 2.8381e-05 - val_loss: 8.5270e-05\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.9553e-05 - val_loss: 2.7353e-04\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 5.0838e-05 - val_loss: 1.8752e-04\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.7704e-05 - val_loss: 9.2615e-05\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 8.2243e-05 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 4.5755e-05 - val_loss: 2.6423e-04\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 5.7242e-05 - val_loss: 7.0687e-04\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 3.2741e-05 - val_loss: 2.8536e-05\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 2.8091e-05 - val_loss: 6.0628e-05\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 2s 10ms/step - loss: 8.6497e-05 - val_loss: 0.0015\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 3s 14ms/step - loss: 4.8295e-05 - val_loss: 7.5262e-05\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 3s 15ms/step - loss: 2.6761e-05 - val_loss: 1.7108e-04\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 5s 24ms/step - loss: 2.0326e-05 - val_loss: 3.3813e-04\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 4s 21ms/step - loss: 2.6751e-05 - val_loss: 1.4238e-04\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 3s 16ms/step - loss: 2.2406e-05 - val_loss: 1.3115e-04\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 5s 25ms/step - loss: 5.3850e-05 - val_loss: 1.0829e-04\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 4s 18ms/step - loss: 5.0228e-05 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 3s 17ms/step - loss: 4.0980e-05 - val_loss: 1.0291e-04\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 2.2485e-05 - val_loss: 8.9802e-05\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 2s 9ms/step - loss: 1.8298e-05 - val_loss: 3.3572e-05\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 3.5780e-05 - val_loss: 7.5453e-05\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 4.8838e-05 - val_loss: 0.0011\n",
      ">p=3: 10, Score=0.05742260836996138\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 12s 21ms/step - loss: 0.0021 - val_loss: 0.0103\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.1571e-04 - val_loss: 0.0065\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.5295e-04 - val_loss: 0.0030\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4242e-04 - val_loss: 0.0016\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7087e-04 - val_loss: 4.0619e-04\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.5674e-04 - val_loss: 8.1123e-04\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7885e-04 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.6391e-05 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1489e-04 - val_loss: 3.4517e-04\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1317e-04 - val_loss: 7.8512e-04\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.5228e-05 - val_loss: 7.1226e-04\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.8653e-05 - val_loss: 3.0646e-04\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.3835e-05 - val_loss: 2.7465e-04\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.1564e-05 - val_loss: 9.8963e-04\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.4166e-05 - val_loss: 2.1944e-04\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.5401e-05 - val_loss: 2.1140e-04\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5316e-05 - val_loss: 6.2496e-04\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9821e-05 - val_loss: 5.7208e-04\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8255e-05 - val_loss: 9.0838e-04\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.8499e-05 - val_loss: 3.6581e-04\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.6566e-05 - val_loss: 1.7253e-04\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.6763e-05 - val_loss: 3.9950e-04\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.0745e-05 - val_loss: 3.3449e-04\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9477e-05 - val_loss: 3.7899e-05\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.1955e-05 - val_loss: 1.1638e-04\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2864e-05 - val_loss: 3.1277e-04\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3510e-05 - val_loss: 3.4485e-04\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.7799e-05 - val_loss: 6.5401e-05\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3268e-05 - val_loss: 4.1216e-04\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.1562e-05 - val_loss: 7.1099e-05\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.9758e-05 - val_loss: 1.1055e-04\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.6248e-05 - val_loss: 1.9767e-04\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2066e-05 - val_loss: 4.8683e-04\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7641e-05 - val_loss: 6.4539e-05\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.6888e-05 - val_loss: 6.6257e-05\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.0536e-05 - val_loss: 4.8904e-05\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.4597e-05 - val_loss: 9.3880e-05\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.8019e-05 - val_loss: 1.1005e-04\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.3442e-05 - val_loss: 8.2273e-04\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.4238e-05 - val_loss: 3.9712e-04\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.2918e-05 - val_loss: 4.4320e-04\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.6732e-05 - val_loss: 6.8446e-04\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7051e-05 - val_loss: 1.8388e-04\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6108e-05 - val_loss: 1.5678e-04\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.1471e-05 - val_loss: 1.5093e-04\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.7625e-05 - val_loss: 9.4195e-05\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.9894e-05 - val_loss: 3.3229e-04\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.1792e-05 - val_loss: 2.3644e-04\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0694e-05 - val_loss: 5.7180e-04\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5727e-05 - val_loss: 3.6088e-05\n",
      ">p=4: 1, Score=0.002612445859995205\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 12s 22ms/step - loss: 0.0023 - val_loss: 0.0104\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.3923e-04 - val_loss: 0.0073\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.9814e-04 - val_loss: 0.0043\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8219e-04 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8240e-04 - val_loss: 6.0734e-04\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.5023e-04 - val_loss: 3.0421e-04\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.4937e-04 - val_loss: 3.9525e-04\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0348e-04 - val_loss: 0.0010\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.5533e-05 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.2145e-05 - val_loss: 2.6926e-04\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.4788e-05 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.2698e-05 - val_loss: 2.1291e-04\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.5391e-05 - val_loss: 4.3390e-04\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.3482e-05 - val_loss: 1.2199e-04\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.0462e-05 - val_loss: 8.2775e-04\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4099e-05 - val_loss: 9.2028e-04\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1435e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1088e-04 - val_loss: 0.0016\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.2100e-05 - val_loss: 9.7185e-04\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.2456e-04 - val_loss: 0.0010\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.9280e-05 - val_loss: 2.2741e-04\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5738e-05 - val_loss: 4.4653e-04\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.0940e-05 - val_loss: 3.9972e-04\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.6300e-05 - val_loss: 3.2380e-04\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5837e-05 - val_loss: 3.8173e-04\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.9307e-05 - val_loss: 6.9639e-04\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3298e-05 - val_loss: 2.4119e-04\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8574e-05 - val_loss: 1.7306e-04\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.2030e-05 - val_loss: 5.1507e-04\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.2941e-05 - val_loss: 2.5877e-04\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5830e-05 - val_loss: 4.4480e-04\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.0661e-05 - val_loss: 1.3616e-04\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5395e-05 - val_loss: 0.0010\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.0098e-05 - val_loss: 3.8478e-05\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.3675e-05 - val_loss: 1.5459e-04\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.7208e-05 - val_loss: 1.9695e-04\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7036e-05 - val_loss: 1.7744e-04\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5008e-05 - val_loss: 4.1427e-04\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.7704e-05 - val_loss: 3.0473e-04\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5306e-05 - val_loss: 8.8194e-05\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4796e-05 - val_loss: 8.6296e-05\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8787e-05 - val_loss: 0.0016\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9333e-05 - val_loss: 3.8837e-05\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4742e-05 - val_loss: 1.5561e-04\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1117e-05 - val_loss: 5.2753e-05\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9804e-05 - val_loss: 2.5235e-05\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.2905e-05 - val_loss: 7.4008e-05\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4649e-05 - val_loss: 4.4205e-05\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8625e-05 - val_loss: 1.8178e-04\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.1101e-05 - val_loss: 9.9972e-06\n",
      ">p=4: 2, Score=0.002240073081338778\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 11s 21ms/step - loss: 0.0020 - val_loss: 0.0096\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.3811e-04 - val_loss: 0.0068\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.1029e-04 - val_loss: 0.0035\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9758e-04 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3868e-04 - val_loss: 9.3272e-04\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.6462e-04 - val_loss: 5.5194e-04\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.6727e-04 - val_loss: 5.1540e-04\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2334e-04 - val_loss: 3.9407e-04\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.5382e-05 - val_loss: 6.8554e-04\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.7026e-04 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 1.0881e-04 - val_loss: 4.0994e-04\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.9809e-05 - val_loss: 3.1112e-04\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 8.3725e-05 - val_loss: 2.6571e-04\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2678e-05 - val_loss: 3.3062e-04\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.8827e-05 - val_loss: 8.4229e-04\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.9147e-05 - val_loss: 8.4981e-04\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2728e-05 - val_loss: 1.9766e-04\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.8224e-05 - val_loss: 7.8796e-04\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.9305e-05 - val_loss: 9.0240e-05\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.7815e-05 - val_loss: 2.8798e-04\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.4340e-05 - val_loss: 1.6979e-04\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.6257e-05 - val_loss: 1.7911e-04\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3637e-05 - val_loss: 5.2249e-05\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.2873e-05 - val_loss: 4.1094e-04\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.2772e-05 - val_loss: 1.8745e-04\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.7206e-05 - val_loss: 1.2908e-04\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8519e-05 - val_loss: 7.1285e-05\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1826e-05 - val_loss: 2.9705e-04\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1882e-05 - val_loss: 6.6096e-05\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.0063e-05 - val_loss: 1.2075e-04\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.7961e-05 - val_loss: 1.5225e-04\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.5712e-05 - val_loss: 1.6036e-04\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8176e-05 - val_loss: 3.2143e-05\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.1468e-05 - val_loss: 1.9727e-04\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6621e-05 - val_loss: 2.7711e-04\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.8986e-05 - val_loss: 2.1217e-04\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.4485e-05 - val_loss: 2.5770e-04\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6484e-05 - val_loss: 4.8712e-05\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0201e-05 - val_loss: 1.9483e-05\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.9066e-05 - val_loss: 7.0880e-05\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.2763e-05 - val_loss: 3.8145e-04\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.1916e-05 - val_loss: 2.0407e-04\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4444e-05 - val_loss: 1.3001e-05\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.2575e-05 - val_loss: 1.4107e-04\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.8525e-05 - val_loss: 8.4010e-05\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.3548e-05 - val_loss: 7.2775e-05\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0505e-05 - val_loss: 3.3511e-05\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.4526e-05 - val_loss: 1.1099e-04\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3792e-05 - val_loss: 0.0011\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.0800e-05 - val_loss: 1.5025e-04\n",
      ">p=4: 3, Score=0.011542571883182973\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 11s 21ms/step - loss: 0.0021 - val_loss: 0.0098\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.2945e-04 - val_loss: 0.0066\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.4890e-04 - val_loss: 0.0034\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.9512e-04 - val_loss: 0.0013\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.6232e-04 - val_loss: 2.7569e-04\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.5694e-05 - val_loss: 5.0154e-04\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0252e-04 - val_loss: 2.5340e-04\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 9.0015e-05 - val_loss: 2.9045e-04\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.1496e-05 - val_loss: 2.9460e-04\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 7.1594e-05 - val_loss: 1.5068e-04\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.5931e-05 - val_loss: 3.1459e-04\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.3818e-05 - val_loss: 1.7371e-04\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.1017e-05 - val_loss: 8.4642e-05\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.6137e-05 - val_loss: 1.3247e-04\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.6636e-05 - val_loss: 3.5916e-04\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1612e-04 - val_loss: 9.0739e-04\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.7325e-05 - val_loss: 2.7708e-04\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.3943e-05 - val_loss: 1.4150e-04\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6476e-05 - val_loss: 2.7699e-04\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.1775e-05 - val_loss: 2.6017e-04\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.0649e-05 - val_loss: 4.3176e-04\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1031e-05 - val_loss: 2.4697e-04\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6720e-05 - val_loss: 5.1667e-04\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4925e-05 - val_loss: 2.4622e-04\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.4032e-05 - val_loss: 7.5245e-04\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4564e-05 - val_loss: 1.0939e-04\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9186e-05 - val_loss: 9.7900e-05\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.4462e-05 - val_loss: 1.8544e-04\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5098e-05 - val_loss: 3.7168e-04\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.9412e-05 - val_loss: 1.8735e-04\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9674e-05 - val_loss: 2.2444e-04\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 9.5062e-05 - val_loss: 3.5257e-05\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.1625e-05 - val_loss: 6.2111e-05\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4800e-05 - val_loss: 6.6050e-05\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0021e-05 - val_loss: 1.5401e-04\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.4531e-05 - val_loss: 1.5039e-04\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.8457e-05 - val_loss: 1.4981e-04\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.5187e-05 - val_loss: 1.5028e-04\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7755e-05 - val_loss: 9.6665e-05\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.9305e-05 - val_loss: 7.8129e-04\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.4983e-05 - val_loss: 2.8379e-05\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.7313e-05 - val_loss: 2.0740e-05\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.6815e-05 - val_loss: 1.3365e-04\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.6960e-05 - val_loss: 8.5629e-04\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.8365e-05 - val_loss: 5.1885e-05\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6773e-05 - val_loss: 6.7323e-05\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3787e-05 - val_loss: 7.8611e-05\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.9383e-05 - val_loss: 4.0305e-05\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3188e-05 - val_loss: 1.0852e-04\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.2250e-05 - val_loss: 1.8712e-05\n",
      ">p=4: 4, Score=0.0023261309252120554\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 11s 21ms/step - loss: 0.0022 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.9482e-04 - val_loss: 0.0075\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.1764e-04 - val_loss: 0.0045\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.1832e-04 - val_loss: 0.0020\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.5232e-04 - val_loss: 5.3859e-04\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1033e-04 - val_loss: 6.5821e-04\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7937e-04 - val_loss: 9.0410e-04\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3268e-04 - val_loss: 3.7368e-04\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0112e-04 - val_loss: 5.9751e-04\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1049e-04 - val_loss: 5.7973e-04\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0052e-04 - val_loss: 2.5987e-04\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.5107e-05 - val_loss: 0.0010\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.4751e-05 - val_loss: 2.9233e-04\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2362e-05 - val_loss: 0.0010\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.5782e-05 - val_loss: 3.3121e-04\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.0970e-04 - val_loss: 3.8202e-04\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.3026e-05 - val_loss: 0.0018\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.8979e-05 - val_loss: 3.7206e-04\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 6.8240e-05 - val_loss: 3.5361e-04\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 9.0499e-05 - val_loss: 5.5879e-04\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.0271e-04 - val_loss: 4.5556e-04\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.2755e-05 - val_loss: 1.1087e-04\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8138e-05 - val_loss: 3.2720e-04\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.5813e-05 - val_loss: 3.0169e-04\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 4.4891e-05 - val_loss: 1.1159e-04\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 4.7501e-05 - val_loss: 2.7071e-04\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.0792e-05 - val_loss: 1.2110e-04\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0018e-05 - val_loss: 9.1187e-05\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.1006e-05 - val_loss: 4.0039e-04\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.7591e-05 - val_loss: 5.0704e-05\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.9713e-05 - val_loss: 8.4293e-04\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.9973e-05 - val_loss: 1.0575e-04\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.7190e-05 - val_loss: 1.5956e-04\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5960e-05 - val_loss: 1.1766e-04\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8260e-05 - val_loss: 1.9588e-05\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.3389e-05 - val_loss: 4.2969e-04\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.4740e-05 - val_loss: 2.2071e-04\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4943e-05 - val_loss: 7.0386e-05\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9768e-05 - val_loss: 4.8977e-05\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 3s 19ms/step - loss: 1.2803e-04 - val_loss: 3.8557e-04\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 4.6894e-05 - val_loss: 5.0168e-04\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 5.5454e-05 - val_loss: 1.0416e-04\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 2.6729e-05 - val_loss: 2.8635e-04\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 3.6854e-05 - val_loss: 2.9403e-05\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8032e-05 - val_loss: 1.7785e-04\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5855e-05 - val_loss: 6.5935e-06\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.9543e-05 - val_loss: 1.8941e-04\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0041e-05 - val_loss: 3.5573e-04\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.2086e-05 - val_loss: 4.0598e-04\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0250e-05 - val_loss: 5.7393e-04\n",
      ">p=4: 5, Score=0.030540963052771986\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 8s 15ms/step - loss: 0.0021 - val_loss: 0.0103\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.7997e-04 - val_loss: 0.0073\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.3317e-04 - val_loss: 0.0043\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5524e-04 - val_loss: 0.0018\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4928e-04 - val_loss: 8.3169e-04\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7665e-04 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0779e-04 - val_loss: 1.3951e-04\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.2967e-05 - val_loss: 5.6138e-04\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0938e-04 - val_loss: 8.7401e-04\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.0005e-04 - val_loss: 3.4385e-04\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.9875e-05 - val_loss: 5.9246e-04\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.3386e-05 - val_loss: 8.7500e-04\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.7457e-05 - val_loss: 1.6199e-04\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.3036e-05 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7208e-05 - val_loss: 6.9875e-04\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.6075e-05 - val_loss: 2.1269e-04\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5422e-05 - val_loss: 6.8595e-04\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.0395e-05 - val_loss: 8.3826e-04\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.1599e-05 - val_loss: 5.2813e-04\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.0455e-05 - val_loss: 1.4196e-04\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7301e-05 - val_loss: 8.7986e-05\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5958e-05 - val_loss: 2.3073e-04\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7192e-05 - val_loss: 2.2751e-04\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.6506e-05 - val_loss: 6.1791e-04\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2321e-04 - val_loss: 9.5882e-04\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.5662e-05 - val_loss: 3.5585e-04\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.0381e-05 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.3902e-05 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.7945e-05 - val_loss: 2.0175e-04\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6503e-05 - val_loss: 4.3947e-04\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.6517e-05 - val_loss: 4.6257e-05\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.5940e-05 - val_loss: 2.0463e-04\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.4535e-05 - val_loss: 8.7650e-05\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8990e-05 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.0661e-05 - val_loss: 3.5006e-04\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.1388e-05 - val_loss: 2.8622e-04\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4357e-05 - val_loss: 6.3485e-04\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.6152e-05 - val_loss: 1.8941e-04\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5729e-05 - val_loss: 2.0495e-04\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4986e-05 - val_loss: 3.1066e-04\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.3303e-05 - val_loss: 3.3228e-05\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4444e-05 - val_loss: 6.7643e-05\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6283e-05 - val_loss: 2.8726e-05\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.4404e-05 - val_loss: 7.4389e-05\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.7837e-05 - val_loss: 2.3830e-05\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.4254e-05 - val_loss: 1.8876e-04\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.6904e-05 - val_loss: 1.2092e-04\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7871e-05 - val_loss: 1.8395e-04\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.7171e-05 - val_loss: 1.8203e-05\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.9075e-05 - val_loss: 5.0463e-05\n",
      ">p=4: 6, Score=0.00527683187101502\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 8s 16ms/step - loss: 0.0020 - val_loss: 0.0098\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.4276e-04 - val_loss: 0.0068\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.2778e-04 - val_loss: 0.0034\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 3.7838e-04 - val_loss: 0.0011\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 2.0198e-04 - val_loss: 4.3672e-04\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.5028e-04 - val_loss: 4.1852e-04\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.2020e-04 - val_loss: 1.9828e-04\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1.1242e-04 - val_loss: 1.4877e-04\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8216e-05 - val_loss: 6.2434e-04\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 8.8185e-05 - val_loss: 3.6614e-04\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 9.3441e-05 - val_loss: 0.0013\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.2285e-05 - val_loss: 3.4325e-04\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.1243e-05 - val_loss: 9.5199e-04\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 4.5652e-05 - val_loss: 5.3521e-04\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.2514e-05 - val_loss: 6.3579e-04\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.6451e-05 - val_loss: 3.7860e-04\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 6.4310e-05 - val_loss: 2.0577e-04\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8146e-05 - val_loss: 3.5108e-04\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 5.5873e-05 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.0856e-05 - val_loss: 1.2052e-04\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 1.1029e-04 - val_loss: 8.4576e-04\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 7.8086e-05 - val_loss: 1.1078e-04\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.3653e-05 - val_loss: 1.7393e-04\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 5.5860e-05 - val_loss: 5.1402e-04\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.3081e-05 - val_loss: 1.1886e-04\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0573e-05 - val_loss: 9.3551e-04\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.2901e-05 - val_loss: 5.6106e-04\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.9849e-05 - val_loss: 2.4600e-04\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.3338e-05 - val_loss: 1.3170e-04\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.5703e-05 - val_loss: 7.0366e-04\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.4194e-05 - val_loss: 8.9748e-05\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.8375e-05 - val_loss: 1.2027e-04\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.4084e-05 - val_loss: 8.8648e-05\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.1818e-05 - val_loss: 4.9834e-05\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.0755e-05 - val_loss: 6.1290e-05\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4570e-05 - val_loss: 3.0643e-04\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.5251e-05 - val_loss: 1.7504e-04\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.0649e-05 - val_loss: 6.4085e-05\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.9749e-05 - val_loss: 1.5501e-04\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 2.5608e-05 - val_loss: 1.2629e-04\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8805e-05 - val_loss: 1.9986e-04\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.0388e-05 - val_loss: 6.6416e-04\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.4568e-05 - val_loss: 9.6428e-05\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9335e-05 - val_loss: 9.9180e-05\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 8.5905e-05 - val_loss: 0.0015\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.0645e-05 - val_loss: 2.2501e-04\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.6558e-05 - val_loss: 9.3906e-05\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3151e-05 - val_loss: 1.4297e-05\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.1338e-05 - val_loss: 1.2584e-04\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.5993e-05 - val_loss: 2.4401e-05\n",
      ">p=4: 7, Score=0.002119748023687862\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 8s 17ms/step - loss: 0.0023 - val_loss: 0.0102\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.1578e-04 - val_loss: 0.0067\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.2680e-04 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.8621e-04 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.7692e-04 - val_loss: 5.2962e-04\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.3043e-04 - val_loss: 1.9451e-04\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.1341e-04 - val_loss: 9.0381e-04\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.2401e-05 - val_loss: 7.9476e-04\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.6021e-05 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.2569e-05 - val_loss: 0.0016\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.1022e-05 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.4266e-05 - val_loss: 4.9986e-04\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.2000e-05 - val_loss: 3.4068e-04\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.5714e-05 - val_loss: 5.9376e-04\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.8452e-05 - val_loss: 1.2581e-04\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3355e-05 - val_loss: 9.1195e-04\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.2622e-05 - val_loss: 2.0270e-04\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.2257e-05 - val_loss: 3.3286e-04\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.9360e-05 - val_loss: 1.0134e-04\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.0508e-05 - val_loss: 8.1847e-04\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.1445e-05 - val_loss: 2.3287e-04\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.7773e-05 - val_loss: 4.5274e-04\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.1917e-05 - val_loss: 1.8841e-04\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.6074e-05 - val_loss: 3.2627e-04\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.5015e-05 - val_loss: 8.6079e-05\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.6431e-05 - val_loss: 3.2422e-04\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.6318e-05 - val_loss: 4.8074e-04\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9804e-05 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.0906e-05 - val_loss: 1.4847e-04\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.9075e-05 - val_loss: 1.1468e-04\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 5.8143e-05 - val_loss: 8.2082e-05\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.9461e-05 - val_loss: 5.8258e-05\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.6793e-05 - val_loss: 1.1801e-04\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.6797e-05 - val_loss: 1.4403e-04\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.9029e-05 - val_loss: 3.0965e-04\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.2458e-05 - val_loss: 3.8350e-04\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.1804e-05 - val_loss: 9.7841e-05\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.1231e-05 - val_loss: 2.0343e-04\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.4205e-05 - val_loss: 1.7289e-04\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.2281e-05 - val_loss: 1.1295e-04\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 2.5103e-05 - val_loss: 4.6890e-05\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.2032e-05 - val_loss: 1.1283e-04\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.9628e-05 - val_loss: 1.4061e-04\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4783e-05 - val_loss: 1.1326e-04\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7462e-05 - val_loss: 5.3144e-04\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.3973e-05 - val_loss: 1.4962e-05\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 2.6427e-05 - val_loss: 2.7428e-04\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.6048e-05 - val_loss: 0.0014\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9478e-05 - val_loss: 1.1758e-04\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7801e-05 - val_loss: 2.8068e-04\n",
      ">p=4: 8, Score=0.01605550933163613\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 10s 19ms/step - loss: 0.0021 - val_loss: 0.0103\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0073\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.0322e-04 - val_loss: 0.0040\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.3275e-04 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.5291e-04 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.2313e-04 - val_loss: 6.1462e-04\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 9.8813e-05 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.0455e-04 - val_loss: 4.8853e-04\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1340e-04 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.7454e-04 - val_loss: 5.6244e-04\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7133e-05 - val_loss: 2.3419e-04\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.6699e-04 - val_loss: 8.3449e-04\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.2571e-04 - val_loss: 1.2747e-04\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.2824e-05 - val_loss: 2.3998e-04\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.9692e-05 - val_loss: 7.4311e-04\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.1520e-05 - val_loss: 1.1697e-04\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4244e-05 - val_loss: 6.2793e-04\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.0786e-04 - val_loss: 5.5330e-04\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.3390e-05 - val_loss: 1.8711e-04\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.1467e-05 - val_loss: 3.6086e-04\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.2810e-05 - val_loss: 3.7919e-04\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.8805e-05 - val_loss: 8.1086e-05\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.1318e-05 - val_loss: 8.4915e-05\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.8009e-05 - val_loss: 9.5739e-05\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9693e-05 - val_loss: 2.1374e-04\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.2075e-05 - val_loss: 3.0930e-04\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 7.3338e-05 - val_loss: 5.8665e-04\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 7.2793e-05 - val_loss: 3.4476e-04\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.9578e-05 - val_loss: 4.0149e-04\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.5215e-05 - val_loss: 2.3394e-04\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.0716e-05 - val_loss: 4.7242e-04\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4996e-05 - val_loss: 1.0551e-04\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.9793e-05 - val_loss: 7.9455e-04\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.4302e-05 - val_loss: 1.2913e-04\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3812e-05 - val_loss: 2.3467e-04\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.4806e-05 - val_loss: 3.0054e-04\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.6435e-05 - val_loss: 1.6872e-04\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8631e-05 - val_loss: 1.5615e-04\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.6873e-05 - val_loss: 8.4795e-04\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.6137e-05 - val_loss: 1.0914e-04\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 2s 16ms/step - loss: 5.9430e-05 - val_loss: 4.6799e-04\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.9956e-05 - val_loss: 1.1987e-04\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.3356e-05 - val_loss: 2.4430e-04\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 3.4963e-05 - val_loss: 4.5122e-05\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.3837e-05 - val_loss: 2.3692e-04\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.6441e-05 - val_loss: 4.2921e-04\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.4393e-05 - val_loss: 3.9761e-05\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4103e-05 - val_loss: 5.2226e-05\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 3.9895e-05 - val_loss: 6.9948e-05\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 3.9418e-05 - val_loss: 7.4561e-05\n",
      ">p=4: 9, Score=0.010964515240630135\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 11s 22ms/step - loss: 0.0021 - val_loss: 0.0099\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.0665e-04 - val_loss: 0.0067\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.0959e-04 - val_loss: 0.0035\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 3.4953e-04 - val_loss: 0.0018\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.4525e-04 - val_loss: 6.9206e-04\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.3965e-04 - val_loss: 4.1813e-04\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.1097e-04 - val_loss: 2.0641e-04\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.3877e-04 - val_loss: 3.5313e-04\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.7779e-05 - val_loss: 2.5495e-04\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 9.3165e-05 - val_loss: 3.9866e-04\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.4917e-05 - val_loss: 7.7131e-04\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.4572e-05 - val_loss: 2.0698e-04\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.8128e-05 - val_loss: 1.7035e-04\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 1.3669e-04 - val_loss: 6.6525e-04\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.1315e-04 - val_loss: 3.0207e-04\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 5.3828e-05 - val_loss: 1.0459e-04\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 6.1985e-05 - val_loss: 1.7435e-04\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.4012e-05 - val_loss: 4.8602e-04\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 8.3343e-05 - val_loss: 1.3174e-04\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 4.8325e-05 - val_loss: 1.5105e-04\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 4.5974e-05 - val_loss: 4.8469e-04\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.6879e-05 - val_loss: 2.4244e-04\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 4.5090e-05 - val_loss: 6.0874e-05\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.5324e-05 - val_loss: 4.4523e-04\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.6797e-05 - val_loss: 1.8317e-04\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 8.1382e-05 - val_loss: 7.6475e-04\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 6.8828e-05 - val_loss: 6.3685e-05\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 4.2844e-05 - val_loss: 2.9289e-04\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0552e-05 - val_loss: 1.0453e-04\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7681e-05 - val_loss: 4.9085e-05\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 4.3198e-05 - val_loss: 8.3082e-05\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2958e-05 - val_loss: 1.1275e-04\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7184e-05 - val_loss: 8.1590e-05\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.3368e-05 - val_loss: 1.1491e-04\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 3.7566e-05 - val_loss: 3.6736e-04\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.4463e-05 - val_loss: 1.5032e-04\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 7.0241e-05 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 6.3771e-05 - val_loss: 1.1307e-04\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 1.8983e-05 - val_loss: 3.3501e-05\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.7376e-05 - val_loss: 5.0670e-05\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.0441e-05 - val_loss: 9.8508e-04\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 6.5234e-05 - val_loss: 9.8662e-05\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 1.8238e-05 - val_loss: 6.0974e-05\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 1.7742e-05 - val_loss: 1.0991e-04\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.2122e-05 - val_loss: 4.3697e-05\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 1.8409e-05 - val_loss: 3.3432e-05\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 2s 11ms/step - loss: 2.0026e-05 - val_loss: 1.0633e-04\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 4.3740e-05 - val_loss: 6.0033e-05\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.8570e-05 - val_loss: 1.4443e-04\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 2s 10ms/step - loss: 2.7807e-05 - val_loss: 1.1157e-04\n",
      ">p=4: 10, Score=0.008765428356127813\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 10s 23ms/step - loss: 0.0025 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0011 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 9.0028e-04 - val_loss: 0.0069\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.6990e-04 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.3368e-04 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.9289e-04 - val_loss: 8.1786e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6106e-04 - val_loss: 4.5896e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.5745e-04 - val_loss: 8.7508e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.4398e-04 - val_loss: 1.8558e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.1768e-04 - val_loss: 2.1611e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 9.2159e-05 - val_loss: 1.6960e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.7200e-04 - val_loss: 2.8074e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1198e-04 - val_loss: 1.8058e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.0722e-05 - val_loss: 2.4183e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 7.3050e-05 - val_loss: 1.5710e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.9525e-05 - val_loss: 1.2434e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 4.3400e-05 - val_loss: 3.8788e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 4.6649e-05 - val_loss: 2.1239e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.0834e-05 - val_loss: 4.2082e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 6.7398e-05 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.0632e-05 - val_loss: 4.5174e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 5.6783e-05 - val_loss: 6.6823e-05\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 6.4628e-05 - val_loss: 4.2028e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2527e-04 - val_loss: 3.1370e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 5.6444e-05 - val_loss: 4.5991e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 8.1005e-05 - val_loss: 2.4732e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.3582e-05 - val_loss: 1.8152e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.1552e-05 - val_loss: 1.9670e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 6.9769e-05 - val_loss: 2.0801e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.9431e-05 - val_loss: 1.4238e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 6.0745e-05 - val_loss: 3.9261e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.0992e-05 - val_loss: 1.7131e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.1053e-05 - val_loss: 8.2105e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.5414e-05 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.0540e-04 - val_loss: 3.5818e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.6112e-05 - val_loss: 1.1745e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.7641e-05 - val_loss: 1.5135e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.6571e-05 - val_loss: 3.3999e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.4294e-05 - val_loss: 2.0259e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.0651e-05 - val_loss: 3.1271e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.1068e-05 - val_loss: 3.7239e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.5684e-05 - val_loss: 5.6258e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.9207e-05 - val_loss: 2.0504e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.4118e-05 - val_loss: 5.8610e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.5626e-05 - val_loss: 4.7110e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.9271e-05 - val_loss: 6.4634e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.4246e-05 - val_loss: 2.3166e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.0758e-05 - val_loss: 3.0710e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.1758e-05 - val_loss: 3.0590e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.2914e-05 - val_loss: 1.5109e-04\n",
      ">p=5: 1, Score=0.013650418259203434\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 20ms/step - loss: 0.0023 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 0.0083\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.8797e-04 - val_loss: 0.0056\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.6856e-04 - val_loss: 0.0033\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.2468e-04 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.1919e-04 - val_loss: 5.7433e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6805e-04 - val_loss: 3.0595e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 9.4957e-05 - val_loss: 4.7627e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.2244e-04 - val_loss: 2.7392e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.2597e-04 - val_loss: 3.6763e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 9.7792e-05 - val_loss: 2.6572e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 8.2913e-05 - val_loss: 2.5332e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 9.4770e-05 - val_loss: 1.6651e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.0310e-04 - val_loss: 1.7871e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 8.1442e-05 - val_loss: 0.0010\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 6.7017e-05 - val_loss: 1.6107e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.5596e-05 - val_loss: 3.7434e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.7498e-05 - val_loss: 4.5221e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.1609e-04 - val_loss: 7.9833e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.7049e-05 - val_loss: 3.8334e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.7131e-05 - val_loss: 1.4122e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 7.6348e-05 - val_loss: 1.0478e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.7459e-05 - val_loss: 2.6624e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 6.3258e-05 - val_loss: 1.5637e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 7.5136e-05 - val_loss: 4.5317e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 4.6097e-05 - val_loss: 6.2106e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 4.5521e-05 - val_loss: 2.7296e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 5.4259e-05 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 3.6532e-05 - val_loss: 6.2756e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 4.7157e-05 - val_loss: 1.0964e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.0482e-04 - val_loss: 4.0882e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 7.7321e-05 - val_loss: 2.3119e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 9.0472e-05 - val_loss: 7.3130e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 9.6380e-05 - val_loss: 4.5616e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 3s 22ms/step - loss: 7.5559e-05 - val_loss: 3.8483e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 4.6493e-05 - val_loss: 1.6503e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 3.8627e-05 - val_loss: 7.7927e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 2.4652e-05 - val_loss: 1.2935e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 6.1461e-05 - val_loss: 4.2003e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 4.2747e-05 - val_loss: 1.7505e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.7212e-05 - val_loss: 1.7755e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 3.9167e-05 - val_loss: 7.0819e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 2.5789e-05 - val_loss: 4.3644e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 2.3381e-05 - val_loss: 5.2154e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 2.4064e-05 - val_loss: 5.8611e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 2.1398e-05 - val_loss: 7.2736e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 3.2402e-05 - val_loss: 4.1801e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.7394e-05 - val_loss: 7.7709e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.0534e-05 - val_loss: 3.6651e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 3.8042e-05 - val_loss: 3.8518e-04\n",
      ">p=5: 2, Score=0.018639082554727793\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 12s 29ms/step - loss: 0.0024 - val_loss: 0.0105\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0084\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 8.7363e-04 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 6.5369e-04 - val_loss: 0.0031\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 3.6401e-04 - val_loss: 0.0020\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 2.1072e-04 - val_loss: 5.1703e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.6348e-04 - val_loss: 8.8179e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.2883e-04 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.7885e-04 - val_loss: 1.9114e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 8.9722e-05 - val_loss: 1.7275e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 9.6665e-05 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.2196e-05 - val_loss: 9.3787e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.0189e-04 - val_loss: 2.6516e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 8.6983e-05 - val_loss: 2.9142e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 7.5013e-05 - val_loss: 1.8999e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 7.7495e-05 - val_loss: 3.2965e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 5.9983e-05 - val_loss: 1.4349e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 9.2933e-05 - val_loss: 3.8654e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 6.2793e-05 - val_loss: 1.9674e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 9.4343e-05 - val_loss: 4.5426e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 9.6359e-05 - val_loss: 3.6398e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 1.2825e-04 - val_loss: 3.2152e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.3553e-05 - val_loss: 5.8162e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 4.4987e-05 - val_loss: 1.1011e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 5.6641e-05 - val_loss: 2.5147e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 6.3196e-05 - val_loss: 2.4481e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.1969e-04 - val_loss: 0.0020\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.5473e-04 - val_loss: 8.3842e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.2330e-05 - val_loss: 3.8166e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 3.6530e-05 - val_loss: 1.6278e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 3.3692e-05 - val_loss: 7.2449e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 4.0612e-05 - val_loss: 2.0832e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 6.0981e-05 - val_loss: 4.6991e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 4.9583e-05 - val_loss: 2.9353e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 3.9351e-05 - val_loss: 1.8430e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 3.2214e-05 - val_loss: 1.4942e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 5.7012e-05 - val_loss: 8.7860e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 2.6835e-05 - val_loss: 8.4260e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.3705e-05 - val_loss: 4.2665e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 2.6386e-05 - val_loss: 8.4129e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.8085e-05 - val_loss: 9.0894e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.9243e-05 - val_loss: 1.3689e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 3.0569e-05 - val_loss: 1.3586e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 3.2335e-05 - val_loss: 2.3333e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.7958e-05 - val_loss: 4.4371e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 1.8807e-05 - val_loss: 1.0727e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.0004e-05 - val_loss: 6.7805e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.8642e-05 - val_loss: 9.5859e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 2.0443e-05 - val_loss: 1.3297e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.5764e-05 - val_loss: 4.2943e-04\n",
      ">p=5: 3, Score=0.018123419431503862\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 12s 34ms/step - loss: 0.0024 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 0.0011 - val_loss: 0.0083\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 8.0169e-04 - val_loss: 0.0056\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 5.3666e-04 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 3.7820e-04 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 2.4042e-04 - val_loss: 7.7934e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 3s 24ms/step - loss: 1.5652e-04 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 9.4730e-05 - val_loss: 2.2533e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.5454e-04 - val_loss: 3.8832e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 1.6685e-04 - val_loss: 1.5212e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 1.0261e-04 - val_loss: 2.4616e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 3s 23ms/step - loss: 1.1546e-04 - val_loss: 9.6364e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 8.5586e-05 - val_loss: 2.7782e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 9.2831e-05 - val_loss: 1.3753e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.1337e-04 - val_loss: 3.7387e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 6.8166e-05 - val_loss: 1.7547e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 7.0602e-05 - val_loss: 1.7729e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.2302e-05 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.6713e-05 - val_loss: 8.3449e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.0080e-05 - val_loss: 3.3714e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.7402e-05 - val_loss: 6.5978e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.7114e-05 - val_loss: 2.6258e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.6033e-05 - val_loss: 1.1380e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.2125e-04 - val_loss: 5.3564e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0163e-04 - val_loss: 1.3727e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.3964e-05 - val_loss: 3.4690e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.1194e-05 - val_loss: 7.9663e-05\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.0725e-05 - val_loss: 3.4035e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.8932e-05 - val_loss: 4.7275e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.9559e-05 - val_loss: 9.9876e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 7.0636e-05 - val_loss: 4.4579e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.8043e-05 - val_loss: 3.8430e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.3538e-05 - val_loss: 1.6954e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 3.2335e-05 - val_loss: 9.4285e-05\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 3.2777e-05 - val_loss: 5.9096e-05\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 4.1084e-05 - val_loss: 5.4706e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.4684e-05 - val_loss: 1.1422e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 4.4500e-05 - val_loss: 1.6875e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.9109e-05 - val_loss: 6.6319e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 3.7124e-05 - val_loss: 2.2478e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.4944e-05 - val_loss: 1.6946e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.5701e-05 - val_loss: 7.7326e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.9499e-05 - val_loss: 2.8513e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 3.1945e-05 - val_loss: 5.9206e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 3.4612e-05 - val_loss: 5.5274e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 3.2218e-05 - val_loss: 3.8093e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 2.2552e-05 - val_loss: 1.5456e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 8.2416e-05 - val_loss: 7.3306e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 3.8252e-05 - val_loss: 2.8874e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 2.2290e-05 - val_loss: 2.2017e-05\n",
      ">p=5: 4, Score=0.0018933114915853366\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 12s 23ms/step - loss: 0.0024 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0086\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.4599e-04 - val_loss: 0.0063\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.9056e-04 - val_loss: 0.0038\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 4.1626e-04 - val_loss: 0.0020\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 2.6090e-04 - val_loss: 9.8341e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.6948e-04 - val_loss: 7.0934e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 1.8530e-04 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.0021e-04 - val_loss: 1.7839e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.4828e-04 - val_loss: 4.4781e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 9.5940e-05 - val_loss: 3.5928e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 7.6183e-05 - val_loss: 2.5522e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 5.7735e-05 - val_loss: 3.3810e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 6.6437e-05 - val_loss: 2.1457e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 6.8345e-05 - val_loss: 7.4746e-05\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 7.7589e-05 - val_loss: 1.1291e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.5700e-05 - val_loss: 1.5820e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.8190e-05 - val_loss: 6.3847e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.7813e-05 - val_loss: 1.8265e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.3418e-05 - val_loss: 2.4121e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.0418e-05 - val_loss: 1.0667e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 6.6786e-05 - val_loss: 9.9960e-05\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.6714e-05 - val_loss: 2.8933e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.7833e-05 - val_loss: 9.7818e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 8.4928e-05 - val_loss: 5.4932e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 5.4779e-05 - val_loss: 3.6617e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 9.0901e-05 - val_loss: 7.1878e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.0735e-04 - val_loss: 2.5306e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 8.7778e-05 - val_loss: 4.3343e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 6.3236e-05 - val_loss: 1.3946e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 3.0131e-05 - val_loss: 6.8615e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 2.1861e-05 - val_loss: 2.9875e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 3.5479e-05 - val_loss: 1.3745e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.7025e-05 - val_loss: 5.9374e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.8286e-05 - val_loss: 3.0078e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.0322e-05 - val_loss: 7.2039e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.3123e-05 - val_loss: 4.3705e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.8489e-05 - val_loss: 3.4004e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.7971e-05 - val_loss: 2.9173e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.7879e-05 - val_loss: 1.3027e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.2676e-05 - val_loss: 3.5080e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.0674e-05 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.1558e-05 - val_loss: 1.3027e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.1528e-05 - val_loss: 4.9116e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 4.0738e-05 - val_loss: 1.2018e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 3.2197e-05 - val_loss: 4.5341e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.9121e-05 - val_loss: 6.0383e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.6270e-05 - val_loss: 3.1246e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.7288e-05 - val_loss: 4.7316e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.9167e-05 - val_loss: 2.6978e-05\n",
      ">p=5: 5, Score=0.0025785919206100516\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 12s 31ms/step - loss: 0.0023 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.0011 - val_loss: 0.0089\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.4678e-04 - val_loss: 0.0063\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.9081e-04 - val_loss: 0.0037\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.0018e-04 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.7916e-04 - val_loss: 7.0130e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 1.8805e-04 - val_loss: 2.9415e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 2s 18ms/step - loss: 1.0923e-04 - val_loss: 5.9146e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.1600e-04 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.4585e-04 - val_loss: 1.6203e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 8.6817e-05 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.0825e-05 - val_loss: 7.9015e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 8.4112e-05 - val_loss: 8.9564e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 7.1001e-05 - val_loss: 2.3811e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.0840e-05 - val_loss: 7.2895e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 9.2779e-05 - val_loss: 3.3055e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.9834e-05 - val_loss: 2.3328e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 8.5540e-05 - val_loss: 5.3648e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 4.6919e-05 - val_loss: 6.2735e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.8174e-05 - val_loss: 3.1499e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.0130e-04 - val_loss: 2.3473e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 7.1052e-05 - val_loss: 1.5804e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.6122e-05 - val_loss: 1.9425e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.1659e-05 - val_loss: 6.2503e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.7526e-05 - val_loss: 1.0267e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.7611e-05 - val_loss: 4.3499e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 9.0681e-05 - val_loss: 7.4407e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.2498e-05 - val_loss: 1.9937e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.5028e-05 - val_loss: 1.0311e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.2125e-05 - val_loss: 8.1219e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.3343e-05 - val_loss: 4.7230e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.9614e-05 - val_loss: 3.4377e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.6790e-05 - val_loss: 1.1990e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.4564e-05 - val_loss: 1.1607e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.6316e-05 - val_loss: 1.4053e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.9513e-05 - val_loss: 1.5619e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.7513e-05 - val_loss: 4.6603e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.9144e-05 - val_loss: 1.9280e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.3976e-05 - val_loss: 3.9979e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.0786e-05 - val_loss: 1.8456e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.2466e-05 - val_loss: 3.1697e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.2235e-05 - val_loss: 2.5938e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.7477e-05 - val_loss: 3.5763e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.4206e-05 - val_loss: 2.8381e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.1369e-05 - val_loss: 1.0533e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.7986e-05 - val_loss: 7.4421e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.8346e-05 - val_loss: 3.5543e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.5029e-05 - val_loss: 1.6752e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.2642e-05 - val_loss: 5.2541e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.8225e-05 - val_loss: 2.8937e-04\n",
      ">p=5: 6, Score=0.0210278041777201\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 11s 25ms/step - loss: 0.0024 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0084\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.7558e-04 - val_loss: 0.0052\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.2538e-04 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.4524e-04 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.8149e-04 - val_loss: 3.5234e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1329e-04 - val_loss: 9.9739e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3177e-04 - val_loss: 0.0016\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.0911e-04 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.0523e-04 - val_loss: 2.8336e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.9319e-05 - val_loss: 5.9293e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.4930e-05 - val_loss: 1.4254e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.7084e-04 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.4201e-04 - val_loss: 2.2730e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.3887e-05 - val_loss: 1.3123e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.4706e-05 - val_loss: 6.1768e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.9832e-05 - val_loss: 2.0029e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.9675e-05 - val_loss: 1.1705e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 7.1149e-05 - val_loss: 1.1908e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.7077e-05 - val_loss: 8.5350e-05\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.6600e-05 - val_loss: 2.3463e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.7907e-05 - val_loss: 3.0278e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 3.9363e-05 - val_loss: 3.8602e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.4723e-05 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.0302e-04 - val_loss: 9.0807e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.3725e-05 - val_loss: 3.4776e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.4345e-05 - val_loss: 8.3364e-05\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.3312e-05 - val_loss: 1.8837e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.9751e-05 - val_loss: 3.0356e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.1835e-05 - val_loss: 2.0388e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.6882e-05 - val_loss: 1.8015e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.3721e-05 - val_loss: 1.4716e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.2274e-05 - val_loss: 5.3059e-05\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.8290e-05 - val_loss: 3.1385e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.6828e-05 - val_loss: 6.2548e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.9253e-05 - val_loss: 5.8466e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.7527e-05 - val_loss: 4.1834e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.8973e-05 - val_loss: 4.0162e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.4327e-05 - val_loss: 2.8667e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.0781e-05 - val_loss: 0.0017\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.3930e-04 - val_loss: 6.0591e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 7.2040e-05 - val_loss: 1.8178e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.7509e-05 - val_loss: 4.8244e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.0429e-05 - val_loss: 6.5729e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.2218e-05 - val_loss: 9.8883e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.3166e-05 - val_loss: 9.6539e-06\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.8967e-05 - val_loss: 2.4524e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.3180e-05 - val_loss: 2.4597e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.8758e-05 - val_loss: 5.3506e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.2104e-05 - val_loss: 6.6619e-05\n",
      ">p=5: 7, Score=0.0054935357184149325\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 12s 23ms/step - loss: 0.0024 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.0498e-04 - val_loss: 0.0054\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 5.3930e-04 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 3.2743e-04 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.2259e-04 - val_loss: 6.9599e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.6620e-04 - val_loss: 5.5359e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.0256e-04 - val_loss: 4.2280e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.2005e-05 - val_loss: 5.1751e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.2383e-05 - val_loss: 3.7235e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.7278e-05 - val_loss: 2.4134e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.1601e-05 - val_loss: 9.4975e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.0979e-04 - val_loss: 3.0512e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.0417e-04 - val_loss: 6.6672e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 9.7526e-05 - val_loss: 5.1356e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.3409e-05 - val_loss: 3.5184e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.8410e-05 - val_loss: 3.6428e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.1690e-05 - val_loss: 4.5205e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.5598e-05 - val_loss: 1.1152e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.5130e-05 - val_loss: 2.9092e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.9490e-05 - val_loss: 6.6412e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.5943e-05 - val_loss: 2.2680e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.0194e-04 - val_loss: 5.5753e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.2355e-04 - val_loss: 4.3433e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 4.8460e-05 - val_loss: 1.0640e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.4553e-05 - val_loss: 6.0435e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.1345e-04 - val_loss: 9.2634e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.2027e-04 - val_loss: 3.2712e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.3282e-05 - val_loss: 1.4276e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.6274e-05 - val_loss: 6.4284e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.5329e-05 - val_loss: 5.2323e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.4981e-05 - val_loss: 7.6644e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.4224e-05 - val_loss: 1.6654e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.5072e-05 - val_loss: 1.7050e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.1829e-05 - val_loss: 1.0372e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.2412e-05 - val_loss: 7.5790e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.0733e-05 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 6.2877e-05 - val_loss: 6.6102e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.1784e-05 - val_loss: 7.3155e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.9657e-05 - val_loss: 3.4844e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.0958e-05 - val_loss: 1.3321e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.3376e-05 - val_loss: 1.2936e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.7082e-05 - val_loss: 5.2035e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.3779e-05 - val_loss: 1.9892e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.3571e-05 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.7791e-05 - val_loss: 1.1341e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.4758e-05 - val_loss: 3.8061e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 2.7454e-05 - val_loss: 2.9267e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.3281e-05 - val_loss: 1.7150e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 3.8590e-05 - val_loss: 3.0994e-04\n",
      ">p=5: 8, Score=0.02021588443312794\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 11s 24ms/step - loss: 0.0024 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.0011 - val_loss: 0.0091\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.1480e-04 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 6.2233e-04 - val_loss: 0.0036\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.5200e-04 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0970e-04 - val_loss: 4.0953e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.8790e-04 - val_loss: 4.2961e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.3832e-04 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 9.8557e-05 - val_loss: 6.4381e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.3802e-04 - val_loss: 1.9898e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.6985e-05 - val_loss: 3.3423e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.1748e-05 - val_loss: 8.2114e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.5811e-05 - val_loss: 3.6182e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.1831e-04 - val_loss: 2.1865e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.4038e-05 - val_loss: 3.3308e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.2846e-05 - val_loss: 2.3101e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.3906e-05 - val_loss: 5.0715e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.5233e-05 - val_loss: 5.3687e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.7748e-05 - val_loss: 8.2790e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.2902e-05 - val_loss: 1.4891e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.8208e-04 - val_loss: 0.0016\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.3137e-04 - val_loss: 7.6554e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.9999e-05 - val_loss: 1.4021e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.6738e-05 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.1395e-05 - val_loss: 5.8294e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.5957e-05 - val_loss: 3.1175e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.5741e-05 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 6.5599e-05 - val_loss: 3.5057e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.3155e-05 - val_loss: 7.6153e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.1279e-05 - val_loss: 6.8819e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.8782e-05 - val_loss: 4.0826e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.4877e-05 - val_loss: 1.9096e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.6632e-05 - val_loss: 7.9368e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.1918e-05 - val_loss: 1.6252e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.2133e-05 - val_loss: 0.0017\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.6853e-05 - val_loss: 4.1631e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.0020e-04 - val_loss: 3.1164e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.1338e-05 - val_loss: 8.1349e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 3.4102e-05 - val_loss: 1.5982e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 3.7751e-05 - val_loss: 1.2668e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.7503e-05 - val_loss: 5.5458e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.5080e-05 - val_loss: 5.8153e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.5724e-05 - val_loss: 1.0259e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.7297e-05 - val_loss: 3.1911e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.3580e-05 - val_loss: 1.6728e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.6561e-05 - val_loss: 9.1906e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 3.0256e-05 - val_loss: 7.3617e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.2302e-05 - val_loss: 2.2975e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.8244e-05 - val_loss: 7.7980e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.8662e-05 - val_loss: 2.1750e-04\n",
      ">p=5: 9, Score=0.015621677448507398\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 11s 24ms/step - loss: 0.0025 - val_loss: 0.0109\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0011 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.9772e-04 - val_loss: 0.0059\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.5954e-04 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.7138e-04 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.3496e-04 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.4637e-04 - val_loss: 8.5560e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.2351e-04 - val_loss: 2.6495e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.7229e-05 - val_loss: 5.1833e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.0291e-04 - val_loss: 5.8686e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.0536e-05 - val_loss: 0.0017\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.0964e-04 - val_loss: 9.8379e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.1743e-04 - val_loss: 1.8450e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.4202e-05 - val_loss: 2.1264e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.3985e-05 - val_loss: 3.4228e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 7.7284e-05 - val_loss: 1.6504e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.1760e-05 - val_loss: 1.3874e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.5806e-05 - val_loss: 2.2705e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.0202e-05 - val_loss: 2.0876e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.3120e-04 - val_loss: 7.7214e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.6884e-05 - val_loss: 3.1737e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.4230e-04 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.3284e-05 - val_loss: 1.7082e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.6944e-05 - val_loss: 6.0406e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.1931e-05 - val_loss: 1.5795e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.4493e-05 - val_loss: 1.4647e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.1816e-05 - val_loss: 6.1654e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.8334e-05 - val_loss: 4.1450e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.6100e-05 - val_loss: 3.1624e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.9792e-05 - val_loss: 2.4382e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.0434e-05 - val_loss: 3.4588e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.9837e-05 - val_loss: 1.4693e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.8745e-05 - val_loss: 2.4245e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.5150e-05 - val_loss: 1.4913e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.1347e-05 - val_loss: 5.6684e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.6273e-05 - val_loss: 1.1726e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.6916e-05 - val_loss: 1.6322e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.7255e-05 - val_loss: 1.3583e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.6945e-05 - val_loss: 6.8992e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.5088e-05 - val_loss: 1.1648e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 4.0988e-05 - val_loss: 7.8720e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.0069e-05 - val_loss: 1.5646e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.7281e-05 - val_loss: 6.6191e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 3.8981e-05 - val_loss: 2.8464e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.3628e-05 - val_loss: 1.5419e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0459e-05 - val_loss: 1.0684e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.7069e-05 - val_loss: 4.5842e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.1641e-05 - val_loss: 1.1686e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.3690e-05 - val_loss: 4.6156e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.7975e-05 - val_loss: 4.2845e-05\n",
      ">p=5: 10, Score=0.0031437368306796998\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 9s 34ms/step - loss: 0.0024 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 0.0084\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.7018e-04 - val_loss: 0.0058\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.7084e-04 - val_loss: 0.0033\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.9218e-04 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 2.3682e-04 - val_loss: 5.3129e-04\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.6349e-04 - val_loss: 3.5411e-04\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.1011e-04 - val_loss: 4.8208e-04\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 9.1964e-05 - val_loss: 2.5857e-04\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.0728e-04 - val_loss: 3.0173e-04\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.1953e-04 - val_loss: 1.0098e-04\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 9.9326e-05 - val_loss: 0.0020\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.0003e-04 - val_loss: 5.5274e-04\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 9.6433e-05 - val_loss: 2.5261e-04\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 5.8696e-05 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.9731e-05 - val_loss: 2.9182e-04\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.4015e-05 - val_loss: 2.1433e-04\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.3071e-05 - val_loss: 2.2362e-04\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.1993e-05 - val_loss: 2.4963e-04\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.0973e-05 - val_loss: 2.8236e-04\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.0053e-04 - val_loss: 1.0807e-04\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.4239e-05 - val_loss: 1.4892e-04\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.2495e-05 - val_loss: 1.6513e-04\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.2968e-05 - val_loss: 1.0813e-04\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.0975e-05 - val_loss: 7.5170e-05\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.8470e-05 - val_loss: 7.4017e-05\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 2.8253e-05 - val_loss: 8.7020e-05\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.1401e-05 - val_loss: 9.4165e-05\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 7.3096e-05 - val_loss: 4.4019e-04\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.8230e-05 - val_loss: 9.4537e-05\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.0898e-05 - val_loss: 1.0318e-04\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.9167e-05 - val_loss: 1.4435e-04\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 4.6555e-05 - val_loss: 4.0957e-05\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.3365e-05 - val_loss: 1.0316e-04\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.3876e-05 - val_loss: 1.0357e-04\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.6270e-05 - val_loss: 2.3188e-04\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 3.7813e-05 - val_loss: 4.3102e-05\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 2.2856e-05 - val_loss: 7.6640e-05\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 3.7418e-05 - val_loss: 3.1062e-04\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 5.2308e-05 - val_loss: 4.6511e-05\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.7278e-05 - val_loss: 6.4061e-05\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 2.4085e-05 - val_loss: 5.1885e-05\n",
      "Epoch 43/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 6.2045e-05 - val_loss: 6.0599e-04\n",
      "Epoch 44/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.9138e-05 - val_loss: 9.4998e-05\n",
      "Epoch 45/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.1745e-05 - val_loss: 2.4141e-05\n",
      "Epoch 46/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.2838e-05 - val_loss: 1.2233e-04\n",
      "Epoch 47/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.9913e-05 - val_loss: 8.8707e-05\n",
      "Epoch 48/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.8290e-05 - val_loss: 3.9566e-05\n",
      "Epoch 49/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.9765e-05 - val_loss: 2.3962e-05\n",
      "Epoch 50/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.8664e-05 - val_loss: 7.4778e-05\n",
      ">p=6: 1, Score=0.00641850201645866\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 9s 28ms/step - loss: 0.0025 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 0.0011 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 8.7491e-04 - val_loss: 0.0065\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 6.6539e-04 - val_loss: 0.0042\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 4.3303e-04 - val_loss: 0.0025\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 2.9997e-04 - val_loss: 9.6003e-04\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.6772e-04 - val_loss: 0.0010\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.2564e-04 - val_loss: 2.2087e-04\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.8408e-05 - val_loss: 8.1840e-04\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.0360e-04 - val_loss: 4.1415e-04\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.0868e-04 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.1000e-05 - val_loss: 3.6513e-04\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 8.4968e-05 - val_loss: 7.1498e-04\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 6.2233e-05 - val_loss: 1.8647e-04\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.7877e-05 - val_loss: 2.3597e-04\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 2s 15ms/step - loss: 6.2124e-05 - val_loss: 6.1626e-04\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 5.1177e-05 - val_loss: 1.8092e-04\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 6.2615e-05 - val_loss: 1.5227e-04\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.2791e-05 - val_loss: 5.8916e-04\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 8.2239e-05 - val_loss: 3.2132e-04\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.6005e-05 - val_loss: 1.6186e-04\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 4.2544e-05 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 7.2315e-05 - val_loss: 4.3691e-04\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 6.9008e-05 - val_loss: 1.1432e-04\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.6836e-05 - val_loss: 7.4705e-05\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.3423e-05 - val_loss: 4.3601e-04\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.6104e-05 - val_loss: 1.4230e-04\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 6.5066e-05 - val_loss: 2.0727e-04\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.5591e-05 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 2.9151e-05 - val_loss: 1.1021e-04\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.2101e-04 - val_loss: 0.0017\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 9.4995e-05 - val_loss: 5.4145e-05\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 4.8466e-05 - val_loss: 1.1920e-04\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.2802e-05 - val_loss: 3.7356e-04\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.0141e-05 - val_loss: 1.8141e-04\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 4.3280e-05 - val_loss: 1.5397e-04\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.1263e-05 - val_loss: 4.1556e-04\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.2615e-05 - val_loss: 2.5195e-05\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 2.9601e-05 - val_loss: 4.6032e-04\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.2701e-05 - val_loss: 3.6636e-04\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 2.4381e-05 - val_loss: 4.2140e-04\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.3275e-05 - val_loss: 8.7503e-05\n",
      "Epoch 43/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 4.6945e-05 - val_loss: 8.5292e-05\n",
      "Epoch 44/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.1601e-05 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 4.0599e-05 - val_loss: 6.9023e-05\n",
      "Epoch 46/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 2.6972e-05 - val_loss: 5.7661e-04\n",
      "Epoch 47/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.4897e-05 - val_loss: 1.1097e-04\n",
      "Epoch 48/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.3304e-05 - val_loss: 7.9572e-04\n",
      "Epoch 49/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 2.9346e-05 - val_loss: 9.6288e-05\n",
      "Epoch 50/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.9785e-05 - val_loss: 2.3511e-04\n",
      ">p=6: 2, Score=0.016988209972623736\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 9s 34ms/step - loss: 0.0026 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 8.2671e-04 - val_loss: 0.0058\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.6350e-04 - val_loss: 0.0033\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.8679e-04 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 2.4515e-04 - val_loss: 7.1370e-04\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.9169e-04 - val_loss: 6.7549e-04\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.2779e-04 - val_loss: 4.1767e-04\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.1490e-04 - val_loss: 2.6806e-04\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.2916e-05 - val_loss: 5.4936e-04\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.4185e-05 - val_loss: 9.4438e-04\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.1645e-04 - val_loss: 4.7540e-04\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 9.5914e-05 - val_loss: 2.9535e-04\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 7.7804e-05 - val_loss: 4.8419e-04\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.5256e-05 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.8921e-05 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.9049e-05 - val_loss: 3.9711e-04\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.1087e-05 - val_loss: 3.2396e-04\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 9.5178e-05 - val_loss: 1.8660e-04\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 8.9006e-05 - val_loss: 5.9333e-04\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.3922e-04 - val_loss: 2.2348e-04\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 7.2867e-05 - val_loss: 7.5555e-04\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.8767e-05 - val_loss: 3.7634e-04\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.6304e-05 - val_loss: 4.1622e-04\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.9644e-05 - val_loss: 2.1913e-04\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.6788e-05 - val_loss: 2.8310e-04\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 8.5445e-05 - val_loss: 2.8718e-04\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.6412e-05 - val_loss: 1.6522e-04\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 4.0402e-05 - val_loss: 6.0040e-04\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.2826e-05 - val_loss: 6.6294e-05\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.8759e-05 - val_loss: 1.9724e-04\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.1138e-05 - val_loss: 2.2992e-04\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 6.2526e-05 - val_loss: 2.2201e-04\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 5.1077e-05 - val_loss: 3.9921e-05\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.8348e-05 - val_loss: 3.5451e-04\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.2203e-05 - val_loss: 1.4535e-04\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.4509e-05 - val_loss: 3.3230e-04\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.0237e-05 - val_loss: 1.0903e-04\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 2.5316e-05 - val_loss: 9.2295e-05\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.1945e-05 - val_loss: 1.5871e-04\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 3.4634e-05 - val_loss: 8.7504e-05\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.1595e-05 - val_loss: 5.7590e-05\n",
      "Epoch 43/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 5.3857e-05 - val_loss: 4.6579e-04\n",
      "Epoch 44/50\n",
      "101/101 [==============================] - 2s 15ms/step - loss: 4.7546e-05 - val_loss: 1.7855e-04\n",
      "Epoch 45/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 2.4155e-05 - val_loss: 9.9966e-06\n",
      "Epoch 46/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 2.3770e-05 - val_loss: 1.1878e-04\n",
      "Epoch 47/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.7681e-05 - val_loss: 4.1972e-04\n",
      "Epoch 48/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 7.2071e-05 - val_loss: 0.0011\n",
      "Epoch 49/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 3.5654e-05 - val_loss: 4.6653e-05\n",
      "Epoch 50/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.6317e-05 - val_loss: 5.8910e-05\n",
      ">p=6: 3, Score=0.007438402099069208\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 11s 35ms/step - loss: 0.0025 - val_loss: 0.0102\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 9.5729e-04 - val_loss: 0.0078\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.8172e-04 - val_loss: 0.0051\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 1s 15ms/step - loss: 5.3498e-04 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 3.5283e-04 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 2.2203e-04 - val_loss: 8.5773e-04\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.5190e-04 - val_loss: 7.8377e-04\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.3107e-04 - val_loss: 6.4958e-04\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.0024e-04 - val_loss: 3.7830e-04\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.0586e-04 - val_loss: 1.4428e-04\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 9.3531e-05 - val_loss: 1.7035e-04\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 8.0046e-05 - val_loss: 3.1809e-04\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 9.1874e-05 - val_loss: 5.8488e-04\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.4858e-05 - val_loss: 3.2106e-04\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 7.6901e-05 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 6.2115e-05 - val_loss: 3.2673e-04\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 6.0243e-05 - val_loss: 8.1492e-05\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 8.0118e-05 - val_loss: 2.0633e-04\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 8.9971e-05 - val_loss: 2.3060e-04\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 7.5191e-05 - val_loss: 1.3398e-04\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 6.2810e-05 - val_loss: 4.3217e-04\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 1s 15ms/step - loss: 9.4825e-05 - val_loss: 7.4900e-04\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 9.3958e-05 - val_loss: 7.3671e-05\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.9953e-05 - val_loss: 2.3483e-04\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 6.6861e-05 - val_loss: 8.9921e-05\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.9017e-05 - val_loss: 5.2192e-04\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 3.2853e-05 - val_loss: 2.6830e-04\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 2s 15ms/step - loss: 4.0019e-05 - val_loss: 1.3848e-04\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 2.2295e-05 - val_loss: 8.8374e-05\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 3.0608e-05 - val_loss: 6.6161e-04\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 3.8190e-05 - val_loss: 1.0381e-04\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 2.9341e-05 - val_loss: 4.5781e-05\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 3.2254e-05 - val_loss: 6.2468e-05\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 4.8416e-05 - val_loss: 3.8637e-04\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.6524e-05 - val_loss: 1.8972e-04\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 7.6272e-05 - val_loss: 4.5500e-04\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 7.5485e-05 - val_loss: 3.4271e-04\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 6.8952e-05 - val_loss: 2.2871e-04\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 4.8677e-05 - val_loss: 3.0172e-04\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 6.2945e-05 - val_loss: 2.3617e-04\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.2697e-05 - val_loss: 4.7832e-04\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 4.4429e-05 - val_loss: 1.8488e-04\n",
      "Epoch 43/50\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 3.2933e-05 - val_loss: 1.2018e-04\n",
      "Epoch 44/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 6.3753e-05 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 9.1790e-05 - val_loss: 4.8227e-04\n",
      "Epoch 46/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.3768e-05 - val_loss: 2.2023e-05\n",
      "Epoch 47/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 4.0521e-05 - val_loss: 3.0982e-05\n",
      "Epoch 48/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.3689e-05 - val_loss: 2.2298e-04\n",
      "Epoch 49/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 5.7850e-05 - val_loss: 2.2875e-04\n",
      "Epoch 50/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 3.8279e-05 - val_loss: 8.1821e-05\n",
      ">p=6: 4, Score=0.015924528997857124\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 12s 33ms/step - loss: 0.0025 - val_loss: 0.0104\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 9.7548e-04 - val_loss: 0.0082\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 7.9907e-04 - val_loss: 0.0056\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 5.8446e-04 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 1s 15ms/step - loss: 3.7552e-04 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.2972e-04 - val_loss: 5.3609e-04\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.4101e-04 - val_loss: 3.8527e-04\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 1.1762e-04 - val_loss: 4.7249e-04\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 8.6777e-05 - val_loss: 2.9728e-04\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.1555e-04 - val_loss: 7.9095e-04\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.1286e-04 - val_loss: 5.3080e-04\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.0582e-04 - val_loss: 8.3438e-04\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 9.0180e-05 - val_loss: 2.3019e-04\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.8482e-05 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.8898e-05 - val_loss: 9.2063e-04\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.4884e-05 - val_loss: 3.4222e-04\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.8667e-05 - val_loss: 1.2050e-04\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 9.2873e-05 - val_loss: 1.4053e-04\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.6533e-05 - val_loss: 5.4749e-04\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 6.9562e-05 - val_loss: 4.2175e-04\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.9163e-05 - val_loss: 3.5114e-04\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 8.0317e-05 - val_loss: 7.7262e-05\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 6.6287e-05 - val_loss: 1.1730e-04\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.7797e-05 - val_loss: 1.2145e-04\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.1470e-05 - val_loss: 1.9360e-04\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 5.0102e-05 - val_loss: 8.3139e-05\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.8404e-05 - val_loss: 4.3915e-04\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.5749e-05 - val_loss: 4.2412e-05\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.8367e-05 - val_loss: 1.0264e-04\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.6202e-05 - val_loss: 9.3134e-05\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.2109e-05 - val_loss: 7.9793e-05\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.5747e-05 - val_loss: 1.3717e-04\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.5448e-05 - val_loss: 4.5275e-05\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.4743e-05 - val_loss: 2.9198e-05\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.3728e-05 - val_loss: 2.4087e-04\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.5335e-05 - val_loss: 6.2052e-04\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.1046e-05 - val_loss: 5.2063e-04\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.3455e-05 - val_loss: 6.2246e-04\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.3603e-05 - val_loss: 2.5781e-04\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.4321e-05 - val_loss: 2.4540e-04\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 6.8232e-05 - val_loss: 3.2480e-04\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 4.5881e-05 - val_loss: 0.0010\n",
      "Epoch 43/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.4385e-05 - val_loss: 3.8136e-05\n",
      "Epoch 44/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.1081e-05 - val_loss: 2.1873e-04\n",
      "Epoch 45/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 2.9919e-05 - val_loss: 1.9579e-04\n",
      "Epoch 46/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.0585e-05 - val_loss: 3.0731e-04\n",
      "Epoch 47/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 3.8885e-05 - val_loss: 1.8809e-04\n",
      "Epoch 48/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 7.7446e-05 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 6.2582e-05 - val_loss: 2.4147e-04\n",
      "Epoch 50/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 2.5493e-05 - val_loss: 2.8408e-05\n",
      ">p=6: 5, Score=0.0033266216632910073\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 12s 36ms/step - loss: 0.0026 - val_loss: 0.0104\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0083\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 8.1714e-04 - val_loss: 0.0056\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - -0s -344us/step - loss: 6.0674e-04 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.6212e-04 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.2952e-04 - val_loss: 4.2351e-04\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 1.6837e-04 - val_loss: 4.6184e-04\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.2872e-04 - val_loss: 1.4138e-04\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 7.6308e-05 - val_loss: 2.8782e-04\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.8099e-05 - val_loss: 6.7743e-04\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 6.3337e-05 - val_loss: 4.4657e-04\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 8.9584e-05 - val_loss: 2.2565e-04\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 5.2966e-05 - val_loss: 2.4456e-04\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 8.9300e-05 - val_loss: 3.7888e-04\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 7.3324e-05 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.9484e-05 - val_loss: 1.8656e-04\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.0615e-05 - val_loss: 1.4103e-04\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 7.0413e-05 - val_loss: 1.1538e-04\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 6.8747e-05 - val_loss: 3.9391e-04\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.2976e-05 - val_loss: 3.6583e-04\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 5.5126e-05 - val_loss: 0.0025\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 6.9083e-05 - val_loss: 1.8554e-04\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.3406e-05 - val_loss: 2.3098e-04\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.7452e-05 - val_loss: 1.7810e-04\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.7913e-05 - val_loss: 1.0860e-04\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 3.4900e-05 - val_loss: 8.4583e-04\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.8113e-05 - val_loss: 4.4730e-04\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.4557e-05 - val_loss: 2.3771e-04\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.9002e-05 - val_loss: 1.2619e-04\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 5.0605e-05 - val_loss: 2.0752e-04\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.1801e-04 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 8.9683e-05 - val_loss: 8.5556e-05\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 6.1053e-05 - val_loss: 1.9074e-04\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.0663e-04 - val_loss: 9.0234e-04\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 5.8487e-05 - val_loss: 2.2593e-04\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.5248e-05 - val_loss: 3.1551e-04\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 2.9515e-05 - val_loss: 1.7156e-04\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.7913e-05 - val_loss: 9.7535e-05\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.2400e-05 - val_loss: 1.3547e-04\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.4701e-05 - val_loss: 5.2785e-05\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 2.6933e-05 - val_loss: 1.9073e-04\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 2.8736e-05 - val_loss: 1.3935e-04\n",
      "Epoch 43/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 2.7883e-05 - val_loss: 2.0317e-04\n",
      "Epoch 44/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.8766e-05 - val_loss: 1.7785e-04\n",
      "Epoch 45/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.7155e-05 - val_loss: 2.2313e-04\n",
      "Epoch 46/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 3.7525e-05 - val_loss: 1.3757e-04\n",
      "Epoch 47/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.3780e-05 - val_loss: 5.7810e-04\n",
      "Epoch 48/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.0262e-05 - val_loss: 1.8833e-04\n",
      "Epoch 49/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.5506e-05 - val_loss: 7.6375e-05\n",
      "Epoch 50/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.5103e-05 - val_loss: 4.7178e-04\n",
      ">p=6: 6, Score=0.025392352836206555\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 11s 32ms/step - loss: 0.0026 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 0.0086\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 8.5013e-04 - val_loss: 0.0063\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.1300e-04 - val_loss: 0.0042\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 4.5060e-04 - val_loss: 0.0022\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.3407e-04 - val_loss: 9.7009e-04\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.6750e-04 - val_loss: 2.7019e-04\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.5455e-04 - val_loss: 5.7601e-04\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 1.4486e-04 - val_loss: 3.8831e-04\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 1.1282e-04 - val_loss: 1.8232e-04\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.0418e-04 - val_loss: 8.7617e-04\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 6.4612e-05 - val_loss: 2.9760e-04\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 8.0488e-05 - val_loss: 2.9279e-04\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 8.4268e-05 - val_loss: 3.1403e-04\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 6.7632e-05 - val_loss: 1.0838e-04\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.2738e-05 - val_loss: 1.2511e-04\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.7050e-05 - val_loss: 2.7859e-04\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.9047e-05 - val_loss: 2.5588e-04\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.0081e-05 - val_loss: 3.4958e-04\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 7.8094e-05 - val_loss: 1.0704e-04\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.0401e-04 - val_loss: 1.9516e-04\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 7.4485e-05 - val_loss: 5.2291e-04\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.3834e-05 - val_loss: 2.0739e-04\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.5399e-05 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.0506e-04 - val_loss: 4.5426e-04\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 9.1582e-05 - val_loss: 3.5121e-04\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.7823e-05 - val_loss: 2.5250e-04\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 4.6336e-05 - val_loss: 2.8127e-04\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.1955e-05 - val_loss: 1.2174e-04\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.2616e-05 - val_loss: 1.4162e-04\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.1708e-05 - val_loss: 1.2436e-04\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.7270e-05 - val_loss: 2.5305e-04\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.0482e-05 - val_loss: 2.1822e-04\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.6208e-05 - val_loss: 1.1556e-04\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.8150e-05 - val_loss: 1.4410e-04\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.0254e-05 - val_loss: 8.2020e-05\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.4070e-05 - val_loss: 3.6309e-04\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.5951e-05 - val_loss: 5.9863e-05\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.1183e-05 - val_loss: 3.1762e-04\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.6108e-05 - val_loss: 8.0278e-04\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.2491e-05 - val_loss: 1.2425e-04\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.7894e-05 - val_loss: 4.7738e-04\n",
      "Epoch 43/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.0198e-05 - val_loss: 4.7399e-05\n",
      "Epoch 44/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 4.3570e-05 - val_loss: 2.0119e-05\n",
      "Epoch 45/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.1733e-05 - val_loss: 3.8303e-04\n",
      "Epoch 46/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.1661e-05 - val_loss: 4.0707e-04\n",
      "Epoch 47/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 2.9583e-05 - val_loss: 6.2854e-05\n",
      "Epoch 48/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.8237e-05 - val_loss: 3.8009e-04\n",
      "Epoch 49/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.5947e-05 - val_loss: 1.4205e-04\n",
      "Epoch 50/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.2452e-05 - val_loss: 6.9475e-04\n",
      ">p=6: 7, Score=0.04981114761903882\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 10s 27ms/step - loss: 0.0026 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 8.8102e-04 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 6.7351e-04 - val_loss: 0.0042\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 4.8457e-04 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.3031e-04 - val_loss: 9.6953e-04\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.9781e-04 - val_loss: 8.5546e-04\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.2580e-04 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.3726e-04 - val_loss: 4.0114e-04\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 1.1348e-04 - val_loss: 0.0021\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 9.2150e-05 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 9.4780e-05 - val_loss: 1.9904e-04\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 7.5511e-05 - val_loss: 1.2355e-04\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 6.4842e-05 - val_loss: 8.6017e-04\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.6857e-05 - val_loss: 0.0027\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.0117e-04 - val_loss: 1.1646e-04\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 8.6898e-05 - val_loss: 1.6166e-04\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 8.3740e-05 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 8.7850e-05 - val_loss: 2.6715e-04\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.9018e-05 - val_loss: 8.1477e-04\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.0313e-05 - val_loss: 1.3677e-04\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.2398e-05 - val_loss: 7.9394e-04\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 1.5175e-04 - val_loss: 7.4216e-04\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 8.3005e-05 - val_loss: 4.5623e-04\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.1545e-05 - val_loss: 1.0285e-04\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.0578e-05 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.3532e-05 - val_loss: 1.7039e-04\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 4.2999e-05 - val_loss: 1.0267e-04\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.0631e-05 - val_loss: 4.7301e-05\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.9852e-05 - val_loss: 5.3923e-04\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 6.3701e-05 - val_loss: 2.0172e-04\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.9423e-05 - val_loss: 6.4290e-05\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.2963e-05 - val_loss: 1.1872e-04\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 8.2110e-05 - val_loss: 4.1995e-04\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.5248e-05 - val_loss: 5.7356e-05\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 2.9183e-05 - val_loss: 9.4470e-05\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.0637e-05 - val_loss: 9.4578e-04\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.0151e-05 - val_loss: 1.5914e-04\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.9501e-05 - val_loss: 4.7221e-05\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.4292e-05 - val_loss: 1.1877e-04\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 5.7395e-05 - val_loss: 3.5749e-04\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.5204e-05 - val_loss: 5.4989e-05\n",
      "Epoch 43/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 2.1078e-05 - val_loss: 6.4981e-05\n",
      "Epoch 44/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 2.6672e-05 - val_loss: 7.3773e-05\n",
      "Epoch 45/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.4585e-05 - val_loss: 1.0207e-04\n",
      "Epoch 46/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.1211e-04 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 7.7331e-05 - val_loss: 1.3371e-04\n",
      "Epoch 48/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.5636e-05 - val_loss: 2.7239e-04\n",
      "Epoch 49/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 4.1367e-05 - val_loss: 2.2877e-04\n",
      "Epoch 50/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.3986e-05 - val_loss: 3.5086e-04\n",
      ">p=6: 8, Score=0.021451213979162276\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 10s 26ms/step - loss: 0.0026 - val_loss: 0.0109\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0084\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 8.1349e-04 - val_loss: 0.0058\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.3016e-04 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.7474e-04 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 2.2216e-04 - val_loss: 6.2824e-04\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 1.8145e-04 - val_loss: 4.9666e-04\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.7534e-04 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.4152e-04 - val_loss: 9.5549e-04\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 8.1326e-05 - val_loss: 1.8841e-04\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 7.4262e-05 - val_loss: 8.1378e-04\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 5.7149e-05 - val_loss: 5.9826e-04\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 8.0329e-05 - val_loss: 3.0001e-04\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 6.8305e-05 - val_loss: 9.1588e-04\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.0023e-05 - val_loss: 3.1270e-04\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 6.6578e-05 - val_loss: 4.9720e-04\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 8.2062e-05 - val_loss: 1.0252e-04\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 6.2786e-05 - val_loss: 2.0270e-04\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 5.5836e-05 - val_loss: 3.7258e-04\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.7886e-05 - val_loss: 7.4275e-04\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.1670e-05 - val_loss: 1.6866e-04\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.2428e-05 - val_loss: 4.7825e-04\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.4123e-05 - val_loss: 2.8129e-04\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 1.0079e-04 - val_loss: 1.7073e-04\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 1.0504e-04 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 8.8716e-05 - val_loss: 1.2398e-04\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.6678e-05 - val_loss: 2.3411e-04\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.6238e-05 - val_loss: 6.7248e-04\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 6.5205e-05 - val_loss: 2.2514e-04\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.2509e-05 - val_loss: 2.2863e-04\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 2.4668e-05 - val_loss: 3.1698e-05\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 4.4895e-05 - val_loss: 1.4741e-04\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.1032e-05 - val_loss: 8.1038e-05\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 3.5667e-05 - val_loss: 2.0698e-04\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 4.6763e-05 - val_loss: 3.5621e-04\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.2486e-05 - val_loss: 3.3475e-04\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.0825e-05 - val_loss: 3.7419e-04\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.0409e-05 - val_loss: 2.6879e-04\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 3.9329e-05 - val_loss: 1.0315e-04\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.0429e-05 - val_loss: 2.2410e-04\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 1.6568e-05 - val_loss: 3.0748e-05\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 1.7968e-05 - val_loss: 1.2079e-04\n",
      "Epoch 43/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 2.4620e-05 - val_loss: 4.8796e-04\n",
      "Epoch 44/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.0706e-05 - val_loss: 4.3082e-05\n",
      "Epoch 45/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 2.4372e-05 - val_loss: 6.0192e-05\n",
      "Epoch 46/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 2.5751e-05 - val_loss: 5.5286e-04\n",
      "Epoch 47/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 2.6158e-05 - val_loss: 1.9442e-05\n",
      "Epoch 48/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 5.8188e-05 - val_loss: 7.0198e-04\n",
      "Epoch 49/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.1959e-05 - val_loss: 5.1443e-04\n",
      "Epoch 50/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 6.1170e-05 - val_loss: 1.6370e-04\n",
      ">p=6: 9, Score=0.01190908151329495\n",
      "Epoch 1/50\n",
      "101/101 [==============================] - 10s 31ms/step - loss: 0.0027 - val_loss: 0.0109\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 2s 15ms/step - loss: 0.0010 - val_loss: 0.0090\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 9.2225e-04 - val_loss: 0.0068\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 6.9538e-04 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.9092e-04 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.1058e-04 - val_loss: 6.1548e-04\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.6651e-04 - val_loss: 5.2241e-04\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.4227e-04 - val_loss: 1.8086e-04\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 9.5070e-05 - val_loss: 8.4365e-04\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.1148e-04 - val_loss: 3.3860e-04\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.0872e-05 - val_loss: 8.2995e-04\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 1.0451e-04 - val_loss: 4.1616e-04\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 8.4080e-05 - val_loss: 7.5673e-04\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.8802e-05 - val_loss: 4.2949e-04\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.5296e-05 - val_loss: 2.2633e-04\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.6013e-05 - val_loss: 1.9458e-04\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 1.0569e-04 - val_loss: 1.7990e-04\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.2598e-05 - val_loss: 2.7789e-04\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.5599e-05 - val_loss: 2.7130e-04\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 7.0990e-05 - val_loss: 5.3299e-04\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 5.8261e-05 - val_loss: 7.3353e-05\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.1066e-05 - val_loss: 4.2339e-04\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.0085e-05 - val_loss: 7.3577e-04\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.8368e-05 - val_loss: 8.2556e-05\n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 6.4918e-05 - val_loss: 6.9002e-05\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.9220e-05 - val_loss: 3.1620e-04\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.2072e-05 - val_loss: 1.7610e-04\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 4.1117e-05 - val_loss: 9.8919e-04\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.1956e-05 - val_loss: 2.2264e-04\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.8276e-05 - val_loss: 3.3059e-04\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 5.7671e-05 - val_loss: 2.6375e-04\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 2.9980e-05 - val_loss: 2.8715e-04\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 3.6332e-05 - val_loss: 1.5041e-04\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 2.9895e-05 - val_loss: 5.1689e-05\n",
      "Epoch 35/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 8.4162e-05 - val_loss: 5.2906e-04\n",
      "Epoch 36/50\n",
      "101/101 [==============================] - 1s 10ms/step - loss: 6.6075e-05 - val_loss: 2.1126e-04\n",
      "Epoch 37/50\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 2.6959e-05 - val_loss: 2.1829e-04\n",
      "Epoch 38/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 4.2689e-05 - val_loss: 6.0708e-04\n",
      "Epoch 39/50\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 4.9380e-05 - val_loss: 5.3132e-04\n",
      "Epoch 40/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 3.5951e-05 - val_loss: 2.1177e-04\n",
      "Epoch 41/50\n",
      "101/101 [==============================] - 2s 18ms/step - loss: 4.0868e-05 - val_loss: 3.9102e-04\n",
      "Epoch 42/50\n",
      "101/101 [==============================] - 2s 15ms/step - loss: 3.6379e-05 - val_loss: 1.3651e-04\n",
      "Epoch 43/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.5988e-05 - val_loss: 5.2646e-04\n",
      "Epoch 44/50\n",
      "101/101 [==============================] - 2s 15ms/step - loss: 5.3694e-05 - val_loss: 1.7649e-04\n",
      "Epoch 45/50\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 7.3694e-05 - val_loss: 4.5750e-04\n",
      "Epoch 46/50\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 4.9518e-05 - val_loss: 4.5876e-04\n",
      "Epoch 47/50\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 2.7585e-05 - val_loss: 1.0769e-04\n",
      "Epoch 48/50\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 1.6975e-05 - val_loss: 3.9299e-05\n",
      "Epoch 49/50\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 2.7392e-05 - val_loss: 3.5518e-04\n",
      "Epoch 50/50\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 2.1321e-05 - val_loss: 4.6925e-05\n",
      ">p=6: 10, Score=0.0067609209509100765\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 11s 28ms/step - loss: 0.0027 - val_loss: 0.0105\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 8.4842e-04 - val_loss: 0.0067\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.1543e-04 - val_loss: 0.0045\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.0034e-04 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.9108e-04 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 2.1894e-04 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.2023e-04 - val_loss: 3.2017e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.0501e-04 - val_loss: 2.0953e-04\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 9.6886e-05 - val_loss: 1.0713e-04\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.1104e-04 - val_loss: 3.1890e-04\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.3080e-04 - val_loss: 5.4571e-04\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 7.8630e-05 - val_loss: 2.3156e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.8595e-05 - val_loss: 1.2710e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.6142e-05 - val_loss: 1.3603e-04\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.7765e-05 - val_loss: 2.7024e-04\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.0599e-05 - val_loss: 6.5003e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.9753e-05 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 7.4285e-05 - val_loss: 1.8795e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.6957e-05 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 5.4995e-05 - val_loss: 1.7331e-04\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.2684e-04 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 1.0377e-04 - val_loss: 4.7468e-04\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.6109e-05 - val_loss: 1.9610e-04\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 5.0207e-05 - val_loss: 1.0035e-04\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.4654e-05 - val_loss: 2.5245e-04\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 7.0329e-05 - val_loss: 3.0771e-04\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 8.0555e-05 - val_loss: 1.4399e-04\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 4.2018e-05 - val_loss: 1.8806e-04\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 2.6330e-05 - val_loss: 2.1086e-04\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 4.2706e-05 - val_loss: 8.4959e-05\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.0426e-05 - val_loss: 4.1532e-04\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.7998e-05 - val_loss: 2.2909e-04\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 2.9826e-05 - val_loss: 9.5234e-05\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.6729e-05 - val_loss: 6.6119e-05\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.1654e-05 - val_loss: 4.6973e-05\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 3.3742e-05 - val_loss: 9.7201e-05\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 2.3208e-05 - val_loss: 1.3813e-04\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.7747e-05 - val_loss: 1.0080e-04\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.7508e-05 - val_loss: 7.9838e-05\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.5678e-05 - val_loss: 3.4827e-04\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.7617e-05 - val_loss: 2.2425e-04\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.3929e-05 - val_loss: 4.5486e-04\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.2295e-05 - val_loss: 7.3208e-05\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.3478e-05 - val_loss: 4.4592e-05\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.5320e-05 - val_loss: 7.5772e-05\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 2.0810e-05 - val_loss: 1.2113e-04\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 4.1622e-05 - val_loss: 5.7676e-05\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.9026e-05 - val_loss: 1.4955e-04\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.4632e-05 - val_loss: 3.8916e-05\n",
      ">p=7: 1, Score=0.0036755274777533486\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 12s 35ms/step - loss: 0.0029 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 0.0010 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 8.3083e-04 - val_loss: 0.0065\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 6.2874e-04 - val_loss: 0.0043\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.8532e-04 - val_loss: 0.0025\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 2.9244e-04 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.6501e-04 - val_loss: 3.0733e-04\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.0178e-04 - val_loss: 3.9559e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 8.5232e-05 - val_loss: 5.7114e-04\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 1.0068e-04 - val_loss: 1.7962e-04\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.0339e-04 - val_loss: 4.6136e-04\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 8.9283e-05 - val_loss: 9.8474e-05\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.9636e-05 - val_loss: 2.1652e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.7656e-05 - val_loss: 7.7465e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.0004e-05 - val_loss: 6.5517e-04\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.3630e-05 - val_loss: 2.9537e-04\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.0049e-05 - val_loss: 2.6854e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.9318e-05 - val_loss: 1.8362e-04\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.8564e-05 - val_loss: 1.7313e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.0501e-05 - val_loss: 4.8704e-04\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.2335e-04 - val_loss: 8.4525e-04\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.2047e-04 - val_loss: 3.7095e-04\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 5.0421e-05 - val_loss: 4.7763e-05\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.3707e-05 - val_loss: 1.0574e-04\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.1099e-05 - val_loss: 1.6506e-04\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.3118e-05 - val_loss: 3.9471e-04\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.2497e-05 - val_loss: 2.4676e-04\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.0317e-05 - val_loss: 2.1339e-04\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 7.3699e-05 - val_loss: 2.0193e-04\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 4.1454e-05 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.9829e-05 - val_loss: 1.3091e-04\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 2.9309e-05 - val_loss: 1.0728e-04\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.5802e-05 - val_loss: 1.6163e-04\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.4833e-05 - val_loss: 3.2092e-04\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.7889e-05 - val_loss: 6.1202e-05\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 2.6903e-05 - val_loss: 3.2259e-04\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 4.8210e-05 - val_loss: 7.1129e-04\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.0044e-05 - val_loss: 1.1134e-04\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.6798e-05 - val_loss: 2.8701e-04\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.6311e-05 - val_loss: 2.4127e-04\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.0368e-05 - val_loss: 9.6844e-05\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.6670e-05 - val_loss: 3.7310e-04\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.0726e-05 - val_loss: 3.6744e-04\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.3249e-05 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.0829e-05 - val_loss: 9.9076e-05\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.0680e-05 - val_loss: 5.5673e-05\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 6.4858e-05 - val_loss: 6.0101e-04\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.3089e-05 - val_loss: 1.5605e-04\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.8282e-05 - val_loss: 4.1887e-04\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.2750e-05 - val_loss: 8.4981e-05\n",
      ">p=7: 2, Score=0.007986262062331662\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 12s 33ms/step - loss: 0.0028 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 0.0098\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 9.2660e-04 - val_loss: 0.0076\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 7.2703e-04 - val_loss: 0.0054\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 5.3831e-04 - val_loss: 0.0032\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.4859e-04 - val_loss: 0.0014\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 2.1905e-04 - val_loss: 6.0662e-04\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.6305e-04 - val_loss: 2.6934e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.4296e-04 - val_loss: 1.8223e-04\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.0766e-04 - val_loss: 2.6487e-04\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 6.7434e-05 - val_loss: 4.0037e-04\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 8.3147e-05 - val_loss: 1.0252e-04\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.0324e-05 - val_loss: 1.7595e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.8367e-05 - val_loss: 1.6638e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.6144e-05 - val_loss: 3.8548e-04\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.7880e-05 - val_loss: 0.0010\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.4329e-05 - val_loss: 2.1031e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.2957e-05 - val_loss: 2.4564e-04\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 7.0266e-05 - val_loss: 2.2050e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.3959e-05 - val_loss: 4.3460e-04\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 6.4242e-05 - val_loss: 1.6085e-04\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 4.1420e-05 - val_loss: 1.1266e-04\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.7177e-05 - val_loss: 1.3336e-04\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.9382e-05 - val_loss: 1.0798e-04\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.0887e-05 - val_loss: 6.2188e-04\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.9889e-05 - val_loss: 2.1568e-04\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.8032e-05 - val_loss: 6.5496e-05\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 4.5414e-05 - val_loss: 8.4437e-05\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.8307e-05 - val_loss: 1.2446e-04\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.8260e-05 - val_loss: 6.6577e-04\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 3.5834e-05 - val_loss: 2.7186e-04\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.1068e-05 - val_loss: 2.7482e-04\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.1187e-05 - val_loss: 1.3199e-04\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.1867e-05 - val_loss: 1.1860e-04\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.1185e-05 - val_loss: 1.1418e-04\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.3250e-05 - val_loss: 3.7176e-04\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 2.7402e-05 - val_loss: 9.0643e-05\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.9927e-05 - val_loss: 1.8462e-05\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.6644e-05 - val_loss: 1.6911e-04\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.1699e-05 - val_loss: 8.4916e-05\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.5610e-05 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 6.9516e-05 - val_loss: 3.6032e-04\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.8512e-05 - val_loss: 3.7504e-04\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.0227e-05 - val_loss: 9.3555e-04\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.5896e-05 - val_loss: 1.9123e-04\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.0264e-05 - val_loss: 3.0025e-04\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.4074e-05 - val_loss: 4.5529e-04\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.6102e-05 - val_loss: 6.6337e-04\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.1655e-05 - val_loss: 5.7905e-04\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.8875e-05 - val_loss: 1.6835e-04\n",
      ">p=7: 3, Score=0.00813280712463893\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 11s 29ms/step - loss: 0.0028 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0090\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 8.5366e-04 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.9278e-04 - val_loss: 0.0039\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 4.3908e-04 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.0406e-04 - val_loss: 7.0639e-04\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 1.5470e-04 - val_loss: 2.5686e-04\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 1.0807e-04 - val_loss: 3.3838e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 8.7973e-05 - val_loss: 1.4886e-04\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.0937e-04 - val_loss: 2.4616e-04\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.3899e-04 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 8.6089e-05 - val_loss: 1.0394e-04\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.9943e-05 - val_loss: 1.5548e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.1744e-05 - val_loss: 3.3054e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.5478e-05 - val_loss: 0.0015\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.7506e-05 - val_loss: 1.6362e-04\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 9.2887e-05 - val_loss: 5.0284e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.0883e-05 - val_loss: 5.3747e-04\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 5.7597e-05 - val_loss: 1.5346e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 5.6465e-05 - val_loss: 3.4685e-04\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 9.5578e-05 - val_loss: 4.6752e-04\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 4.9663e-05 - val_loss: 1.0919e-04\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 6.1256e-05 - val_loss: 8.7650e-05\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 5.8788e-05 - val_loss: 8.0171e-05\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 7.6206e-05 - val_loss: 4.1942e-04\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 5.9338e-05 - val_loss: 6.9598e-04\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.2602e-05 - val_loss: 2.1100e-04\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 3.3573e-05 - val_loss: 1.6583e-04\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.3283e-05 - val_loss: 5.4551e-04\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 6.3457e-05 - val_loss: 3.4750e-04\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 5.2954e-05 - val_loss: 1.6493e-04\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 6.2759e-05 - val_loss: 6.4520e-04\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 2s 22ms/step - loss: 3.5170e-05 - val_loss: 1.0865e-04\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 5.0911e-05 - val_loss: 9.0940e-05\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.1390e-05 - val_loss: 7.6746e-04\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 5.5049e-05 - val_loss: 1.9023e-04\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 2.3225e-05 - val_loss: 1.1104e-04\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 4.4040e-05 - val_loss: 3.6653e-05\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.1828e-05 - val_loss: 1.3013e-04\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.3166e-05 - val_loss: 2.8990e-05\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.9454e-05 - val_loss: 2.2622e-05\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.7701e-05 - val_loss: 4.1460e-04\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.7454e-05 - val_loss: 2.2192e-04\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.6365e-05 - val_loss: 2.0928e-04\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 2.8721e-05 - val_loss: 3.0478e-04\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.7392e-05 - val_loss: 4.2179e-05\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.2184e-05 - val_loss: 9.2872e-05\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.2441e-05 - val_loss: 9.1029e-05\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 2.8630e-05 - val_loss: 4.8568e-05\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 4.4232e-05 - val_loss: 2.3564e-04\n",
      ">p=7: 4, Score=0.01713597448542714\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 11s 39ms/step - loss: 0.0026 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 0.0011 - val_loss: 0.0089\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 8.4379e-04 - val_loss: 0.0067\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.3488e-04 - val_loss: 0.0046\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.7906e-04 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 3.1342e-04 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.9786e-04 - val_loss: 4.4710e-04\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.3069e-04 - val_loss: 6.0538e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 1.2800e-04 - val_loss: 4.2788e-04\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 1.2691e-04 - val_loss: 1.8686e-04\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 6.8586e-05 - val_loss: 4.0782e-04\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.1957e-05 - val_loss: 6.4120e-04\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 7.6370e-05 - val_loss: 2.8748e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.5889e-05 - val_loss: 2.1784e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 7.7455e-05 - val_loss: 1.9457e-04\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 7.8509e-05 - val_loss: 3.0699e-04\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 6.5345e-05 - val_loss: 1.4000e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 4.6064e-05 - val_loss: 4.4300e-04\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 8.0536e-05 - val_loss: 8.1224e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 7.8175e-05 - val_loss: 2.8413e-04\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 3.8070e-05 - val_loss: 1.3404e-04\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.7772e-05 - val_loss: 3.5613e-04\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.1609e-05 - val_loss: 4.7428e-04\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.2051e-05 - val_loss: 2.0111e-04\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 1.2270e-04 - val_loss: 9.7017e-04\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.1487e-04 - val_loss: 2.8458e-04\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.5014e-05 - val_loss: 8.2731e-05\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.3385e-05 - val_loss: 3.0696e-04\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 4.6694e-05 - val_loss: 4.2826e-05\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 3.6080e-05 - val_loss: 7.0539e-04\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 6.8693e-05 - val_loss: 6.6668e-04\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 2s 23ms/step - loss: 8.2507e-05 - val_loss: 1.1933e-04\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 4.4363e-05 - val_loss: 5.0250e-05\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 4.0231e-05 - val_loss: 6.8971e-04\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 7.1191e-05 - val_loss: 5.5610e-04\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 3.9531e-05 - val_loss: 1.3928e-04\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 3.0546e-05 - val_loss: 7.4483e-05\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 3.3225e-05 - val_loss: 6.6958e-05\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.0544e-05 - val_loss: 1.3301e-04\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.5258e-05 - val_loss: 5.1361e-05\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.4299e-05 - val_loss: 3.8670e-05\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 6.1133e-05 - val_loss: 0.0012\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.5714e-05 - val_loss: 1.1992e-04\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.4590e-05 - val_loss: 3.5646e-05\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.1825e-05 - val_loss: 1.0509e-04\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.7916e-05 - val_loss: 1.5316e-05\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.7407e-05 - val_loss: 3.3926e-05\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.5425e-05 - val_loss: 1.7224e-04\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.1658e-05 - val_loss: 1.6324e-04\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.1722e-05 - val_loss: 1.0511e-04\n",
      ">p=7: 5, Score=0.006927494541741908\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 10s 40ms/step - loss: 0.0029 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 0.0010 - val_loss: 0.0091\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 8.7728e-04 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.9996e-04 - val_loss: 0.0039\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.2685e-04 - val_loss: 0.0020\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.2701e-04 - val_loss: 9.6479e-04\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.9190e-04 - val_loss: 4.9475e-04\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 1.4300e-04 - val_loss: 3.0148e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 9.2681e-05 - val_loss: 4.2950e-04\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 7.7431e-05 - val_loss: 3.9776e-04\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 9.9986e-05 - val_loss: 3.0593e-04\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 8.6282e-05 - val_loss: 2.1993e-04\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 6.6407e-05 - val_loss: 3.2280e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 7.6564e-05 - val_loss: 4.0451e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 5.7061e-05 - val_loss: 1.9837e-04\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 5.6726e-05 - val_loss: 4.2074e-04\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 2s 24ms/step - loss: 5.4355e-05 - val_loss: 2.8255e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 5.0972e-05 - val_loss: 5.6839e-04\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 5.0868e-05 - val_loss: 1.7437e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 6.5975e-05 - val_loss: 3.0450e-04\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 4.8664e-05 - val_loss: 2.8148e-04\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 8.6947e-05 - val_loss: 5.3237e-04\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 8.7708e-05 - val_loss: 2.7615e-04\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.5116e-05 - val_loss: 7.6704e-05\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.3749e-05 - val_loss: 8.7046e-05\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.5402e-05 - val_loss: 9.4831e-05\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.9819e-05 - val_loss: 5.3738e-04\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.2101e-05 - val_loss: 2.1674e-04\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 4.8995e-05 - val_loss: 2.3861e-04\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 4.3845e-05 - val_loss: 1.0033e-04\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.4445e-05 - val_loss: 1.9152e-04\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 7.4874e-05 - val_loss: 6.1637e-05\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.3101e-05 - val_loss: 5.3362e-05\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.0887e-05 - val_loss: 8.2946e-05\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.0117e-05 - val_loss: 1.9049e-04\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.4237e-05 - val_loss: 1.3188e-04\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 3.5648e-05 - val_loss: 6.1330e-05\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.6175e-05 - val_loss: 1.4070e-04\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.3216e-05 - val_loss: 8.5357e-05\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.7007e-05 - val_loss: 3.5167e-04\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.8558e-05 - val_loss: 1.2909e-04\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.2105e-05 - val_loss: 6.6501e-04\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.2293e-05 - val_loss: 1.2296e-04\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.6858e-05 - val_loss: 2.3374e-04\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.9949e-05 - val_loss: 3.7520e-04\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.3550e-05 - val_loss: 1.5183e-04\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.5834e-05 - val_loss: 1.7603e-04\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.2023e-05 - val_loss: 9.8582e-05\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.1960e-05 - val_loss: 4.4058e-05\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 2.9388e-05 - val_loss: 4.4742e-05\n",
      ">p=7: 6, Score=0.004756446287501603\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 9s 29ms/step - loss: 0.0027 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 0.0010 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 8.7997e-04 - val_loss: 0.0069\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 7.0473e-04 - val_loss: 0.0045\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.0870e-04 - val_loss: 0.0024\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.0503e-04 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.7821e-04 - val_loss: 4.7183e-04\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.3064e-04 - val_loss: 1.2162e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 7.4000e-05 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 9.1179e-05 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 8.5270e-05 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 9.2341e-05 - val_loss: 2.9512e-04\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.9089e-05 - val_loss: 2.5738e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.9273e-05 - val_loss: 5.4102e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 9.5379e-05 - val_loss: 2.4575e-04\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.6795e-05 - val_loss: 8.9875e-04\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.2246e-05 - val_loss: 3.1029e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 5.1302e-05 - val_loss: 2.8826e-04\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.5483e-05 - val_loss: 1.8215e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 7.9878e-05 - val_loss: 5.1030e-04\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 8.0335e-05 - val_loss: 2.2108e-04\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 8.3586e-05 - val_loss: 3.1581e-04\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.8159e-05 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.0852e-05 - val_loss: 2.1569e-04\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.5543e-05 - val_loss: 3.3417e-04\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.0078e-05 - val_loss: 9.4830e-05\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.0963e-05 - val_loss: 9.4807e-05\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 2.8066e-05 - val_loss: 4.9135e-04\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.8748e-05 - val_loss: 1.0449e-04\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 3.8965e-05 - val_loss: 4.7903e-04\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.2444e-05 - val_loss: 5.3305e-04\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.8212e-05 - val_loss: 9.7549e-04\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 3.2868e-05 - val_loss: 7.3516e-05\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 8.7402e-05 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 1.0638e-04 - val_loss: 1.5901e-04\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.5760e-05 - val_loss: 3.7938e-05\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.2839e-05 - val_loss: 8.9456e-05\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.1334e-05 - val_loss: 6.8113e-05\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.0751e-05 - val_loss: 1.0176e-04\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.4203e-05 - val_loss: 4.2012e-05\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.5656e-05 - val_loss: 6.2683e-05\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.5724e-05 - val_loss: 3.3010e-04\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 4.7799e-05 - val_loss: 1.0083e-04\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.0252e-05 - val_loss: 1.8814e-04\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.8615e-05 - val_loss: 5.3406e-05\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.3194e-05 - val_loss: 8.5684e-05\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.1217e-05 - val_loss: 2.6369e-04\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 2.6728e-05 - val_loss: 8.3566e-05\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.8408e-05 - val_loss: 3.8261e-04\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.8192e-05 - val_loss: 1.1424e-04\n",
      ">p=7: 7, Score=0.007486192771466449\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 10s 35ms/step - loss: 0.0030 - val_loss: 0.0118\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 0.0011 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 9.8103e-04 - val_loss: 0.0070\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.1339e-04 - val_loss: 0.0043\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.2072e-04 - val_loss: 0.0024\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 2.6400e-04 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 1.5835e-04 - val_loss: 3.5118e-04\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.4852e-04 - val_loss: 1.7910e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 1.0103e-04 - val_loss: 2.2841e-04\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 1.8212e-04 - val_loss: 0.0010\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.4656e-04 - val_loss: 2.9154e-04\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.6728e-05 - val_loss: 2.4108e-04\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.0905e-05 - val_loss: 2.5544e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 9.3651e-05 - val_loss: 2.2165e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 7.4147e-05 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 4.7832e-05 - val_loss: 1.8156e-04\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.7298e-05 - val_loss: 4.9034e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 7.5197e-05 - val_loss: 1.1844e-04\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.8440e-05 - val_loss: 8.1878e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.5331e-05 - val_loss: 7.3599e-04\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.2153e-05 - val_loss: 3.1112e-04\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.2299e-04 - val_loss: 3.5587e-04\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.0365e-05 - val_loss: 0.0010\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.9896e-05 - val_loss: 1.6469e-04\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 6.7369e-05 - val_loss: 3.5593e-04\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 7.1821e-05 - val_loss: 1.7152e-04\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.3748e-05 - val_loss: 7.0749e-05\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.0026e-05 - val_loss: 5.4418e-05\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 4.0146e-05 - val_loss: 2.9707e-04\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.2746e-05 - val_loss: 2.4559e-04\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.9901e-05 - val_loss: 6.2676e-04\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.9146e-05 - val_loss: 4.2052e-05\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.0643e-05 - val_loss: 9.5962e-05\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.4590e-05 - val_loss: 8.9483e-04\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.7741e-05 - val_loss: 6.4868e-04\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 4.1117e-05 - val_loss: 1.4423e-04\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 3.6729e-05 - val_loss: 5.9646e-05\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.4233e-05 - val_loss: 9.4754e-05\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.1146e-05 - val_loss: 4.6458e-05\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.7166e-05 - val_loss: 1.7957e-04\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.0431e-05 - val_loss: 7.3346e-04\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 5.2475e-05 - val_loss: 1.8037e-04\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.7881e-05 - val_loss: 2.1654e-04\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.7886e-05 - val_loss: 8.8879e-05\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.4775e-05 - val_loss: 6.7194e-05\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.4401e-05 - val_loss: 2.6367e-04\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.7896e-05 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.2323e-05 - val_loss: 5.5639e-04\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.6989e-05 - val_loss: 5.1233e-04\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.4087e-05 - val_loss: 1.6120e-04\n",
      ">p=7: 8, Score=0.01295178517466411\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 11s 34ms/step - loss: 0.0029 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 9.4058e-04 - val_loss: 0.0075\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 7.1360e-04 - val_loss: 0.0049\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.2162e-04 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.4367e-04 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.3921e-04 - val_loss: 6.4656e-04\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.1360e-04 - val_loss: 5.3284e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 8.6718e-05 - val_loss: 2.6828e-04\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 8.5544e-05 - val_loss: 1.6572e-04\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.6914e-05 - val_loss: 5.7632e-04\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.4146e-05 - val_loss: 5.2162e-04\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 9.6103e-05 - val_loss: 4.2468e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 1.0791e-04 - val_loss: 1.3742e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 7.2092e-05 - val_loss: 1.5312e-04\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 5.2633e-05 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 8.3019e-05 - val_loss: 2.2344e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.5626e-05 - val_loss: 6.8975e-04\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 5.0381e-05 - val_loss: 1.3857e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.4697e-05 - val_loss: 3.2211e-04\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 5.3101e-05 - val_loss: 9.7945e-05\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 5.4378e-05 - val_loss: 9.4352e-05\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 5.7806e-05 - val_loss: 9.7080e-05\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.3905e-05 - val_loss: 8.9725e-05\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.6216e-05 - val_loss: 3.5779e-04\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.3817e-05 - val_loss: 3.1224e-04\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 5.7808e-05 - val_loss: 3.5989e-04\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.5765e-05 - val_loss: 4.3813e-04\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.0125e-05 - val_loss: 1.1501e-04\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 8.1370e-05 - val_loss: 9.8304e-04\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.9290e-05 - val_loss: 1.0095e-04\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.3272e-05 - val_loss: 2.5121e-04\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.6148e-05 - val_loss: 5.5270e-05\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.3516e-05 - val_loss: 1.1630e-04\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 2.5812e-05 - val_loss: 3.6931e-05\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.0634e-05 - val_loss: 1.6511e-04\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.0971e-05 - val_loss: 4.7159e-04\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 4.8032e-05 - val_loss: 8.8620e-05\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.7140e-05 - val_loss: 7.5155e-05\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.4070e-05 - val_loss: 1.3324e-04\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.3232e-05 - val_loss: 2.3517e-04\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.9630e-05 - val_loss: 2.0218e-04\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.3161e-05 - val_loss: 4.0951e-05\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.7381e-05 - val_loss: 3.9723e-05\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.4433e-05 - val_loss: 2.2228e-04\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.5294e-05 - val_loss: 1.3321e-04\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.4459e-05 - val_loss: 1.1405e-04\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.3253e-05 - val_loss: 1.1538e-04\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 2.5843e-05 - val_loss: 2.1569e-05\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.4489e-05 - val_loss: 9.1414e-04\n",
      ">p=7: 9, Score=0.04798320878762752\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 10s 37ms/step - loss: 0.0029 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 8.6628e-04 - val_loss: 0.0068\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 6.7581e-04 - val_loss: 0.0045\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 4.6913e-04 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 3.7819e-04 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 2s 26ms/step - loss: 2.2555e-04 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 2s 25ms/step - loss: 1.1617e-04 - val_loss: 3.6265e-04\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 1.0990e-04 - val_loss: 1.0847e-04\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 2s 17ms/step - loss: 9.7537e-05 - val_loss: 5.9325e-04\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 6.9844e-05 - val_loss: 1.2528e-04\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 6.2259e-05 - val_loss: 2.7226e-04\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 6.3685e-05 - val_loss: 4.8390e-04\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 8.9448e-05 - val_loss: 1.8751e-04\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 8.1570e-05 - val_loss: 2.0814e-04\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 9.2934e-05 - val_loss: 4.2886e-04\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 1.0421e-04 - val_loss: 2.3454e-04\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 7.4401e-05 - val_loss: 1.3905e-04\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 5.1285e-05 - val_loss: 2.1325e-04\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 7.3141e-05 - val_loss: 4.9691e-04\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 1.2166e-04 - val_loss: 2.7666e-04\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 6.0696e-05 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 9.5488e-05 - val_loss: 4.0554e-04\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 4.7654e-05 - val_loss: 1.4397e-04\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 5.1677e-05 - val_loss: 2.2254e-04\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 6.2961e-05 - val_loss: 1.9213e-04\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 5.0227e-05 - val_loss: 1.3173e-04\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.9975e-05 - val_loss: 8.9710e-05\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.5257e-05 - val_loss: 2.1675e-04\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 1s 16ms/step - loss: 5.9465e-05 - val_loss: 2.7946e-04\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 5.6010e-05 - val_loss: 4.6916e-05\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.1170e-05 - val_loss: 5.3029e-05\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.0439e-05 - val_loss: 1.0863e-04\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 4.0333e-05 - val_loss: 1.3549e-04\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.4660e-05 - val_loss: 2.5218e-04\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.1268e-05 - val_loss: 1.1404e-04\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.4682e-05 - val_loss: 2.8288e-04\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 3.9381e-05 - val_loss: 6.0912e-04\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 3.6260e-05 - val_loss: 6.0701e-05\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 2.9482e-05 - val_loss: 3.4334e-05\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 3.2421e-05 - val_loss: 1.3199e-04\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.2343e-05 - val_loss: 2.5359e-04\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 4.3738e-05 - val_loss: 2.8196e-04\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.3174e-05 - val_loss: 2.0825e-04\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.6048e-05 - val_loss: 2.3889e-04\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 1s 15ms/step - loss: 3.5127e-05 - val_loss: 6.0482e-05\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 2.6956e-05 - val_loss: 2.0620e-04\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 2.8159e-05 - val_loss: 1.2093e-04\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 4.2349e-05 - val_loss: 6.9567e-04\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 1s 11ms/step - loss: 8.5101e-05 - val_loss: 0.0010\n",
      ">p=7: 10, Score=0.06033371319063008\n",
      "Epoch 1/50\n",
      "76/76 [==============================] - 15s 48ms/step - loss: 0.0030 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 9.5364e-04 - val_loss: 0.0075\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 7.5382e-04 - val_loss: 0.0053\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.2730e-04 - val_loss: 0.0033\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 3.8377e-04 - val_loss: 0.0017\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 2.3810e-04 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.9385e-04 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.5787e-04 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 1.0070e-04 - val_loss: 3.6630e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.9701e-05 - val_loss: 2.4979e-04\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.0064e-04 - val_loss: 6.1271e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.1984e-04 - val_loss: 5.4188e-04\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.3804e-04 - val_loss: 5.4886e-04\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.3739e-04 - val_loss: 2.7984e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.6425e-05 - val_loss: 8.2514e-04\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.9803e-05 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.0678e-05 - val_loss: 5.5996e-04\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.3303e-05 - val_loss: 1.5995e-04\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.2081e-05 - val_loss: 3.3167e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.0953e-05 - val_loss: 5.3139e-04\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 5.9791e-05 - val_loss: 4.7997e-04\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.5386e-05 - val_loss: 2.9938e-04\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.2230e-05 - val_loss: 2.6275e-04\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 8.5065e-05 - val_loss: 3.9937e-04\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.4603e-05 - val_loss: 2.1038e-04\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 7.2679e-05 - val_loss: 9.7112e-05\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.9917e-05 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.5597e-05 - val_loss: 2.0823e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.3334e-05 - val_loss: 1.2797e-04\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.2479e-05 - val_loss: 5.7088e-04\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 8.3750e-05 - val_loss: 2.4027e-04\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.2743e-04 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.5123e-04 - val_loss: 2.2932e-04\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.9480e-05 - val_loss: 1.5065e-04\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.8957e-05 - val_loss: 1.8101e-04\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.4415e-05 - val_loss: 5.7064e-04\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.1775e-04 - val_loss: 7.2504e-04\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.1952e-05 - val_loss: 2.0231e-04\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.1767e-05 - val_loss: 7.0043e-04\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.1462e-05 - val_loss: 4.0175e-04\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.8462e-05 - val_loss: 7.2749e-05\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.0829e-05 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.6029e-05 - val_loss: 6.0215e-04\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.4760e-05 - val_loss: 7.1873e-05\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.9373e-05 - val_loss: 3.5683e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 3.9554e-05 - val_loss: 6.5952e-05\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.8493e-05 - val_loss: 1.5438e-04\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 2.2066e-05 - val_loss: 1.5167e-04\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.9699e-05 - val_loss: 4.5973e-05\n",
      ">p=8: 1, Score=0.004509437712840736\n",
      "Epoch 1/50\n",
      "76/76 [==============================] - 10s 41ms/step - loss: 0.0031 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0011 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.1935e-04 - val_loss: 0.0074\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.8527e-04 - val_loss: 0.0052\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.3230e-04 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.8644e-04 - val_loss: 0.0023\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 2.8337e-04 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.7945e-04 - val_loss: 4.7124e-04\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.8661e-04 - val_loss: 3.9111e-04\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.3593e-04 - val_loss: 4.0791e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.3627e-04 - val_loss: 6.3114e-04\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.8451e-04 - val_loss: 2.5099e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.0223e-04 - val_loss: 3.2232e-04\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.2680e-04 - val_loss: 6.8935e-04\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.6027e-04 - val_loss: 2.1303e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.3970e-04 - val_loss: 1.8246e-04\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 9.6089e-05 - val_loss: 2.4574e-04\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.2682e-05 - val_loss: 3.1719e-04\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 8.3834e-05 - val_loss: 6.0301e-04\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 9.0416e-05 - val_loss: 7.2671e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.0021e-04 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 9.0003e-05 - val_loss: 4.8797e-04\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 7.2271e-05 - val_loss: 4.3273e-04\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.0423e-05 - val_loss: 4.1650e-04\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.9812e-05 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.8249e-05 - val_loss: 1.7047e-04\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.0376e-04 - val_loss: 7.2506e-04\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 9.5178e-05 - val_loss: 1.4480e-04\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.0498e-05 - val_loss: 1.7277e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.4086e-05 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.6581e-05 - val_loss: 9.7919e-05\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.6604e-05 - val_loss: 1.7473e-04\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.3655e-05 - val_loss: 9.3833e-05\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 3.7635e-05 - val_loss: 7.1843e-05\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 2.8005e-05 - val_loss: 2.7991e-04\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 3.3833e-05 - val_loss: 8.5604e-05\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.7890e-05 - val_loss: 2.1838e-04\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.9489e-05 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.9415e-05 - val_loss: 9.3275e-05\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.7930e-05 - val_loss: 4.9188e-04\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 3.4049e-05 - val_loss: 5.8149e-05\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 6.2756e-05 - val_loss: 4.8377e-04\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.7001e-05 - val_loss: 6.8984e-04\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.7318e-05 - val_loss: 9.4355e-05\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.8568e-05 - val_loss: 1.1869e-04\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.7986e-05 - val_loss: 4.9152e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 1.2151e-04 - val_loss: 6.1985e-04\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.0430e-04 - val_loss: 1.0647e-04\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 9.8680e-05 - val_loss: 1.3029e-04\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.7731e-05 - val_loss: 2.2529e-04\n",
      ">p=8: 2, Score=0.02827438584063202\n",
      "Epoch 1/50\n",
      "76/76 [==============================] - 9s 38ms/step - loss: 0.0030 - val_loss: 0.0109\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 2s 21ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 9.3589e-04 - val_loss: 0.0074\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 7.7551e-04 - val_loss: 0.0055\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.9242e-04 - val_loss: 0.0041\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.0875e-04 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.1239e-04 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 2.1311e-04 - val_loss: 4.5428e-04\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.3051e-04 - val_loss: 2.0442e-04\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.4982e-04 - val_loss: 4.3179e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.8763e-04 - val_loss: 3.3408e-04\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 1.7879e-04 - val_loss: 5.8948e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.3926e-04 - val_loss: 3.1247e-04\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.0400e-04 - val_loss: 2.7506e-04\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 1.0774e-04 - val_loss: 1.4038e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.4378e-05 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.4956e-05 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 6.5677e-05 - val_loss: 2.8348e-04\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 6.7624e-05 - val_loss: 1.7690e-04\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 7.8862e-05 - val_loss: 1.9276e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.6220e-05 - val_loss: 9.8442e-04\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 6.6906e-05 - val_loss: 2.2954e-04\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.3724e-04 - val_loss: 0.0016\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.5596e-04 - val_loss: 9.4071e-04\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.9301e-05 - val_loss: 2.5452e-04\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 8.0756e-05 - val_loss: 3.0709e-04\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.0143e-05 - val_loss: 1.5242e-04\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.6956e-05 - val_loss: 5.9026e-04\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 5.0555e-05 - val_loss: 3.7371e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 3.9716e-05 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.4795e-05 - val_loss: 1.4250e-04\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 9.3580e-05 - val_loss: 0.0010\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 9.8206e-05 - val_loss: 2.7070e-04\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 4.0805e-05 - val_loss: 2.2906e-04\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 6.2143e-05 - val_loss: 2.2100e-04\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.8371e-05 - val_loss: 1.8441e-04\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.3949e-05 - val_loss: 1.0870e-04\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 2.3507e-05 - val_loss: 6.4364e-04\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.1499e-05 - val_loss: 6.6625e-04\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 7.1583e-05 - val_loss: 2.0319e-04\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 5.8112e-05 - val_loss: 2.3293e-04\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 6.7315e-05 - val_loss: 1.5286e-04\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.2333e-05 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 3.0338e-05 - val_loss: 7.4638e-05\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.4211e-05 - val_loss: 4.5064e-04\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.8794e-05 - val_loss: 1.7203e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.5103e-05 - val_loss: 3.3481e-04\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.7939e-05 - val_loss: 2.0552e-04\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.4134e-05 - val_loss: 3.4295e-04\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 8.0824e-05 - val_loss: 3.2764e-05\n",
      ">p=8: 3, Score=0.007770927186356857\n",
      "Epoch 1/50\n",
      "76/76 [==============================] - 11s 47ms/step - loss: 0.0033 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 9.9150e-04 - val_loss: 0.0077\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 7.2664e-04 - val_loss: 0.0054\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.2537e-04 - val_loss: 0.0038\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 4.5294e-04 - val_loss: 0.0020\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 2.8935e-04 - val_loss: 7.8659e-04\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 2.8684e-04 - val_loss: 4.2492e-04\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.3921e-04 - val_loss: 2.9639e-04\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 2.8844e-04 - val_loss: 7.0155e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 2.2247e-04 - val_loss: 8.9163e-04\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.3989e-04 - val_loss: 9.9049e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.9631e-04 - val_loss: 4.9824e-04\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.2025e-05 - val_loss: 9.6320e-04\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.1017e-04 - val_loss: 3.7684e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.1596e-04 - val_loss: 3.7605e-04\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.0177e-05 - val_loss: 0.0020\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.6535e-05 - val_loss: 2.6381e-04\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.4746e-05 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 8.2811e-05 - val_loss: 5.4596e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.2393e-05 - val_loss: 3.1927e-04\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.1813e-04 - val_loss: 9.0565e-04\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.9147e-05 - val_loss: 0.0010\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.0952e-05 - val_loss: 3.2567e-04\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.4796e-05 - val_loss: 0.0010\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 3.2824e-05 - val_loss: 0.0010\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.7774e-05 - val_loss: 2.3908e-04\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.6425e-05 - val_loss: 4.4054e-04\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.1627e-05 - val_loss: 9.2784e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.8417e-05 - val_loss: 2.9062e-04\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.6123e-05 - val_loss: 1.6815e-04\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.0831e-05 - val_loss: 3.4833e-04\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.1929e-05 - val_loss: 1.6806e-04\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.6175e-05 - val_loss: 2.3734e-04\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.9174e-05 - val_loss: 6.6129e-04\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.0111e-05 - val_loss: 2.4433e-04\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 3.4955e-05 - val_loss: 3.5228e-04\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 5.1059e-05 - val_loss: 1.5858e-04\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 8.9457e-05 - val_loss: 9.3303e-04\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 8.2388e-05 - val_loss: 5.0398e-04\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 3.3645e-05 - val_loss: 8.6718e-05\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 3.8732e-05 - val_loss: 7.6888e-04\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.9400e-05 - val_loss: 3.2609e-04\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.3285e-05 - val_loss: 2.1809e-04\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 3.5309e-05 - val_loss: 5.7202e-04\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 3.8900e-05 - val_loss: 1.4384e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.6373e-05 - val_loss: 5.5800e-04\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.6892e-05 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.8825e-05 - val_loss: 2.3496e-04\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.1333e-04 - val_loss: 6.7792e-04\n",
      ">p=8: 4, Score=0.051209802040830255\n",
      "Epoch 1/50\n",
      "76/76 [==============================] - 9s 30ms/step - loss: 0.0032 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.1874e-04 - val_loss: 0.0074\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.6731e-04 - val_loss: 0.0050\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.3345e-04 - val_loss: 0.0034\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.3724e-04 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 2.4612e-04 - val_loss: 9.6959e-04\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.9975e-04 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.1859e-04 - val_loss: 6.9382e-04\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 8.5473e-05 - val_loss: 2.2494e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.2293e-04 - val_loss: 6.5074e-04\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.4597e-04 - val_loss: 6.1689e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.3134e-04 - val_loss: 4.9520e-04\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.4514e-04 - val_loss: 4.5596e-04\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.9065e-05 - val_loss: 3.4860e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.4038e-04 - val_loss: 5.6609e-04\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.8784e-04 - val_loss: 3.1054e-04\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.4889e-04 - val_loss: 3.3367e-04\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.0907e-04 - val_loss: 5.0965e-04\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 6.5055e-05 - val_loss: 2.9048e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.3641e-05 - val_loss: 2.4025e-04\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 7.6145e-05 - val_loss: 2.1834e-04\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 6.8591e-05 - val_loss: 7.4147e-04\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.7559e-05 - val_loss: 1.3109e-04\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.3044e-05 - val_loss: 3.7596e-04\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 9.3476e-05 - val_loss: 4.9301e-04\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 9.6872e-05 - val_loss: 8.4241e-04\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.5542e-05 - val_loss: 1.1627e-04\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.0466e-05 - val_loss: 1.7688e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.8212e-05 - val_loss: 0.0018\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 5.3460e-05 - val_loss: 3.3036e-04\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 4.1873e-05 - val_loss: 6.6201e-05\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 4.1255e-05 - val_loss: 1.0762e-04\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 4.6247e-05 - val_loss: 7.0796e-04\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 5.2203e-05 - val_loss: 1.2419e-04\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 8.9371e-05 - val_loss: 7.9682e-04\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 1.0495e-04 - val_loss: 3.8295e-04\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 2s 21ms/step - loss: 5.6298e-05 - val_loss: 1.2217e-04\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 7.3905e-05 - val_loss: 6.4706e-04\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 7.2448e-05 - val_loss: 8.5254e-05\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 1s 20ms/step - loss: 4.9965e-05 - val_loss: 4.2407e-04\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 4.3181e-05 - val_loss: 1.2282e-04\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 2.9335e-05 - val_loss: 1.4444e-04\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 5.3405e-05 - val_loss: 2.7338e-04\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.3300e-05 - val_loss: 2.6442e-04\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 8.5615e-05 - val_loss: 5.5719e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.0735e-05 - val_loss: 1.9693e-04\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.0597e-05 - val_loss: 7.5084e-05\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 2.5588e-05 - val_loss: 1.8845e-04\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.1765e-05 - val_loss: 7.2888e-05\n",
      ">p=8: 5, Score=0.00681612582411617\n",
      "Epoch 1/50\n",
      "76/76 [==============================] - 11s 33ms/step - loss: 0.0032 - val_loss: 0.0114\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0100\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.0010 - val_loss: 0.0082\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.1891e-04 - val_loss: 0.0059\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.4536e-04 - val_loss: 0.0039\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.1135e-04 - val_loss: 0.0023\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.0482e-04 - val_loss: 8.2143e-04\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.7851e-04 - val_loss: 9.5723e-04\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.5358e-04 - val_loss: 4.9795e-04\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.4321e-04 - val_loss: 5.2688e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.5146e-04 - val_loss: 0.0013\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 8.9112e-05 - val_loss: 6.1445e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 9.4080e-05 - val_loss: 2.2112e-04\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 1.2886e-04 - val_loss: 2.3558e-04\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.2302e-04 - val_loss: 8.6166e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.6543e-05 - val_loss: 2.6812e-04\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 8.7162e-05 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.4919e-05 - val_loss: 0.0010\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.5816e-05 - val_loss: 7.1995e-04\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.0302e-05 - val_loss: 7.7266e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.5607e-05 - val_loss: 1.4571e-04\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.0584e-05 - val_loss: 2.6823e-04\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.3881e-05 - val_loss: 2.5671e-04\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 1.2450e-04 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.2308e-04 - val_loss: 1.5308e-04\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.6508e-05 - val_loss: 5.3217e-04\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.7217e-05 - val_loss: 1.7857e-04\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.8587e-05 - val_loss: 1.7143e-04\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.3226e-05 - val_loss: 1.1712e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.4993e-05 - val_loss: 6.7073e-05\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.4159e-05 - val_loss: 2.5021e-04\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 6.9126e-05 - val_loss: 1.3970e-04\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 6.4422e-05 - val_loss: 1.8380e-04\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.0352e-04 - val_loss: 2.4532e-04\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.5025e-05 - val_loss: 1.8777e-04\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.1522e-04 - val_loss: 2.4390e-04\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.7986e-05 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.3767e-05 - val_loss: 7.1858e-04\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.1712e-05 - val_loss: 8.1860e-05\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.1880e-05 - val_loss: 5.6248e-04\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.3451e-05 - val_loss: 5.0417e-04\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.4407e-05 - val_loss: 4.9834e-04\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.6280e-05 - val_loss: 9.3225e-05\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.3570e-05 - val_loss: 1.5227e-04\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.8930e-05 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.5261e-05 - val_loss: 1.7981e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 2.9380e-05 - val_loss: 2.6858e-04\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 4.7091e-05 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.1444e-05 - val_loss: 4.1360e-04\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 2.4914e-05 - val_loss: 1.4952e-04\n",
      ">p=8: 6, Score=0.01288937492063269\n",
      "Epoch 1/50\n",
      "76/76 [==============================] - 9s 32ms/step - loss: 0.0031 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.8648e-04 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.0563e-04 - val_loss: 0.0048\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.2235e-04 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 3.8171e-04 - val_loss: 0.0017\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 2.4006e-04 - val_loss: 8.3083e-04\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.9883e-04 - val_loss: 3.6509e-04\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.2829e-04 - val_loss: 5.6573e-04\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.9489e-05 - val_loss: 4.0002e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.0930e-05 - val_loss: 5.8624e-04\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 6.3363e-05 - val_loss: 8.3084e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.8953e-05 - val_loss: 5.3219e-04\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.6899e-04 - val_loss: 0.0020\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.6123e-04 - val_loss: 5.1130e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.3320e-05 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.2773e-05 - val_loss: 4.8900e-04\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 9.1575e-05 - val_loss: 1.6713e-04\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.0118e-05 - val_loss: 3.2969e-04\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.7206e-05 - val_loss: 1.5879e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 5.0480e-05 - val_loss: 4.2833e-04\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 3.8543e-05 - val_loss: 9.4924e-04\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.2949e-05 - val_loss: 4.4804e-04\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.4479e-05 - val_loss: 7.7425e-04\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.7841e-05 - val_loss: 0.0010\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.5597e-05 - val_loss: 9.4383e-04\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 4.5298e-05 - val_loss: 7.8662e-05\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.6900e-05 - val_loss: 6.0773e-04\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 3.9368e-05 - val_loss: 2.5677e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.1023e-04 - val_loss: 5.1925e-04\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.2506e-04 - val_loss: 2.8065e-04\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 9.5202e-05 - val_loss: 1.2424e-04\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.0549e-04 - val_loss: 1.0270e-04\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 9.3485e-05 - val_loss: 2.9889e-04\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.7111e-05 - val_loss: 1.1789e-04\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 3.8016e-05 - val_loss: 3.9183e-04\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 2.9256e-05 - val_loss: 1.5816e-04\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 3.7432e-05 - val_loss: 4.2856e-04\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.9018e-05 - val_loss: 1.3219e-04\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.4521e-05 - val_loss: 2.1270e-04\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 2.8992e-05 - val_loss: 4.9642e-04\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.8715e-05 - val_loss: 1.8107e-04\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.4922e-05 - val_loss: 3.2143e-04\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 4.3026e-05 - val_loss: 6.2876e-05\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 3.3018e-05 - val_loss: 1.2751e-04\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.6455e-05 - val_loss: 6.0453e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.0631e-05 - val_loss: 5.2071e-04\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.0153e-05 - val_loss: 4.3012e-04\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.2123e-05 - val_loss: 7.1765e-04\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.8480e-05 - val_loss: 6.8970e-05\n",
      ">p=8: 7, Score=0.00789837577030994\n",
      "Epoch 1/50\n",
      "76/76 [==============================] - 11s 30ms/step - loss: 0.0030 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 9.6036e-04 - val_loss: 0.0079\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.0210e-04 - val_loss: 0.0057\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.5745e-04 - val_loss: 0.0037\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.1111e-04 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 2.9952e-04 - val_loss: 0.0010\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 2.4547e-04 - val_loss: 4.0707e-04\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 1.3183e-04 - val_loss: 6.8864e-04\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.6103e-04 - val_loss: 6.6530e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.5626e-04 - val_loss: 2.9979e-04\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.1277e-04 - val_loss: 3.1539e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.1275e-04 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 7.3254e-05 - val_loss: 1.8079e-04\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 2s 20ms/step - loss: 8.9509e-05 - val_loss: 5.9669e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 7.2614e-05 - val_loss: 6.3927e-04\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 2s 21ms/step - loss: 7.5510e-05 - val_loss: 3.0424e-04\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 5.7398e-05 - val_loss: 6.7734e-04\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.9780e-05 - val_loss: 5.1868e-04\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 6.8737e-05 - val_loss: 8.1357e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.9053e-05 - val_loss: 1.0819e-04\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.0517e-05 - val_loss: 3.5963e-04\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 9.7415e-05 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.6774e-04 - val_loss: 7.1528e-04\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.4299e-05 - val_loss: 2.1615e-04\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.4801e-05 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.4867e-05 - val_loss: 7.7056e-04\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.1652e-05 - val_loss: 3.6552e-04\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 3.9764e-05 - val_loss: 4.4842e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 6.1699e-05 - val_loss: 2.4220e-04\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 8.3447e-05 - val_loss: 6.4335e-04\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 7.2706e-05 - val_loss: 1.1561e-04\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 6.8535e-05 - val_loss: 2.9289e-04\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 9.8514e-05 - val_loss: 1.4632e-04\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 8.1447e-05 - val_loss: 2.4728e-04\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 2s 20ms/step - loss: 5.2027e-05 - val_loss: 1.0068e-04\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 7.2801e-05 - val_loss: 7.7417e-05\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 4.3760e-05 - val_loss: 7.3048e-04\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 4.0056e-05 - val_loss: 4.2137e-04\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 3.4763e-05 - val_loss: 2.3303e-04\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 5.6324e-05 - val_loss: 4.8075e-04\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 4.9872e-05 - val_loss: 2.7924e-04\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 2.9747e-05 - val_loss: 1.7285e-04\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 3.1220e-05 - val_loss: 1.1774e-04\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.1110e-05 - val_loss: 4.7631e-05\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.0259e-05 - val_loss: 2.5624e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 2.2250e-05 - val_loss: 1.4807e-04\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 6.4259e-05 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 1.0914e-04 - val_loss: 4.0513e-04\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 3.9379e-05 - val_loss: 5.5283e-04\n",
      ">p=8: 8, Score=0.02725914237089455\n",
      "Epoch 1/50\n",
      "76/76 [==============================] - 11s 36ms/step - loss: 0.0031 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 2s 20ms/step - loss: 9.6930e-04 - val_loss: 0.0078\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 7.7400e-04 - val_loss: 0.0053\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.8380e-04 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.1469e-04 - val_loss: 0.0018\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 2.9245e-04 - val_loss: 7.6512e-04\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 1.8100e-04 - val_loss: 4.3390e-04\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.4128e-04 - val_loss: 3.1681e-04\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 9.3264e-05 - val_loss: 7.4029e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.4288e-05 - val_loss: 2.1510e-04\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 8.8760e-05 - val_loss: 1.4530e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 1.0326e-04 - val_loss: 5.0497e-04\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 1s 20ms/step - loss: 1.1913e-04 - val_loss: 8.7924e-04\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 1.1005e-04 - val_loss: 7.8336e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 8.2756e-05 - val_loss: 1.0186e-04\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.3262e-05 - val_loss: 3.9188e-04\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 5.0809e-05 - val_loss: 2.9006e-04\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.3482e-05 - val_loss: 8.5066e-04\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.6410e-05 - val_loss: 1.3130e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.4720e-05 - val_loss: 9.2388e-04\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 6.8866e-05 - val_loss: 4.1129e-04\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.6815e-05 - val_loss: 1.7409e-04\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.0089e-04 - val_loss: 6.6560e-04\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.4493e-04 - val_loss: 5.2955e-04\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 1.3174e-04 - val_loss: 8.3815e-04\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 6.4725e-05 - val_loss: 6.8329e-04\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 4.7327e-05 - val_loss: 1.8337e-04\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 4.4092e-05 - val_loss: 5.1933e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.7757e-05 - val_loss: 2.4583e-04\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.4590e-05 - val_loss: 1.4414e-04\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 3.3321e-05 - val_loss: 2.5584e-04\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.0140e-05 - val_loss: 7.1140e-04\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 3.2355e-05 - val_loss: 3.8401e-04\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 7.2749e-05 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 1.0623e-04 - val_loss: 3.0166e-04\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 7.0578e-05 - val_loss: 3.6803e-04\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.6882e-05 - val_loss: 5.5996e-05\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.1743e-05 - val_loss: 7.8921e-05\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.2318e-05 - val_loss: 1.9708e-04\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.6858e-05 - val_loss: 3.4991e-05\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 3.4117e-05 - val_loss: 4.9309e-04\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 5.1063e-05 - val_loss: 6.3377e-04\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.9861e-05 - val_loss: 4.3889e-04\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 2.6888e-05 - val_loss: 7.3355e-05\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 2.6050e-05 - val_loss: 3.4459e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 3.1855e-05 - val_loss: 6.7436e-05\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 5.3230e-05 - val_loss: 3.3525e-04\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 2.4964e-05 - val_loss: 1.0706e-04\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 2.7100e-05 - val_loss: 3.5528e-04\n",
      ">p=8: 9, Score=0.02269405231345445\n",
      "Epoch 1/50\n",
      "76/76 [==============================] - 10s 36ms/step - loss: 0.0030 - val_loss: 0.0109\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 0.0091\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 8.4227e-04 - val_loss: 0.0069\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 7.1168e-04 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.3595e-04 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 3.5291e-04 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 2.3355e-04 - val_loss: 7.8825e-04\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.9207e-04 - val_loss: 6.0332e-04\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.3086e-04 - val_loss: 7.4407e-04\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.3263e-04 - val_loss: 4.4119e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 8.0544e-05 - val_loss: 2.0881e-04\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 9.7841e-05 - val_loss: 3.4234e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 1.0002e-04 - val_loss: 2.0653e-04\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.4453e-04 - val_loss: 0.0010\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 1.6143e-04 - val_loss: 5.4670e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.9997e-05 - val_loss: 2.6934e-04\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 6.8620e-05 - val_loss: 1.9666e-04\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.0872e-05 - val_loss: 1.0939e-04\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.7056e-05 - val_loss: 3.4154e-04\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 6.1907e-05 - val_loss: 2.5461e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.3872e-05 - val_loss: 5.3376e-04\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 5.4134e-05 - val_loss: 0.0010\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 6.5157e-05 - val_loss: 6.8662e-05\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.2370e-05 - val_loss: 2.9284e-04\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 3.4149e-05 - val_loss: 2.4348e-04\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 6.0471e-05 - val_loss: 2.2815e-04\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 4.6777e-05 - val_loss: 3.8673e-04\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 7.8981e-05 - val_loss: 5.6521e-04\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 7.1249e-05 - val_loss: 4.0452e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 6.4349e-05 - val_loss: 1.9120e-04\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 9.6480e-05 - val_loss: 8.5041e-04\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 1.1649e-04 - val_loss: 9.7502e-05\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 6.5522e-05 - val_loss: 1.6473e-04\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 6.5463e-05 - val_loss: 9.3642e-04\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 8.0752e-05 - val_loss: 4.0293e-04\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.4118e-05 - val_loss: 2.7003e-04\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.4931e-05 - val_loss: 5.0371e-05\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 7.5622e-05 - val_loss: 0.0014\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 4.2239e-05 - val_loss: 1.3094e-04\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.4243e-05 - val_loss: 1.1828e-04\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 6.4287e-05 - val_loss: 3.0394e-04\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 7.8778e-05 - val_loss: 6.9391e-04\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 9.4592e-05 - val_loss: 6.6713e-05\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.6185e-05 - val_loss: 8.7358e-05\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 5.5786e-05 - val_loss: 5.8705e-05\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.0720e-05 - val_loss: 1.3115e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.1612e-05 - val_loss: 2.4652e-04\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 4.1881e-05 - val_loss: 4.5950e-04\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.2287e-05 - val_loss: 2.6999e-05\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 4.3412e-05 - val_loss: 6.1529e-04\n",
      ">p=8: 10, Score=0.04173352790530771\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 9s 35ms/step - loss: 0.0032 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 8.9984e-04 - val_loss: 0.0074\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.5315e-04 - val_loss: 0.0055\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.6390e-04 - val_loss: 0.0039\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.8039e-04 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 3.2972e-04 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.5856e-04 - val_loss: 6.8370e-04\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.5506e-04 - val_loss: 4.1727e-04\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.6734e-04 - val_loss: 8.4334e-04\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.3699e-04 - val_loss: 5.7776e-04\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.5764e-05 - val_loss: 3.9960e-04\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.4569e-04 - val_loss: 6.6811e-04\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.6780e-04 - val_loss: 8.2228e-04\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.0771e-04 - val_loss: 1.7274e-04\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.2201e-04 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.3707e-04 - val_loss: 2.8415e-04\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.5568e-05 - val_loss: 1.4551e-04\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.4827e-05 - val_loss: 3.2418e-04\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 3.8942e-05 - val_loss: 8.6678e-04\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.9735e-05 - val_loss: 6.6223e-04\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.4668e-05 - val_loss: 2.0159e-04\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 6.0019e-05 - val_loss: 3.3114e-04\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.0567e-05 - val_loss: 2.9545e-04\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 6.9681e-05 - val_loss: 4.4066e-04\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.0992e-05 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.6722e-05 - val_loss: 4.5382e-04\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.1329e-05 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.3696e-05 - val_loss: 2.6421e-04\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.8318e-05 - val_loss: 1.5335e-04\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.7678e-05 - val_loss: 1.9059e-04\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.3961e-05 - val_loss: 9.1323e-04\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.0300e-05 - val_loss: 1.5699e-04\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.3993e-05 - val_loss: 2.7635e-04\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 6.5752e-05 - val_loss: 2.6663e-04\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.2004e-05 - val_loss: 1.9435e-04\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 5.5604e-05 - val_loss: 4.2831e-04\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 5.7860e-05 - val_loss: 3.3903e-04\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.9125e-05 - val_loss: 2.1118e-04\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.0989e-05 - val_loss: 5.1942e-05\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.3807e-05 - val_loss: 6.4044e-04\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.1315e-05 - val_loss: 1.7559e-04\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.2447e-05 - val_loss: 5.2576e-04\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 4.1336e-05 - val_loss: 1.5211e-04\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 4.1694e-05 - val_loss: 1.6472e-04\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.6362e-05 - val_loss: 3.9341e-05\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.3404e-05 - val_loss: 5.8870e-05\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.7187e-05 - val_loss: 8.8112e-05\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3672e-05 - val_loss: 1.1441e-04\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.8305e-05 - val_loss: 3.8557e-04\n",
      ">p=9: 1, Score=0.024066658806987107\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 10s 34ms/step - loss: 0.0032 - val_loss: 0.0116\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 0.0011 - val_loss: 0.0101\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.6872e-04 - val_loss: 0.0083\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.1136e-04 - val_loss: 0.0062\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.3978e-04 - val_loss: 0.0044\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.3429e-04 - val_loss: 0.0033\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.6887e-04 - val_loss: 0.0018\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.2569e-04 - val_loss: 7.8073e-04\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.5316e-04 - val_loss: 8.0153e-04\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1858e-04 - val_loss: 4.5862e-04\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.1826e-04 - val_loss: 3.6600e-04\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.0966e-04 - val_loss: 6.0812e-04\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 7.9194e-05 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.0244e-04 - val_loss: 1.4762e-04\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.0693e-04 - val_loss: 5.6055e-04\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.1434e-04 - val_loss: 8.5185e-04\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.4448e-04 - val_loss: 3.1880e-04\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.7850e-05 - val_loss: 3.7866e-04\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 7.7110e-05 - val_loss: 4.5275e-04\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.4573e-05 - val_loss: 3.1225e-04\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.0121e-04 - val_loss: 8.1442e-04\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5616e-04 - val_loss: 6.9231e-04\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.6009e-05 - val_loss: 1.4180e-04\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.7405e-05 - val_loss: 4.1077e-04\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.7235e-05 - val_loss: 6.4729e-04\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 6.1715e-05 - val_loss: 5.0238e-04\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.9133e-05 - val_loss: 2.1254e-04\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.8433e-05 - val_loss: 5.1786e-04\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.9106e-05 - val_loss: 1.5624e-04\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.2231e-05 - val_loss: 8.8677e-04\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.2967e-05 - val_loss: 6.6145e-04\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.7676e-05 - val_loss: 1.0435e-04\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.5066e-05 - val_loss: 1.3805e-04\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.2079e-05 - val_loss: 3.0876e-04\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.0299e-04 - val_loss: 9.2882e-05\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.3898e-05 - val_loss: 1.0277e-04\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.4934e-05 - val_loss: 8.1911e-05\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.8188e-05 - val_loss: 3.2962e-04\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.5025e-05 - val_loss: 6.0378e-05\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.0545e-05 - val_loss: 1.7069e-04\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 3.2800e-05 - val_loss: 1.1112e-04\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 3.5735e-05 - val_loss: 9.7391e-05\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 4.1784e-05 - val_loss: 2.5865e-04\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 5.0093e-05 - val_loss: 1.7515e-04\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 9.3178e-05 - val_loss: 9.1989e-04\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.1374e-04 - val_loss: 4.1475e-04\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 5.6186e-05 - val_loss: 5.7062e-04\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 5.9040e-05 - val_loss: 1.1360e-04\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.1039e-05 - val_loss: 2.4058e-04\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 8.0055e-05 - val_loss: 1.9144e-04\n",
      ">p=9: 2, Score=0.019660391262732446\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 9s 34ms/step - loss: 0.0036 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 0.0099\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.4462e-04 - val_loss: 0.0080\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.1430e-04 - val_loss: 0.0062\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.5956e-04 - val_loss: 0.0045\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.4347e-04 - val_loss: 0.0031\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.7717e-04 - val_loss: 0.0019\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.6689e-04 - val_loss: 0.0010\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.7029e-04 - val_loss: 8.2537e-04\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.4941e-04 - val_loss: 6.5339e-04\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.0877e-04 - val_loss: 0.0022\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 9.3496e-05 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.0391e-04 - val_loss: 4.0905e-04\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 9.5060e-05 - val_loss: 3.7499e-04\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1600e-04 - val_loss: 3.9651e-04\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.0502e-04 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.0353e-05 - val_loss: 2.0392e-04\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 8.1695e-05 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 7.4456e-05 - val_loss: 2.9679e-04\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.2725e-05 - val_loss: 5.7984e-04\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.6728e-05 - val_loss: 0.0016\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.4167e-05 - val_loss: 2.1812e-04\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.8657e-05 - val_loss: 1.9944e-04\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.2229e-05 - val_loss: 2.1133e-04\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.3466e-04 - val_loss: 3.5681e-04\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.5722e-04 - val_loss: 2.3319e-04\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.5711e-04 - val_loss: 4.6573e-04\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6853e-04 - val_loss: 7.1649e-04\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.2407e-04 - val_loss: 1.0976e-04\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.5494e-05 - val_loss: 2.6737e-04\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.2758e-05 - val_loss: 4.3094e-04\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.2879e-05 - val_loss: 4.4629e-04\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 3.0887e-05 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.1662e-05 - val_loss: 5.1957e-04\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.7129e-05 - val_loss: 3.6124e-04\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.7296e-05 - val_loss: 2.0122e-04\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.9742e-05 - val_loss: 7.6859e-05\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 6.0525e-05 - val_loss: 2.3469e-04\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.6551e-05 - val_loss: 2.2611e-04\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 4.7703e-05 - val_loss: 7.3736e-05\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 3.4868e-05 - val_loss: 1.1774e-04\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 2.7086e-05 - val_loss: 6.4308e-04\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 6.2044e-05 - val_loss: 1.2671e-04\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 4.9099e-05 - val_loss: 2.5375e-04\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 4.5564e-05 - val_loss: 1.8493e-04\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 4.0927e-05 - val_loss: 2.0506e-04\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 2.9202e-05 - val_loss: 5.2734e-05\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 3.4650e-05 - val_loss: 2.1532e-04\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 21ms/step - loss: 4.8635e-05 - val_loss: 8.4977e-05\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 3.4594e-05 - val_loss: 1.6162e-04\n",
      ">p=9: 3, Score=0.01975029008463025\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 13s 38ms/step - loss: 0.0033 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 0.0010 - val_loss: 0.0082\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.3540e-04 - val_loss: 0.0062\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 6.4008e-04 - val_loss: 0.0043\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.9066e-04 - val_loss: 0.0027\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.5933e-04 - val_loss: 0.0017\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.0418e-04 - val_loss: 9.0415e-04\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.7750e-04 - val_loss: 5.3506e-04\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.3326e-04 - val_loss: 3.4738e-04\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.2010e-04 - val_loss: 3.9899e-04\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 9.2624e-05 - val_loss: 6.1931e-04\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.2446e-04 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.1198e-04 - val_loss: 3.2529e-04\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.1846e-05 - val_loss: 2.0413e-04\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 8.7083e-05 - val_loss: 2.2536e-04\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 8.2075e-05 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 7.6356e-05 - val_loss: 1.3862e-04\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 7.7122e-05 - val_loss: 6.4361e-04\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.8312e-05 - val_loss: 4.7348e-04\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.8872e-05 - val_loss: 9.0231e-04\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.6297e-05 - val_loss: 3.2255e-04\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.5535e-05 - val_loss: 2.2715e-04\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.7928e-05 - val_loss: 2.3745e-04\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.7434e-05 - val_loss: 2.2486e-04\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.4725e-05 - val_loss: 2.3315e-04\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 7.1370e-05 - val_loss: 4.4589e-04\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.9320e-05 - val_loss: 7.1779e-04\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.1230e-05 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 5.1941e-05 - val_loss: 3.4515e-04\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.2092e-05 - val_loss: 6.3622e-04\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.8612e-05 - val_loss: 3.9089e-04\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 6.2846e-05 - val_loss: 3.2136e-04\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.1915e-04 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2266e-04 - val_loss: 2.2741e-04\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.3030e-05 - val_loss: 1.9457e-04\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.0431e-05 - val_loss: 8.4615e-04\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.9707e-05 - val_loss: 4.4335e-04\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.4478e-05 - val_loss: 1.9682e-04\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.4140e-05 - val_loss: 3.6516e-04\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.9826e-05 - val_loss: 1.2276e-04\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 2.9537e-05 - val_loss: 4.9361e-04\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 7.1574e-05 - val_loss: 4.9715e-04\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 5.4363e-05 - val_loss: 2.8245e-04\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 5.4210e-05 - val_loss: 2.3465e-04\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 7.6530e-05 - val_loss: 8.2665e-04\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.0102e-05 - val_loss: 5.7394e-05\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.8059e-05 - val_loss: 5.1906e-04\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.3302e-05 - val_loss: 1.0401e-04\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.6547e-05 - val_loss: 6.3904e-05\n",
      ">p=9: 4, Score=0.00747820085962303\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 11s 36ms/step - loss: 0.0033 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 0.0011 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 9.5467e-04 - val_loss: 0.0080\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 7.7923e-04 - val_loss: 0.0060\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 6.2071e-04 - val_loss: 0.0042\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 4.5278e-04 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.2309e-04 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.6085e-04 - val_loss: 8.1793e-04\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.2780e-04 - val_loss: 5.6324e-04\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.4371e-04 - val_loss: 3.9001e-04\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.4422e-04 - val_loss: 4.7914e-04\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 9.3846e-05 - val_loss: 0.0020\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.5792e-04 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.3031e-04 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 5.5905e-05 - val_loss: 4.3333e-04\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.5250e-04 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.5392e-04 - val_loss: 4.4332e-04\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 8.2818e-05 - val_loss: 6.6695e-04\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 2s 22ms/step - loss: 5.5234e-05 - val_loss: 7.8158e-04\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 7.0582e-05 - val_loss: 1.8182e-04\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 5.7962e-05 - val_loss: 3.9242e-04\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 4.6515e-05 - val_loss: 2.8113e-04\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 6.7870e-05 - val_loss: 1.3871e-04\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.8466e-05 - val_loss: 1.8636e-04\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.5659e-05 - val_loss: 1.8545e-04\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.6896e-05 - val_loss: 1.7057e-04\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 6.9977e-05 - val_loss: 1.3182e-04\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 20ms/step - loss: 8.6653e-05 - val_loss: 3.0620e-04\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 7.2759e-05 - val_loss: 4.7206e-04\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 8.0584e-05 - val_loss: 1.1187e-04\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.0055e-04 - val_loss: 2.2078e-04\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 7.3396e-05 - val_loss: 3.4189e-04\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.8337e-05 - val_loss: 9.5484e-05\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.0950e-05 - val_loss: 4.0641e-04\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.8009e-05 - val_loss: 8.0298e-05\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.1391e-05 - val_loss: 2.0042e-04\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.4375e-05 - val_loss: 1.1866e-04\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 5.4739e-05 - val_loss: 2.6092e-04\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 6.6388e-05 - val_loss: 1.8753e-04\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 7.9062e-05 - val_loss: 1.2353e-04\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.7098e-05 - val_loss: 1.0290e-04\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.5735e-05 - val_loss: 1.5036e-04\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.8810e-05 - val_loss: 6.5200e-04\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.2979e-05 - val_loss: 3.6287e-04\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.6057e-05 - val_loss: 0.0012\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.8295e-05 - val_loss: 6.6395e-05\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.0279e-05 - val_loss: 2.4953e-04\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 4.1857e-05 - val_loss: 2.2223e-04\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 5.1356e-05 - val_loss: 2.3099e-04\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 4.7501e-05 - val_loss: 4.8540e-05\n",
      ">p=9: 5, Score=0.007589752203784883\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 11s 35ms/step - loss: 0.0032 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.8987e-04 - val_loss: 0.0079\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.7570e-04 - val_loss: 0.0058\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.9407e-04 - val_loss: 0.0040\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.5063e-04 - val_loss: 0.0025\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 3.2884e-04 - val_loss: 0.0017\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 3.1686e-04 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.4468e-04 - val_loss: 0.0010\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.2015e-04 - val_loss: 2.9782e-04\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 9.5947e-05 - val_loss: 1.8631e-04\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.2522e-04 - val_loss: 0.0020\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 8.7340e-05 - val_loss: 5.6936e-04\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 6.0725e-05 - val_loss: 5.9488e-04\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 6.0339e-05 - val_loss: 4.4371e-04\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 6.3845e-05 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 8.7427e-05 - val_loss: 6.4039e-04\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.0894e-04 - val_loss: 7.0726e-04\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.9399e-05 - val_loss: 1.9997e-04\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.9220e-05 - val_loss: 0.0018\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.6042e-05 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.0154e-05 - val_loss: 2.4961e-04\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.9515e-05 - val_loss: 1.8516e-04\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.4313e-05 - val_loss: 1.9964e-04\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.5339e-04 - val_loss: 8.0451e-04\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.0165e-04 - val_loss: 1.6288e-04\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2712e-04 - val_loss: 6.0521e-04\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.7121e-05 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 6.6236e-05 - val_loss: 2.6824e-04\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.3368e-05 - val_loss: 2.2067e-04\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.9264e-05 - val_loss: 4.0579e-04\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.0917e-05 - val_loss: 1.7674e-04\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.7808e-05 - val_loss: 2.9494e-04\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.2016e-05 - val_loss: 9.1551e-05\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.7300e-05 - val_loss: 8.4612e-05\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.7201e-05 - val_loss: 3.1696e-04\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.0882e-05 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.9634e-05 - val_loss: 5.4381e-04\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.3493e-05 - val_loss: 1.5650e-04\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.0849e-05 - val_loss: 2.8557e-04\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.1070e-05 - val_loss: 7.7459e-04\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.4926e-05 - val_loss: 9.9309e-04\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.9613e-05 - val_loss: 5.9183e-04\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.6502e-05 - val_loss: 9.0059e-05\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.3868e-05 - val_loss: 1.7474e-04\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.1202e-05 - val_loss: 8.7422e-04\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.8088e-05 - val_loss: 4.8791e-04\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.7603e-05 - val_loss: 2.6341e-04\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.1160e-05 - val_loss: 3.2644e-04\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.6977e-05 - val_loss: 1.0236e-04\n",
      ">p=9: 6, Score=0.014752859715372324\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 9s 30ms/step - loss: 0.0033 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 9.0054e-04 - val_loss: 0.0076\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.3565e-04 - val_loss: 0.0053\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.3589e-04 - val_loss: 0.0034\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.7086e-04 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.0918e-04 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.9738e-04 - val_loss: 7.2577e-04\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2116e-04 - val_loss: 8.7118e-04\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1041e-04 - val_loss: 0.0023\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.0253e-05 - val_loss: 7.1176e-04\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.0114e-05 - val_loss: 6.0857e-04\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.1981e-05 - val_loss: 4.9436e-04\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.7460e-05 - val_loss: 5.5297e-04\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.6334e-04 - val_loss: 0.0028\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6519e-04 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1832e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.6249e-05 - val_loss: 1.1530e-04\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.8663e-05 - val_loss: 3.4259e-04\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.5850e-05 - val_loss: 6.8429e-04\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.9153e-05 - val_loss: 8.4740e-04\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.9313e-05 - val_loss: 1.8887e-04\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.0295e-05 - val_loss: 3.5490e-04\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.3213e-05 - val_loss: 3.5298e-04\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.5546e-05 - val_loss: 4.2689e-04\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.7446e-05 - val_loss: 1.6298e-04\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.6575e-05 - val_loss: 7.8326e-04\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.8656e-05 - val_loss: 8.1931e-04\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.4294e-05 - val_loss: 2.9142e-04\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.4399e-05 - val_loss: 2.0283e-04\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.6004e-05 - val_loss: 7.5323e-04\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.9579e-05 - val_loss: 3.8865e-04\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.6905e-05 - val_loss: 8.1143e-04\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.8768e-05 - val_loss: 3.8962e-04\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.0135e-05 - val_loss: 2.1740e-04\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.3214e-05 - val_loss: 1.0378e-04\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.8422e-05 - val_loss: 2.0211e-04\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.8796e-05 - val_loss: 1.5827e-04\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.0466e-05 - val_loss: 4.0862e-04\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.9439e-05 - val_loss: 3.7158e-04\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.3043e-05 - val_loss: 8.0679e-04\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.8256e-05 - val_loss: 7.9959e-04\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 9.7306e-05 - val_loss: 1.6728e-04\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1091e-04 - val_loss: 7.8891e-05\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.0950e-04 - val_loss: 6.4890e-04\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.3018e-05 - val_loss: 7.3394e-05\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.3053e-05 - val_loss: 2.9967e-04\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.8477e-05 - val_loss: 9.4056e-05\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.3009e-05 - val_loss: 5.3870e-04\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.0321e-05 - val_loss: 2.4095e-04\n",
      ">p=9: 7, Score=0.015169985999818891\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 8s 29ms/step - loss: 0.0033 - val_loss: 0.0116\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0101\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.8564e-04 - val_loss: 0.0082\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.1015e-04 - val_loss: 0.0060\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.4411e-04 - val_loss: 0.0040\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.5761e-04 - val_loss: 0.0023\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.0631e-04 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.9796e-04 - val_loss: 5.2208e-04\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6033e-04 - val_loss: 3.3170e-04\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.0582e-04 - val_loss: 1.2254e-04\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 9.4229e-05 - val_loss: 4.1725e-04\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.1975e-05 - val_loss: 7.0549e-04\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 9.1543e-05 - val_loss: 2.1259e-04\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2105e-04 - val_loss: 1.7510e-04\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.8823e-05 - val_loss: 2.1097e-04\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.8780e-05 - val_loss: 0.0018\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.9709e-05 - val_loss: 0.0021\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.7125e-05 - val_loss: 3.7307e-04\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.2659e-05 - val_loss: 3.5614e-04\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.8133e-05 - val_loss: 2.4502e-04\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.7214e-05 - val_loss: 3.4385e-04\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.7961e-05 - val_loss: 1.2860e-04\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.2060e-05 - val_loss: 3.2965e-04\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.5704e-05 - val_loss: 9.2088e-04\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.0331e-05 - val_loss: 6.8204e-04\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.3277e-05 - val_loss: 0.0017\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.1015e-05 - val_loss: 1.5598e-04\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.9416e-05 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.7332e-05 - val_loss: 1.4585e-04\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.3630e-05 - val_loss: 2.5043e-04\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.6555e-05 - val_loss: 2.2725e-04\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1417e-04 - val_loss: 0.0015\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.1268e-05 - val_loss: 1.7984e-04\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.1975e-05 - val_loss: 3.2503e-04\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.8317e-05 - val_loss: 3.1256e-04\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.3237e-05 - val_loss: 2.4584e-04\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.0584e-05 - val_loss: 2.0051e-04\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.5022e-05 - val_loss: 3.1229e-04\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.0057e-04 - val_loss: 2.0228e-04\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.8163e-05 - val_loss: 7.8004e-05\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.9023e-05 - val_loss: 8.9208e-04\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.1132e-05 - val_loss: 4.1171e-04\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.1904e-05 - val_loss: 3.7755e-04\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.8001e-05 - val_loss: 2.4987e-04\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.3388e-05 - val_loss: 3.9787e-04\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.4101e-05 - val_loss: 5.5241e-04\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.2171e-05 - val_loss: 1.4436e-04\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.1673e-05 - val_loss: 6.3083e-05\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.4876e-05 - val_loss: 8.7987e-05\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.0958e-05 - val_loss: 0.0015\n",
      ">p=9: 8, Score=0.09409237536601722\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 8s 29ms/step - loss: 0.0029 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0090\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.6095e-04 - val_loss: 0.0068\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.5684e-04 - val_loss: 0.0046\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.2322e-04 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.6720e-04 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.5022e-04 - val_loss: 7.6174e-04\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.5764e-04 - val_loss: 0.0010\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.3833e-04 - val_loss: 5.4110e-04\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.3275e-04 - val_loss: 2.6354e-04\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0329e-04 - val_loss: 1.8717e-04\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 9.7591e-05 - val_loss: 1.5081e-04\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.0844e-05 - val_loss: 4.5543e-04\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.3704e-04 - val_loss: 4.5128e-04\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.7407e-05 - val_loss: 4.5546e-04\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.3183e-05 - val_loss: 4.7450e-04\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.7251e-05 - val_loss: 2.9044e-04\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.8139e-05 - val_loss: 1.6698e-04\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.8315e-05 - val_loss: 2.0839e-04\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.9115e-05 - val_loss: 4.1738e-04\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.2038e-04 - val_loss: 5.2484e-05\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.9348e-05 - val_loss: 2.8937e-04\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.4672e-05 - val_loss: 1.9899e-04\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.8487e-05 - val_loss: 4.3325e-04\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.8629e-05 - val_loss: 5.4630e-04\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.8539e-05 - val_loss: 8.4125e-05\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.5086e-05 - val_loss: 1.1445e-04\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.5688e-05 - val_loss: 5.2896e-04\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.3534e-05 - val_loss: 1.8422e-04\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0237e-04 - val_loss: 1.9284e-04\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.4664e-05 - val_loss: 6.9707e-05\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.9485e-05 - val_loss: 1.5061e-04\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.3625e-04 - val_loss: 6.9977e-04\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.3383e-05 - val_loss: 2.7457e-04\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.5087e-05 - val_loss: 2.6160e-04\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.0593e-05 - val_loss: 4.1980e-04\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.3780e-05 - val_loss: 1.3340e-04\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.0362e-05 - val_loss: 3.0322e-04\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.9489e-05 - val_loss: 6.4922e-04\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.4916e-05 - val_loss: 4.5527e-04\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.4024e-05 - val_loss: 1.6979e-04\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.2933e-05 - val_loss: 4.0663e-04\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.1107e-05 - val_loss: 2.9920e-04\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.4310e-05 - val_loss: 1.2071e-04\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.1754e-05 - val_loss: 9.4502e-05\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.8221e-05 - val_loss: 6.2838e-04\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.3293e-05 - val_loss: 1.2018e-04\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.3451e-05 - val_loss: 2.2990e-04\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.6026e-05 - val_loss: 0.0011\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.8888e-05 - val_loss: 6.2991e-05\n",
      ">p=9: 9, Score=0.006616467726416886\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 9s 30ms/step - loss: 0.0033 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 9.4990e-04 - val_loss: 0.0076\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.5442e-04 - val_loss: 0.0056\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.7990e-04 - val_loss: 0.0038\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.5946e-04 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.2430e-04 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.2349e-04 - val_loss: 9.7323e-04\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.5670e-04 - val_loss: 2.8882e-04\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.3589e-04 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.5743e-05 - val_loss: 4.5620e-04\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 9.8701e-05 - val_loss: 3.8945e-04\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.4607e-05 - val_loss: 8.3542e-04\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.1173e-05 - val_loss: 7.9488e-04\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.4515e-05 - val_loss: 7.8840e-04\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.2301e-05 - val_loss: 0.0019\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.6871e-05 - val_loss: 2.3737e-04\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.9172e-05 - val_loss: 5.8671e-04\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.9105e-05 - val_loss: 2.2066e-04\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.9022e-05 - val_loss: 4.1988e-04\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9795e-04 - val_loss: 0.0024\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.7874e-04 - val_loss: 3.4773e-04\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.3331e-05 - val_loss: 3.1219e-04\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.3189e-05 - val_loss: 5.5446e-04\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.0474e-05 - val_loss: 3.4884e-04\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.9115e-05 - val_loss: 4.4597e-04\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.7164e-05 - val_loss: 0.0015\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.3008e-05 - val_loss: 9.5705e-04\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.8784e-05 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0252e-04 - val_loss: 3.6167e-04\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.1091e-05 - val_loss: 4.1474e-04\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.6607e-05 - val_loss: 3.8930e-04\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.8578e-05 - val_loss: 1.7833e-04\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.8675e-05 - val_loss: 1.8330e-04\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.0433e-05 - val_loss: 3.1712e-04\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7279e-05 - val_loss: 2.6160e-04\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.8830e-05 - val_loss: 2.4696e-04\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.8421e-05 - val_loss: 9.3673e-05\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.0722e-05 - val_loss: 5.7582e-04\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.7656e-05 - val_loss: 1.6058e-04\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.7841e-05 - val_loss: 4.1816e-04\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.6830e-05 - val_loss: 1.0657e-04\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.6728e-05 - val_loss: 6.8395e-04\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.9799e-05 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.1260e-05 - val_loss: 5.9447e-04\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.8391e-05 - val_loss: 6.3136e-05\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.8145e-05 - val_loss: 1.6834e-04\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 9.4406e-05 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0152e-04 - val_loss: 5.6997e-05\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.1274e-05 - val_loss: 0.0011\n",
      ">p=9: 10, Score=0.06021526060067117\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 8s 29ms/step - loss: 0.0036 - val_loss: 0.0114\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.4904e-04 - val_loss: 0.0075\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.6495e-04 - val_loss: 0.0057\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.5296e-04 - val_loss: 0.0042\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.5028e-04 - val_loss: 0.0028\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.1669e-04 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 2.2250e-04 - val_loss: 9.0116e-04\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.7126e-04 - val_loss: 4.5872e-04\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.2891e-04 - val_loss: 4.8508e-04\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 1.4759e-04 - val_loss: 0.0017\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.9598e-05 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.0929e-04 - val_loss: 3.5489e-04\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.1891e-04 - val_loss: 2.9071e-04\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 9.4331e-05 - val_loss: 2.7355e-04\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.9164e-05 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.7127e-05 - val_loss: 5.6419e-04\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 6.0900e-05 - val_loss: 3.8718e-04\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.9256e-05 - val_loss: 8.0133e-04\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 1.0229e-04 - val_loss: 1.7990e-04\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.0317e-04 - val_loss: 3.4105e-04\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.0964e-04 - val_loss: 4.3450e-04\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.5352e-05 - val_loss: 3.2705e-04\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.4271e-05 - val_loss: 4.7373e-04\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.3756e-05 - val_loss: 3.1822e-04\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 7.2525e-05 - val_loss: 1.4449e-04\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.7937e-05 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.2187e-05 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.9159e-05 - val_loss: 2.1337e-04\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.5586e-05 - val_loss: 1.6885e-04\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.1173e-05 - val_loss: 1.7223e-04\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.8326e-05 - val_loss: 2.8623e-04\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 3.1874e-05 - val_loss: 4.1172e-04\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.5157e-05 - val_loss: 1.7322e-04\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.2783e-05 - val_loss: 1.0880e-04\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.0302e-05 - val_loss: 7.1199e-05\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 4.8854e-05 - val_loss: 6.2878e-04\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.2922e-05 - val_loss: 7.7103e-05\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.7078e-05 - val_loss: 1.1605e-04\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.0635e-05 - val_loss: 3.8083e-04\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.1694e-05 - val_loss: 1.0745e-04\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 3.4872e-05 - val_loss: 4.3676e-04\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.0683e-05 - val_loss: 5.7503e-04\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 6.0078e-05 - val_loss: 3.6175e-04\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.3750e-05 - val_loss: 1.5015e-04\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 5.1075e-05 - val_loss: 1.1013e-04\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.0803e-05 - val_loss: 5.4752e-05\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 4.7027e-05 - val_loss: 7.9694e-04\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.5383e-05 - val_loss: 1.5758e-04\n",
      ">p=10: 1, Score=0.01091561425710097\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 9s 46ms/step - loss: 0.0034 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0102\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0088\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.2734e-04 - val_loss: 0.0074\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 7.7356e-04 - val_loss: 0.0056\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.9943e-04 - val_loss: 0.0039\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 4.5514e-04 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.0300e-04 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 2.7092e-04 - val_loss: 6.5613e-04\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.7996e-04 - val_loss: 3.3566e-04\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 1.2996e-04 - val_loss: 3.2025e-04\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.0725e-04 - val_loss: 3.8871e-04\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.2095e-04 - val_loss: 2.3433e-04\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.1361e-04 - val_loss: 4.3934e-04\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.2003e-05 - val_loss: 3.0815e-04\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.5656e-05 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.6570e-05 - val_loss: 2.5216e-04\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.2684e-05 - val_loss: 2.5328e-04\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.6463e-05 - val_loss: 3.8879e-04\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.0146e-05 - val_loss: 3.2971e-04\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 7.8773e-05 - val_loss: 0.0010\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.1792e-05 - val_loss: 1.4360e-04\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.9545e-05 - val_loss: 8.8757e-04\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 9.6317e-05 - val_loss: 4.2075e-04\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.2566e-05 - val_loss: 4.2999e-04\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.1253e-05 - val_loss: 1.6727e-04\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.9301e-05 - val_loss: 1.8929e-04\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.8779e-05 - val_loss: 6.4924e-04\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.5972e-05 - val_loss: 1.2422e-04\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.9989e-05 - val_loss: 4.5633e-04\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 6.2880e-05 - val_loss: 9.5140e-05\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.9202e-05 - val_loss: 8.0624e-05\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.7845e-05 - val_loss: 2.0469e-04\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.1540e-04 - val_loss: 4.3133e-04\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.3719e-04 - val_loss: 3.8063e-04\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.0685e-05 - val_loss: 4.0521e-04\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 3.8008e-05 - val_loss: 1.4389e-04\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.7224e-05 - val_loss: 2.7694e-04\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 3.7773e-05 - val_loss: 4.7743e-04\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.2127e-05 - val_loss: 7.5364e-05\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.7745e-05 - val_loss: 1.3312e-04\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.0840e-05 - val_loss: 8.2927e-05\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 3.4714e-05 - val_loss: 1.5921e-04\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.8542e-05 - val_loss: 9.4131e-05\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.2430e-05 - val_loss: 1.7788e-04\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.0884e-05 - val_loss: 1.8132e-04\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.7151e-05 - val_loss: 1.0997e-04\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.9457e-05 - val_loss: 1.5722e-04\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.7249e-05 - val_loss: 1.8464e-04\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 2.3497e-05 - val_loss: 3.5426e-04\n",
      ">p=10: 2, Score=0.017952824418898672\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 8s 34ms/step - loss: 0.0034 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 0.0101\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0088\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 8.9867e-04 - val_loss: 0.0071\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.5297e-04 - val_loss: 0.0053\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.7505e-04 - val_loss: 0.0036\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.2539e-04 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 2.6517e-04 - val_loss: 0.0010\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 2.2548e-04 - val_loss: 8.5290e-04\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 1.0608e-04 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.5678e-04 - val_loss: 5.6444e-04\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.9572e-05 - val_loss: 1.6407e-04\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 8.7858e-05 - val_loss: 4.2792e-04\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.3501e-05 - val_loss: 5.5164e-04\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 9.0053e-05 - val_loss: 1.8426e-04\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 8.1590e-05 - val_loss: 7.8066e-04\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.9921e-05 - val_loss: 5.1331e-04\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 6.3064e-05 - val_loss: 3.6687e-04\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.4544e-05 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.6273e-05 - val_loss: 1.3210e-04\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 7.3726e-05 - val_loss: 2.9066e-04\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.9989e-05 - val_loss: 6.8909e-04\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.3595e-05 - val_loss: 2.4562e-04\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.6720e-05 - val_loss: 6.9717e-04\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.8994e-05 - val_loss: 2.5597e-04\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.5938e-05 - val_loss: 1.5649e-04\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.4706e-05 - val_loss: 3.3122e-04\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.9511e-05 - val_loss: 6.4607e-04\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.2438e-05 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.8301e-05 - val_loss: 1.9127e-04\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 6.5076e-05 - val_loss: 6.0268e-04\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.4134e-05 - val_loss: 4.4113e-04\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 5.4407e-05 - val_loss: 2.9293e-04\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.7256e-05 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 9.5280e-05 - val_loss: 1.2725e-04\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.4580e-05 - val_loss: 2.2685e-04\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.7557e-05 - val_loss: 4.6366e-05\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.2047e-05 - val_loss: 1.3794e-04\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.3542e-05 - val_loss: 1.8769e-04\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 3.1339e-05 - val_loss: 2.5437e-04\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 3.4178e-05 - val_loss: 3.7204e-04\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 4.0492e-05 - val_loss: 1.0928e-04\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.3056e-05 - val_loss: 2.1812e-04\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.1542e-05 - val_loss: 1.1440e-04\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.1566e-05 - val_loss: 6.3183e-05\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.2545e-05 - val_loss: 4.1535e-04\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.3601e-05 - val_loss: 1.0641e-04\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.9318e-05 - val_loss: 8.4611e-05\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 2.2612e-05 - val_loss: 4.2461e-04\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 4.4814e-05 - val_loss: 6.4400e-04\n",
      ">p=10: 3, Score=0.04130839370191097\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 8s 32ms/step - loss: 0.0035 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0100\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 0.0085\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 8.7168e-04 - val_loss: 0.0069\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.3443e-04 - val_loss: 0.0053\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.0379e-04 - val_loss: 0.0037\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.3809e-04 - val_loss: 0.0022\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 2.9902e-04 - val_loss: 0.0010\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.6579e-04 - val_loss: 4.9677e-04\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.7063e-04 - val_loss: 4.2366e-04\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 1.1605e-04 - val_loss: 1.2990e-04\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.6535e-04 - val_loss: 4.0767e-04\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.5782e-04 - val_loss: 9.7104e-05\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.0521e-04 - val_loss: 6.3002e-04\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 1.0376e-04 - val_loss: 3.1538e-04\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 1.2304e-04 - val_loss: 5.6549e-04\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 7.6851e-05 - val_loss: 2.1305e-04\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.3686e-05 - val_loss: 1.0844e-04\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.6612e-05 - val_loss: 2.1792e-04\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.3086e-05 - val_loss: 1.7209e-04\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 6.8139e-05 - val_loss: 8.4405e-05\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.0018e-05 - val_loss: 1.9189e-04\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.8280e-05 - val_loss: 5.2920e-04\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.0553e-05 - val_loss: 1.3966e-04\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.3370e-05 - val_loss: 3.5305e-04\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.6807e-05 - val_loss: 3.7273e-04\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.3493e-05 - val_loss: 4.6543e-04\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.6214e-05 - val_loss: 9.6455e-04\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.7922e-05 - val_loss: 5.0105e-04\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 4.8366e-05 - val_loss: 3.6856e-04\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.4066e-05 - val_loss: 1.7574e-04\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.3604e-05 - val_loss: 2.1588e-04\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 7.6124e-05 - val_loss: 1.8114e-04\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.3187e-05 - val_loss: 5.8475e-05\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.1070e-05 - val_loss: 3.5570e-04\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 4.4196e-05 - val_loss: 6.3562e-04\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.3072e-05 - val_loss: 2.3498e-04\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.3292e-05 - val_loss: 3.3306e-04\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.1043e-05 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.2824e-05 - val_loss: 1.0736e-04\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.8366e-05 - val_loss: 4.0085e-04\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.0895e-05 - val_loss: 1.5539e-04\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 4.3195e-05 - val_loss: 7.3381e-05\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.6136e-05 - val_loss: 1.5466e-04\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 3.5263e-05 - val_loss: 7.6789e-04\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.2392e-05 - val_loss: 3.9837e-04\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.6441e-05 - val_loss: 4.2255e-04\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 5.8470e-05 - val_loss: 4.6182e-05\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.2497e-05 - val_loss: 1.3997e-04\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.8096e-05 - val_loss: 4.4910e-05\n",
      ">p=10: 4, Score=0.006483438482973725\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 8s 32ms/step - loss: 0.0035 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0102\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 9.9930e-04 - val_loss: 0.0087\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.9950e-04 - val_loss: 0.0070\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.6204e-04 - val_loss: 0.0052\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.3513e-04 - val_loss: 0.0035\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.8358e-04 - val_loss: 0.0023\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.3219e-04 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 2.1555e-04 - val_loss: 4.8759e-04\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.4566e-04 - val_loss: 2.9622e-04\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.8762e-05 - val_loss: 2.3912e-04\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.1359e-05 - val_loss: 6.5305e-04\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.3227e-05 - val_loss: 4.5397e-04\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.3273e-05 - val_loss: 1.5719e-04\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.6687e-05 - val_loss: 3.0786e-04\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.3924e-04 - val_loss: 6.7469e-04\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.3998e-04 - val_loss: 3.4057e-04\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 9.7996e-05 - val_loss: 2.9068e-04\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.8644e-05 - val_loss: 2.2214e-04\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.4846e-05 - val_loss: 3.0090e-04\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.2405e-05 - val_loss: 7.3488e-04\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.7235e-05 - val_loss: 2.9849e-04\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 7.1224e-05 - val_loss: 4.8110e-04\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.9959e-05 - val_loss: 6.9313e-04\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.2946e-05 - val_loss: 2.5989e-04\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 8.1702e-05 - val_loss: 5.9731e-04\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.5041e-05 - val_loss: 8.6128e-05\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.9565e-05 - val_loss: 3.8118e-04\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.6258e-05 - val_loss: 2.6485e-04\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 3.6546e-05 - val_loss: 5.5031e-04\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.1358e-05 - val_loss: 1.6955e-04\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.5682e-05 - val_loss: 4.1932e-04\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.5119e-05 - val_loss: 1.4040e-04\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.4432e-05 - val_loss: 2.0266e-04\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.4642e-05 - val_loss: 1.1791e-04\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 7.5051e-05 - val_loss: 2.8165e-04\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.6223e-05 - val_loss: 3.8155e-04\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.0187e-05 - val_loss: 1.2983e-04\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.7975e-05 - val_loss: 1.0683e-04\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 7.7414e-05 - val_loss: 6.3830e-05\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.9675e-05 - val_loss: 1.8552e-04\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.0811e-05 - val_loss: 2.5614e-04\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.0469e-04 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.3206e-05 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.2083e-05 - val_loss: 2.0808e-04\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.2561e-05 - val_loss: 3.8974e-04\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.8114e-05 - val_loss: 1.3279e-04\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.2891e-05 - val_loss: 9.2691e-05\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.1739e-05 - val_loss: 2.9734e-04\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.5001e-05 - val_loss: 3.5201e-05\n",
      ">p=10: 5, Score=0.004660504055209458\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 8s 31ms/step - loss: 0.0036 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0099\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.8529e-04 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.4712e-04 - val_loss: 0.0067\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.8027e-04 - val_loss: 0.0048\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 5.1108e-04 - val_loss: 0.0031\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.3636e-04 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 2.2490e-04 - val_loss: 8.4960e-04\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 2.0757e-04 - val_loss: 3.1315e-04\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.0021e-04 - val_loss: 4.2690e-04\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 1.0662e-04 - val_loss: 2.1333e-04\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 8.4698e-05 - val_loss: 1.9664e-04\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 1.3696e-04 - val_loss: 2.2501e-04\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.0556e-04 - val_loss: 4.1062e-04\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 1.3772e-04 - val_loss: 6.0210e-04\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 1.3841e-04 - val_loss: 6.8163e-04\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 8.7501e-05 - val_loss: 1.6781e-04\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.0405e-04 - val_loss: 2.4411e-04\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.5388e-05 - val_loss: 1.4063e-04\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.2873e-05 - val_loss: 7.2443e-04\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 5.2696e-05 - val_loss: 9.4946e-04\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.7768e-05 - val_loss: 2.8718e-04\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.3710e-05 - val_loss: 1.6365e-04\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.4426e-05 - val_loss: 2.3205e-04\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 5.2739e-05 - val_loss: 2.4111e-04\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.3290e-05 - val_loss: 2.6735e-04\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.1994e-05 - val_loss: 1.0714e-04\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.7709e-05 - val_loss: 3.9637e-04\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.8627e-05 - val_loss: 4.4645e-04\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 4.9024e-05 - val_loss: 9.1822e-04\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.3693e-05 - val_loss: 2.4710e-04\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 4.0493e-05 - val_loss: 2.2185e-04\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.1087e-05 - val_loss: 5.2303e-04\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.2514e-05 - val_loss: 2.0284e-04\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.2637e-05 - val_loss: 8.8143e-04\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 4.5050e-05 - val_loss: 4.8168e-04\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.3272e-05 - val_loss: 2.5087e-04\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.8751e-05 - val_loss: 6.8685e-05\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.0566e-05 - val_loss: 4.3342e-04\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.9758e-05 - val_loss: 3.1150e-04\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.8956e-05 - val_loss: 6.6665e-05\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.9055e-05 - val_loss: 1.2228e-04\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.0962e-05 - val_loss: 7.6931e-05\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.6639e-05 - val_loss: 2.1695e-04\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.6694e-05 - val_loss: 2.2058e-04\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 2.7565e-05 - val_loss: 1.1727e-04\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 2.8337e-05 - val_loss: 1.5460e-04\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 2.6606e-05 - val_loss: 5.1954e-04\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.1258e-05 - val_loss: 2.2214e-04\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.4775e-05 - val_loss: 1.2491e-04\n",
      ">p=10: 6, Score=0.012655799218919128\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 8s 35ms/step - loss: 0.0035 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0100\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 22ms/step - loss: 9.6905e-04 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 8.8700e-04 - val_loss: 0.0067\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.8421e-04 - val_loss: 0.0049\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.1234e-04 - val_loss: 0.0035\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.9121e-04 - val_loss: 0.0022\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.3079e-04 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.9795e-04 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.6888e-04 - val_loss: 2.9132e-04\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.2823e-04 - val_loss: 2.1424e-04\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 1.0521e-04 - val_loss: 4.2841e-04\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.3117e-04 - val_loss: 3.0864e-04\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.6598e-04 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 1.6050e-04 - val_loss: 2.3524e-04\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.1407e-05 - val_loss: 4.1726e-04\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 1.1026e-04 - val_loss: 1.5457e-04\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.5133e-05 - val_loss: 0.0021\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 8.3406e-05 - val_loss: 3.3041e-04\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.0907e-05 - val_loss: 7.6235e-04\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.5985e-05 - val_loss: 5.8262e-04\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.9566e-05 - val_loss: 7.8248e-04\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.1037e-05 - val_loss: 0.0017\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.9035e-05 - val_loss: 3.6856e-04\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.0517e-05 - val_loss: 2.0306e-04\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 4.8268e-05 - val_loss: 2.9755e-04\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 7.7828e-05 - val_loss: 5.8229e-04\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.4923e-05 - val_loss: 8.3635e-04\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.7045e-05 - val_loss: 2.0440e-04\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.7424e-05 - val_loss: 1.3998e-04\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 6.7528e-05 - val_loss: 1.8179e-04\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.4009e-05 - val_loss: 1.2864e-04\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.2991e-05 - val_loss: 2.0331e-04\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.4968e-05 - val_loss: 2.1001e-04\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 7.1269e-05 - val_loss: 3.4793e-04\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.2268e-05 - val_loss: 7.7736e-05\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.4788e-05 - val_loss: 8.4803e-05\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.3490e-05 - val_loss: 2.0280e-04\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.0715e-05 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.9176e-05 - val_loss: 1.7551e-04\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 2.8404e-05 - val_loss: 0.0010\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.2843e-05 - val_loss: 3.7102e-04\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.1446e-05 - val_loss: 1.4709e-04\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.2824e-05 - val_loss: 2.8506e-04\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.6948e-05 - val_loss: 2.1841e-04\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.9596e-05 - val_loss: 5.6151e-04\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 2.6085e-05 - val_loss: 1.8839e-04\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.3644e-05 - val_loss: 0.0014\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.9118e-05 - val_loss: 6.3365e-05\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.9128e-05 - val_loss: 9.5580e-05\n",
      ">p=10: 7, Score=0.015268086281139404\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 8s 32ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0102\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 0.0087\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.6268e-04 - val_loss: 0.0069\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.6200e-04 - val_loss: 0.0050\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.2779e-04 - val_loss: 0.0035\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 3.8216e-04 - val_loss: 0.0023\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.8508e-04 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.0476e-04 - val_loss: 5.4991e-04\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.3096e-04 - val_loss: 4.2880e-04\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 1.4073e-04 - val_loss: 8.4253e-04\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 8.1345e-05 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.2405e-04 - val_loss: 2.1428e-04\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 7.9003e-05 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 8.7062e-05 - val_loss: 7.7052e-04\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.6171e-05 - val_loss: 0.0010\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 8.8313e-05 - val_loss: 1.2422e-04\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 8.9787e-05 - val_loss: 5.4182e-04\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 8.5438e-05 - val_loss: 1.4770e-04\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.0278e-05 - val_loss: 5.9441e-04\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 7.6795e-05 - val_loss: 3.0462e-04\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.2478e-05 - val_loss: 5.6239e-04\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.2013e-05 - val_loss: 4.9397e-04\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 9.2369e-05 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.2477e-05 - val_loss: 3.6976e-04\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.1492e-05 - val_loss: 1.5726e-04\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.5334e-05 - val_loss: 2.1800e-04\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.9011e-05 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.9716e-05 - val_loss: 3.7984e-04\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 4.7539e-05 - val_loss: 9.0893e-05\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.0260e-05 - val_loss: 1.7640e-04\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.9452e-05 - val_loss: 7.8294e-05\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.0031e-05 - val_loss: 1.2471e-04\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.9850e-05 - val_loss: 2.8509e-04\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.9860e-05 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.3829e-05 - val_loss: 1.0443e-04\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.5653e-05 - val_loss: 2.4882e-04\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.9189e-05 - val_loss: 1.6578e-04\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.4559e-05 - val_loss: 2.6316e-04\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 6.3613e-05 - val_loss: 3.1740e-04\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.0747e-05 - val_loss: 0.0015\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 5.0570e-05 - val_loss: 1.2085e-04\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.8248e-05 - val_loss: 1.7294e-04\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 6.9451e-05 - val_loss: 9.7394e-04\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 6.9852e-05 - val_loss: 7.0454e-04\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 3.2999e-05 - val_loss: 6.8473e-05\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 6.5642e-05 - val_loss: 8.4799e-04\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.0376e-05 - val_loss: 1.2403e-04\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 2.4384e-05 - val_loss: 7.6582e-04\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.9554e-05 - val_loss: 3.2821e-04\n",
      ">p=10: 8, Score=0.03922606410924345\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 8s 31ms/step - loss: 0.0036 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0101\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0087\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 8.5051e-04 - val_loss: 0.0069\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.4228e-04 - val_loss: 0.0053\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 5.8998e-04 - val_loss: 0.0037\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.3365e-04 - val_loss: 0.0024\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.0782e-04 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 2.2724e-04 - val_loss: 7.9493e-04\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.3748e-04 - val_loss: 7.5614e-04\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.4599e-04 - val_loss: 3.4618e-04\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.8115e-04 - val_loss: 8.6840e-04\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.4139e-04 - val_loss: 2.1599e-04\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.9501e-05 - val_loss: 3.6034e-04\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.4298e-05 - val_loss: 8.4351e-04\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.2953e-05 - val_loss: 2.4881e-04\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 6.0923e-05 - val_loss: 6.5542e-04\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 7.6233e-05 - val_loss: 6.6704e-04\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 9.4114e-05 - val_loss: 4.9173e-04\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 8.7248e-05 - val_loss: 4.1622e-04\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.9893e-05 - val_loss: 1.4692e-04\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.4982e-05 - val_loss: 2.4290e-04\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.1604e-05 - val_loss: 3.2988e-04\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 7.4678e-05 - val_loss: 3.4668e-04\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.5205e-05 - val_loss: 2.5321e-04\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 9.1644e-05 - val_loss: 6.8146e-04\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.2431e-05 - val_loss: 3.5304e-04\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 4.6434e-05 - val_loss: 1.6311e-04\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.6248e-05 - val_loss: 1.1632e-04\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.9476e-05 - val_loss: 9.7549e-04\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.6556e-05 - val_loss: 1.5294e-04\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.9289e-05 - val_loss: 1.6053e-04\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 3.8310e-05 - val_loss: 4.6355e-05\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 5.3576e-05 - val_loss: 3.7629e-04\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.0978e-05 - val_loss: 7.2300e-04\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.1719e-05 - val_loss: 8.4535e-05\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.5053e-05 - val_loss: 2.2579e-04\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.4758e-05 - val_loss: 4.9878e-04\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.9049e-05 - val_loss: 1.0453e-04\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 3.7287e-05 - val_loss: 4.0479e-04\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.3870e-05 - val_loss: 7.5874e-05\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.6319e-05 - val_loss: 1.3572e-04\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.7071e-05 - val_loss: 7.3873e-04\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.2938e-05 - val_loss: 1.7646e-04\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.6007e-05 - val_loss: 1.5578e-04\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 2.7390e-05 - val_loss: 1.3121e-04\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.5408e-05 - val_loss: 1.9663e-04\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 2.9580e-05 - val_loss: 7.7398e-05\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.8458e-05 - val_loss: 1.9123e-04\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 2.6248e-05 - val_loss: 3.2469e-05\n",
      ">p=10: 9, Score=0.007272651419043541\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0119\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.0012 - val_loss: 0.0109\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 9.1790e-04 - val_loss: 0.0076\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.7477e-04 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.3349e-04 - val_loss: 0.0036\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.3190e-04 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.4194e-04 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 2.4037e-04 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.9520e-04 - val_loss: 2.7293e-04\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.2197e-04 - val_loss: 9.9655e-04\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 1.2848e-04 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 8.7236e-05 - val_loss: 5.4153e-04\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 9.2316e-05 - val_loss: 1.3742e-04\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 8.2033e-05 - val_loss: 8.0312e-04\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 4.9110e-05 - val_loss: 3.7938e-04\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.6708e-05 - val_loss: 7.0247e-04\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 1.2971e-04 - val_loss: 6.6322e-04\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 1.1697e-04 - val_loss: 9.4532e-04\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.4704e-05 - val_loss: 6.8181e-04\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.1003e-05 - val_loss: 1.3118e-04\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 8.9959e-05 - val_loss: 0.0020\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 7.9924e-05 - val_loss: 3.4294e-04\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 16ms/step - loss: 7.1929e-05 - val_loss: 6.7934e-04\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.3503e-05 - val_loss: 8.8552e-04\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.8098e-05 - val_loss: 4.8475e-04\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 6.4265e-05 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 5.4105e-05 - val_loss: 4.0486e-04\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 4.1349e-05 - val_loss: 4.5382e-04\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.6920e-05 - val_loss: 6.4200e-04\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 4.4706e-05 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.2432e-05 - val_loss: 3.7246e-04\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.0649e-05 - val_loss: 5.6995e-04\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.5340e-05 - val_loss: 3.1256e-04\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 4.5582e-05 - val_loss: 1.8120e-04\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 6.6096e-05 - val_loss: 1.5328e-04\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.2018e-05 - val_loss: 1.8776e-04\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 3.0780e-05 - val_loss: 2.7657e-04\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 2.6870e-05 - val_loss: 1.9120e-04\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 3.2185e-05 - val_loss: 3.4085e-04\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.7471e-05 - val_loss: 2.5906e-04\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 4.4927e-05 - val_loss: 1.2527e-04\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.2195e-05 - val_loss: 7.4782e-05\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 4.0673e-05 - val_loss: 7.5122e-05\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.0754e-05 - val_loss: 1.7914e-04\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.8088e-05 - val_loss: 1.2104e-04\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 3.9607e-05 - val_loss: 5.2785e-05\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 6.5986e-05 - val_loss: 6.5426e-04\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 7.2324e-05 - val_loss: 2.3223e-04\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 5.0408e-05 - val_loss: 0.0013\n",
      ">p=10: 10, Score=0.07167885196395218\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 8s 38ms/step - loss: 0.0038 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 0.0082\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 8.3124e-04 - val_loss: 0.0065\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.9687e-04 - val_loss: 0.0048\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.5922e-04 - val_loss: 0.0032\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.8211e-04 - val_loss: 0.0020\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.0914e-04 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6767e-04 - val_loss: 8.4584e-04\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.3740e-04 - val_loss: 1.8761e-04\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.9505e-04 - val_loss: 7.8063e-04\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.7633e-04 - val_loss: 4.1530e-04\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.7558e-04 - val_loss: 3.1352e-04\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 9.6358e-05 - val_loss: 3.2661e-04\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.2692e-05 - val_loss: 9.4471e-04\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 7.8745e-05 - val_loss: 3.8028e-04\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.1157e-04 - val_loss: 3.4747e-04\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.4802e-05 - val_loss: 3.4980e-04\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.9755e-05 - val_loss: 5.2330e-04\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 6.0600e-05 - val_loss: 3.8402e-04\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0227e-04 - val_loss: 7.2099e-04\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 8.8098e-05 - val_loss: 4.2254e-04\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 9.2869e-05 - val_loss: 1.4756e-04\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.2030e-04 - val_loss: 2.9168e-04\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.7997e-05 - val_loss: 5.9620e-04\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 7.2704e-05 - val_loss: 1.5969e-04\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0515e-04 - val_loss: 2.5370e-04\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.0329e-05 - val_loss: 7.9289e-04\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.2410e-04 - val_loss: 1.4174e-04\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.9364e-05 - val_loss: 1.7154e-04\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.1826e-04 - val_loss: 9.1689e-05\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 4.5327e-05 - val_loss: 3.1865e-04\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.9220e-05 - val_loss: 7.9831e-04\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.9301e-05 - val_loss: 5.2372e-04\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 3.1729e-05 - val_loss: 7.6672e-04\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.8094e-05 - val_loss: 2.2182e-04\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 4.8158e-05 - val_loss: 2.0379e-04\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.8301e-05 - val_loss: 1.6956e-04\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.1764e-05 - val_loss: 1.3529e-04\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.4021e-05 - val_loss: 2.0856e-04\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.7495e-05 - val_loss: 1.6149e-04\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.6243e-05 - val_loss: 9.3734e-05\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.5453e-05 - val_loss: 3.2025e-04\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.3795e-05 - val_loss: 1.0478e-04\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 3.8532e-05 - val_loss: 2.3675e-04\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.0145e-05 - val_loss: 3.5810e-04\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 8.5785e-05 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.1355e-05 - val_loss: 2.1706e-04\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 5.5134e-05 - val_loss: 4.8117e-05\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.7549e-05 - val_loss: 4.4417e-04\n",
      ">p=11: 1, Score=0.024561051395721734\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 8s 35ms/step - loss: 0.0042 - val_loss: 0.0118\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0105\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 9.3989e-04 - val_loss: 0.0072\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 7.0989e-04 - val_loss: 0.0056\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 5.8746e-04 - val_loss: 0.0041\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.5589e-04 - val_loss: 0.0028\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.0717e-04 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.4161e-04 - val_loss: 0.0019\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.9055e-04 - val_loss: 6.2108e-04\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.4236e-04 - val_loss: 5.5232e-04\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.1987e-04 - val_loss: 2.0291e-04\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.0167e-04 - val_loss: 1.8632e-04\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 9.9513e-05 - val_loss: 1.6188e-04\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.1228e-05 - val_loss: 0.0017\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.1558e-04 - val_loss: 2.3833e-04\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.3332e-05 - val_loss: 5.2998e-04\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0137e-04 - val_loss: 2.9269e-04\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 8.4557e-05 - val_loss: 2.4760e-04\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.2435e-05 - val_loss: 4.1025e-04\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 4.5447e-05 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0707e-04 - val_loss: 8.6101e-04\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.7621e-05 - val_loss: 0.0010\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 5.5096e-05 - val_loss: 4.4546e-04\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.7531e-05 - val_loss: 2.0819e-04\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.4308e-05 - val_loss: 3.1625e-04\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 5.2051e-05 - val_loss: 1.6261e-04\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.9300e-05 - val_loss: 4.0596e-04\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 5.7171e-05 - val_loss: 1.5845e-04\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.8968e-05 - val_loss: 2.4511e-04\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.6393e-05 - val_loss: 6.4735e-04\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.2276e-05 - val_loss: 9.8622e-05\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 5.3852e-05 - val_loss: 9.7981e-04\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.0364e-05 - val_loss: 1.7821e-04\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.1187e-05 - val_loss: 1.5896e-04\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.5889e-05 - val_loss: 1.5179e-04\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 7.0975e-05 - val_loss: 9.8129e-04\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 7.8096e-05 - val_loss: 4.3886e-04\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 5.3741e-05 - val_loss: 4.0467e-05\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.3845e-05 - val_loss: 5.7569e-04\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 2.6790e-05 - val_loss: 2.1105e-04\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 7.2729e-05 - val_loss: 4.9246e-04\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 7.5136e-05 - val_loss: 2.1732e-04\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.5651e-05 - val_loss: 3.4706e-04\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.0157e-05 - val_loss: 6.9403e-05\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 3.7057e-05 - val_loss: 5.4553e-04\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.8804e-05 - val_loss: 2.7568e-04\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 4.5536e-05 - val_loss: 2.7149e-04\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.4765e-05 - val_loss: 1.2698e-04\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.9549e-05 - val_loss: 1.2138e-04\n",
      ">p=11: 2, Score=0.009006167238112539\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 9s 34ms/step - loss: 0.0034 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0101\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 0.0085\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 8.6512e-04 - val_loss: 0.0070\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 7.6166e-04 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 5.9694e-04 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.9223e-04 - val_loss: 0.0035\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.1391e-04 - val_loss: 0.0024\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 3.0843e-04 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.2851e-04 - val_loss: 7.7665e-04\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.7683e-04 - val_loss: 5.3849e-04\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.3530e-04 - val_loss: 3.1417e-04\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.6596e-04 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.0240e-04 - val_loss: 3.0889e-04\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 9.5981e-05 - val_loss: 2.8097e-04\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.2753e-04 - val_loss: 3.8034e-04\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.8381e-05 - val_loss: 5.6835e-04\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.8831e-05 - val_loss: 2.5751e-04\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 7.1073e-05 - val_loss: 2.8854e-04\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 7.1412e-05 - val_loss: 2.6597e-04\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.0511e-05 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.9077e-05 - val_loss: 8.2954e-04\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.3681e-05 - val_loss: 9.1695e-04\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 6.0503e-05 - val_loss: 1.8420e-04\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.2190e-05 - val_loss: 8.4833e-04\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 6.7581e-05 - val_loss: 3.5878e-04\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.3008e-05 - val_loss: 8.8143e-04\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.8449e-05 - val_loss: 9.6314e-04\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 6.0431e-05 - val_loss: 3.0455e-04\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 7.4983e-05 - val_loss: 6.9748e-04\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.8697e-05 - val_loss: 9.0632e-04\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 6.9989e-05 - val_loss: 4.4149e-04\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.1588e-04 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.2779e-05 - val_loss: 5.8308e-04\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.5916e-05 - val_loss: 2.7544e-04\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 9.3105e-05 - val_loss: 1.1217e-04\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 6.1232e-05 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.2971e-05 - val_loss: 0.0014\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.0319e-04 - val_loss: 4.6496e-04\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 6.8736e-05 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 5.5245e-05 - val_loss: 6.7308e-04\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.5685e-05 - val_loss: 4.3884e-04\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.3937e-05 - val_loss: 3.8709e-04\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 4.1998e-05 - val_loss: 8.7589e-05\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.3563e-05 - val_loss: 3.1476e-04\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.8399e-05 - val_loss: 2.6001e-04\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 4.9885e-05 - val_loss: 1.1024e-04\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.3945e-05 - val_loss: 1.8944e-04\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.7247e-05 - val_loss: 9.5521e-04\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 3.0518e-05 - val_loss: 5.6511e-04\n",
      ">p=11: 3, Score=0.02884904679376632\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 9s 36ms/step - loss: 0.0039 - val_loss: 0.0120\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0108\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 8.8854e-04 - val_loss: 0.0076\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 7.8729e-04 - val_loss: 0.0059\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.9874e-04 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 5.1304e-04 - val_loss: 0.0029\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.5106e-04 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.8189e-04 - val_loss: 9.3853e-04\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.6197e-04 - val_loss: 5.9807e-04\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.2506e-04 - val_loss: 7.8671e-04\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.7048e-04 - val_loss: 5.6146e-04\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.4344e-04 - val_loss: 6.3501e-04\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 9.3496e-05 - val_loss: 4.1109e-04\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.2608e-04 - val_loss: 1.1081e-04\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 9.6844e-05 - val_loss: 3.4599e-04\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 9.6840e-05 - val_loss: 2.2010e-04\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.2627e-04 - val_loss: 2.7983e-04\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0163e-04 - val_loss: 2.7104e-04\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.2548e-04 - val_loss: 1.2815e-04\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.5469e-04 - val_loss: 3.5320e-04\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.0883e-04 - val_loss: 9.1832e-04\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 8.7910e-05 - val_loss: 2.2376e-04\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.2533e-05 - val_loss: 1.4677e-04\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 6.5459e-05 - val_loss: 1.8800e-04\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.0915e-05 - val_loss: 4.0042e-04\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 7.3574e-05 - val_loss: 1.1151e-04\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.6003e-05 - val_loss: 2.4642e-04\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.1744e-05 - val_loss: 3.6200e-04\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 5.7941e-05 - val_loss: 2.4544e-04\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.5753e-05 - val_loss: 6.8106e-04\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 7.4248e-05 - val_loss: 6.4534e-05\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.7174e-05 - val_loss: 1.6166e-04\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.8555e-05 - val_loss: 5.6625e-04\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 5.3571e-05 - val_loss: 8.2786e-05\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 7.8791e-05 - val_loss: 7.1474e-04\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.8943e-05 - val_loss: 4.1188e-04\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.3369e-05 - val_loss: 1.7754e-04\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 6.4892e-05 - val_loss: 1.3267e-04\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.6913e-05 - val_loss: 4.1339e-04\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 6.1026e-05 - val_loss: 1.5336e-04\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.4118e-05 - val_loss: 5.1209e-04\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.8990e-05 - val_loss: 2.5581e-04\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.8862e-05 - val_loss: 7.5977e-05\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.7373e-05 - val_loss: 3.0734e-04\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 6.0282e-05 - val_loss: 3.3410e-04\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.4334e-05 - val_loss: 9.3099e-05\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.1992e-05 - val_loss: 4.2786e-05\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 3.7660e-05 - val_loss: 5.7761e-05\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.9819e-05 - val_loss: 5.2891e-04\n",
      ">p=11: 4, Score=0.04680329584516585\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 9s 39ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0088\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.9616e-04 - val_loss: 0.0073\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.9614e-04 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.1178e-04 - val_loss: 0.0040\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 5.1864e-04 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.7318e-04 - val_loss: 0.0017\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 2.1640e-04 - val_loss: 6.8859e-04\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.7125e-04 - val_loss: 4.5278e-04\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.3027e-04 - val_loss: 2.6070e-04\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.1437e-04 - val_loss: 3.1555e-04\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.4346e-04 - val_loss: 8.6351e-04\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.4452e-04 - val_loss: 3.5453e-04\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 7.4147e-05 - val_loss: 9.8111e-04\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.6696e-05 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.7138e-05 - val_loss: 0.0010\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.1668e-04 - val_loss: 6.2452e-04\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 9.2634e-05 - val_loss: 3.7410e-04\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.7068e-05 - val_loss: 4.6254e-04\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.6656e-04 - val_loss: 1.2932e-04\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.7375e-05 - val_loss: 8.6307e-04\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 5.1284e-05 - val_loss: 2.5646e-04\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.7762e-05 - val_loss: 9.2493e-04\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 5.4371e-05 - val_loss: 7.0259e-04\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.5647e-05 - val_loss: 0.0010\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.4140e-05 - val_loss: 1.9262e-04\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 6.0329e-05 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.6850e-05 - val_loss: 4.9187e-04\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.0826e-05 - val_loss: 9.3259e-05\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 5.0146e-05 - val_loss: 1.8813e-04\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.0069e-05 - val_loss: 1.4355e-04\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 3.2038e-05 - val_loss: 2.1911e-04\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.8406e-05 - val_loss: 1.0519e-04\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 4.1903e-05 - val_loss: 3.2807e-04\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.8932e-05 - val_loss: 4.2482e-04\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 4.6984e-05 - val_loss: 1.7131e-04\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 6.4895e-05 - val_loss: 5.8251e-04\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.7758e-05 - val_loss: 6.5453e-05\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 4.6908e-05 - val_loss: 1.2816e-04\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 4.0087e-05 - val_loss: 8.5751e-04\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.0154e-05 - val_loss: 6.4601e-04\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6314e-05 - val_loss: 2.1176e-04\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.8169e-05 - val_loss: 2.9606e-04\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 7.2536e-05 - val_loss: 4.3819e-04\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 7.6811e-05 - val_loss: 4.8099e-04\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 9.5049e-05 - val_loss: 8.7608e-04\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.4733e-05 - val_loss: 1.5804e-04\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.3934e-05 - val_loss: 1.3101e-04\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.6415e-05 - val_loss: 1.0043e-04\n",
      ">p=11: 5, Score=0.014172137889545411\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 8s 36ms/step - loss: 0.0036 - val_loss: 0.0116\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0105\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 0.0010 - val_loss: 0.0089\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 8.9580e-04 - val_loss: 0.0069\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 6.6781e-04 - val_loss: 0.0049\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.1246e-04 - val_loss: 0.0033\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 4.0204e-04 - val_loss: 0.0020\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.8204e-04 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.1333e-04 - val_loss: 0.0010\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 2.3754e-04 - val_loss: 3.6391e-04\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.3934e-04 - val_loss: 2.4139e-04\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 9.8742e-05 - val_loss: 2.1252e-04\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 7.5019e-05 - val_loss: 3.5419e-04\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 6.9279e-05 - val_loss: 3.4978e-04\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.2578e-05 - val_loss: 8.2321e-04\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 9.3971e-05 - val_loss: 4.1300e-04\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 8.7739e-05 - val_loss: 4.9172e-04\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 6.5151e-05 - val_loss: 3.2707e-04\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.9716e-05 - val_loss: 3.2557e-04\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 7.1597e-05 - val_loss: 2.4871e-04\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 6.9041e-05 - val_loss: 2.8943e-04\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.1272e-05 - val_loss: 3.9011e-04\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.7142e-05 - val_loss: 5.6720e-04\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.0156e-04 - val_loss: 4.5113e-04\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.4855e-05 - val_loss: 5.8522e-04\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.0650e-04 - val_loss: 7.4378e-04\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 9.9404e-05 - val_loss: 1.3376e-04\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 4.8226e-05 - val_loss: 3.4545e-04\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.9311e-05 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 7.8725e-05 - val_loss: 5.5106e-04\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 6.8929e-05 - val_loss: 7.1883e-05\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.9101e-05 - val_loss: 4.1751e-04\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 4.8823e-05 - val_loss: 1.8491e-04\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.7196e-05 - val_loss: 1.7699e-04\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.9218e-05 - val_loss: 3.8645e-04\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 4.3458e-05 - val_loss: 2.1236e-04\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.0505e-05 - val_loss: 3.0822e-04\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.8809e-05 - val_loss: 1.8790e-04\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.7495e-05 - val_loss: 2.9425e-04\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.1276e-05 - val_loss: 1.0918e-04\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 5.1025e-05 - val_loss: 1.5845e-04\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.6684e-05 - val_loss: 3.4171e-04\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.7824e-05 - val_loss: 5.6425e-05\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 2.4803e-05 - val_loss: 4.6112e-04\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6252e-05 - val_loss: 1.9823e-04\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2996e-05 - val_loss: 1.7071e-04\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.8126e-05 - val_loss: 8.8190e-05\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.5743e-05 - val_loss: 9.6605e-05\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.5382e-05 - val_loss: 8.4956e-05\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.8252e-05 - val_loss: 3.7100e-04\n",
      ">p=11: 6, Score=0.029903787071816623\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 9s 45ms/step - loss: 0.0039 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0102\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 0.0087\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 9.2261e-04 - val_loss: 0.0069\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 7.2774e-04 - val_loss: 0.0051\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.6308e-04 - val_loss: 0.0036\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.2909e-04 - val_loss: 0.0024\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.2463e-04 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 2.3065e-04 - val_loss: 7.4631e-04\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.3768e-04 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.4047e-04 - val_loss: 3.6163e-04\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6370e-04 - val_loss: 4.3557e-04\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.2028e-04 - val_loss: 1.7920e-04\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 9.1208e-05 - val_loss: 3.9182e-04\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 6.6534e-05 - val_loss: 4.1350e-04\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.0609e-05 - val_loss: 3.4690e-04\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.6562e-05 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.2991e-04 - val_loss: 3.8519e-04\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.2420e-04 - val_loss: 3.8207e-04\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 7.0463e-05 - val_loss: 3.0851e-04\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.9712e-05 - val_loss: 8.5723e-04\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 6.3311e-05 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.8097e-05 - val_loss: 4.3733e-04\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.7659e-05 - val_loss: 3.6506e-04\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 8.9065e-05 - val_loss: 2.9137e-04\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 6.0268e-05 - val_loss: 9.9157e-04\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 8.0509e-05 - val_loss: 6.8659e-04\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.7731e-05 - val_loss: 2.0099e-04\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 4.3717e-05 - val_loss: 3.9172e-04\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 6.4426e-05 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 5.5196e-05 - val_loss: 1.8880e-04\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 7.9036e-05 - val_loss: 2.6004e-04\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 5.3549e-05 - val_loss: 7.8072e-04\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 7.6752e-05 - val_loss: 4.3662e-04\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 8.9186e-05 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 6.1791e-05 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 5.7845e-05 - val_loss: 1.9378e-04\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 6.5947e-05 - val_loss: 1.4408e-04\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.4539e-05 - val_loss: 1.5845e-04\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.0024e-05 - val_loss: 4.1547e-04\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.4515e-05 - val_loss: 2.0738e-04\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.3705e-05 - val_loss: 2.7483e-04\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 5.5165e-05 - val_loss: 4.0397e-04\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 6.4191e-05 - val_loss: 0.0016\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 5.9054e-05 - val_loss: 6.2181e-05\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 3.6106e-05 - val_loss: 1.3460e-04\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 4.5466e-05 - val_loss: 1.3397e-04\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 4.9438e-05 - val_loss: 7.2198e-04\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7883e-05 - val_loss: 2.2445e-04\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.8336e-05 - val_loss: 2.4294e-04\n",
      ">p=11: 7, Score=0.01779379090294242\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 9s 36ms/step - loss: 0.0039 - val_loss: 0.0117\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0107\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 9.7317e-04 - val_loss: 0.0078\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 7.9744e-04 - val_loss: 0.0060\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 6.3134e-04 - val_loss: 0.0042\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.2547e-04 - val_loss: 0.0027\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.4444e-04 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.1953e-04 - val_loss: 6.4270e-04\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.5707e-04 - val_loss: 4.4201e-04\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.3764e-04 - val_loss: 4.0544e-04\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.7955e-04 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.7410e-04 - val_loss: 5.1674e-04\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.0385e-04 - val_loss: 2.9705e-04\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 9.9685e-05 - val_loss: 9.9908e-04\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.8885e-05 - val_loss: 0.0010\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.1258e-04 - val_loss: 7.6591e-04\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.8250e-05 - val_loss: 7.9512e-04\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.6030e-05 - val_loss: 6.8526e-04\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 6.7256e-05 - val_loss: 5.2122e-04\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0831e-04 - val_loss: 1.5611e-04\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.3027e-04 - val_loss: 2.7832e-04\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.7876e-05 - val_loss: 5.2552e-04\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.2355e-05 - val_loss: 2.0226e-04\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 5.6749e-05 - val_loss: 2.5144e-04\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.7575e-05 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.9053e-05 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 7.2555e-05 - val_loss: 2.1735e-04\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.2025e-05 - val_loss: 2.9260e-04\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.0296e-05 - val_loss: 0.0010\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 7.2813e-05 - val_loss: 3.8857e-04\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.4221e-05 - val_loss: 3.5586e-04\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.0472e-05 - val_loss: 1.2385e-04\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 6.6397e-05 - val_loss: 2.5105e-04\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.7093e-05 - val_loss: 4.2076e-04\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.6399e-05 - val_loss: 9.9660e-04\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.7668e-05 - val_loss: 2.9034e-04\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 3.2485e-05 - val_loss: 2.0755e-04\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.3765e-05 - val_loss: 3.9669e-04\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 5.0285e-05 - val_loss: 3.7722e-04\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.7859e-05 - val_loss: 2.3890e-04\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.1711e-05 - val_loss: 4.6163e-04\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.9572e-05 - val_loss: 0.0015\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.6889e-05 - val_loss: 2.0340e-04\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.0623e-05 - val_loss: 2.8607e-04\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.2839e-05 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.1884e-05 - val_loss: 3.8010e-04\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.2423e-05 - val_loss: 6.3506e-04\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 2.7720e-05 - val_loss: 4.2240e-04\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.6742e-05 - val_loss: 2.0670e-04\n",
      ">p=11: 8, Score=0.020833901362493634\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 11s 42ms/step - loss: 0.0039 - val_loss: 0.0117\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0106\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 9.9509e-04 - val_loss: 0.0089\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 9.1913e-04 - val_loss: 0.0073\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.0754e-04 - val_loss: 0.0054\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.6757e-04 - val_loss: 0.0038\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.5427e-04 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.5057e-04 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.7156e-04 - val_loss: 9.3907e-04\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.6767e-04 - val_loss: 8.8035e-04\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.4377e-04 - val_loss: 7.8118e-04\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 9.1040e-05 - val_loss: 4.9611e-04\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.2065e-04 - val_loss: 5.5313e-04\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 8.4084e-05 - val_loss: 4.1842e-04\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 7.4546e-05 - val_loss: 5.5828e-04\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 7.5990e-05 - val_loss: 2.1086e-04\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 7.2850e-05 - val_loss: 2.8864e-04\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 6.2384e-05 - val_loss: 1.7788e-04\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 6.5851e-05 - val_loss: 4.3101e-04\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.8699e-05 - val_loss: 4.2988e-04\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 6.3116e-05 - val_loss: 3.5598e-04\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 8.9732e-05 - val_loss: 6.5595e-04\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 4.5683e-05 - val_loss: 3.6848e-04\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 4.3829e-05 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 6.2931e-05 - val_loss: 1.5163e-04\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 9.2933e-05 - val_loss: 2.3321e-04\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.6894e-05 - val_loss: 4.9035e-04\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.9313e-05 - val_loss: 5.7867e-04\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.6325e-04 - val_loss: 0.0011\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.0472e-04 - val_loss: 1.2979e-04\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 5.4288e-05 - val_loss: 8.2949e-05\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 6.1102e-05 - val_loss: 3.0367e-04\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.3481e-05 - val_loss: 9.7351e-05\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 3.6592e-05 - val_loss: 1.2989e-04\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.3220e-05 - val_loss: 1.8508e-04\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 4.1665e-05 - val_loss: 4.9087e-05\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.4825e-05 - val_loss: 3.7931e-04\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.5823e-05 - val_loss: 5.1487e-04\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.2730e-04 - val_loss: 7.5018e-04\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 6.6428e-05 - val_loss: 2.9796e-04\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 5.5155e-05 - val_loss: 5.1542e-04\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.9249e-05 - val_loss: 5.9733e-05\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.8180e-05 - val_loss: 5.6727e-04\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.4011e-05 - val_loss: 9.8880e-04\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.8550e-05 - val_loss: 1.6816e-04\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.6100e-05 - val_loss: 6.4703e-05\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 3.3311e-05 - val_loss: 5.7979e-04\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 8.4139e-05 - val_loss: 2.7792e-04\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.1403e-05 - val_loss: 2.1506e-04\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 5.6687e-05 - val_loss: 3.0582e-04\n",
      ">p=11: 9, Score=0.018741450912784785\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 8s 33ms/step - loss: 0.0040 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 0.0105\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 9.1659e-04 - val_loss: 0.0075\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 7.6216e-04 - val_loss: 0.0057\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.1825e-04 - val_loss: 0.0042\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.6880e-04 - val_loss: 0.0030\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.8153e-04 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.3788e-04 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 2.2159e-04 - val_loss: 5.7962e-04\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.2032e-04 - val_loss: 6.7198e-04\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.4178e-04 - val_loss: 2.5883e-04\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 7.8087e-05 - val_loss: 2.9137e-04\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.3429e-04 - val_loss: 3.6146e-04\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 9.6507e-05 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 7.8029e-05 - val_loss: 2.5601e-04\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0625e-04 - val_loss: 2.8379e-04\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 7.0237e-05 - val_loss: 8.3642e-04\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0109e-04 - val_loss: 5.6815e-04\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.3945e-05 - val_loss: 8.4593e-04\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.4240e-05 - val_loss: 2.6345e-04\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.5805e-04 - val_loss: 2.5479e-04\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 9.0409e-05 - val_loss: 8.6764e-04\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 6.9950e-05 - val_loss: 1.3895e-04\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.0984e-05 - val_loss: 5.4774e-04\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.3466e-05 - val_loss: 3.4025e-04\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 4.6244e-05 - val_loss: 0.0015\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.0411e-04 - val_loss: 7.3143e-04\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 4.0946e-05 - val_loss: 4.9884e-04\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 6.9919e-05 - val_loss: 2.0740e-04\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 6.5241e-05 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 9.5023e-05 - val_loss: 2.4041e-04\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.7513e-05 - val_loss: 1.4231e-04\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 4.7530e-05 - val_loss: 3.8181e-04\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.5904e-05 - val_loss: 5.5034e-04\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 4.7993e-05 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.3769e-04 - val_loss: 0.0034\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 9.5126e-05 - val_loss: 0.0017\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 6.6826e-05 - val_loss: 7.8122e-04\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.4121e-05 - val_loss: 1.4864e-04\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 3.5368e-05 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.0751e-05 - val_loss: 3.0060e-04\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.2808e-05 - val_loss: 2.8206e-04\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 3.7232e-05 - val_loss: 0.0014\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 4.9924e-05 - val_loss: 2.6426e-04\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 7.0081e-05 - val_loss: 3.8900e-04\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 8.0744e-05 - val_loss: 2.0460e-04\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 4.4929e-05 - val_loss: 2.2782e-04\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 5.4518e-05 - val_loss: 2.3611e-04\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 5.4647e-05 - val_loss: 5.8744e-04\n",
      ">p=11: 10, Score=0.037411830271594226\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 7s 32ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 9.4951e-04 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 9.3575e-04 - val_loss: 0.0076\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 8.4429e-04 - val_loss: 0.0060\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.0904e-04 - val_loss: 0.0045\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.2790e-04 - val_loss: 0.0032\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 3.7631e-04 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 2.7706e-04 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 2.1157e-04 - val_loss: 5.2972e-04\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 1.5336e-04 - val_loss: 3.5271e-04\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 1.0587e-04 - val_loss: 4.4312e-04\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 8.8524e-05 - val_loss: 8.8365e-04\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 9.4040e-05 - val_loss: 9.3918e-04\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.0943e-05 - val_loss: 7.2093e-04\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 9.0729e-05 - val_loss: 2.3007e-04\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.3131e-05 - val_loss: 9.5294e-04\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 6.2035e-05 - val_loss: 3.0821e-04\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 1.1169e-04 - val_loss: 2.3616e-04\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.9965e-05 - val_loss: 6.0181e-04\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 7.1277e-05 - val_loss: 0.0020\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 9.9169e-05 - val_loss: 1.7547e-04\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.5249e-05 - val_loss: 5.7305e-04\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.1380e-05 - val_loss: 8.3940e-05\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 7.1558e-05 - val_loss: 5.5710e-04\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.8632e-05 - val_loss: 1.5122e-04\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 6.0043e-05 - val_loss: 2.1688e-04\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 8.2614e-05 - val_loss: 3.1784e-04\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 6.7283e-05 - val_loss: 4.6260e-04\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.5875e-05 - val_loss: 1.4298e-04\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 7.3585e-05 - val_loss: 9.4355e-05\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.1826e-05 - val_loss: 5.2183e-04\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 1.1238e-04 - val_loss: 1.1254e-04\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.4371e-05 - val_loss: 9.9164e-05\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.2664e-05 - val_loss: 9.4022e-05\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.6555e-05 - val_loss: 3.2564e-04\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.5783e-05 - val_loss: 1.2240e-04\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 3.6814e-05 - val_loss: 1.8018e-04\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.5955e-05 - val_loss: 8.8699e-05\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 4.9418e-05 - val_loss: 6.4379e-05\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.6635e-05 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.5236e-05 - val_loss: 1.2297e-04\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.6122e-05 - val_loss: 5.1520e-05\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.0008e-05 - val_loss: 3.5002e-04\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.5718e-05 - val_loss: 2.1579e-04\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 3.7986e-05 - val_loss: 2.1182e-04\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 2.5753e-05 - val_loss: 2.5690e-04\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.2044e-05 - val_loss: 2.4713e-04\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 3.8812e-05 - val_loss: 6.1574e-05\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 3.2054e-05 - val_loss: 6.8024e-05\n",
      ">p=12: 1, Score=0.006392067007254809\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 8s 51ms/step - loss: 0.0041 - val_loss: 0.0122\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 0.0013 - val_loss: 0.0113\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0102\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 9.9103e-04 - val_loss: 0.0090\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 9.3327e-04 - val_loss: 0.0076\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 7.6486e-04 - val_loss: 0.0060\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 6.8154e-04 - val_loss: 0.0045\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.8469e-04 - val_loss: 0.0030\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.0045e-04 - val_loss: 0.0019\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 2.6858e-04 - val_loss: 9.7992e-04\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 1.8538e-04 - val_loss: 5.2517e-04\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.4774e-04 - val_loss: 4.7235e-04\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 1.6745e-04 - val_loss: 3.4270e-04\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 1.4276e-04 - val_loss: 3.1858e-04\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 1.3372e-04 - val_loss: 3.6318e-04\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.4568e-04 - val_loss: 1.2084e-04\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 9.4865e-05 - val_loss: 2.1863e-04\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.9931e-05 - val_loss: 5.1470e-04\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 6.9778e-05 - val_loss: 3.0455e-04\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.0111e-04 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.9246e-05 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 6.1954e-05 - val_loss: 2.7883e-04\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.3887e-05 - val_loss: 5.1074e-04\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.9477e-05 - val_loss: 3.3508e-04\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.2961e-05 - val_loss: 8.5479e-04\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 8.1101e-05 - val_loss: 3.7515e-04\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.0113e-04 - val_loss: 1.7085e-04\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.8050e-05 - val_loss: 1.9714e-04\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.5048e-05 - val_loss: 3.7284e-04\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 1.1229e-04 - val_loss: 1.9442e-04\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 7.5198e-05 - val_loss: 1.3945e-04\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.8581e-05 - val_loss: 2.8732e-04\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.2185e-05 - val_loss: 2.0592e-04\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.0589e-05 - val_loss: 5.3078e-04\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 6.0783e-05 - val_loss: 9.3027e-05\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.9425e-05 - val_loss: 4.8062e-04\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.0802e-05 - val_loss: 1.2996e-04\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.7190e-05 - val_loss: 4.3924e-04\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.9506e-05 - val_loss: 7.8094e-05\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.6102e-05 - val_loss: 1.7461e-04\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 3.7865e-05 - val_loss: 2.1187e-04\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 4.2331e-05 - val_loss: 1.0215e-04\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.9289e-05 - val_loss: 1.0436e-04\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 3.2927e-05 - val_loss: 2.5985e-04\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 2.7831e-05 - val_loss: 1.6480e-04\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 4.6007e-05 - val_loss: 3.3635e-04\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 5.6003e-05 - val_loss: 2.4703e-04\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 4.1075e-05 - val_loss: 3.2169e-04\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 1s 16ms/step - loss: 4.6296e-05 - val_loss: 2.5393e-04\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.0427e-05 - val_loss: 6.3014e-04\n",
      ">p=12: 2, Score=0.030359544325619936\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 8s 36ms/step - loss: 0.0041 - val_loss: 0.0116\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0106\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 9.7891e-04 - val_loss: 0.0082\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 8.4018e-04 - val_loss: 0.0066\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.7959e-04 - val_loss: 0.0050\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.3925e-04 - val_loss: 0.0036\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 4.4705e-04 - val_loss: 0.0023\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.2594e-04 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 2.1781e-04 - val_loss: 6.6523e-04\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.9121e-04 - val_loss: 6.4872e-04\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 1.5519e-04 - val_loss: 2.4322e-04\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 9.4403e-05 - val_loss: 2.2701e-04\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 8.0224e-05 - val_loss: 3.5938e-04\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 9.8102e-05 - val_loss: 7.3793e-04\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 6.1427e-05 - val_loss: 3.0591e-04\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 6.5802e-05 - val_loss: 4.7234e-04\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 7.5176e-05 - val_loss: 5.5231e-04\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 8.6474e-05 - val_loss: 1.7290e-04\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.6419e-05 - val_loss: 6.7773e-04\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.7360e-05 - val_loss: 2.0418e-04\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.0010e-05 - val_loss: 4.4736e-04\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.1354e-05 - val_loss: 4.9198e-04\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 7.8791e-05 - val_loss: 1.8818e-04\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.8160e-05 - val_loss: 4.7347e-04\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 4.7439e-05 - val_loss: 3.6935e-04\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.5644e-05 - val_loss: 1.1495e-04\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 4.3271e-05 - val_loss: 4.8485e-04\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.6679e-05 - val_loss: 3.0599e-04\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.7840e-05 - val_loss: 2.9591e-04\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 5.3299e-05 - val_loss: 1.0353e-04\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 5.5641e-05 - val_loss: 1.3456e-04\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 4.1266e-05 - val_loss: 2.6124e-04\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 8.9044e-05 - val_loss: 3.3218e-04\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.8712e-05 - val_loss: 1.4396e-04\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.9607e-05 - val_loss: 1.1234e-04\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 4.3547e-05 - val_loss: 1.6914e-04\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.9720e-05 - val_loss: 2.8735e-04\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 3.1652e-05 - val_loss: 2.1670e-04\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.7585e-05 - val_loss: 8.9017e-05\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.5466e-05 - val_loss: 4.3447e-05\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.0376e-05 - val_loss: 7.8455e-05\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 5.4407e-05 - val_loss: 1.8661e-04\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 5.2042e-05 - val_loss: 3.0479e-04\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.9875e-05 - val_loss: 6.3502e-05\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 3.0495e-05 - val_loss: 8.8416e-05\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 3.8862e-05 - val_loss: 1.2338e-04\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 3.3013e-05 - val_loss: 2.3293e-04\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 3.4691e-05 - val_loss: 8.9121e-05\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.7303e-05 - val_loss: 6.0523e-05\n",
      ">p=12: 3, Score=0.005973232691758312\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 8s 38ms/step - loss: 0.0039 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 0.0012 - val_loss: 0.0106\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 0.0010 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 9.1144e-04 - val_loss: 0.0078\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 7.8714e-04 - val_loss: 0.0062\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.6882e-04 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 5.0475e-04 - val_loss: 0.0032\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.3282e-04 - val_loss: 0.0021\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 2.8750e-04 - val_loss: 0.0010\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 2.4832e-04 - val_loss: 5.0822e-04\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 1.8258e-04 - val_loss: 3.8917e-04\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.0728e-04 - val_loss: 3.2398e-04\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 1.1573e-04 - val_loss: 5.7334e-04\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 1.0311e-04 - val_loss: 9.0656e-04\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 7.6613e-05 - val_loss: 2.7548e-04\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 8.4388e-05 - val_loss: 3.9770e-04\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.4996e-05 - val_loss: 9.0493e-04\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 9.1918e-05 - val_loss: 4.3248e-04\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.6309e-05 - val_loss: 5.7491e-04\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 8.4796e-05 - val_loss: 3.1472e-04\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.8109e-05 - val_loss: 2.5260e-04\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.0435e-05 - val_loss: 7.3370e-04\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.6968e-05 - val_loss: 2.5201e-04\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.9662e-05 - val_loss: 4.8399e-04\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 7.3171e-05 - val_loss: 2.3163e-04\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.6749e-05 - val_loss: 2.8855e-04\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.2112e-05 - val_loss: 4.7990e-04\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.3814e-05 - val_loss: 4.1932e-04\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.0458e-04 - val_loss: 1.7707e-04\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.9451e-05 - val_loss: 9.3110e-04\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.0748e-05 - val_loss: 1.8637e-04\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 7.4542e-05 - val_loss: 2.2684e-04\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.8571e-05 - val_loss: 1.5492e-04\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.6694e-05 - val_loss: 8.7367e-04\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 7.6253e-05 - val_loss: 4.7065e-04\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.2423e-05 - val_loss: 3.4010e-04\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 3.4793e-05 - val_loss: 6.6385e-04\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.5458e-05 - val_loss: 1.1337e-04\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 3.5037e-05 - val_loss: 2.3231e-04\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.6304e-05 - val_loss: 0.0016\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.1173e-05 - val_loss: 2.9751e-04\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 2.8498e-05 - val_loss: 2.9329e-04\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.0746e-05 - val_loss: 4.9150e-04\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 4.5964e-05 - val_loss: 1.0844e-04\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.2212e-05 - val_loss: 2.4069e-04\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.4792e-05 - val_loss: 5.6810e-04\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.6932e-05 - val_loss: 4.0236e-04\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.1246e-05 - val_loss: 2.2004e-04\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 4.6125e-05 - val_loss: 7.7771e-05\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.1116e-05 - val_loss: 7.6833e-05\n",
      ">p=12: 4, Score=0.011388130951672792\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 8s 32ms/step - loss: 0.0040 - val_loss: 0.0114\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0105\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0093\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 8.6726e-04 - val_loss: 0.0076\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.4975e-04 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 6.2854e-04 - val_loss: 0.0041\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.4660e-04 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.5328e-04 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 2.3299e-04 - val_loss: 5.5529e-04\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 1.5793e-04 - val_loss: 5.8226e-04\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.2078e-04 - val_loss: 2.2502e-04\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.0081e-04 - val_loss: 2.0746e-04\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.8168e-05 - val_loss: 2.0720e-04\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 8.3134e-05 - val_loss: 1.7679e-04\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 8.1087e-05 - val_loss: 1.3117e-04\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.4700e-05 - val_loss: 3.8701e-04\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.1755e-05 - val_loss: 4.8430e-04\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.1904e-04 - val_loss: 6.8782e-04\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.3155e-05 - val_loss: 5.6479e-04\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.1467e-05 - val_loss: 1.7374e-04\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 6.7589e-05 - val_loss: 2.0248e-04\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.8432e-05 - val_loss: 4.2647e-04\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 7.3622e-05 - val_loss: 6.5288e-04\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.7395e-05 - val_loss: 1.6445e-04\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.0813e-05 - val_loss: 3.1052e-04\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 7.8313e-05 - val_loss: 2.9534e-04\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.4965e-05 - val_loss: 9.9880e-05\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 7.1733e-05 - val_loss: 9.9352e-04\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 1.0881e-04 - val_loss: 1.1511e-04\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 4.6780e-05 - val_loss: 6.4226e-04\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 7.2530e-05 - val_loss: 3.2861e-04\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 6.5762e-05 - val_loss: 5.0987e-04\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.9011e-05 - val_loss: 8.7399e-05\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.8657e-05 - val_loss: 1.9171e-04\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.0918e-04 - val_loss: 3.1864e-04\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 6.7297e-05 - val_loss: 5.1133e-04\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 6.3962e-05 - val_loss: 7.1288e-04\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.5064e-05 - val_loss: 9.4108e-05\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 4.2416e-05 - val_loss: 2.3204e-04\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 3.0997e-05 - val_loss: 3.0609e-04\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 3.4345e-05 - val_loss: 7.8082e-05\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 5.6908e-05 - val_loss: 9.4203e-05\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 3.6169e-05 - val_loss: 1.7776e-04\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 6.6472e-05 - val_loss: 9.4774e-05\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.9834e-05 - val_loss: 1.9048e-04\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 2.9448e-05 - val_loss: 2.6937e-04\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 3.9944e-05 - val_loss: 2.9490e-04\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.7131e-05 - val_loss: 4.6401e-05\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 6.5781e-05 - val_loss: 7.7811e-05\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 2.2609e-05 - val_loss: 1.4620e-04\n",
      ">p=12: 5, Score=0.010603137343423441\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 8s 35ms/step - loss: 0.0044 - val_loss: 0.0120\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0109\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0097\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 9.5060e-04 - val_loss: 0.0084\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 8.2504e-04 - val_loss: 0.0068\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.9378e-04 - val_loss: 0.0052\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 5.0805e-04 - val_loss: 0.0036\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 4.6276e-04 - val_loss: 0.0024\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.5726e-04 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 2.4833e-04 - val_loss: 7.6169e-04\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 1.8337e-04 - val_loss: 3.8902e-04\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.1682e-04 - val_loss: 5.0723e-04\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 9.1936e-05 - val_loss: 6.2212e-04\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 8.0328e-05 - val_loss: 4.2228e-04\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.6566e-05 - val_loss: 7.5785e-04\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.2613e-05 - val_loss: 5.5277e-04\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 9.9797e-05 - val_loss: 3.6050e-04\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 7.6555e-05 - val_loss: 7.9022e-04\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 4.6493e-05 - val_loss: 7.6995e-04\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.7976e-05 - val_loss: 3.4628e-04\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 9.8504e-05 - val_loss: 1.7921e-04\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 7.4307e-05 - val_loss: 1.5230e-04\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 7.5663e-05 - val_loss: 9.9084e-04\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 1.1592e-04 - val_loss: 1.5060e-04\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 7.3938e-05 - val_loss: 4.0351e-04\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.2472e-05 - val_loss: 2.4707e-04\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 7.3427e-05 - val_loss: 2.8504e-04\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.0692e-05 - val_loss: 2.3719e-04\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.7839e-05 - val_loss: 3.8574e-04\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 4.4111e-05 - val_loss: 9.3633e-04\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 3.7336e-05 - val_loss: 2.1478e-04\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 5.0351e-05 - val_loss: 6.2477e-04\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 7.4159e-05 - val_loss: 2.1787e-04\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 5.3306e-05 - val_loss: 2.3727e-04\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 6.5121e-05 - val_loss: 8.6653e-04\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 3.5890e-05 - val_loss: 5.3833e-04\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 4.6977e-05 - val_loss: 2.8330e-04\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.7626e-05 - val_loss: 8.9353e-04\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.8163e-05 - val_loss: 1.4473e-04\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 4.3291e-05 - val_loss: 2.3892e-04\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 3.8854e-05 - val_loss: 3.3383e-04\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 8.4500e-05 - val_loss: 4.6890e-04\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 6.3016e-05 - val_loss: 3.2071e-04\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 3.1144e-05 - val_loss: 7.0070e-04\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.8650e-05 - val_loss: 3.8262e-04\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.4144e-05 - val_loss: 1.2611e-04\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.7451e-05 - val_loss: 3.7880e-04\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 5.2151e-05 - val_loss: 3.4273e-04\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 2.8291e-05 - val_loss: 1.8145e-04\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 3.4489e-05 - val_loss: 3.4944e-04\n",
      ">p=12: 6, Score=0.019587624410632998\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 8s 37ms/step - loss: 0.0039 - val_loss: 0.0122\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0111\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 9.8282e-04 - val_loss: 0.0083\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 8.7138e-04 - val_loss: 0.0065\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.7782e-04 - val_loss: 0.0048\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 4.9105e-04 - val_loss: 0.0032\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 4.0593e-04 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 2.7496e-04 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0601e-04 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 1.9296e-04 - val_loss: 6.3746e-04\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 1.2926e-04 - val_loss: 2.1440e-04\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 8.9333e-05 - val_loss: 0.0010\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 8.5508e-05 - val_loss: 1.8536e-04\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 9.0381e-05 - val_loss: 3.7634e-04\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.3747e-05 - val_loss: 8.9133e-04\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.3914e-05 - val_loss: 9.4028e-04\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 5.8879e-05 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 7.1420e-05 - val_loss: 2.9030e-04\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.7587e-05 - val_loss: 2.5377e-04\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.2617e-05 - val_loss: 1.8049e-04\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 4.7863e-05 - val_loss: 9.4086e-04\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.4276e-05 - val_loss: 5.1621e-04\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.3222e-04 - val_loss: 1.5796e-04\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.3876e-05 - val_loss: 3.3415e-04\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.0374e-05 - val_loss: 9.1999e-04\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.9657e-05 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 9.7897e-05 - val_loss: 9.7265e-05\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.6811e-05 - val_loss: 1.9849e-04\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.8677e-05 - val_loss: 3.9524e-04\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.5971e-05 - val_loss: 3.4909e-04\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 6.3144e-05 - val_loss: 5.2407e-04\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 9.4036e-05 - val_loss: 1.4626e-04\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.3915e-05 - val_loss: 4.8573e-04\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.6731e-05 - val_loss: 0.0010\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 4.5107e-05 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.7235e-05 - val_loss: 2.0874e-04\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.3447e-05 - val_loss: 3.3375e-04\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 4.3619e-05 - val_loss: 5.4708e-05\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.3096e-05 - val_loss: 7.9493e-04\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.9813e-05 - val_loss: 1.0949e-04\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 9.8260e-05 - val_loss: 5.7402e-04\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.1206e-05 - val_loss: 4.1289e-04\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.0421e-05 - val_loss: 1.9529e-04\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.3260e-05 - val_loss: 8.8209e-05\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.6279e-05 - val_loss: 4.4463e-04\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 3.9678e-05 - val_loss: 2.5259e-04\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.9366e-05 - val_loss: 8.1194e-05\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.7154e-05 - val_loss: 1.7493e-04\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.4765e-05 - val_loss: 5.1417e-04\n",
      ">p=12: 7, Score=0.030054256785660982\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 8s 35ms/step - loss: 0.0039 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0104\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 0.0091\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 9.5580e-04 - val_loss: 0.0077\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.9393e-04 - val_loss: 0.0061\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 6.7504e-04 - val_loss: 0.0044\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.9411e-04 - val_loss: 0.0030\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 3.5336e-04 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 2.5322e-04 - val_loss: 8.6872e-04\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 2.0886e-04 - val_loss: 5.0123e-04\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 1.4916e-04 - val_loss: 0.0016\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.2013e-04 - val_loss: 2.1352e-04\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 9.0029e-05 - val_loss: 2.8389e-04\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 9.9238e-05 - val_loss: 1.9490e-04\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.1359e-04 - val_loss: 7.6631e-04\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 8.4187e-05 - val_loss: 3.7572e-04\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 6.2930e-05 - val_loss: 7.4387e-04\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.4370e-04 - val_loss: 2.4744e-04\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.0400e-05 - val_loss: 3.0226e-04\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 8.6599e-05 - val_loss: 1.4085e-04\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 1.1534e-04 - val_loss: 4.1796e-04\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.1285e-05 - val_loss: 4.6578e-04\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 8.8413e-05 - val_loss: 4.5332e-04\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.6151e-05 - val_loss: 2.4916e-04\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 8.4108e-05 - val_loss: 1.3975e-04\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.1345e-05 - val_loss: 9.8099e-04\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.0247e-05 - val_loss: 2.8190e-04\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.1781e-05 - val_loss: 1.3694e-04\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 5.4589e-05 - val_loss: 2.3620e-04\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 8.1027e-05 - val_loss: 9.0232e-05\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 7.6224e-05 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.0348e-05 - val_loss: 4.1098e-04\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 7.7276e-05 - val_loss: 2.6626e-04\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.8197e-05 - val_loss: 1.8805e-04\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.1639e-05 - val_loss: 3.2541e-04\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.0239e-05 - val_loss: 2.3149e-04\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 6.5421e-05 - val_loss: 8.2651e-04\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.4010e-05 - val_loss: 9.3470e-05\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.3802e-05 - val_loss: 1.3514e-04\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 7.4006e-05 - val_loss: 2.5834e-04\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 6.0377e-05 - val_loss: 5.6483e-04\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 5.7555e-05 - val_loss: 2.0030e-04\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 4.3664e-05 - val_loss: 1.5882e-04\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.9068e-05 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 7.6027e-05 - val_loss: 6.4715e-05\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 4.7302e-05 - val_loss: 1.5581e-04\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 3.5890e-05 - val_loss: 5.9811e-05\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.7039e-05 - val_loss: 1.0066e-04\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.1093e-05 - val_loss: 1.8264e-04\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 4.3003e-05 - val_loss: 1.1799e-04\n",
      ">p=12: 8, Score=0.011662867473205552\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 9s 38ms/step - loss: 0.0041 - val_loss: 0.0121\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0109\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 9.6003e-04 - val_loss: 0.0078\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 8.2226e-04 - val_loss: 0.0063\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.8277e-04 - val_loss: 0.0048\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.6086e-04 - val_loss: 0.0035\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.1060e-04 - val_loss: 0.0024\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 2.9319e-04 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 1.9941e-04 - val_loss: 9.6217e-04\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 1.7176e-04 - val_loss: 4.6152e-04\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.0691e-04 - val_loss: 2.1097e-04\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 1.2305e-04 - val_loss: 3.6440e-04\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 9.0705e-05 - val_loss: 1.4821e-04\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.4803e-05 - val_loss: 6.3078e-04\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.7788e-05 - val_loss: 4.4193e-04\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 8.0687e-05 - val_loss: 5.7859e-04\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 6.7965e-05 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 1.0256e-04 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.3514e-05 - val_loss: 3.7908e-04\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 8.6228e-05 - val_loss: 0.0019\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.1750e-05 - val_loss: 4.3756e-04\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 8.7674e-05 - val_loss: 3.2159e-04\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.8399e-05 - val_loss: 1.9930e-04\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.7712e-05 - val_loss: 5.7937e-04\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.7452e-05 - val_loss: 1.7764e-04\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.6273e-05 - val_loss: 2.5247e-04\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 5.7858e-05 - val_loss: 2.8005e-04\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.5078e-05 - val_loss: 3.9650e-04\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.3245e-05 - val_loss: 6.6475e-04\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.4829e-05 - val_loss: 5.2444e-04\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 4.7958e-05 - val_loss: 4.7822e-04\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 5.2454e-05 - val_loss: 9.5664e-05\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.1181e-05 - val_loss: 4.2565e-04\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 7.1938e-05 - val_loss: 1.9335e-04\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.8129e-05 - val_loss: 5.9849e-04\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.4110e-05 - val_loss: 6.2018e-04\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.8668e-05 - val_loss: 3.6453e-04\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.7895e-05 - val_loss: 3.6667e-04\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 3.8856e-05 - val_loss: 2.7320e-04\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 2.5827e-05 - val_loss: 3.3744e-04\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 3.7284e-05 - val_loss: 2.1677e-04\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 3.7577e-05 - val_loss: 3.8522e-04\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 3.8401e-05 - val_loss: 1.4482e-04\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 3.3179e-05 - val_loss: 2.9204e-04\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 3.4989e-05 - val_loss: 2.9749e-04\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 5.4089e-05 - val_loss: 5.2391e-04\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 3.1965e-05 - val_loss: 1.0097e-04\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 3.0226e-05 - val_loss: 4.4946e-04\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 2.7978e-05 - val_loss: 1.1888e-04\n",
      ">p=12: 9, Score=0.011304646614007652\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 9s 45ms/step - loss: 0.0040 - val_loss: 0.0118\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0106\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0092\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 9.1689e-04 - val_loss: 0.0076\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 8.0689e-04 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 6.3869e-04 - val_loss: 0.0040\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.1451e-04 - val_loss: 0.0024\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 3.1591e-04 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 1.9728e-04 - val_loss: 8.3019e-04\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 1.2172e-04 - val_loss: 4.1710e-04\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.1549e-04 - val_loss: 3.7321e-04\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 8.4945e-05 - val_loss: 2.0888e-04\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.9332e-05 - val_loss: 4.0355e-04\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 6.5329e-05 - val_loss: 3.2654e-04\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 8.3454e-05 - val_loss: 5.1280e-04\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 9.5002e-05 - val_loss: 0.0010\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 6.3010e-05 - val_loss: 2.3695e-04\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.1177e-05 - val_loss: 7.5545e-04\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 7.5984e-05 - val_loss: 3.0771e-04\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 6.9365e-05 - val_loss: 6.2746e-04\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 4.9370e-05 - val_loss: 2.5146e-04\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 6.3951e-05 - val_loss: 3.8446e-04\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 5.2400e-05 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.5742e-05 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 7.1945e-05 - val_loss: 1.6078e-04\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 4.7509e-05 - val_loss: 4.6588e-04\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 6.6686e-05 - val_loss: 4.1478e-04\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.3251e-05 - val_loss: 5.6811e-04\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.8971e-05 - val_loss: 4.8637e-04\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 6.2434e-05 - val_loss: 3.3179e-04\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.2719e-05 - val_loss: 5.2636e-04\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.7797e-05 - val_loss: 2.0685e-04\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.9045e-05 - val_loss: 1.6095e-04\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 3.5142e-05 - val_loss: 2.4894e-04\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.5781e-05 - val_loss: 1.7307e-04\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.0151e-05 - val_loss: 2.5538e-04\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 0s 10ms/step - loss: 4.9068e-05 - val_loss: 2.1589e-04\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.8581e-05 - val_loss: 0.0010\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.0310e-05 - val_loss: 1.9843e-04\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.0824e-05 - val_loss: 8.3184e-05\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.4544e-05 - val_loss: 2.5691e-04\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 3.5810e-05 - val_loss: 2.0053e-04\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 4.9931e-05 - val_loss: 1.1170e-04\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 6.0391e-05 - val_loss: 2.5243e-04\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 5.3562e-05 - val_loss: 2.9635e-04\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 1s 11ms/step - loss: 4.5812e-05 - val_loss: 4.5121e-04\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 6.2239e-05 - val_loss: 3.4931e-05\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 5.2128e-05 - val_loss: 7.1133e-05\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 3.2919e-05 - val_loss: 4.0668e-04\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 1s 12ms/step - loss: 3.2397e-05 - val_loss: 6.7812e-05\n",
      ">p=12: 10, Score=0.009441626025363803\n",
      "[[0.006654581375187263, 0.015223288210108876, 0.009404462616657838, 0.004897721737506799, 0.008669953240314499, 0.015825610898900777, 0.005411266829469241, 0.010416479199193418, 0.021938770078122616, 0.013794367259833962], [0.009924157347995788, 0.003904810728272423, 0.008580950088799, 0.03764419234357774, 0.010821628529811278, 0.01654985098866746, 0.008360658102901652, 0.006532988481922075, 0.008207216887967661, 0.029206194449216127], [0.020314181165304035, 0.0034100117773050442, 0.003802148421527818, 0.013468830729834735, 0.002925612534454558, 0.0791537924669683, 0.003248215580242686, 0.004298163912608288, 0.0032920775993261486, 0.05742260836996138], [0.002612445859995205, 0.002240073081338778, 0.011542571883182973, 0.0023261309252120554, 0.030540963052771986, 0.00527683187101502, 0.002119748023687862, 0.01605550933163613, 0.010964515240630135, 0.008765428356127813], [0.013650418259203434, 0.018639082554727793, 0.018123419431503862, 0.0018933114915853366, 0.0025785919206100516, 0.0210278041777201, 0.0054935357184149325, 0.02021588443312794, 0.015621677448507398, 0.0031437368306796998], [0.00641850201645866, 0.016988209972623736, 0.007438402099069208, 0.015924528997857124, 0.0033266216632910073, 0.025392352836206555, 0.04981114761903882, 0.021451213979162276, 0.01190908151329495, 0.0067609209509100765], [0.0036755274777533486, 0.007986262062331662, 0.00813280712463893, 0.01713597448542714, 0.006927494541741908, 0.004756446287501603, 0.007486192771466449, 0.01295178517466411, 0.04798320878762752, 0.06033371319063008], [0.004509437712840736, 0.02827438584063202, 0.007770927186356857, 0.051209802040830255, 0.00681612582411617, 0.01288937492063269, 0.00789837577030994, 0.02725914237089455, 0.02269405231345445, 0.04173352790530771], [0.024066658806987107, 0.019660391262732446, 0.01975029008463025, 0.00747820085962303, 0.007589752203784883, 0.014752859715372324, 0.015169985999818891, 0.09409237536601722, 0.006616467726416886, 0.06021526060067117], [0.01091561425710097, 0.017952824418898672, 0.04130839370191097, 0.006483438482973725, 0.004660504055209458, 0.012655799218919128, 0.015268086281139404, 0.03922606410924345, 0.007272651419043541, 0.07167885196395218], [0.024561051395721734, 0.009006167238112539, 0.02884904679376632, 0.04680329584516585, 0.014172137889545411, 0.029903787071816623, 0.01779379090294242, 0.020833901362493634, 0.018741450912784785, 0.037411830271594226], [0.006392067007254809, 0.030359544325619936, 0.005973232691758312, 0.011388130951672792, 0.010603137343423441, 0.019587624410632998, 0.030054256785660982, 0.011662867473205552, 0.011304646614007652, 0.009441626025363803]] [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Param=1, Mean=0.011:, Std=0.005\n",
      "Param=2, Mean=0.014:, Std=0.010\n",
      "Param=3, Mean=0.019:, Std=0.026\n",
      "Param=4, Mean=0.009:, Std=0.008\n",
      "Param=5, Mean=0.012:, Std=0.007\n",
      "Param=6, Mean=0.017:, Std=0.013\n",
      "Param=7, Mean=0.018:, Std=0.019\n",
      "Param=8, Mean=0.021:, Std=0.015\n",
      "Param=9, Mean=0.027:, Std=0.027\n",
      "Param=10, Mean=0.023:, Std=0.020\n",
      "Param=11, Mean=0.025:, Std=0.011\n",
      "Param=12, Mean=0.015:, Std=0.009\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = 80, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = 80))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=batch_size, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=batch_size)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # resumindo a média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = mean(scores[i]), std(scores[i])\n",
    "        print(f'Param={params[i]}, Mean={m:.3f}:, Std={s:.3f}')\n",
    "    # boxplot das pontuações\n",
    "    pyplot.boxplot(scores, labels=params)\n",
    "    pyplot.savefig('figura[0].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repetindo o experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            score = score * 100.0\n",
    "            scores.append(score)\n",
    "            print(f'>p={p}: {r+1}, Score={score}')\n",
    "        all_scores.append(scores)\n",
    "    # resumindo os resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = np.arange(1, 13)\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste no modelo com diluição - dropout - 0.05, 0.1, 0.2, 0.3, para verficação do mais adequado para a aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 18ms/step - loss: 0.0023 - val_loss: 0.0104\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.8775e-04 - val_loss: 0.0079\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.1105e-04 - val_loss: 0.0051\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.0505e-04 - val_loss: 0.0030\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.4763e-04 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.7800e-04 - val_loss: 5.4346e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1472e-04 - val_loss: 8.7140e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.7840e-05 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.1067e-05 - val_loss: 0.0024\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.6962e-05 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.4632e-05 - val_loss: 4.9026e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.4397e-05 - val_loss: 3.8352e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1978e-04 - val_loss: 2.7316e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.1212e-05 - val_loss: 9.2529e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.6928e-05 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.3603e-05 - val_loss: 5.8489e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.6050e-05 - val_loss: 4.9445e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0687e-04 - val_loss: 2.1384e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.3120e-05 - val_loss: 8.6305e-05\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.0258e-05 - val_loss: 6.8705e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.4921e-05 - val_loss: 4.7236e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.9555e-05 - val_loss: 3.5306e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.2390e-05 - val_loss: 3.5996e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.7747e-05 - val_loss: 8.0011e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.3318e-05 - val_loss: 4.0960e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.4919e-05 - val_loss: 1.3731e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.7148e-05 - val_loss: 1.5943e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.9498e-05 - val_loss: 8.9072e-05\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.0939e-05 - val_loss: 7.7426e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.9809e-05 - val_loss: 1.6217e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.1374e-05 - val_loss: 2.5149e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.9622e-05 - val_loss: 5.2405e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.9704e-05 - val_loss: 6.1043e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.5562e-05 - val_loss: 2.2683e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.4475e-05 - val_loss: 5.6348e-05\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4629e-05 - val_loss: 9.5340e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.4991e-05 - val_loss: 8.9207e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.5755e-05 - val_loss: 1.1283e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.8823e-05 - val_loss: 1.0827e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.7521e-05 - val_loss: 1.3080e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.9160e-05 - val_loss: 1.1348e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.3869e-05 - val_loss: 1.3461e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.3285e-05 - val_loss: 1.1024e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.6559e-05 - val_loss: 4.9809e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.9000e-05 - val_loss: 4.0017e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.1989e-05 - val_loss: 1.2481e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.5642e-05 - val_loss: 1.9339e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.7937e-05 - val_loss: 1.5075e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.0097e-05 - val_loss: 1.9838e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.7080e-05 - val_loss: 3.7230e-05\n",
      ">p=0.05: 1, Score=3.345781806274317e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 7s 15ms/step - loss: 0.0023 - val_loss: 0.0104\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 9.9207e-04 - val_loss: 0.0082\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 8.1177e-04 - val_loss: 0.0055\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 5.5158e-04 - val_loss: 0.0031\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.7740e-04 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.9927e-04 - val_loss: 8.2188e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3250e-04 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.2067e-04 - val_loss: 1.8487e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.6492e-05 - val_loss: 3.3893e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 7.0142e-05 - val_loss: 1.8498e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.8239e-05 - val_loss: 2.4506e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.0345e-05 - val_loss: 4.3332e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.2333e-05 - val_loss: 0.0010\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.5902e-05 - val_loss: 2.6490e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 9.0392e-05 - val_loss: 1.4194e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.1776e-05 - val_loss: 3.0512e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.5478e-05 - val_loss: 1.8444e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.5011e-05 - val_loss: 4.1186e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.8313e-05 - val_loss: 3.6769e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.3948e-05 - val_loss: 2.8224e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.9609e-05 - val_loss: 1.5884e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.3341e-05 - val_loss: 3.2682e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.4643e-05 - val_loss: 1.4718e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.4269e-05 - val_loss: 6.0944e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.5297e-05 - val_loss: 2.8017e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.0870e-05 - val_loss: 1.4482e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.3222e-05 - val_loss: 3.7616e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.9113e-05 - val_loss: 1.7408e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.3415e-05 - val_loss: 1.0430e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.3404e-05 - val_loss: 4.4076e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.6093e-05 - val_loss: 3.1884e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.0353e-05 - val_loss: 2.2409e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.7541e-05 - val_loss: 3.0265e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.6500e-05 - val_loss: 4.0193e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.4569e-05 - val_loss: 1.5196e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.7777e-05 - val_loss: 1.3817e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.8133e-05 - val_loss: 2.2995e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.4454e-05 - val_loss: 1.3652e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.3211e-05 - val_loss: 1.1753e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.1204e-05 - val_loss: 1.2297e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.8459e-05 - val_loss: 2.9716e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.1637e-05 - val_loss: 2.4025e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.4764e-05 - val_loss: 2.0928e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.1513e-05 - val_loss: 4.0827e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.3678e-05 - val_loss: 4.6678e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.9865e-05 - val_loss: 7.4351e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.4087e-05 - val_loss: 2.2663e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.4941e-05 - val_loss: 4.0541e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.3555e-05 - val_loss: 2.7671e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.5506e-05 - val_loss: 2.5829e-05\n",
      ">p=0.05: 2, Score=3.666978227556683e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 16ms/step - loss: 0.0024 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.7470e-04 - val_loss: 0.0059\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.5689e-04 - val_loss: 0.0031\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.1778e-04 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.7450e-04 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1973e-04 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0615e-04 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.3043e-05 - val_loss: 7.7140e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.9041e-05 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 9.3724e-05 - val_loss: 2.5494e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 8.9697e-05 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.1738e-05 - val_loss: 7.3062e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.8796e-05 - val_loss: 6.2834e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.3186e-05 - val_loss: 3.6001e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.2876e-05 - val_loss: 3.7478e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.1801e-05 - val_loss: 8.2256e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 5.5521e-05 - val_loss: 8.3660e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.5885e-05 - val_loss: 1.6929e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.9498e-05 - val_loss: 5.8042e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.3103e-04 - val_loss: 3.3343e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 9.4774e-05 - val_loss: 1.9954e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 7.8929e-05 - val_loss: 1.8933e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 8.6769e-05 - val_loss: 3.7120e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 8.3274e-05 - val_loss: 1.7173e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0326e-04 - val_loss: 8.8778e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.6490e-05 - val_loss: 1.9453e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.9133e-05 - val_loss: 1.0253e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.2194e-05 - val_loss: 8.9495e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.4625e-05 - val_loss: 2.5118e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.7312e-05 - val_loss: 2.5806e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.7050e-05 - val_loss: 1.9077e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.3093e-05 - val_loss: 6.3003e-05\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.1315e-05 - val_loss: 5.0482e-05\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.5207e-05 - val_loss: 1.7395e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.8785e-05 - val_loss: 9.7493e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.0507e-05 - val_loss: 9.8580e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.7531e-05 - val_loss: 6.5863e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.4676e-05 - val_loss: 1.0576e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.0237e-05 - val_loss: 6.3858e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.9744e-05 - val_loss: 1.4146e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.9495e-05 - val_loss: 1.0425e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.7136e-05 - val_loss: 8.3330e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.6748e-05 - val_loss: 1.8172e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.9030e-05 - val_loss: 2.8696e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.7421e-05 - val_loss: 7.0747e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.9722e-05 - val_loss: 4.3324e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.8249e-05 - val_loss: 3.8823e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.8382e-05 - val_loss: 2.5933e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.6578e-05 - val_loss: 1.5097e-04\n",
      ">p=0.05: 3, Score=9.073798719327897e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 17ms/step - loss: 0.0024 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.4259e-04 - val_loss: 0.0062\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.3053e-04 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.7030e-04 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.0172e-04 - val_loss: 0.0014\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3336e-04 - val_loss: 0.0019\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.1501e-05 - val_loss: 9.5635e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0112e-04 - val_loss: 3.2487e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.6758e-05 - val_loss: 2.3496e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 5.2448e-05 - val_loss: 0.0010\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.9942e-05 - val_loss: 0.0026\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.3805e-05 - val_loss: 1.4313e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.6099e-05 - val_loss: 1.6857e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.3457e-05 - val_loss: 1.6512e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.3490e-05 - val_loss: 5.7077e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.9251e-05 - val_loss: 4.4428e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.5881e-05 - val_loss: 6.6635e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.2631e-05 - val_loss: 2.2035e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.6393e-05 - val_loss: 2.7442e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.9760e-05 - val_loss: 9.5761e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.1170e-05 - val_loss: 4.6856e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2053e-05 - val_loss: 9.3491e-05\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.5633e-05 - val_loss: 4.9523e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2306e-05 - val_loss: 8.1508e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.7933e-05 - val_loss: 5.3365e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0576e-04 - val_loss: 3.2443e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.4759e-05 - val_loss: 1.4326e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.3538e-05 - val_loss: 7.8671e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.7075e-05 - val_loss: 2.8427e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.8857e-05 - val_loss: 2.2450e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.3111e-05 - val_loss: 5.4380e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.0205e-05 - val_loss: 1.5830e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.1980e-05 - val_loss: 6.9032e-05\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.9231e-05 - val_loss: 1.3466e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.3875e-05 - val_loss: 1.5068e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.7755e-05 - val_loss: 1.0582e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.1613e-05 - val_loss: 5.7761e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.1779e-05 - val_loss: 1.4655e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.6121e-05 - val_loss: 4.7312e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.6038e-05 - val_loss: 2.8117e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.8741e-05 - val_loss: 4.3485e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.4358e-05 - val_loss: 1.7461e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.9627e-05 - val_loss: 6.1244e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.0256e-05 - val_loss: 2.6333e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.0433e-05 - val_loss: 1.4915e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.5177e-05 - val_loss: 9.7129e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.9061e-05 - val_loss: 2.7549e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.6033e-05 - val_loss: 2.5832e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.2347e-05 - val_loss: 3.0787e-04\n",
      ">p=0.05: 4, Score=0.00021751994790975004\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 20ms/step - loss: 0.0023 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.5505e-04 - val_loss: 0.0060\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 5.6190e-04 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.3654e-04 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.8068e-04 - val_loss: 9.9329e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.2473e-04 - val_loss: 9.4496e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 8.6700e-05 - val_loss: 9.6376e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.4178e-04 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.5669e-05 - val_loss: 0.0011\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.0436e-05 - val_loss: 6.8821e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.2285e-04 - val_loss: 3.8971e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 7.7026e-05 - val_loss: 4.3919e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.8481e-05 - val_loss: 8.5429e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.7784e-05 - val_loss: 8.3609e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.1370e-05 - val_loss: 6.1051e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.4379e-05 - val_loss: 2.3123e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 8.0626e-05 - val_loss: 2.3853e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.7039e-05 - val_loss: 1.5112e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.4008e-05 - val_loss: 3.2829e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.0906e-05 - val_loss: 3.6377e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 5.2686e-05 - val_loss: 7.1017e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 5.9109e-05 - val_loss: 3.5544e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.5160e-05 - val_loss: 2.7204e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.2902e-05 - val_loss: 7.0782e-05\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.7285e-05 - val_loss: 7.0387e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.3317e-05 - val_loss: 6.9788e-05\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.6249e-05 - val_loss: 9.5252e-05\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.2855e-05 - val_loss: 3.6023e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.5665e-05 - val_loss: 1.4312e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.8123e-05 - val_loss: 1.9166e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.6679e-05 - val_loss: 7.4472e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.0823e-05 - val_loss: 1.3993e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.9557e-05 - val_loss: 4.2569e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.0953e-05 - val_loss: 2.1752e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.9418e-05 - val_loss: 3.3251e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 4.0860e-05 - val_loss: 3.6062e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 5.4894e-05 - val_loss: 2.7102e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.0082e-05 - val_loss: 3.6452e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.1507e-05 - val_loss: 1.2284e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.0379e-05 - val_loss: 1.5911e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.9350e-05 - val_loss: 2.0335e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.9133e-05 - val_loss: 1.2287e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.6569e-05 - val_loss: 1.6834e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.4338e-05 - val_loss: 3.2478e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.0018e-05 - val_loss: 8.0954e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.0846e-05 - val_loss: 5.9496e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2217e-05 - val_loss: 2.7405e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.5472e-05 - val_loss: 1.5839e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.5177e-05 - val_loss: 4.1986e-05\n",
      ">p=0.05: 5, Score=5.051307016401552e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 18ms/step - loss: 0.0024 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.9147e-04 - val_loss: 0.0083\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.8691e-04 - val_loss: 0.0055\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.5016e-04 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 3.1811e-04 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.9642e-04 - val_loss: 7.6913e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.4477e-05 - val_loss: 2.7868e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.5292e-05 - val_loss: 2.9439e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.6172e-04 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.2026e-04 - val_loss: 2.7383e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.8428e-05 - val_loss: 2.6297e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.0369e-05 - val_loss: 1.6922e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 7.6194e-05 - val_loss: 2.5893e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.4453e-05 - val_loss: 2.6214e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.0617e-05 - val_loss: 1.3932e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.1916e-05 - val_loss: 4.0606e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 1.1683e-04 - val_loss: 8.8728e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.9168e-05 - val_loss: 2.0191e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.7400e-05 - val_loss: 2.5358e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.3480e-05 - val_loss: 3.3260e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.1047e-05 - val_loss: 4.3056e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.4709e-05 - val_loss: 2.0341e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.5286e-05 - val_loss: 2.5499e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.4551e-05 - val_loss: 2.7410e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 6.5459e-05 - val_loss: 2.0827e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.8008e-05 - val_loss: 5.2229e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.3938e-05 - val_loss: 6.4856e-05\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 2.1869e-05 - val_loss: 7.2122e-05\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.0714e-05 - val_loss: 2.9872e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.6189e-05 - val_loss: 4.7470e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.9281e-05 - val_loss: 6.8910e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.5465e-05 - val_loss: 5.3487e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.2409e-05 - val_loss: 2.9882e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.3509e-05 - val_loss: 5.0429e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.0387e-05 - val_loss: 2.0061e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.1448e-05 - val_loss: 9.1944e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.3053e-05 - val_loss: 6.3174e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.2077e-05 - val_loss: 2.4732e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.3272e-05 - val_loss: 3.9640e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.6256e-05 - val_loss: 1.6636e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.9211e-05 - val_loss: 4.2189e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.1148e-05 - val_loss: 7.7046e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.4009e-05 - val_loss: 7.0266e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.7563e-05 - val_loss: 3.1791e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.7669e-05 - val_loss: 2.4443e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.6532e-05 - val_loss: 2.8549e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.5370e-05 - val_loss: 8.4799e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.5299e-05 - val_loss: 2.8494e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.3865e-05 - val_loss: 6.5751e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.8998e-05 - val_loss: 0.0011\n",
      ">p=0.05: 6, Score=0.0006604550289921463\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 18ms/step - loss: 0.0023 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.4589e-04 - val_loss: 0.0060\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.1965e-04 - val_loss: 0.0036\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.3753e-04 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.4333e-04 - val_loss: 8.8193e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.4895e-04 - val_loss: 7.7885e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.2658e-05 - val_loss: 2.6363e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.4064e-04 - val_loss: 0.0026\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0122e-04 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.9673e-05 - val_loss: 3.5797e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0925e-04 - val_loss: 3.3419e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.2885e-05 - val_loss: 6.7905e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.4468e-05 - val_loss: 3.0147e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0364e-04 - val_loss: 2.4628e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0113e-04 - val_loss: 2.0931e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.2070e-05 - val_loss: 4.9409e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.9343e-05 - val_loss: 2.8257e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 8.8096e-05 - val_loss: 3.1434e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 9.3621e-05 - val_loss: 3.7361e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.3943e-05 - val_loss: 4.5937e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.3436e-05 - val_loss: 1.3671e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.5487e-05 - val_loss: 3.0338e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.0014e-05 - val_loss: 4.2474e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.6337e-05 - val_loss: 2.5577e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.8685e-05 - val_loss: 1.1046e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.5226e-05 - val_loss: 3.0527e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.6876e-05 - val_loss: 3.1681e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.8684e-05 - val_loss: 7.3955e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.4270e-05 - val_loss: 1.6945e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.9007e-05 - val_loss: 4.0127e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.1151e-05 - val_loss: 4.1476e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.4638e-05 - val_loss: 3.6881e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.4065e-05 - val_loss: 1.0791e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.5969e-05 - val_loss: 1.9310e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.3861e-05 - val_loss: 2.9431e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.9272e-05 - val_loss: 2.6389e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.0203e-05 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.5272e-05 - val_loss: 1.0792e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.9627e-05 - val_loss: 4.3632e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.7972e-05 - val_loss: 2.2583e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.0723e-05 - val_loss: 5.3566e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 2.9837e-05 - val_loss: 3.5770e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.4668e-05 - val_loss: 9.0407e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.4528e-05 - val_loss: 4.9318e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.7317e-05 - val_loss: 5.1933e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.3871e-05 - val_loss: 8.7183e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.3570e-05 - val_loss: 5.4616e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.8811e-05 - val_loss: 5.2735e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.1017e-05 - val_loss: 4.5085e-04\n",
      ">p=0.05: 7, Score=0.00019439544121269137\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 11s 19ms/step - loss: 0.0022 - val_loss: 0.0105\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.1236e-04 - val_loss: 0.0061\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.8551e-04 - val_loss: 0.0037\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.2803e-04 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.2522e-04 - val_loss: 4.1800e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1347e-04 - val_loss: 8.4371e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.6935e-05 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.7139e-05 - val_loss: 3.7026e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.5779e-05 - val_loss: 5.0533e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.5244e-05 - val_loss: 8.0594e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.5898e-05 - val_loss: 2.9712e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.9488e-05 - val_loss: 2.9684e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.1793e-05 - val_loss: 1.4938e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.5601e-05 - val_loss: 3.9074e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.9991e-05 - val_loss: 2.3782e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.4764e-05 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.0969e-05 - val_loss: 3.1013e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.7991e-05 - val_loss: 3.2289e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.1218e-05 - val_loss: 1.5189e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 3.6995e-05 - val_loss: 6.4525e-05\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.5528e-05 - val_loss: 4.5726e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.9715e-05 - val_loss: 2.7202e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.6927e-05 - val_loss: 2.3358e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.8491e-05 - val_loss: 2.2227e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.0260e-05 - val_loss: 1.7190e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.0811e-05 - val_loss: 7.4963e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.0318e-05 - val_loss: 5.8490e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.9643e-05 - val_loss: 7.1904e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.4788e-05 - val_loss: 1.9025e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.8459e-05 - val_loss: 1.1378e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.0479e-05 - val_loss: 9.7048e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.2347e-05 - val_loss: 5.4850e-05\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6748e-05 - val_loss: 2.9386e-05\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.4844e-05 - val_loss: 3.8514e-05\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.8857e-05 - val_loss: 5.7482e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.9953e-05 - val_loss: 2.0361e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.4461e-05 - val_loss: 3.3740e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.8889e-05 - val_loss: 4.6177e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.8140e-05 - val_loss: 3.0410e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.0140e-05 - val_loss: 7.9071e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.1846e-05 - val_loss: 1.1359e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.7846e-05 - val_loss: 1.7953e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.4280e-05 - val_loss: 9.5739e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.2140e-05 - val_loss: 5.7831e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 2.2131e-05 - val_loss: 2.2970e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 2.8011e-05 - val_loss: 1.8244e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.8734e-05 - val_loss: 6.7904e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.1480e-05 - val_loss: 2.8031e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.8287e-05 - val_loss: 1.3714e-04\n",
      ">p=0.05: 8, Score=0.00010299507266608998\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 12s 26ms/step - loss: 0.0023 - val_loss: 0.0105\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 9.9102e-04 - val_loss: 0.0081\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.1459e-04 - val_loss: 0.0054\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.5108e-04 - val_loss: 0.0031\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.7516e-04 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0303e-04 - val_loss: 7.2480e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.2847e-04 - val_loss: 8.1212e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.4705e-04 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4105e-04 - val_loss: 4.6396e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.4028e-05 - val_loss: 1.1789e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.5746e-05 - val_loss: 1.0896e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.6827e-05 - val_loss: 3.2164e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.1841e-05 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0350e-04 - val_loss: 6.4203e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0614e-04 - val_loss: 7.9402e-05\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.9072e-05 - val_loss: 1.5500e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.3398e-05 - val_loss: 1.8461e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.6023e-05 - val_loss: 2.6959e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.5298e-05 - val_loss: 3.4255e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.9693e-05 - val_loss: 1.8254e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.0395e-05 - val_loss: 7.3845e-05\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.4793e-05 - val_loss: 1.1354e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.5892e-05 - val_loss: 3.7490e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 5.6622e-05 - val_loss: 5.0300e-05\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.3847e-05 - val_loss: 3.6907e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.0545e-05 - val_loss: 5.4689e-05\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.0427e-05 - val_loss: 1.5542e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.7852e-05 - val_loss: 5.2583e-05\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.3072e-05 - val_loss: 1.5405e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.3155e-05 - val_loss: 1.2238e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.7258e-05 - val_loss: 6.9929e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.3641e-05 - val_loss: 7.7280e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.0487e-05 - val_loss: 1.9094e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.0186e-05 - val_loss: 1.4134e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.8297e-05 - val_loss: 2.4315e-05\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4421e-05 - val_loss: 2.1955e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.2444e-05 - val_loss: 6.5258e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.0337e-05 - val_loss: 2.3979e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.2579e-05 - val_loss: 1.8858e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.1261e-05 - val_loss: 1.4421e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 4.1560e-05 - val_loss: 7.7903e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.4043e-05 - val_loss: 1.2893e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.4720e-05 - val_loss: 3.5710e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.2734e-05 - val_loss: 8.0734e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.9174e-05 - val_loss: 1.0260e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4260e-05 - val_loss: 3.3153e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.9550e-05 - val_loss: 2.7822e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.3384e-05 - val_loss: 1.0694e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.6181e-06 - val_loss: 3.6497e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.9332e-05 - val_loss: 6.2983e-04\n",
      ">p=0.05: 9, Score=0.00033517004339955747\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 12s 24ms/step - loss: 0.0024 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.5098e-04 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.5325e-04 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.2290e-04 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.5781e-04 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.9320e-04 - val_loss: 0.0025\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6637e-04 - val_loss: 0.0010\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3042e-04 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.5580e-05 - val_loss: 9.6336e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0858e-04 - val_loss: 2.8151e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.0869e-05 - val_loss: 1.5499e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2714e-04 - val_loss: 3.7921e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.1902e-05 - val_loss: 6.8708e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.3336e-05 - val_loss: 2.0649e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.4034e-04 - val_loss: 7.2093e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.8993e-05 - val_loss: 8.0806e-05\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.7549e-05 - val_loss: 0.0010\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.0451e-05 - val_loss: 1.6271e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.0016e-05 - val_loss: 1.5394e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.1835e-05 - val_loss: 1.9543e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.7340e-05 - val_loss: 1.9720e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.3530e-05 - val_loss: 2.0403e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.0475e-05 - val_loss: 3.4426e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.3554e-05 - val_loss: 1.0473e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.8482e-05 - val_loss: 1.7142e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.4492e-05 - val_loss: 2.8211e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.5232e-05 - val_loss: 9.0078e-05\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.7312e-05 - val_loss: 6.8188e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.6985e-05 - val_loss: 1.6272e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.8170e-05 - val_loss: 8.3104e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.4929e-05 - val_loss: 1.6446e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.7931e-05 - val_loss: 4.4598e-05\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.0390e-05 - val_loss: 9.3541e-05\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.5988e-05 - val_loss: 1.7125e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.5193e-05 - val_loss: 6.6314e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.0767e-05 - val_loss: 8.5999e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.4288e-05 - val_loss: 3.1358e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.4134e-05 - val_loss: 2.2431e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.9660e-05 - val_loss: 2.3777e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.3496e-05 - val_loss: 1.9832e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.1392e-05 - val_loss: 5.5503e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.5640e-05 - val_loss: 4.4914e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.4036e-05 - val_loss: 1.7133e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.7916e-05 - val_loss: 6.3456e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.9193e-05 - val_loss: 1.8002e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.1287e-05 - val_loss: 7.7440e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2232e-05 - val_loss: 9.3890e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.2140e-05 - val_loss: 6.3278e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1570e-05 - val_loss: 6.9005e-05\n",
      ">p=0.05: 10, Score=6.295963248703629e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 18ms/step - loss: 0.0024 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.9143e-04 - val_loss: 0.0081\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.2289e-04 - val_loss: 0.0051\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.6399e-04 - val_loss: 0.0027\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.7563e-04 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.9749e-04 - val_loss: 6.4155e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.2381e-04 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.7661e-04 - val_loss: 0.0039\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0964e-04 - val_loss: 5.9816e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0510e-04 - val_loss: 1.9855e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.5599e-05 - val_loss: 1.5596e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1095e-04 - val_loss: 2.7007e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.3905e-05 - val_loss: 1.5004e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1802e-04 - val_loss: 3.3792e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.2810e-05 - val_loss: 3.8396e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.6422e-05 - val_loss: 3.3963e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.8220e-05 - val_loss: 7.6704e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.9808e-05 - val_loss: 4.4487e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.5218e-05 - val_loss: 1.6227e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.6154e-05 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.0449e-05 - val_loss: 6.3457e-05\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.2356e-05 - val_loss: 2.9535e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.9789e-05 - val_loss: 1.6053e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.7473e-05 - val_loss: 4.1915e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.1657e-05 - val_loss: 1.2867e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1123e-04 - val_loss: 5.4740e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.2480e-05 - val_loss: 9.8422e-05\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.1648e-05 - val_loss: 2.5355e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.1620e-05 - val_loss: 2.8698e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.0977e-05 - val_loss: 1.3264e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.9329e-05 - val_loss: 7.9245e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1929e-04 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.6353e-05 - val_loss: 2.8207e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.7400e-05 - val_loss: 1.1413e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.4099e-05 - val_loss: 5.1134e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.3154e-05 - val_loss: 1.2260e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.3014e-05 - val_loss: 1.3529e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.2972e-05 - val_loss: 1.8446e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.5742e-05 - val_loss: 1.2354e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.2552e-05 - val_loss: 7.8445e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.5373e-05 - val_loss: 6.1141e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.6165e-05 - val_loss: 4.6722e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.3908e-05 - val_loss: 5.9291e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.6949e-05 - val_loss: 5.9368e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.8408e-05 - val_loss: 6.2369e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.2863e-05 - val_loss: 1.6248e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.4515e-05 - val_loss: 2.7027e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.3227e-05 - val_loss: 1.3951e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.1930e-05 - val_loss: 3.0087e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.6996e-05 - val_loss: 6.3985e-04\n",
      ">p=0.1: 1, Score=0.00040300344699062407\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 17ms/step - loss: 0.0024 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.6242e-04 - val_loss: 0.0061\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.8213e-04 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.9555e-04 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.2714e-04 - val_loss: 6.4265e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2493e-04 - val_loss: 3.7335e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.9057e-05 - val_loss: 5.0999e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0135e-04 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1468e-04 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0510e-04 - val_loss: 3.0750e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.7019e-05 - val_loss: 5.2344e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.2578e-05 - val_loss: 4.8315e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.6183e-05 - val_loss: 7.0801e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3460e-04 - val_loss: 3.3121e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3352e-04 - val_loss: 3.2033e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.3760e-05 - val_loss: 6.0243e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.5983e-05 - val_loss: 1.7830e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.2703e-05 - val_loss: 2.0059e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.7247e-05 - val_loss: 1.1722e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.5222e-05 - val_loss: 1.1449e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.4924e-05 - val_loss: 5.4864e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0260e-04 - val_loss: 1.2314e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.7185e-05 - val_loss: 1.7453e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.8501e-05 - val_loss: 1.1204e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.0240e-05 - val_loss: 4.7274e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.6927e-05 - val_loss: 7.9443e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.4858e-05 - val_loss: 1.7277e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.6280e-05 - val_loss: 2.0778e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.2657e-05 - val_loss: 9.2157e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.1044e-05 - val_loss: 1.4591e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.1326e-05 - val_loss: 1.2105e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.1560e-05 - val_loss: 2.4033e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.1289e-05 - val_loss: 2.5850e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.4659e-05 - val_loss: 3.9979e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.3897e-05 - val_loss: 5.0876e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.2524e-05 - val_loss: 1.9694e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.9444e-05 - val_loss: 5.3440e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.9541e-05 - val_loss: 3.8371e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.0478e-05 - val_loss: 3.6803e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.0618e-05 - val_loss: 3.3400e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.0602e-05 - val_loss: 6.7627e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.2221e-05 - val_loss: 4.1912e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.6916e-05 - val_loss: 2.0673e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.0050e-05 - val_loss: 3.7822e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.7648e-05 - val_loss: 1.2313e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.0250e-05 - val_loss: 6.0581e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.4022e-05 - val_loss: 1.5350e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.9386e-05 - val_loss: 6.6609e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.8224e-05 - val_loss: 6.0724e-05\n",
      ">p=0.1: 2, Score=5.637644790112972e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 22ms/step - loss: 0.0023 - val_loss: 0.0101\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.6743e-04 - val_loss: 0.0076\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.2306e-04 - val_loss: 0.0054\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.7306e-04 - val_loss: 0.0031\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.7760e-04 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.4073e-04 - val_loss: 6.1474e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.6789e-04 - val_loss: 3.3228e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0336e-05 - val_loss: 3.5060e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.8943e-05 - val_loss: 8.7475e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.8428e-05 - val_loss: 0.0021\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.3565e-05 - val_loss: 2.8341e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.7540e-05 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.8093e-05 - val_loss: 2.5407e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.6245e-05 - val_loss: 5.1014e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2153e-04 - val_loss: 0.0026\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.5633e-05 - val_loss: 1.4107e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.4196e-05 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.2828e-05 - val_loss: 2.4129e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.3333e-04 - val_loss: 9.1832e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.4660e-04 - val_loss: 2.7678e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.4994e-05 - val_loss: 1.0174e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.3559e-05 - val_loss: 4.3412e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.3792e-05 - val_loss: 1.4573e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.8515e-05 - val_loss: 7.4720e-05\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.5490e-05 - val_loss: 2.9773e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.6491e-05 - val_loss: 2.2502e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.6801e-05 - val_loss: 6.4636e-05\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.6931e-05 - val_loss: 4.9952e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.4509e-05 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.4386e-05 - val_loss: 9.8069e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.4540e-04 - val_loss: 0.0023\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0729e-04 - val_loss: 5.1661e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.2685e-05 - val_loss: 2.9402e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.9475e-05 - val_loss: 1.4699e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.2437e-05 - val_loss: 2.4157e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.6409e-05 - val_loss: 4.7877e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.3598e-05 - val_loss: 4.0006e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.5707e-05 - val_loss: 6.4317e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.8821e-05 - val_loss: 2.4650e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.5296e-05 - val_loss: 8.7422e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.7290e-05 - val_loss: 1.2510e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.7447e-05 - val_loss: 6.7757e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.8550e-05 - val_loss: 2.9650e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.3854e-05 - val_loss: 3.2208e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.7127e-05 - val_loss: 2.4056e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.3184e-05 - val_loss: 5.8569e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.1906e-05 - val_loss: 1.3131e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.2066e-05 - val_loss: 7.9784e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.2799e-05 - val_loss: 1.2440e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.2268e-05 - val_loss: 3.0249e-04\n",
      ">p=0.1: 3, Score=0.00019597022037487477\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 17ms/step - loss: 0.0025 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0089\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.5443e-04 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.2666e-04 - val_loss: 0.0042\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.7813e-04 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.7255e-04 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.0058e-04 - val_loss: 0.0019\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.8653e-04 - val_loss: 7.9432e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.5509e-04 - val_loss: 6.9680e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.9796e-05 - val_loss: 0.0027\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.4313e-04 - val_loss: 1.5936e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.9501e-05 - val_loss: 1.9147e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.3281e-05 - val_loss: 5.2385e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.3322e-05 - val_loss: 1.9774e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.7035e-04 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1481e-04 - val_loss: 6.7707e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.6729e-05 - val_loss: 1.5724e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.8939e-05 - val_loss: 3.1631e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.7190e-05 - val_loss: 1.1120e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.1724e-05 - val_loss: 1.0961e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.6099e-05 - val_loss: 1.0790e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0351e-04 - val_loss: 3.0797e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.6018e-05 - val_loss: 3.6663e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.5900e-05 - val_loss: 3.0766e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0065e-05 - val_loss: 7.1502e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0316e-04 - val_loss: 3.8140e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.4309e-05 - val_loss: 3.0709e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.8307e-05 - val_loss: 1.9754e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.7321e-05 - val_loss: 1.7508e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.7527e-05 - val_loss: 5.2630e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.4257e-05 - val_loss: 8.1616e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.0850e-05 - val_loss: 8.9112e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.1629e-05 - val_loss: 3.4869e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.8261e-05 - val_loss: 5.3466e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.4655e-05 - val_loss: 3.5541e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.6601e-05 - val_loss: 7.4600e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.0057e-05 - val_loss: 3.6141e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.2057e-05 - val_loss: 7.5718e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.5647e-05 - val_loss: 4.8304e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.3644e-05 - val_loss: 1.0080e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.4574e-05 - val_loss: 8.5163e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.8647e-05 - val_loss: 3.3548e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.4872e-05 - val_loss: 1.2863e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.9141e-05 - val_loss: 5.2586e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.9188e-05 - val_loss: 3.1952e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.1640e-05 - val_loss: 1.1135e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.4676e-05 - val_loss: 2.3986e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.3646e-05 - val_loss: 8.1245e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.7772e-05 - val_loss: 5.9406e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.0857e-05 - val_loss: 3.6335e-04\n",
      ">p=0.1: 4, Score=0.00024515215773135424\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 18ms/step - loss: 0.0024 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0082\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.7212e-04 - val_loss: 0.0057\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.5762e-04 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.5966e-04 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.2064e-04 - val_loss: 8.6389e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.8325e-04 - val_loss: 0.0029\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.6924e-04 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0684e-05 - val_loss: 2.5297e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1842e-04 - val_loss: 3.0739e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.1660e-05 - val_loss: 1.3300e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.6154e-05 - val_loss: 4.3670e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.4279e-05 - val_loss: 6.1033e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.2565e-04 - val_loss: 5.1317e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.7986e-05 - val_loss: 8.1088e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.5557e-05 - val_loss: 3.2141e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1131e-04 - val_loss: 3.9971e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.6466e-05 - val_loss: 1.4994e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.1886e-05 - val_loss: 2.4262e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.2437e-05 - val_loss: 1.5618e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.0030e-05 - val_loss: 2.7287e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.7068e-05 - val_loss: 6.4279e-05\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.3369e-05 - val_loss: 8.7780e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.3751e-05 - val_loss: 4.0165e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.8373e-05 - val_loss: 2.2517e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.6360e-05 - val_loss: 2.4186e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.9654e-05 - val_loss: 8.1727e-05\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.4240e-05 - val_loss: 2.8736e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.3703e-05 - val_loss: 5.2308e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.6543e-05 - val_loss: 9.3708e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.9700e-05 - val_loss: 6.5132e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.1717e-05 - val_loss: 2.1779e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.6221e-05 - val_loss: 5.9624e-05\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.4877e-05 - val_loss: 1.5472e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.8377e-05 - val_loss: 6.7839e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.7581e-05 - val_loss: 9.5193e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.0222e-05 - val_loss: 3.9176e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.5895e-05 - val_loss: 1.5757e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.3205e-05 - val_loss: 1.2707e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.4705e-05 - val_loss: 2.7576e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.9648e-05 - val_loss: 1.6465e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.1304e-05 - val_loss: 3.1831e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.0685e-05 - val_loss: 7.6918e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.1194e-05 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.5049e-05 - val_loss: 1.1286e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.0978e-05 - val_loss: 3.1562e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.7717e-05 - val_loss: 4.5977e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.3112e-05 - val_loss: 1.9487e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.7340e-05 - val_loss: 1.6389e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.3922e-05 - val_loss: 1.3293e-04\n",
      ">p=0.1: 5, Score=0.0001307122001890093\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 17ms/step - loss: 0.0025 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.4342e-04 - val_loss: 0.0056\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.0630e-04 - val_loss: 0.0033\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.9434e-04 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.2112e-04 - val_loss: 5.6834e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.6832e-04 - val_loss: 3.2777e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.8125e-05 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.7823e-05 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.4681e-04 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2628e-04 - val_loss: 1.8504e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.5697e-05 - val_loss: 2.3069e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.3958e-05 - val_loss: 4.7336e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.1330e-05 - val_loss: 7.1470e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.5992e-05 - val_loss: 2.0669e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0953e-04 - val_loss: 3.6714e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.3160e-04 - val_loss: 1.0734e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3583e-04 - val_loss: 6.1843e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.6245e-05 - val_loss: 3.8471e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.2528e-05 - val_loss: 2.1147e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.3493e-05 - val_loss: 8.8729e-05\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.1963e-05 - val_loss: 1.7866e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.1541e-05 - val_loss: 3.6379e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.1359e-05 - val_loss: 3.0259e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.2755e-05 - val_loss: 7.2613e-05\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0926e-04 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3390e-04 - val_loss: 5.7150e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.6797e-05 - val_loss: 2.6222e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.7003e-05 - val_loss: 3.5822e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.9780e-05 - val_loss: 2.9569e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.8738e-05 - val_loss: 1.2203e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.8335e-05 - val_loss: 1.2568e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.1683e-05 - val_loss: 7.1117e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.5782e-05 - val_loss: 1.8648e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.0314e-05 - val_loss: 6.5559e-05\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.0584e-05 - val_loss: 9.0576e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.2392e-05 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.3886e-05 - val_loss: 2.5764e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.0888e-05 - val_loss: 8.6069e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.8483e-05 - val_loss: 1.6951e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.8126e-05 - val_loss: 6.9669e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.9344e-05 - val_loss: 4.2751e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.3117e-05 - val_loss: 8.7236e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1322e-04 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.7214e-05 - val_loss: 4.1041e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.6804e-05 - val_loss: 4.3319e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.1819e-05 - val_loss: 3.0323e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.7893e-05 - val_loss: 3.0785e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.7361e-05 - val_loss: 9.3986e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.2304e-05 - val_loss: 8.7492e-05\n",
      ">p=0.1: 6, Score=5.870149834663607e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 10s 28ms/step - loss: 0.0024 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0086\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.1934e-04 - val_loss: 0.0062\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.1124e-04 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.5140e-04 - val_loss: 0.0024\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.1363e-04 - val_loss: 9.3767e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.7632e-04 - val_loss: 4.5968e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3155e-04 - val_loss: 2.1338e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1481e-04 - val_loss: 4.4969e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.4942e-05 - val_loss: 3.6036e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.8097e-04 - val_loss: 3.0943e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.8155e-05 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.9931e-05 - val_loss: 4.8337e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2332e-04 - val_loss: 6.5626e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0470e-04 - val_loss: 3.1086e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.6791e-05 - val_loss: 5.2143e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1469e-04 - val_loss: 6.8288e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.4782e-05 - val_loss: 4.3859e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0737e-04 - val_loss: 6.3351e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.7042e-05 - val_loss: 4.6370e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.2165e-05 - val_loss: 4.5127e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.4511e-05 - val_loss: 8.2642e-05\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.0434e-05 - val_loss: 7.5213e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.3345e-05 - val_loss: 1.8752e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.3682e-05 - val_loss: 4.2152e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.5799e-05 - val_loss: 1.3284e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1562e-04 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.7397e-05 - val_loss: 1.6829e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.4249e-05 - val_loss: 3.2881e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.8911e-05 - val_loss: 4.9259e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.8506e-05 - val_loss: 6.1488e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.4926e-05 - val_loss: 5.1612e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.0205e-05 - val_loss: 3.7616e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.3649e-05 - val_loss: 8.6149e-05\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.0760e-05 - val_loss: 8.1970e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.3130e-05 - val_loss: 3.5059e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.6803e-05 - val_loss: 1.7244e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.4118e-05 - val_loss: 3.0547e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.3532e-05 - val_loss: 3.0896e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.9570e-05 - val_loss: 7.0690e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.3715e-05 - val_loss: 8.2705e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.7018e-05 - val_loss: 2.1894e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.1374e-05 - val_loss: 1.1262e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.5241e-05 - val_loss: 5.5369e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.0497e-05 - val_loss: 6.9587e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.2404e-05 - val_loss: 3.1308e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.7863e-05 - val_loss: 1.4140e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.1129e-05 - val_loss: 3.9553e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.2433e-05 - val_loss: 3.3915e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.7148e-05 - val_loss: 1.0899e-04\n",
      ">p=0.1: 7, Score=4.996023199055344e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 18ms/step - loss: 0.0023 - val_loss: 0.0103\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0078\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.8687e-04 - val_loss: 0.0052\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.5743e-04 - val_loss: 0.0031\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.7349e-04 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.5510e-04 - val_loss: 5.7382e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.4210e-04 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2999e-04 - val_loss: 1.6197e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.6918e-04 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.7028e-04 - val_loss: 4.9734e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.8518e-05 - val_loss: 3.1832e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.7767e-05 - val_loss: 5.2764e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.7972e-05 - val_loss: 4.1251e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1285e-04 - val_loss: 1.6904e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.4563e-05 - val_loss: 1.8514e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.7288e-05 - val_loss: 3.0241e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1207e-04 - val_loss: 2.5650e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.0595e-05 - val_loss: 2.7448e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.2823e-05 - val_loss: 7.9681e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.8640e-05 - val_loss: 1.2441e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1932e-04 - val_loss: 7.8817e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0176e-04 - val_loss: 9.5653e-05\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.2817e-05 - val_loss: 8.6929e-05\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1735e-04 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1687e-04 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.2938e-05 - val_loss: 7.3406e-05\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.1254e-05 - val_loss: 1.5611e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.8251e-05 - val_loss: 3.6404e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.1601e-05 - val_loss: 4.3753e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.2708e-05 - val_loss: 4.5249e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.1266e-05 - val_loss: 1.5278e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.5585e-05 - val_loss: 1.7297e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.5202e-05 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.6593e-05 - val_loss: 3.8295e-05\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.2856e-05 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2423e-05 - val_loss: 7.1808e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.1165e-05 - val_loss: 2.5538e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.1096e-05 - val_loss: 8.1760e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2228e-05 - val_loss: 0.0010\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.6649e-05 - val_loss: 7.5672e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.7004e-05 - val_loss: 9.3994e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.5254e-05 - val_loss: 4.0602e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.4823e-05 - val_loss: 4.0484e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.9139e-05 - val_loss: 4.0151e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.0916e-05 - val_loss: 3.4050e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.1630e-05 - val_loss: 1.3938e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.4699e-05 - val_loss: 1.7338e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.6340e-05 - val_loss: 8.5697e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.5437e-05 - val_loss: 5.8823e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.3723e-05 - val_loss: 1.5713e-04\n",
      ">p=0.1: 8, Score=0.00012444851745385677\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 18ms/step - loss: 0.0024 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0090\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0240e-04 - val_loss: 0.0065\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.7784e-04 - val_loss: 0.0040\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.2994e-04 - val_loss: 0.0022\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.0617e-04 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.8213e-04 - val_loss: 5.9586e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.2459e-04 - val_loss: 5.9759e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.9673e-05 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.4139e-04 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.2810e-04 - val_loss: 3.6912e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2066e-04 - val_loss: 2.2565e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.5216e-05 - val_loss: 7.6566e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.9597e-05 - val_loss: 1.9248e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.1784e-05 - val_loss: 2.0421e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.4101e-05 - val_loss: 1.0878e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.3638e-05 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.9096e-05 - val_loss: 7.7183e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.2484e-05 - val_loss: 2.3254e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0840e-04 - val_loss: 4.6490e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.3076e-05 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.9133e-05 - val_loss: 3.8659e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.8593e-05 - val_loss: 2.1027e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.0945e-05 - val_loss: 2.8885e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.9504e-05 - val_loss: 4.3980e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.9557e-05 - val_loss: 2.7428e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.2087e-05 - val_loss: 1.8130e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.8345e-05 - val_loss: 2.9132e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0241e-05 - val_loss: 4.1413e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.6447e-05 - val_loss: 4.3182e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.0385e-05 - val_loss: 3.0325e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.8861e-05 - val_loss: 5.9328e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.3129e-05 - val_loss: 4.5577e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.9812e-05 - val_loss: 6.6881e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.9519e-05 - val_loss: 3.0482e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.9105e-05 - val_loss: 3.3226e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.9549e-05 - val_loss: 7.3785e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.2446e-05 - val_loss: 4.0239e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.2920e-05 - val_loss: 2.2405e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.4446e-05 - val_loss: 3.3952e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.8499e-05 - val_loss: 1.4906e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.8692e-05 - val_loss: 3.2392e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.6504e-05 - val_loss: 2.3982e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.9123e-05 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.3795e-05 - val_loss: 2.1721e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.9052e-05 - val_loss: 5.6237e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.9815e-05 - val_loss: 6.4382e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.5929e-05 - val_loss: 7.1794e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.6176e-05 - val_loss: 6.3366e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.6814e-05 - val_loss: 1.6464e-04\n",
      ">p=0.1: 9, Score=0.00015619644545949996\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 20ms/step - loss: 0.0025 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0090\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.3965e-04 - val_loss: 0.0062\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.4163e-04 - val_loss: 0.0037\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.3587e-04 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.2941e-04 - val_loss: 8.1702e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.2320e-04 - val_loss: 0.0018\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.5453e-04 - val_loss: 3.7748e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1793e-04 - val_loss: 2.8042e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.7015e-04 - val_loss: 3.8407e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1618e-04 - val_loss: 1.1267e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.4812e-05 - val_loss: 4.1926e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.3867e-05 - val_loss: 5.4786e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.0924e-05 - val_loss: 5.4577e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.4247e-05 - val_loss: 2.4152e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.8387e-05 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.3344e-05 - val_loss: 1.8150e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.5887e-05 - val_loss: 2.3509e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0355e-04 - val_loss: 5.8734e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.6360e-05 - val_loss: 7.0477e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.5272e-05 - val_loss: 2.3123e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.4530e-05 - val_loss: 3.8067e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.8739e-05 - val_loss: 3.2204e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.7781e-05 - val_loss: 3.5471e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1060e-04 - val_loss: 3.0251e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.8387e-05 - val_loss: 3.6721e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.7313e-05 - val_loss: 1.9661e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.8668e-05 - val_loss: 8.5579e-05\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.4100e-05 - val_loss: 4.3833e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.3817e-05 - val_loss: 7.9043e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.6693e-05 - val_loss: 2.9711e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.7414e-05 - val_loss: 6.7677e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.5631e-05 - val_loss: 1.0549e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.0069e-05 - val_loss: 1.1699e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.7457e-05 - val_loss: 1.1650e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.8192e-05 - val_loss: 6.2314e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.6850e-05 - val_loss: 1.0262e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.3799e-05 - val_loss: 4.7583e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.9158e-05 - val_loss: 6.3103e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.2077e-05 - val_loss: 1.2689e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.7421e-05 - val_loss: 3.7293e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.7368e-05 - val_loss: 1.2324e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.4959e-05 - val_loss: 5.1066e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2719e-05 - val_loss: 1.2070e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.3253e-05 - val_loss: 2.0399e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.9843e-05 - val_loss: 3.7045e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.8912e-05 - val_loss: 1.7638e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.1554e-05 - val_loss: 1.6317e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.9897e-05 - val_loss: 1.1050e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.5655e-05 - val_loss: 1.4310e-04\n",
      ">p=0.1: 10, Score=0.00011331335554132238\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 17ms/step - loss: 0.0024 - val_loss: 0.0109\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0091\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.6049e-04 - val_loss: 0.0073\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.1611e-04 - val_loss: 0.0051\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.1931e-04 - val_loss: 0.0034\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.5042e-04 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.6567e-04 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.7115e-04 - val_loss: 7.4581e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.5750e-04 - val_loss: 0.0020\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.8355e-04 - val_loss: 2.3524e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2231e-04 - val_loss: 2.1228e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0477e-04 - val_loss: 2.0608e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.4426e-05 - val_loss: 0.0018\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.0791e-05 - val_loss: 4.0935e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0416e-04 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0588e-05 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.2435e-05 - val_loss: 5.2077e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.7148e-05 - val_loss: 2.5250e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.6962e-05 - val_loss: 2.0137e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.8018e-05 - val_loss: 1.3158e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.4585e-04 - val_loss: 5.3297e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.9456e-05 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.9548e-04 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.7688e-04 - val_loss: 0.0016\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.6356e-05 - val_loss: 1.6679e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.2277e-05 - val_loss: 1.8409e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.8627e-05 - val_loss: 7.0201e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.7854e-05 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.7357e-05 - val_loss: 4.5519e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.2538e-05 - val_loss: 1.4735e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.4704e-05 - val_loss: 8.2547e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1924e-04 - val_loss: 0.0010\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.8640e-05 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.1720e-05 - val_loss: 4.1083e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.4715e-05 - val_loss: 1.0088e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2965e-05 - val_loss: 8.2450e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.3983e-05 - val_loss: 2.8407e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1303e-04 - val_loss: 8.4513e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0736e-04 - val_loss: 1.5402e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.6290e-05 - val_loss: 7.3878e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.8664e-05 - val_loss: 7.2887e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.9870e-05 - val_loss: 7.0512e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.3244e-05 - val_loss: 8.5849e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.2956e-05 - val_loss: 1.4879e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.5756e-05 - val_loss: 2.6492e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.0126e-05 - val_loss: 5.1036e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.6817e-05 - val_loss: 6.3519e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.2152e-05 - val_loss: 3.5644e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.6665e-05 - val_loss: 1.6227e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.8520e-05 - val_loss: 3.5093e-05\n",
      ">p=0.2: 1, Score=3.4859323932323605e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 17ms/step - loss: 0.0025 - val_loss: 0.0109\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0091\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0947e-04 - val_loss: 0.0068\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.8106e-04 - val_loss: 0.0048\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.6088e-04 - val_loss: 0.0032\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.2723e-04 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.7407e-04 - val_loss: 6.8278e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.4993e-04 - val_loss: 4.7184e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.7536e-04 - val_loss: 1.9908e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.2788e-04 - val_loss: 5.9125e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.3958e-04 - val_loss: 3.3343e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3652e-04 - val_loss: 4.7177e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 9.8932e-05 - val_loss: 5.0433e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.0991e-05 - val_loss: 3.2271e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.5202e-05 - val_loss: 9.3329e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1580e-04 - val_loss: 3.2665e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.3243e-05 - val_loss: 1.9414e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.5123e-05 - val_loss: 0.0030\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0396e-04 - val_loss: 2.9174e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.1866e-04 - val_loss: 0.0010\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2134e-04 - val_loss: 1.2834e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.9596e-05 - val_loss: 0.0019\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.2024e-05 - val_loss: 3.5033e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.3986e-05 - val_loss: 4.6338e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.5133e-05 - val_loss: 1.1338e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.0670e-05 - val_loss: 3.3003e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.1598e-05 - val_loss: 3.7173e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.4266e-05 - val_loss: 6.1407e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.2478e-05 - val_loss: 3.8247e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.2279e-05 - val_loss: 1.2825e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.2568e-05 - val_loss: 0.0023\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.4495e-05 - val_loss: 1.3135e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.6145e-05 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.3922e-05 - val_loss: 2.2508e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.4463e-04 - val_loss: 9.6853e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.8815e-05 - val_loss: 4.7223e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.0726e-05 - val_loss: 1.1735e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.4069e-05 - val_loss: 4.9875e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2766e-05 - val_loss: 1.7175e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.4606e-05 - val_loss: 1.9057e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.4797e-05 - val_loss: 4.4636e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.7702e-05 - val_loss: 8.4407e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.4160e-05 - val_loss: 4.8785e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1276e-04 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0053e-04 - val_loss: 3.6673e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.0702e-05 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.9553e-05 - val_loss: 1.5884e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.0930e-05 - val_loss: 3.1082e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.1152e-05 - val_loss: 3.3551e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.4330e-05 - val_loss: 5.8199e-04\n",
      ">p=0.2: 2, Score=0.00027346829301677644\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 17ms/step - loss: 0.0024 - val_loss: 0.0109\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.8508e-04 - val_loss: 0.0067\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.5699e-04 - val_loss: 0.0043\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.4541e-04 - val_loss: 0.0025\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.1583e-04 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.9788e-04 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.8059e-04 - val_loss: 0.0016\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.7760e-04 - val_loss: 3.6354e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.6101e-04 - val_loss: 3.0722e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3907e-04 - val_loss: 3.5886e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.6314e-05 - val_loss: 5.9021e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.5670e-04 - val_loss: 7.0103e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.4708e-04 - val_loss: 5.8605e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1232e-04 - val_loss: 1.8822e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.1673e-05 - val_loss: 2.4409e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.2628e-05 - val_loss: 4.1849e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0851e-04 - val_loss: 1.3993e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.2431e-05 - val_loss: 8.6634e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.4732e-05 - val_loss: 4.6733e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.8484e-05 - val_loss: 2.2456e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.8198e-05 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.2385e-05 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0166e-04 - val_loss: 2.2500e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0194e-05 - val_loss: 7.8948e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.2821e-05 - val_loss: 1.0079e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.8582e-05 - val_loss: 5.6424e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.4548e-05 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.0396e-05 - val_loss: 8.2552e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.4079e-05 - val_loss: 0.0025\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.7584e-05 - val_loss: 0.0010\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.4649e-05 - val_loss: 1.7152e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.5795e-05 - val_loss: 1.5739e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.4736e-05 - val_loss: 4.8561e-05\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.3719e-05 - val_loss: 3.7132e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.7473e-05 - val_loss: 4.2985e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.7253e-05 - val_loss: 3.0599e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 8.1667e-05 - val_loss: 1.1773e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.1853e-05 - val_loss: 7.5269e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.4615e-05 - val_loss: 0.0024\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.3278e-05 - val_loss: 1.0193e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0017e-04 - val_loss: 2.9978e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.5478e-05 - val_loss: 8.9343e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.7368e-05 - val_loss: 1.5191e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0988e-04 - val_loss: 0.0012\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.9141e-05 - val_loss: 1.3925e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.1706e-05 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.0738e-05 - val_loss: 9.1884e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.7910e-05 - val_loss: 1.4161e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.9653e-05 - val_loss: 6.5650e-05\n",
      ">p=0.2: 3, Score=8.064370194915682e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 17ms/step - loss: 0.0025 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0086\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.4443e-04 - val_loss: 0.0063\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.1734e-04 - val_loss: 0.0043\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.4032e-04 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.4829e-04 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.6393e-04 - val_loss: 8.7560e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.3269e-04 - val_loss: 2.8282e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6961e-04 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.6705e-04 - val_loss: 3.3456e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.7022e-04 - val_loss: 5.9861e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2360e-04 - val_loss: 1.5093e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2907e-04 - val_loss: 2.9154e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2040e-04 - val_loss: 2.3577e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.4392e-05 - val_loss: 1.3181e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3955e-04 - val_loss: 1.8147e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.4747e-05 - val_loss: 4.2723e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.7497e-05 - val_loss: 2.6992e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.8215e-05 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.8888e-05 - val_loss: 1.8609e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.4317e-04 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1886e-04 - val_loss: 7.3832e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.1452e-05 - val_loss: 5.5434e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.6800e-05 - val_loss: 3.7075e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0761e-04 - val_loss: 9.2001e-05\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.5777e-05 - val_loss: 1.1927e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.0432e-05 - val_loss: 4.8024e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.6740e-05 - val_loss: 5.2132e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.3534e-05 - val_loss: 7.2549e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1622e-04 - val_loss: 3.5256e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.7427e-05 - val_loss: 6.5681e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.2489e-05 - val_loss: 5.1953e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.3424e-05 - val_loss: 1.8977e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.7056e-05 - val_loss: 8.7830e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.9742e-05 - val_loss: 2.5259e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1562e-04 - val_loss: 8.3478e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3809e-04 - val_loss: 9.9166e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.9111e-05 - val_loss: 6.4135e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.3921e-05 - val_loss: 3.8489e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.8458e-05 - val_loss: 1.0667e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.3062e-05 - val_loss: 8.4377e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.3981e-05 - val_loss: 1.9642e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.4890e-05 - val_loss: 0.0010\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.0242e-05 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.0428e-05 - val_loss: 3.1150e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.8947e-05 - val_loss: 6.3534e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.7935e-05 - val_loss: 8.6960e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.1233e-05 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.7242e-05 - val_loss: 5.1647e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.2623e-05 - val_loss: 3.9510e-05\n",
      ">p=0.2: 4, Score=6.95828566676937e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 17ms/step - loss: 0.0026 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.6752e-04 - val_loss: 0.0063\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.7166e-04 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.2691e-04 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.4154e-04 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.8840e-04 - val_loss: 8.2456e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.1883e-04 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.4690e-04 - val_loss: 0.0015\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.4852e-04 - val_loss: 2.6376e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.2221e-04 - val_loss: 2.1724e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.5783e-04 - val_loss: 4.3739e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2294e-04 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3757e-04 - val_loss: 4.2503e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.3301e-04 - val_loss: 1.1053e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0266e-05 - val_loss: 8.1403e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2094e-04 - val_loss: 3.6099e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.6880e-05 - val_loss: 1.2975e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.3817e-05 - val_loss: 1.6967e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.5220e-05 - val_loss: 1.5176e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2223e-04 - val_loss: 1.3245e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.5807e-05 - val_loss: 2.2211e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.0799e-05 - val_loss: 6.4965e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1223e-04 - val_loss: 9.7953e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2180e-04 - val_loss: 4.5221e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1507e-04 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.6964e-05 - val_loss: 6.1468e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2329e-04 - val_loss: 7.0354e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.4143e-04 - val_loss: 3.8171e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0472e-04 - val_loss: 8.9207e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.4563e-05 - val_loss: 1.4589e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.7388e-05 - val_loss: 2.2355e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.6181e-05 - val_loss: 8.6302e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.1951e-05 - val_loss: 5.1106e-05\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.5232e-05 - val_loss: 5.4585e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0719e-05 - val_loss: 5.8951e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.2927e-05 - val_loss: 1.2444e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.4026e-05 - val_loss: 1.7949e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.0584e-05 - val_loss: 5.9389e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.8716e-05 - val_loss: 6.6038e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.9640e-05 - val_loss: 5.7042e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.1642e-05 - val_loss: 2.8451e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.7442e-05 - val_loss: 2.4322e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0674e-04 - val_loss: 4.5208e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.1265e-05 - val_loss: 3.1736e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.8706e-05 - val_loss: 3.3026e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.4432e-05 - val_loss: 6.5733e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.0477e-05 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3407e-04 - val_loss: 0.0011\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.4072e-05 - val_loss: 1.4638e-04\n",
      ">p=0.2: 5, Score=0.0001559116062708199\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 18ms/step - loss: 0.0025 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.7038e-04 - val_loss: 0.0062\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.8821e-04 - val_loss: 0.0037\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.4814e-04 - val_loss: 0.0022\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.6010e-04 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.4101e-04 - val_loss: 4.4014e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.9311e-04 - val_loss: 3.8675e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.0062e-04 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.1217e-04 - val_loss: 2.4532e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.5350e-04 - val_loss: 3.0008e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.5988e-04 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1195e-04 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1730e-04 - val_loss: 1.3502e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0466e-04 - val_loss: 8.7992e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3514e-04 - val_loss: 3.1698e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.0084e-05 - val_loss: 9.1489e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3500e-04 - val_loss: 6.2549e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.4217e-04 - val_loss: 1.9816e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.5480e-05 - val_loss: 5.0993e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.6171e-05 - val_loss: 1.5085e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.8818e-05 - val_loss: 3.3188e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.4914e-05 - val_loss: 7.0494e-05\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.1004e-05 - val_loss: 1.6039e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.9307e-05 - val_loss: 2.7094e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.9015e-05 - val_loss: 4.5321e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.6238e-04 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5388e-04 - val_loss: 5.0530e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.7979e-05 - val_loss: 5.9885e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.0357e-05 - val_loss: 1.8214e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.2340e-05 - val_loss: 1.5406e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.7182e-05 - val_loss: 1.1494e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.0500e-05 - val_loss: 3.7789e-05\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.1277e-05 - val_loss: 1.8330e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.3549e-05 - val_loss: 1.5245e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.5110e-05 - val_loss: 2.2631e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.2563e-05 - val_loss: 2.1505e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.0952e-05 - val_loss: 5.9624e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.4938e-05 - val_loss: 3.0542e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.3233e-05 - val_loss: 3.1174e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.3515e-04 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.1426e-05 - val_loss: 1.8358e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.1122e-05 - val_loss: 8.0126e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.4482e-05 - val_loss: 1.2568e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.9095e-05 - val_loss: 3.4363e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.3155e-05 - val_loss: 1.9339e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.1904e-05 - val_loss: 1.9958e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.5389e-05 - val_loss: 5.8815e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.8436e-05 - val_loss: 2.0489e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.8508e-05 - val_loss: 2.9760e-05\n",
      ">p=0.2: 6, Score=3.911520616384223e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 20ms/step - loss: 0.0024 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0090\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.7079e-04 - val_loss: 0.0067\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.8855e-04 - val_loss: 0.0042\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.4472e-04 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.3934e-04 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.0883e-04 - val_loss: 5.5767e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.9065e-04 - val_loss: 6.7908e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.8106e-04 - val_loss: 0.0027\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.0785e-04 - val_loss: 3.9207e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.6003e-04 - val_loss: 0.0027\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.3766e-04 - val_loss: 0.0027\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.0432e-04 - val_loss: 1.3485e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.3427e-05 - val_loss: 5.1640e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.3454e-05 - val_loss: 2.6168e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.0500e-05 - val_loss: 5.0908e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.6312e-05 - val_loss: 1.8595e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.2502e-05 - val_loss: 2.8559e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.7962e-05 - val_loss: 2.0131e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.3217e-05 - val_loss: 8.9922e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.4643e-05 - val_loss: 1.3112e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.6743e-05 - val_loss: 0.0021\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.1340e-05 - val_loss: 2.0185e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.6633e-05 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.9806e-05 - val_loss: 1.1277e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.8096e-04 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.5591e-04 - val_loss: 8.7373e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1609e-04 - val_loss: 7.1632e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0285e-04 - val_loss: 1.3198e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.5932e-05 - val_loss: 4.4506e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.6748e-05 - val_loss: 4.7732e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.3255e-05 - val_loss: 3.1253e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.5712e-05 - val_loss: 9.5135e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.1833e-05 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.0449e-05 - val_loss: 1.1732e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.2092e-05 - val_loss: 5.9239e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2410e-05 - val_loss: 5.9398e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.6241e-05 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.7767e-05 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.2772e-05 - val_loss: 1.4144e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3.0512e-05 - val_loss: 2.6543e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.8772e-05 - val_loss: 2.1853e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.6089e-05 - val_loss: 3.6911e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.3393e-05 - val_loss: 2.0130e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.6367e-05 - val_loss: 4.4419e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 5.1118e-05 - val_loss: 2.4703e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.4404e-05 - val_loss: 8.6349e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.5017e-05 - val_loss: 2.0667e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.8385e-05 - val_loss: 5.3837e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.5129e-05 - val_loss: 2.4921e-05\n",
      ">p=0.2: 7, Score=5.8048088249051943e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 18ms/step - loss: 0.0024 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.5061e-04 - val_loss: 0.0059\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.4514e-04 - val_loss: 0.0035\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.3135e-04 - val_loss: 0.0020\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 2.7788e-04 - val_loss: 8.2909e-04\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0743e-04 - val_loss: 9.3866e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.8463e-04 - val_loss: 1.9515e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.3372e-04 - val_loss: 2.8873e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.1466e-04 - val_loss: 3.2991e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.5112e-04 - val_loss: 2.6913e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.0025e-04 - val_loss: 2.4291e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.2300e-04 - val_loss: 0.0019\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 2.0142e-04 - val_loss: 4.6762e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.5249e-04 - val_loss: 5.4391e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2456e-04 - val_loss: 8.1470e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2074e-04 - val_loss: 3.2682e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2973e-04 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.3635e-05 - val_loss: 3.8961e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.1835e-05 - val_loss: 2.1422e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 9.6710e-05 - val_loss: 1.5065e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0906e-04 - val_loss: 1.8018e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.9455e-05 - val_loss: 1.6349e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0705e-05 - val_loss: 2.0599e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.8653e-05 - val_loss: 1.0981e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0798e-05 - val_loss: 2.8789e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2134e-04 - val_loss: 5.7752e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.2282e-05 - val_loss: 6.8647e-05\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.8532e-05 - val_loss: 2.1968e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.1264e-05 - val_loss: 7.9315e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.6395e-05 - val_loss: 4.7489e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.1961e-05 - val_loss: 1.4298e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.7628e-05 - val_loss: 8.2246e-05\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2022e-04 - val_loss: 0.0017\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.3764e-04 - val_loss: 1.9392e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4.0749e-05 - val_loss: 5.5786e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.8317e-05 - val_loss: 3.2542e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.7563e-05 - val_loss: 3.8845e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.2555e-05 - val_loss: 2.7878e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.4594e-05 - val_loss: 1.8630e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.1639e-05 - val_loss: 1.7740e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.3166e-05 - val_loss: 1.5535e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 6.5357e-05 - val_loss: 7.6539e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.1846e-05 - val_loss: 1.8563e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.9239e-05 - val_loss: 2.5842e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.8621e-05 - val_loss: 6.6323e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.7018e-05 - val_loss: 8.6810e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.7221e-05 - val_loss: 4.1551e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.9001e-05 - val_loss: 1.9386e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.4868e-05 - val_loss: 5.5466e-05\n",
      ">p=0.2: 8, Score=4.8921625420916826e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 18ms/step - loss: 0.0024 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 9.0905e-04 - val_loss: 0.0065\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.3630e-04 - val_loss: 0.0044\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.8277e-04 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.9812e-04 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.8853e-04 - val_loss: 5.9594e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.5333e-04 - val_loss: 3.9498e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.6090e-04 - val_loss: 6.7733e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1584e-04 - val_loss: 0.0022\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0853e-04 - val_loss: 2.1247e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.3998e-05 - val_loss: 1.5632e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.0039e-04 - val_loss: 9.6963e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2549e-04 - val_loss: 1.8773e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.5707e-05 - val_loss: 8.4686e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1365e-04 - val_loss: 3.3747e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.3977e-05 - val_loss: 2.5123e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.6349e-05 - val_loss: 2.3487e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.5405e-05 - val_loss: 1.7450e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.5303e-05 - val_loss: 1.9997e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.5270e-05 - val_loss: 1.4938e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.1348e-04 - val_loss: 8.1540e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0385e-04 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.8931e-05 - val_loss: 8.9310e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.4564e-05 - val_loss: 0.0017\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.3046e-05 - val_loss: 2.7261e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 7.4433e-05 - val_loss: 1.0299e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.4826e-05 - val_loss: 4.8570e-05\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.6106e-05 - val_loss: 1.6985e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 6.5903e-05 - val_loss: 6.1786e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.0781e-05 - val_loss: 1.3016e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.4309e-05 - val_loss: 5.9083e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.9645e-05 - val_loss: 3.0866e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.7563e-05 - val_loss: 1.6072e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 7.8389e-05 - val_loss: 4.4838e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.7528e-05 - val_loss: 1.0362e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 4.9305e-05 - val_loss: 1.8639e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 3.5631e-05 - val_loss: 1.0688e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.5402e-05 - val_loss: 1.4459e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.2802e-05 - val_loss: 1.6507e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.3894e-05 - val_loss: 4.5296e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.6791e-05 - val_loss: 4.4546e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.5723e-05 - val_loss: 1.6593e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.7569e-05 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.9276e-05 - val_loss: 5.5418e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.1228e-05 - val_loss: 2.7884e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.9447e-05 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.9725e-05 - val_loss: 3.8558e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.8639e-05 - val_loss: 6.9007e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.0935e-05 - val_loss: 4.9384e-05\n",
      ">p=0.2: 9, Score=4.5777975174132735e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 18ms/step - loss: 0.0024 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.7940e-04 - val_loss: 0.0073\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.0346e-04 - val_loss: 0.0052\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.7078e-04 - val_loss: 0.0033\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.8133e-04 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.4635e-04 - val_loss: 0.0020\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.3567e-04 - val_loss: 6.5393e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5020e-04 - val_loss: 4.6930e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1140e-04 - val_loss: 7.1558e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1038e-04 - val_loss: 2.4564e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.6750e-04 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2831e-04 - val_loss: 0.0016\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.8355e-04 - val_loss: 7.1243e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.2120e-04 - val_loss: 3.4100e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.8084e-04 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0265e-04 - val_loss: 5.6905e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.0998e-04 - val_loss: 1.2996e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.6195e-05 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.4327e-05 - val_loss: 9.3405e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3616e-04 - val_loss: 3.4222e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.3573e-05 - val_loss: 4.8198e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.5247e-05 - val_loss: 1.4622e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.0292e-04 - val_loss: 0.0018\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.5842e-04 - val_loss: 3.2206e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.0146e-05 - val_loss: 8.7213e-05\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.7123e-05 - val_loss: 1.2281e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1268e-04 - val_loss: 5.4118e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.9010e-05 - val_loss: 7.0213e-05\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 8.4065e-05 - val_loss: 0.0016\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.8234e-05 - val_loss: 7.7751e-05\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 6.7853e-05 - val_loss: 9.3999e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 5.3355e-05 - val_loss: 7.9571e-05\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.1248e-05 - val_loss: 3.6265e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.1068e-05 - val_loss: 2.2318e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 6.9300e-05 - val_loss: 9.8515e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 1.0688e-04 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.3974e-04 - val_loss: 8.1131e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.8371e-05 - val_loss: 9.4553e-05\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.6547e-05 - val_loss: 1.1070e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4.6038e-05 - val_loss: 4.9318e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.6657e-05 - val_loss: 6.3804e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.5327e-05 - val_loss: 2.7838e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.7570e-05 - val_loss: 4.9954e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.7164e-04 - val_loss: 0.0028\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.7693e-04 - val_loss: 3.4292e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.5405e-05 - val_loss: 7.7374e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 3.8175e-05 - val_loss: 6.9142e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 5.2986e-05 - val_loss: 1.9495e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 6.5343e-05 - val_loss: 0.0016\n",
      ">p=0.2: 10, Score=0.0010194701608270407\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 11s 25ms/step - loss: 0.0024 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0079\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.6265e-04 - val_loss: 0.0054\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.1324e-04 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.9844e-04 - val_loss: 0.0020\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.7620e-04 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.4725e-04 - val_loss: 4.1691e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.0548e-04 - val_loss: 9.3680e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.1042e-04 - val_loss: 4.4077e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5647e-04 - val_loss: 3.0030e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.7108e-04 - val_loss: 2.4935e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1899e-04 - val_loss: 1.6903e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.7585e-04 - val_loss: 0.0027\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5138e-04 - val_loss: 1.7042e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5132e-04 - val_loss: 1.9539e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1947e-04 - val_loss: 2.1745e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1157e-04 - val_loss: 1.1704e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0445e-04 - val_loss: 4.6510e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1523e-04 - val_loss: 5.4782e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2400e-04 - val_loss: 8.3611e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.6705e-05 - val_loss: 4.6444e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0316e-04 - val_loss: 2.9495e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2697e-04 - val_loss: 4.5695e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1409e-04 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2725e-04 - val_loss: 1.5416e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.5827e-05 - val_loss: 2.7836e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.1083e-05 - val_loss: 5.1037e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3786e-04 - val_loss: 8.8224e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.9091e-05 - val_loss: 1.7111e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.8716e-05 - val_loss: 1.1174e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.7014e-04 - val_loss: 9.4184e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.4146e-04 - val_loss: 4.7400e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.7476e-04 - val_loss: 8.5952e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 9.8771e-05 - val_loss: 3.8917e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.2936e-05 - val_loss: 1.7864e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.7275e-05 - val_loss: 2.0667e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.7369e-05 - val_loss: 3.7523e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0656e-04 - val_loss: 5.3723e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3790e-04 - val_loss: 8.0598e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.1109e-05 - val_loss: 1.3560e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.6178e-05 - val_loss: 1.3087e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.5371e-05 - val_loss: 8.2427e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.8906e-05 - val_loss: 4.7156e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.8439e-05 - val_loss: 4.8010e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.2088e-05 - val_loss: 3.3826e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.0004e-05 - val_loss: 4.7374e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.7860e-05 - val_loss: 7.2177e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.6149e-05 - val_loss: 6.8964e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.2811e-05 - val_loss: 5.7321e-05\n",
      ">p=0.3: 1, Score=0.00010452657443238422\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 10s 21ms/step - loss: 0.0024 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.3967e-04 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.0044e-04 - val_loss: 0.0051\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.7021e-04 - val_loss: 0.0032\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.3016e-04 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.5934e-04 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.6479e-04 - val_loss: 5.2600e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.9973e-04 - val_loss: 4.3785e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.1766e-04 - val_loss: 0.0019\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.8086e-04 - val_loss: 5.3078e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.7712e-04 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3854e-04 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1800e-04 - val_loss: 7.1852e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3871e-04 - val_loss: 1.3589e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.1183e-04 - val_loss: 8.3088e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3547e-04 - val_loss: 0.0012\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.2140e-05 - val_loss: 0.0021\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.3714e-04 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.8957e-04 - val_loss: 7.8261e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1969e-04 - val_loss: 4.2919e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.8613e-05 - val_loss: 2.0724e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0104e-04 - val_loss: 3.1666e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.4323e-05 - val_loss: 5.6930e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.0020e-04 - val_loss: 2.0026e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.6566e-05 - val_loss: 2.1166e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.9205e-05 - val_loss: 8.2885e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5002e-04 - val_loss: 3.0422e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.2235e-05 - val_loss: 3.3345e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.4241e-04 - val_loss: 2.8518e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.9048e-05 - val_loss: 1.7618e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.9352e-05 - val_loss: 4.6281e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0900e-04 - val_loss: 2.6834e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.0529e-05 - val_loss: 6.4732e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.4596e-05 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.4049e-05 - val_loss: 6.0645e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.7809e-05 - val_loss: 1.5131e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.5619e-05 - val_loss: 1.1284e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1628e-04 - val_loss: 5.7743e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0022e-04 - val_loss: 2.3379e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.5503e-05 - val_loss: 5.8759e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4039e-04 - val_loss: 3.0483e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.9309e-05 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.5200e-04 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0069e-04 - val_loss: 5.6358e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.8104e-05 - val_loss: 1.0772e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.0494e-05 - val_loss: 2.9586e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.9435e-05 - val_loss: 1.4107e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.7234e-05 - val_loss: 7.8063e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.0242e-05 - val_loss: 4.7349e-04\n",
      ">p=0.3: 2, Score=0.00034877535654231906\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 10s 22ms/step - loss: 0.0025 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 0.0099\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0082\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.0611e-04 - val_loss: 0.0060\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.2884e-04 - val_loss: 0.0039\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.5974e-04 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.5518e-04 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.1303e-04 - val_loss: 7.4220e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.8253e-04 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.9412e-04 - val_loss: 8.4335e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.6072e-04 - val_loss: 2.3312e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.1876e-04 - val_loss: 2.0601e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3655e-04 - val_loss: 1.7070e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.9664e-05 - val_loss: 6.5962e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0447e-04 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.3008e-04 - val_loss: 2.3081e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.1824e-04 - val_loss: 1.3361e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1560e-04 - val_loss: 1.3632e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2504e-04 - val_loss: 5.4914e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.4461e-05 - val_loss: 4.6277e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2608e-04 - val_loss: 2.3518e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1898e-04 - val_loss: 3.6345e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.3420e-05 - val_loss: 2.4019e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.1300e-04 - val_loss: 5.6943e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.7705e-05 - val_loss: 4.9142e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.6409e-05 - val_loss: 7.5018e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.4091e-05 - val_loss: 9.8843e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1795e-04 - val_loss: 1.3561e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.0881e-05 - val_loss: 5.4570e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.8164e-05 - val_loss: 9.9838e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.2044e-04 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1087e-04 - val_loss: 6.9713e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.7554e-05 - val_loss: 1.7139e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.8204e-05 - val_loss: 1.7560e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.4267e-05 - val_loss: 3.9551e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.0262e-05 - val_loss: 3.4049e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.1093e-05 - val_loss: 2.8327e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.1300e-05 - val_loss: 9.6132e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.6772e-05 - val_loss: 0.0012\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.8798e-05 - val_loss: 2.1075e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.6485e-05 - val_loss: 6.8048e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.3860e-05 - val_loss: 3.6199e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0436e-04 - val_loss: 0.0014\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.2564e-05 - val_loss: 1.1111e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.7585e-05 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5770e-04 - val_loss: 7.2706e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.7693e-05 - val_loss: 1.8457e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.0510e-04 - val_loss: 7.6839e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.6954e-05 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.9152e-05 - val_loss: 0.0019\n",
      ">p=0.3: 3, Score=0.0008903805864974856\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 20ms/step - loss: 0.0026 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.6974e-04 - val_loss: 0.0071\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.4992e-04 - val_loss: 0.0048\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.4517e-04 - val_loss: 0.0030\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 4.0856e-04 - val_loss: 0.0018\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.2623e-04 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0249e-04 - val_loss: 5.8645e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.0285e-04 - val_loss: 6.4514e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.7752e-04 - val_loss: 2.0580e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6593e-04 - val_loss: 4.9661e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2976e-04 - val_loss: 8.4995e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3860e-04 - val_loss: 2.3268e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5581e-04 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3939e-04 - val_loss: 5.0752e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.4898e-04 - val_loss: 2.1426e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.8355e-05 - val_loss: 3.1110e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.7672e-05 - val_loss: 7.7123e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.8764e-05 - val_loss: 9.5589e-05\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.4443e-05 - val_loss: 2.4619e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.6380e-05 - val_loss: 6.2340e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.9822e-05 - val_loss: 2.2958e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.0660e-05 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.7586e-04 - val_loss: 7.0494e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2860e-04 - val_loss: 8.8471e-05\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.7317e-05 - val_loss: 1.3121e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.2183e-05 - val_loss: 5.1825e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.0075e-05 - val_loss: 1.3581e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.9673e-05 - val_loss: 1.1738e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.6577e-05 - val_loss: 6.5849e-05\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3578e-04 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1247e-04 - val_loss: 5.0700e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.0727e-05 - val_loss: 0.0016\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0204e-04 - val_loss: 4.2536e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.6297e-05 - val_loss: 4.2483e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.9936e-05 - val_loss: 1.4308e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.3793e-05 - val_loss: 6.7033e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.2156e-05 - val_loss: 0.0015\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.3025e-05 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.7542e-05 - val_loss: 9.5642e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.2695e-05 - val_loss: 8.0075e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.6511e-05 - val_loss: 8.0639e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.6715e-05 - val_loss: 4.2456e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.8029e-04 - val_loss: 0.0017\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.5450e-04 - val_loss: 1.1869e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.6544e-05 - val_loss: 3.5758e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 5.0120e-05 - val_loss: 5.2012e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.0610e-05 - val_loss: 4.1078e-05\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.1276e-05 - val_loss: 1.0160e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.1869e-05 - val_loss: 6.6449e-05\n",
      ">p=0.3: 4, Score=0.00010206607112195343\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 10s 21ms/step - loss: 0.0026 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0074\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.7735e-04 - val_loss: 0.0052\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.8333e-04 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.0477e-04 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.2579e-04 - val_loss: 0.0011\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.8289e-04 - val_loss: 4.5220e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.9446e-04 - val_loss: 0.0016\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.9086e-04 - val_loss: 4.8710e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.3972e-04 - val_loss: 5.7078e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6645e-04 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3402e-04 - val_loss: 1.3986e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0317e-04 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3328e-04 - val_loss: 0.0010\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0127e-04 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.9498e-04 - val_loss: 9.6017e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.9510e-04 - val_loss: 5.3966e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1870e-04 - val_loss: 2.1370e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2674e-04 - val_loss: 1.1046e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.6921e-05 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.7599e-05 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.6045e-05 - val_loss: 1.1311e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.3026e-05 - val_loss: 3.3387e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.0557e-05 - val_loss: 4.6037e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0804e-04 - val_loss: 9.8451e-05\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3960e-04 - val_loss: 8.2388e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2007e-04 - val_loss: 3.8697e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3132e-04 - val_loss: 1.7010e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.0608e-05 - val_loss: 3.4693e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.6101e-05 - val_loss: 1.2956e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.5938e-05 - val_loss: 1.2684e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.0027e-05 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.9473e-04 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.5852e-04 - val_loss: 9.6334e-05\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.8161e-05 - val_loss: 1.6718e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.5534e-05 - val_loss: 1.1137e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.8440e-05 - val_loss: 1.3664e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.5071e-05 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.4666e-04 - val_loss: 6.4543e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 1.0318e-04 - val_loss: 2.3147e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.1347e-04 - val_loss: 7.0764e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.7267e-04 - val_loss: 7.9720e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 7.5016e-05 - val_loss: 7.2158e-05\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 6.2384e-05 - val_loss: 8.7753e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.2670e-05 - val_loss: 2.9786e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 3.9174e-05 - val_loss: 4.2114e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.7521e-05 - val_loss: 4.9652e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.1877e-04 - val_loss: 8.7967e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 8.7339e-05 - val_loss: 5.9996e-04\n",
      ">p=0.3: 5, Score=0.0003264884580858052\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 10s 21ms/step - loss: 0.0026 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0099\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0076\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.7634e-04 - val_loss: 0.0052\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.1856e-04 - val_loss: 0.0032\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.0756e-04 - val_loss: 0.0020\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.9464e-04 - val_loss: 9.5330e-04\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.5214e-04 - val_loss: 4.0315e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.9492e-04 - val_loss: 2.4951e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5555e-04 - val_loss: 4.4377e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5992e-04 - val_loss: 1.8272e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4099e-04 - val_loss: 0.0022\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.5234e-04 - val_loss: 0.0022\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.8686e-04 - val_loss: 3.0611e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.5982e-04 - val_loss: 3.2522e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.5212e-04 - val_loss: 4.9740e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.4654e-04 - val_loss: 2.0261e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2387e-04 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3031e-04 - val_loss: 1.6818e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.3608e-05 - val_loss: 2.1698e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.6431e-05 - val_loss: 5.4683e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.0994e-05 - val_loss: 3.8287e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.7930e-04 - val_loss: 9.4441e-05\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.4924e-05 - val_loss: 2.6054e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 8.0826e-05 - val_loss: 1.2667e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 6.2631e-05 - val_loss: 3.4956e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 8.7994e-05 - val_loss: 0.0017\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.3503e-05 - val_loss: 4.8733e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.9368e-05 - val_loss: 1.0590e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.5995e-05 - val_loss: 1.4679e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.9602e-05 - val_loss: 2.7945e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.0038e-05 - val_loss: 1.7385e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.7100e-04 - val_loss: 0.0023\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 1.5472e-04 - val_loss: 2.0566e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.0026e-05 - val_loss: 9.7152e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.7870e-05 - val_loss: 7.3562e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.7331e-05 - val_loss: 1.2469e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.1273e-05 - val_loss: 4.9634e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.8479e-05 - val_loss: 4.2380e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.9574e-05 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.2126e-05 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.9844e-05 - val_loss: 8.5725e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.1556e-05 - val_loss: 7.0128e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.0153e-05 - val_loss: 2.0696e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.5818e-05 - val_loss: 4.7589e-05\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.5107e-05 - val_loss: 4.3934e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.8751e-05 - val_loss: 7.6766e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.3965e-05 - val_loss: 2.4200e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.2637e-05 - val_loss: 1.0998e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.2945e-05 - val_loss: 2.2751e-04\n",
      ">p=0.3: 6, Score=0.00023642179439775646\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 22ms/step - loss: 0.0025 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0089\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.5029e-04 - val_loss: 0.0064\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.9355e-04 - val_loss: 0.0043\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.8067e-04 - val_loss: 0.0030\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.9338e-04 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.7938e-04 - val_loss: 0.0017\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.6520e-04 - val_loss: 8.2643e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.1411e-04 - val_loss: 5.1194e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.8613e-04 - val_loss: 3.3580e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.2509e-04 - val_loss: 7.1992e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.6044e-04 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.0150e-04 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.8721e-04 - val_loss: 2.6874e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.4805e-04 - val_loss: 7.2682e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 9.7063e-05 - val_loss: 1.9791e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 9.1631e-05 - val_loss: 1.9593e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3190e-04 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0399e-04 - val_loss: 1.4548e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.5708e-04 - val_loss: 2.2627e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4877e-04 - val_loss: 5.1282e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.2967e-05 - val_loss: 1.7184e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.7948e-05 - val_loss: 1.1441e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.5961e-05 - val_loss: 3.8082e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.0459e-05 - val_loss: 0.0018\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 9.7038e-05 - val_loss: 6.0156e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.2431e-05 - val_loss: 0.0017\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.1366e-05 - val_loss: 7.4707e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 5.6735e-05 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.9555e-05 - val_loss: 7.2313e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 8.4258e-05 - val_loss: 1.3629e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.7864e-04 - val_loss: 0.0022\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.8070e-04 - val_loss: 3.5786e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.4215e-05 - val_loss: 1.0227e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.4427e-05 - val_loss: 8.0225e-05\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 7.5709e-05 - val_loss: 3.3443e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 6.5890e-05 - val_loss: 4.8306e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 1.1393e-04 - val_loss: 6.9807e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 1.6329e-04 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 6.8717e-05 - val_loss: 5.1071e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 1.3929e-04 - val_loss: 9.5259e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.0087e-04 - val_loss: 5.7750e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.8690e-05 - val_loss: 2.0362e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.6322e-05 - val_loss: 1.2043e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 5.1473e-05 - val_loss: 4.8848e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 6.8084e-05 - val_loss: 8.7800e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 4.4957e-05 - val_loss: 1.3409e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.2876e-05 - val_loss: 7.6419e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.1771e-05 - val_loss: 5.6224e-05\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.3270e-04 - val_loss: 0.0013\n",
      ">p=0.3: 7, Score=0.0008139059063978493\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 21ms/step - loss: 0.0024 - val_loss: 0.0114\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.0012 - val_loss: 0.0082\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 9.4805e-04 - val_loss: 0.0059\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 7.3423e-04 - val_loss: 0.0039\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.6227e-04 - val_loss: 0.0023\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 3.8318e-04 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.3793e-04 - val_loss: 7.0696e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 2.3524e-04 - val_loss: 6.1200e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.8934e-04 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.7757e-04 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.7992e-04 - val_loss: 3.2023e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2504e-04 - val_loss: 6.2963e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4042e-04 - val_loss: 4.1291e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3825e-04 - val_loss: 0.0031\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.9572e-04 - val_loss: 2.9769e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.0251e-04 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.1848e-04 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1324e-04 - val_loss: 1.8020e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.1694e-05 - val_loss: 2.6117e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1148e-04 - val_loss: 4.5284e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.4814e-05 - val_loss: 9.1724e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2821e-04 - val_loss: 6.1395e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.3021e-04 - val_loss: 1.4847e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.8857e-05 - val_loss: 5.2160e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.5506e-04 - val_loss: 3.3712e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.6264e-05 - val_loss: 5.6983e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.9846e-05 - val_loss: 2.2282e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6224e-04 - val_loss: 1.9296e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0007e-04 - val_loss: 3.3308e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5919e-04 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.5713e-04 - val_loss: 5.7840e-05\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.1397e-05 - val_loss: 4.1381e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4847e-04 - val_loss: 0.0010\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.5645e-05 - val_loss: 1.3367e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.3428e-05 - val_loss: 8.5587e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 6.8881e-05 - val_loss: 6.1252e-05\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.0688e-05 - val_loss: 9.9387e-05\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.8473e-05 - val_loss: 5.8086e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0848e-04 - val_loss: 5.7340e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.0717e-05 - val_loss: 1.6613e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.1234e-05 - val_loss: 1.1267e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.0543e-05 - val_loss: 3.2976e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.5990e-04 - val_loss: 0.0014\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.8553e-04 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2436e-04 - val_loss: 8.8506e-05\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.3242e-05 - val_loss: 7.4560e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.5776e-05 - val_loss: 1.0813e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.8404e-05 - val_loss: 6.6628e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.4148e-05 - val_loss: 0.0014\n",
      ">p=0.3: 8, Score=0.0007743084570392966\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 8s 21ms/step - loss: 0.0025 - val_loss: 0.0114\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0095\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0011 - val_loss: 0.0075\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.7795e-04 - val_loss: 0.0055\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.4006e-04 - val_loss: 0.0038\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.9738e-04 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.5465e-04 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.6878e-04 - val_loss: 7.5526e-04\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.0933e-04 - val_loss: 3.8739e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6045e-04 - val_loss: 3.1236e-04\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2207e-04 - val_loss: 4.8389e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.1730e-04 - val_loss: 8.2081e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2737e-04 - val_loss: 4.2066e-04\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.0770e-04 - val_loss: 6.0224e-04\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.6482e-04 - val_loss: 5.9900e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.3044e-04 - val_loss: 6.9622e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.0693e-04 - val_loss: 1.0664e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.3908e-04 - val_loss: 0.0016\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1884e-04 - val_loss: 3.2240e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.9619e-04 - val_loss: 7.6014e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.8117e-04 - val_loss: 0.0019\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.0589e-05 - val_loss: 1.2136e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.0347e-05 - val_loss: 9.2807e-05\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.8020e-05 - val_loss: 1.1836e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.7728e-05 - val_loss: 1.1638e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.6416e-04 - val_loss: 0.0023\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.5732e-05 - val_loss: 2.4043e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.8456e-04 - val_loss: 0.0023\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4836e-04 - val_loss: 1.0139e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.7688e-04 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6205e-04 - val_loss: 9.0639e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2167e-04 - val_loss: 4.7453e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0849e-04 - val_loss: 0.0023\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 8.3719e-05 - val_loss: 3.4162e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.5841e-04 - val_loss: 9.3780e-04\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.8644e-05 - val_loss: 9.1271e-05\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.3191e-05 - val_loss: 2.5029e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.0854e-05 - val_loss: 2.5939e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 9.4616e-05 - val_loss: 6.0889e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.6390e-05 - val_loss: 4.4963e-04\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.9614e-05 - val_loss: 8.0820e-05\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.5271e-05 - val_loss: 2.8613e-04\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.2310e-04 - val_loss: 8.6968e-04\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.4784e-05 - val_loss: 5.3352e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.2984e-05 - val_loss: 3.0618e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.0348e-04 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0189e-04 - val_loss: 6.4994e-05\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.0576e-05 - val_loss: 2.1093e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.0232e-05 - val_loss: 2.0990e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.1998e-05 - val_loss: 2.5409e-05\n",
      ">p=0.3: 9, Score=7.809725502738729e-05\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 9s 20ms/step - loss: 0.0025 - val_loss: 0.0114\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0080\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 8.2634e-04 - val_loss: 0.0057\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 6.7824e-04 - val_loss: 0.0037\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.6743e-04 - val_loss: 0.0023\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 3.4288e-04 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.8422e-04 - val_loss: 0.0017\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 2.4872e-04 - val_loss: 4.7706e-04\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0039e-04 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.8666e-04 - val_loss: 3.5479e-04\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.7789e-04 - val_loss: 3.1068e-04\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 2.4709e-04 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 1.6106e-04 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1545e-04 - val_loss: 2.0694e-04\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1798e-04 - val_loss: 2.0163e-04\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.9685e-04 - val_loss: 4.0786e-04\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.4660e-04 - val_loss: 6.6825e-04\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.4556e-05 - val_loss: 9.9067e-04\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.0105e-04 - val_loss: 4.8492e-04\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.6131e-04 - val_loss: 2.2225e-04\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 1.8853e-04 - val_loss: 3.6482e-04\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.5504e-04 - val_loss: 2.0190e-04\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.2450e-05 - val_loss: 4.0542e-04\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 1.1077e-04 - val_loss: 2.3966e-04\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.5213e-05 - val_loss: 1.9675e-04\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.8956e-05 - val_loss: 1.6514e-04\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.9833e-05 - val_loss: 7.1140e-04\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.6528e-05 - val_loss: 8.2856e-04\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 4.0707e-05 - val_loss: 9.1728e-04\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.4244e-05 - val_loss: 5.5847e-04\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.1295e-05 - val_loss: 1.2108e-04\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 5.0864e-05 - val_loss: 1.0349e-04\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2411e-04 - val_loss: 4.8890e-04\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.1359e-04 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.3619e-04 - val_loss: 3.5894e-04\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.1611e-05 - val_loss: 2.0844e-04\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 7.1880e-05 - val_loss: 1.4157e-04\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.4293e-05 - val_loss: 1.5926e-04\n",
      "Epoch 40/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.1484e-05 - val_loss: 7.1357e-05\n",
      "Epoch 41/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 8.0232e-05 - val_loss: 7.4248e-04\n",
      "Epoch 42/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.5721e-05 - val_loss: 6.4154e-05\n",
      "Epoch 43/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 3.0061e-05 - val_loss: 7.0130e-05\n",
      "Epoch 44/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 5.9208e-05 - val_loss: 1.8236e-04\n",
      "Epoch 45/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 5.3533e-05 - val_loss: 3.8022e-04\n",
      "Epoch 46/50\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 4.4661e-05 - val_loss: 1.7441e-04\n",
      "Epoch 47/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 4.5239e-05 - val_loss: 3.1697e-04\n",
      "Epoch 48/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.6554e-05 - val_loss: 8.0862e-04\n",
      "Epoch 49/50\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 1.2161e-04 - val_loss: 8.9427e-04\n",
      "Epoch 50/50\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.0095e-05 - val_loss: 4.9092e-05\n",
      ">p=0.3: 10, Score=0.00010871886479435489\n",
      "[[3.345781806274317e-05, 3.666978227556683e-05, 9.073798719327897e-05, 0.00021751994790975004, 5.051307016401552e-05, 0.0006604550289921463, 0.00019439544121269137, 0.00010299507266608998, 0.00033517004339955747, 6.295963248703629e-05], [0.00040300344699062407, 5.637644790112972e-05, 0.00019597022037487477, 0.00024515215773135424, 0.0001307122001890093, 5.870149834663607e-05, 4.996023199055344e-05, 0.00012444851745385677, 0.00015619644545949996, 0.00011331335554132238], [3.4859323932323605e-05, 0.00027346829301677644, 8.064370194915682e-05, 6.95828566676937e-05, 0.0001559116062708199, 3.911520616384223e-05, 5.8048088249051943e-05, 4.8921625420916826e-05, 4.5777975174132735e-05, 0.0010194701608270407], [0.00010452657443238422, 0.00034877535654231906, 0.0008903805864974856, 0.00010206607112195343, 0.0003264884580858052, 0.00023642179439775646, 0.0008139059063978493, 0.0007743084570392966, 7.809725502738729e-05, 0.00010871886479435489]] [0.05, 0.1, 0.2, 0.3]\n",
      "Param=0.05, Mean=0.000:, Std=0.000\n",
      "Param=0.1, Mean=0.000:, Std=0.000\n",
      "Param=0.2, Mean=0.000:, Std=0.000\n",
      "Param=0.3, Mean=0.000:, Std=0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, dropout):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = 80, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units = 80))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=5, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=5)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # resumindo a média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = mean(scores[i]), std(scores[i])\n",
    "        print(f'Param={params[i]}, Mean={m:.3f}:, Std={s:.3f}')\n",
    "    # boxplot das pontuações\n",
    "    pyplot.boxplot(scores, labels=params)\n",
    "    pyplot.savefig('figura[0].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repetindo o experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            score = score\n",
    "            scores.append(score)\n",
    "            print(f'>p={p}: {r+1}, Score={score}')\n",
    "        all_scores.append(scores)\n",
    "    # resumindo os resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = [0.05, 0.1, 0.2, 0.3]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando o modelo com os padrões mais adequados visualizados nos testes anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "68/68 [==============================] - 8s 28ms/step - loss: 0.0032 - val_loss: 0.0110\n",
      "Epoch 2/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 3/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 9.2736e-04 - val_loss: 0.0076\n",
      "Epoch 4/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.7348e-04 - val_loss: 0.0056\n",
      "Epoch 5/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.9080e-04 - val_loss: 0.0039\n",
      "Epoch 6/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.7910e-04 - val_loss: 0.0024\n",
      "Epoch 7/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 3.4696e-04 - val_loss: 0.0012\n",
      "Epoch 8/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.9836e-04 - val_loss: 4.9834e-04\n",
      "Epoch 9/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.3948e-04 - val_loss: 0.0010\n",
      "Epoch 10/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.0105e-04 - val_loss: 6.8855e-04\n",
      "Epoch 11/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 6.9671e-05 - val_loss: 1.4003e-04\n",
      "Epoch 12/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.5268e-05 - val_loss: 5.1235e-04\n",
      "Epoch 13/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 7.4709e-05 - val_loss: 3.5843e-04\n",
      "Epoch 14/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 9.2047e-05 - val_loss: 4.1905e-04\n",
      "Epoch 15/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 8.5989e-05 - val_loss: 2.4428e-04\n",
      "Epoch 16/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 6.3048e-05 - val_loss: 4.2773e-04\n",
      "Epoch 17/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.6516e-04 - val_loss: 9.6378e-04\n",
      "Epoch 18/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.6490e-04 - val_loss: 7.3665e-04\n",
      "Epoch 19/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.5653e-05 - val_loss: 4.6113e-04\n",
      "Epoch 20/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.0320e-05 - val_loss: 3.5394e-04\n",
      "Epoch 21/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.6877e-05 - val_loss: 1.7684e-04\n",
      "Epoch 22/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 6.5950e-05 - val_loss: 3.7546e-04\n",
      "Epoch 23/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.6712e-05 - val_loss: 5.3253e-04\n",
      "Epoch 24/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.7560e-05 - val_loss: 2.2131e-04\n",
      "Epoch 25/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.7019e-05 - val_loss: 4.2243e-04\n",
      "Epoch 26/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.8081e-05 - val_loss: 5.6501e-04\n",
      "Epoch 27/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.5482e-05 - val_loss: 3.6247e-04\n",
      "Epoch 28/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.6073e-05 - val_loss: 2.9690e-04\n",
      "Epoch 29/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.4381e-05 - val_loss: 6.8605e-04\n",
      "Epoch 30/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.8371e-05 - val_loss: 4.9874e-04\n",
      "Epoch 31/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.9747e-05 - val_loss: 2.6305e-04\n",
      "Epoch 32/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.4655e-05 - val_loss: 1.9509e-04\n",
      "Epoch 33/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 5.6786e-05 - val_loss: 2.9975e-04\n",
      "Epoch 34/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.6979e-05 - val_loss: 1.0910e-04\n",
      "Epoch 35/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.8988e-05 - val_loss: 4.8723e-04\n",
      "Epoch 36/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.4630e-05 - val_loss: 3.2890e-04\n",
      "Epoch 37/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.7257e-05 - val_loss: 0.0011\n",
      "Epoch 38/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 5.3656e-05 - val_loss: 2.2393e-04\n",
      "Epoch 39/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 5.4829e-05 - val_loss: 3.8061e-04\n",
      "Epoch 40/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.0006e-05 - val_loss: 3.5797e-04\n",
      "Epoch 41/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.6990e-05 - val_loss: 4.4348e-04\n",
      "Epoch 42/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 4.7375e-05 - val_loss: 2.2177e-04\n",
      "Epoch 43/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.8075e-05 - val_loss: 1.3174e-04\n",
      "Epoch 44/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 5.6867e-05 - val_loss: 1.1971e-04\n",
      "Epoch 45/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 5.4974e-05 - val_loss: 1.3021e-04\n",
      "Epoch 46/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 8.4663e-05 - val_loss: 0.0011\n",
      "Epoch 47/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.1309e-04 - val_loss: 0.0011\n",
      "Epoch 48/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 8.0082e-05 - val_loss: 2.8256e-04\n",
      "Epoch 49/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.0843e-04 - val_loss: 0.0011\n",
      "Epoch 50/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 9.8857e-05 - val_loss: 1.3267e-04\n",
      "Epoch 51/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 4.0587e-05 - val_loss: 1.1671e-04\n",
      "Epoch 52/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 5.0397e-05 - val_loss: 1.6061e-04\n",
      "Epoch 53/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 5.0893e-05 - val_loss: 7.0278e-05\n",
      "Epoch 54/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 5.3710e-05 - val_loss: 3.6169e-04\n",
      "Epoch 55/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 8.5430e-05 - val_loss: 9.3874e-05\n",
      "Epoch 56/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 8.9169e-05 - val_loss: 9.4167e-05\n",
      "Epoch 57/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 7.0862e-05 - val_loss: 1.6328e-04\n",
      "Epoch 58/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 4.9818e-05 - val_loss: 6.7977e-05\n",
      "Epoch 59/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 5.6387e-05 - val_loss: 5.2689e-04\n",
      "Epoch 60/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.8446e-05 - val_loss: 3.4995e-05\n",
      "Epoch 61/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 6.9771e-05 - val_loss: 4.4898e-04\n",
      "Epoch 62/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 6.6215e-05 - val_loss: 2.0959e-04\n",
      "Epoch 63/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 6.7348e-05 - val_loss: 2.6661e-04\n",
      "Epoch 64/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.3506e-05 - val_loss: 5.4355e-04\n",
      "Epoch 65/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.1210e-05 - val_loss: 1.2120e-04\n",
      "Epoch 66/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.2016e-05 - val_loss: 1.0146e-04\n",
      "Epoch 67/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 2.8579e-05 - val_loss: 2.8156e-04\n",
      "Epoch 68/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.6806e-05 - val_loss: 5.8706e-05\n",
      "Epoch 69/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.4859e-05 - val_loss: 1.2903e-04\n",
      "Epoch 70/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.2362e-05 - val_loss: 2.4715e-05\n",
      "Epoch 71/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.6755e-05 - val_loss: 2.7557e-04\n",
      "Epoch 72/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.8512e-05 - val_loss: 5.0128e-04\n",
      "Epoch 73/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.8733e-05 - val_loss: 3.4912e-05\n",
      "Epoch 74/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.5424e-05 - val_loss: 1.2710e-05\n",
      "Epoch 75/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.4259e-05 - val_loss: 1.8182e-04\n",
      "Epoch 76/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.7022e-05 - val_loss: 6.8693e-05\n",
      "Epoch 77/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.5319e-05 - val_loss: 1.4851e-04\n",
      "Epoch 78/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 3.3336e-05 - val_loss: 4.7708e-04\n",
      "Epoch 79/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.8818e-05 - val_loss: 2.8845e-04\n",
      "Epoch 80/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.3293e-05 - val_loss: 1.2819e-04\n",
      "Epoch 81/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.4901e-05 - val_loss: 2.8803e-05\n",
      "Epoch 82/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.2410e-05 - val_loss: 8.4834e-05\n",
      "Epoch 83/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.7862e-05 - val_loss: 5.4757e-05\n",
      "Epoch 84/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.9637e-05 - val_loss: 1.7530e-04\n",
      "Epoch 85/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 2.2509e-05 - val_loss: 1.6456e-04\n",
      "Epoch 86/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.1983e-05 - val_loss: 5.2178e-04\n",
      "Epoch 87/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.6610e-05 - val_loss: 1.4364e-04\n",
      "Epoch 88/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.9066e-05 - val_loss: 2.0760e-04\n",
      "Epoch 89/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.3257e-05 - val_loss: 8.8120e-05\n",
      "Epoch 90/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.3735e-05 - val_loss: 1.8716e-05\n",
      "Epoch 91/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.2414e-05 - val_loss: 7.6961e-04\n",
      "Epoch 92/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 4.1912e-05 - val_loss: 6.0380e-04\n",
      "Epoch 93/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.7194e-05 - val_loss: 3.1151e-04\n",
      "Epoch 94/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.1509e-05 - val_loss: 4.3421e-05\n",
      "Epoch 95/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.6504e-05 - val_loss: 2.1259e-05\n",
      "Epoch 96/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 6.1839e-05 - val_loss: 4.7333e-04\n",
      "Epoch 97/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 6.0798e-05 - val_loss: 2.3934e-04\n",
      "Epoch 98/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 8.0041e-05 - val_loss: 2.5086e-04\n",
      "Epoch 99/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 7.4133e-05 - val_loss: 3.4649e-05\n",
      "Epoch 100/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 4.0977e-05 - val_loss: 2.8756e-05\n",
      "Epoch 101/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.3228e-05 - val_loss: 9.8149e-05\n",
      "Epoch 102/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.4150e-05 - val_loss: 2.5338e-05\n",
      "Epoch 103/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.7692e-05 - val_loss: 8.5115e-04\n",
      "Epoch 104/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.5344e-05 - val_loss: 8.4478e-05\n",
      "Epoch 105/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.1942e-05 - val_loss: 1.2357e-04\n",
      "Epoch 106/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.6359e-05 - val_loss: 3.9794e-05\n",
      "Epoch 107/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.0773e-05 - val_loss: 1.0312e-04\n",
      "Epoch 108/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.3438e-05 - val_loss: 9.5842e-05\n",
      "Epoch 109/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.1200e-05 - val_loss: 1.6835e-05\n",
      "Epoch 110/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.4707e-05 - val_loss: 5.3268e-05\n",
      "Epoch 111/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.3653e-05 - val_loss: 8.7336e-05\n",
      "Epoch 112/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.2127e-05 - val_loss: 2.0435e-05\n",
      "Epoch 113/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 8.7029e-06 - val_loss: 4.2796e-05\n",
      "Epoch 114/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 1.9016e-05 - val_loss: 7.9727e-05\n",
      "Epoch 115/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 3.1343e-05 - val_loss: 8.6648e-04\n",
      "Epoch 116/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 4.3765e-05 - val_loss: 7.1079e-05\n",
      "Epoch 117/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.0889e-05 - val_loss: 7.3971e-05\n",
      "Epoch 118/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.3131e-05 - val_loss: 8.7035e-05\n",
      "Epoch 119/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.9523e-05 - val_loss: 2.5949e-04\n",
      "Epoch 120/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.9040e-05 - val_loss: 3.4280e-04\n",
      "Epoch 121/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.7879e-05 - val_loss: 1.7788e-04\n",
      "Epoch 122/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.2484e-05 - val_loss: 2.4784e-05\n",
      "Epoch 123/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.3244e-05 - val_loss: 7.9493e-05\n",
      "Epoch 124/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.4740e-06 - val_loss: 1.8569e-05\n",
      "Epoch 125/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.0903e-05 - val_loss: 4.8344e-04\n",
      "Epoch 126/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.4494e-05 - val_loss: 7.0735e-05\n",
      "Epoch 127/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.5676e-05 - val_loss: 7.3618e-05\n",
      "Epoch 128/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.1565e-05 - val_loss: 2.2270e-04\n",
      "Epoch 129/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 8.7151e-06 - val_loss: 2.5604e-05\n",
      "Epoch 130/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 9.0565e-06 - val_loss: 2.6909e-05\n",
      "Epoch 131/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.0141e-05 - val_loss: 4.4005e-05\n",
      "Epoch 132/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 1.1476e-05 - val_loss: 1.0688e-04\n",
      "Epoch 133/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.9771e-05 - val_loss: 2.1482e-04\n",
      "Epoch 134/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.3799e-05 - val_loss: 1.2459e-04\n",
      "Epoch 135/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.1349e-05 - val_loss: 3.3159e-04\n",
      "Epoch 136/150\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 2.2621e-05 - val_loss: 1.2651e-04\n",
      "Epoch 137/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.4762e-05 - val_loss: 1.3147e-04\n",
      "Epoch 138/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.2861e-05 - val_loss: 1.9402e-05\n",
      "Epoch 139/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.6784e-05 - val_loss: 3.4008e-04\n",
      "Epoch 140/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 1.9116e-05 - val_loss: 4.4125e-05\n",
      "Epoch 141/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.1586e-05 - val_loss: 2.9862e-04\n",
      "Epoch 142/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.8303e-05 - val_loss: 3.5659e-05\n",
      "Epoch 143/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.5032e-05 - val_loss: 1.9604e-04\n",
      "Epoch 144/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.2269e-05 - val_loss: 7.3446e-05\n",
      "Epoch 145/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.0516e-05 - val_loss: 3.2057e-04\n",
      "Epoch 146/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.3795e-05 - val_loss: 3.4075e-04\n",
      "Epoch 147/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.6989e-05 - val_loss: 0.0019\n",
      "Epoch 148/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.5090e-05 - val_loss: 7.3771e-05\n",
      "Epoch 149/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.5264e-06 - val_loss: 3.1236e-05\n",
      "Epoch 150/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.0940e-05 - val_loss: 1.4599e-05\n",
      ">1: Score=9.20531601877883e-06\n",
      "Epoch 1/150\n",
      "68/68 [==============================] - 8s 28ms/step - loss: 0.0031 - val_loss: 0.0112\n",
      "Epoch 2/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 3/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0081\n",
      "Epoch 4/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.6739e-04 - val_loss: 0.0060\n",
      "Epoch 5/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.3865e-04 - val_loss: 0.0041\n",
      "Epoch 6/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.6246e-04 - val_loss: 0.0026\n",
      "Epoch 7/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 3.5258e-04 - val_loss: 0.0013\n",
      "Epoch 8/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.8254e-04 - val_loss: 7.0963e-04\n",
      "Epoch 9/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.1689e-04 - val_loss: 0.0012\n",
      "Epoch 10/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.5861e-04 - val_loss: 7.0968e-04\n",
      "Epoch 11/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7248e-04 - val_loss: 1.7304e-04\n",
      "Epoch 12/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.4664e-04 - val_loss: 6.0497e-04\n",
      "Epoch 13/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.3856e-04 - val_loss: 6.6465e-04\n",
      "Epoch 14/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.0628e-05 - val_loss: 2.6817e-04\n",
      "Epoch 15/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 9.8801e-05 - val_loss: 1.7273e-04\n",
      "Epoch 16/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.6678e-05 - val_loss: 3.2793e-04\n",
      "Epoch 17/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.8934e-05 - val_loss: 2.6518e-04\n",
      "Epoch 18/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.6305e-05 - val_loss: 4.4553e-04\n",
      "Epoch 19/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.0912e-05 - val_loss: 3.1258e-04\n",
      "Epoch 20/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.0113e-04 - val_loss: 6.2536e-04\n",
      "Epoch 21/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.9924e-05 - val_loss: 0.0017\n",
      "Epoch 22/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.8076e-05 - val_loss: 3.4692e-04\n",
      "Epoch 23/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.1545e-04 - val_loss: 0.0011\n",
      "Epoch 24/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.2246e-04 - val_loss: 2.8465e-04\n",
      "Epoch 25/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.2322e-04 - val_loss: 3.2696e-04\n",
      "Epoch 26/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.0042e-04 - val_loss: 7.4012e-04\n",
      "Epoch 27/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.0396e-05 - val_loss: 1.3426e-04\n",
      "Epoch 28/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 6.3874e-05 - val_loss: 2.6723e-04\n",
      "Epoch 29/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.4557e-05 - val_loss: 1.2942e-04\n",
      "Epoch 30/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.5765e-05 - val_loss: 7.6254e-04\n",
      "Epoch 31/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.0643e-05 - val_loss: 4.4753e-04\n",
      "Epoch 32/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.4170e-05 - val_loss: 1.8886e-04\n",
      "Epoch 33/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.5527e-05 - val_loss: 6.6874e-04\n",
      "Epoch 34/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.6998e-05 - val_loss: 6.4991e-04\n",
      "Epoch 35/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.4441e-05 - val_loss: 1.2166e-04\n",
      "Epoch 36/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.9388e-05 - val_loss: 1.9602e-04\n",
      "Epoch 37/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.2243e-05 - val_loss: 3.3056e-04\n",
      "Epoch 38/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.3562e-05 - val_loss: 2.0303e-04\n",
      "Epoch 39/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 9.5973e-05 - val_loss: 0.0014\n",
      "Epoch 40/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.0303e-04 - val_loss: 5.9578e-04\n",
      "Epoch 41/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.4556e-05 - val_loss: 5.9603e-05\n",
      "Epoch 42/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.1326e-05 - val_loss: 3.3172e-04\n",
      "Epoch 43/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.2562e-05 - val_loss: 6.5317e-05\n",
      "Epoch 44/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.3852e-05 - val_loss: 1.1903e-04\n",
      "Epoch 45/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.4155e-05 - val_loss: 3.9958e-04\n",
      "Epoch 46/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.6036e-05 - val_loss: 6.4731e-05\n",
      "Epoch 47/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.8206e-05 - val_loss: 1.9991e-04\n",
      "Epoch 48/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.3442e-05 - val_loss: 1.1055e-04\n",
      "Epoch 49/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9990e-05 - val_loss: 3.3575e-04\n",
      "Epoch 50/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.4266e-05 - val_loss: 5.4842e-04\n",
      "Epoch 51/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.3851e-05 - val_loss: 2.9261e-05\n",
      "Epoch 52/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.4010e-05 - val_loss: 1.3691e-04\n",
      "Epoch 53/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.5683e-05 - val_loss: 2.5640e-04\n",
      "Epoch 54/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.1277e-05 - val_loss: 7.7606e-05\n",
      "Epoch 55/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.8816e-05 - val_loss: 1.0753e-04\n",
      "Epoch 56/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.8792e-05 - val_loss: 8.2912e-05\n",
      "Epoch 57/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.3289e-05 - val_loss: 7.7874e-05\n",
      "Epoch 58/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.3760e-05 - val_loss: 2.5461e-04\n",
      "Epoch 59/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.8743e-05 - val_loss: 9.1615e-05\n",
      "Epoch 60/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9913e-05 - val_loss: 9.4137e-05\n",
      "Epoch 61/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.4412e-05 - val_loss: 3.4625e-05\n",
      "Epoch 62/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.7505e-05 - val_loss: 6.9542e-05\n",
      "Epoch 63/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.5975e-05 - val_loss: 1.6388e-04\n",
      "Epoch 64/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 2.2331e-05 - val_loss: 7.0290e-05\n",
      "Epoch 65/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 2.2744e-05 - val_loss: 8.1515e-05\n",
      "Epoch 66/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.8185e-05 - val_loss: 2.0860e-04\n",
      "Epoch 67/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.8444e-05 - val_loss: 6.3628e-04\n",
      "Epoch 68/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.1022e-05 - val_loss: 8.3920e-05\n",
      "Epoch 69/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.1996e-05 - val_loss: 7.6852e-05\n",
      "Epoch 70/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.5623e-05 - val_loss: 2.3486e-04\n",
      "Epoch 71/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.4236e-05 - val_loss: 7.3978e-04\n",
      "Epoch 72/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.6192e-05 - val_loss: 1.3296e-04\n",
      "Epoch 73/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 3.1868e-05 - val_loss: 2.0450e-04\n",
      "Epoch 74/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.2114e-05 - val_loss: 2.8598e-05\n",
      "Epoch 75/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.3150e-05 - val_loss: 2.7749e-04\n",
      "Epoch 76/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.5818e-05 - val_loss: 1.3944e-04\n",
      "Epoch 77/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.3437e-05 - val_loss: 3.8295e-05\n",
      "Epoch 78/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9729e-05 - val_loss: 3.6781e-05\n",
      "Epoch 79/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.4769e-05 - val_loss: 4.2219e-04\n",
      "Epoch 80/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.0221e-05 - val_loss: 1.8638e-04\n",
      "Epoch 81/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.7746e-05 - val_loss: 1.4266e-04\n",
      "Epoch 82/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.3456e-05 - val_loss: 1.4300e-04\n",
      "Epoch 83/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.4720e-05 - val_loss: 6.8775e-05\n",
      "Epoch 84/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.1309e-05 - val_loss: 1.5984e-04\n",
      "Epoch 85/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.4374e-05 - val_loss: 5.1570e-04\n",
      "Epoch 86/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.7469e-05 - val_loss: 1.3872e-04\n",
      "Epoch 87/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.2366e-05 - val_loss: 8.7519e-05\n",
      "Epoch 88/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.5498e-05 - val_loss: 7.5307e-05\n",
      "Epoch 89/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.6832e-05 - val_loss: 1.1774e-04\n",
      "Epoch 90/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.8493e-06 - val_loss: 9.8930e-05\n",
      "Epoch 91/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7767e-05 - val_loss: 7.7523e-05\n",
      "Epoch 92/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.6175e-05 - val_loss: 3.9761e-04\n",
      "Epoch 93/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.9784e-05 - val_loss: 1.3093e-04\n",
      "Epoch 94/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.6536e-05 - val_loss: 5.6745e-04\n",
      "Epoch 95/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.2701e-05 - val_loss: 2.5053e-04\n",
      "Epoch 96/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.6213e-05 - val_loss: 3.9318e-05\n",
      "Epoch 97/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.8459e-05 - val_loss: 3.5063e-04\n",
      "Epoch 98/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.5760e-05 - val_loss: 2.4875e-04\n",
      "Epoch 99/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.8597e-05 - val_loss: 8.1556e-04\n",
      "Epoch 100/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.8131e-05 - val_loss: 2.7999e-04\n",
      "Epoch 101/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.5458e-05 - val_loss: 9.2475e-05\n",
      "Epoch 102/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.0495e-05 - val_loss: 4.9295e-05\n",
      "Epoch 103/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.5878e-05 - val_loss: 1.4083e-05\n",
      "Epoch 104/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.3305e-05 - val_loss: 1.3986e-04\n",
      "Epoch 105/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.5719e-05 - val_loss: 3.1605e-04\n",
      "Epoch 106/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.7163e-05 - val_loss: 4.8275e-04\n",
      "Epoch 107/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.5844e-05 - val_loss: 4.4779e-04\n",
      "Epoch 108/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.1986e-05 - val_loss: 1.8052e-04\n",
      "Epoch 109/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.5214e-05 - val_loss: 5.5124e-04\n",
      "Epoch 110/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.9884e-05 - val_loss: 2.6980e-04\n",
      "Epoch 111/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.9056e-05 - val_loss: 1.1163e-04\n",
      "Epoch 112/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.4480e-05 - val_loss: 7.4742e-05\n",
      "Epoch 113/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.6169e-05 - val_loss: 3.3683e-04\n",
      "Epoch 114/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.6635e-05 - val_loss: 1.7292e-05\n",
      "Epoch 115/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.4614e-05 - val_loss: 5.0612e-04\n",
      "Epoch 116/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.6506e-05 - val_loss: 1.7198e-04\n",
      "Epoch 117/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.6269e-05 - val_loss: 6.4922e-05\n",
      "Epoch 118/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0605e-05 - val_loss: 1.8133e-05\n",
      "Epoch 119/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.5820e-05 - val_loss: 3.4418e-05\n",
      "Epoch 120/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.2773e-06 - val_loss: 8.5858e-05\n",
      "Epoch 121/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1742e-05 - val_loss: 5.5579e-05\n",
      "Epoch 122/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.4078e-05 - val_loss: 9.5130e-05\n",
      "Epoch 123/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0383e-05 - val_loss: 2.9291e-05\n",
      "Epoch 124/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.3425e-05 - val_loss: 7.6881e-05\n",
      "Epoch 125/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.3842e-05 - val_loss: 0.0010\n",
      "Epoch 126/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.8714e-05 - val_loss: 9.9884e-05\n",
      "Epoch 127/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.3221e-05 - val_loss: 2.5207e-05\n",
      "Epoch 128/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 9.8776e-06 - val_loss: 2.0310e-04\n",
      "Epoch 129/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9103e-05 - val_loss: 4.2294e-04\n",
      "Epoch 130/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.6667e-05 - val_loss: 6.6694e-05\n",
      "Epoch 131/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.1280e-05 - val_loss: 2.5731e-05\n",
      "Epoch 132/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.6436e-05 - val_loss: 0.0010\n",
      "Epoch 133/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.4399e-05 - val_loss: 2.5842e-04\n",
      "Epoch 134/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.1864e-05 - val_loss: 4.0969e-05\n",
      "Epoch 135/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.6174e-05 - val_loss: 1.7657e-05\n",
      "Epoch 136/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.8091e-05 - val_loss: 5.9494e-05\n",
      "Epoch 137/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.3701e-05 - val_loss: 4.7339e-05\n",
      "Epoch 138/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7624e-05 - val_loss: 7.0199e-05\n",
      "Epoch 139/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.7348e-05 - val_loss: 8.5791e-05\n",
      "Epoch 140/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.8680e-05 - val_loss: 3.6557e-05\n",
      "Epoch 141/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.1500e-05 - val_loss: 2.2517e-04\n",
      "Epoch 142/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.7340e-05 - val_loss: 6.9954e-06\n",
      "Epoch 143/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.0427e-05 - val_loss: 6.8646e-05\n",
      "Epoch 144/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.0258e-05 - val_loss: 1.0866e-05\n",
      "Epoch 145/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.8931e-06 - val_loss: 3.2305e-05\n",
      "Epoch 146/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.4570e-05 - val_loss: 1.6123e-05\n",
      "Epoch 147/150\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 8.1340e-06 - val_loss: 7.5456e-06\n",
      "Epoch 148/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.2169e-05 - val_loss: 1.6179e-05\n",
      "Epoch 149/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.4738e-05 - val_loss: 3.1464e-04\n",
      "Epoch 150/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.1146e-05 - val_loss: 1.6288e-04\n",
      ">2: Score=7.865702355047688e-05\n",
      "Epoch 1/150\n",
      "68/68 [==============================] - 9s 29ms/step - loss: 0.0033 - val_loss: 0.0111\n",
      "Epoch 2/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0096\n",
      "Epoch 3/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0076\n",
      "Epoch 4/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.9300e-04 - val_loss: 0.0056\n",
      "Epoch 5/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.8054e-04 - val_loss: 0.0040\n",
      "Epoch 6/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.5200e-04 - val_loss: 0.0027\n",
      "Epoch 7/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.6406e-04 - val_loss: 0.0016\n",
      "Epoch 8/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.0851e-04 - val_loss: 0.0012\n",
      "Epoch 9/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.4786e-04 - val_loss: 0.0015\n",
      "Epoch 10/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.4794e-04 - val_loss: 7.5230e-04\n",
      "Epoch 11/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.7506e-05 - val_loss: 2.9571e-04\n",
      "Epoch 12/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.8903e-05 - val_loss: 5.6935e-04\n",
      "Epoch 13/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.3488e-04 - val_loss: 3.8878e-04\n",
      "Epoch 14/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.2277e-04 - val_loss: 2.0165e-04\n",
      "Epoch 15/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.0271e-04 - val_loss: 7.4354e-04\n",
      "Epoch 16/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.2078e-04 - val_loss: 5.4678e-04\n",
      "Epoch 17/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.6135e-04 - val_loss: 7.1191e-04\n",
      "Epoch 18/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7118e-04 - val_loss: 9.4957e-04\n",
      "Epoch 19/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.2863e-04 - val_loss: 2.5542e-04\n",
      "Epoch 20/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.2262e-04 - val_loss: 5.0236e-04\n",
      "Epoch 21/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.1439e-05 - val_loss: 3.1472e-04\n",
      "Epoch 22/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 9.5028e-05 - val_loss: 7.8672e-04\n",
      "Epoch 23/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.1729e-05 - val_loss: 7.6394e-04\n",
      "Epoch 24/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.3448e-05 - val_loss: 7.0059e-04\n",
      "Epoch 25/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.7711e-05 - val_loss: 3.7927e-04\n",
      "Epoch 26/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.9767e-05 - val_loss: 2.7535e-04\n",
      "Epoch 27/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.8206e-05 - val_loss: 2.0632e-04\n",
      "Epoch 28/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.5250e-05 - val_loss: 8.8870e-05\n",
      "Epoch 29/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.2530e-05 - val_loss: 1.6114e-04\n",
      "Epoch 30/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.2548e-05 - val_loss: 1.1820e-04\n",
      "Epoch 31/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.5522e-05 - val_loss: 1.0536e-04\n",
      "Epoch 32/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.8785e-05 - val_loss: 3.1640e-04\n",
      "Epoch 33/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.2995e-05 - val_loss: 2.7814e-04\n",
      "Epoch 34/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.3299e-05 - val_loss: 1.2682e-04\n",
      "Epoch 35/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.9425e-05 - val_loss: 6.7178e-05\n",
      "Epoch 36/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.1622e-05 - val_loss: 2.5949e-04\n",
      "Epoch 37/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 7.1193e-05 - val_loss: 2.3648e-04\n",
      "Epoch 38/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 9.2406e-05 - val_loss: 1.3354e-04\n",
      "Epoch 39/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0535e-04 - val_loss: 5.0258e-04\n",
      "Epoch 40/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.0334e-05 - val_loss: 2.5378e-04\n",
      "Epoch 41/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.6953e-05 - val_loss: 2.0248e-04\n",
      "Epoch 42/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.3649e-05 - val_loss: 8.6979e-05\n",
      "Epoch 43/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.1121e-05 - val_loss: 1.0292e-04\n",
      "Epoch 44/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.1592e-05 - val_loss: 3.4274e-04\n",
      "Epoch 45/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.4166e-05 - val_loss: 9.9599e-05\n",
      "Epoch 46/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.7906e-05 - val_loss: 2.3090e-04\n",
      "Epoch 47/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.6524e-05 - val_loss: 8.1623e-04\n",
      "Epoch 48/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.6963e-05 - val_loss: 5.3627e-04\n",
      "Epoch 49/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.5923e-05 - val_loss: 0.0012\n",
      "Epoch 50/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 8.1691e-05 - val_loss: 1.3926e-04\n",
      "Epoch 51/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.3776e-05 - val_loss: 4.6366e-05\n",
      "Epoch 52/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.4345e-05 - val_loss: 4.2810e-05\n",
      "Epoch 53/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.3381e-05 - val_loss: 2.2719e-04\n",
      "Epoch 54/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.6135e-05 - val_loss: 2.4785e-04\n",
      "Epoch 55/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.9931e-05 - val_loss: 4.3269e-05\n",
      "Epoch 56/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.8001e-05 - val_loss: 6.3108e-04\n",
      "Epoch 57/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.2675e-05 - val_loss: 3.7889e-04\n",
      "Epoch 58/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9361e-05 - val_loss: 2.7943e-05\n",
      "Epoch 59/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.0951e-05 - val_loss: 1.7775e-04\n",
      "Epoch 60/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.8821e-05 - val_loss: 5.1941e-05\n",
      "Epoch 61/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.5897e-05 - val_loss: 2.9921e-04\n",
      "Epoch 62/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.5401e-05 - val_loss: 1.3347e-04\n",
      "Epoch 63/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.9184e-05 - val_loss: 9.3819e-05\n",
      "Epoch 64/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1553e-05 - val_loss: 4.9860e-05\n",
      "Epoch 65/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.4740e-05 - val_loss: 1.2584e-04\n",
      "Epoch 66/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.3770e-05 - val_loss: 4.0799e-05\n",
      "Epoch 67/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.8522e-05 - val_loss: 3.7266e-04\n",
      "Epoch 68/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.3525e-05 - val_loss: 1.0270e-04\n",
      "Epoch 69/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7019e-05 - val_loss: 1.0003e-04\n",
      "Epoch 70/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.0117e-05 - val_loss: 6.6049e-05\n",
      "Epoch 71/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.7725e-05 - val_loss: 8.4210e-05\n",
      "Epoch 72/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.5432e-05 - val_loss: 1.3090e-04\n",
      "Epoch 73/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.7850e-05 - val_loss: 4.4636e-04\n",
      "Epoch 74/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.8650e-05 - val_loss: 5.7128e-05\n",
      "Epoch 75/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9017e-05 - val_loss: 2.7773e-04\n",
      "Epoch 76/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.2894e-05 - val_loss: 9.9474e-05\n",
      "Epoch 77/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.4134e-05 - val_loss: 3.4019e-04\n",
      "Epoch 78/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.4983e-05 - val_loss: 4.3224e-05\n",
      "Epoch 79/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.4288e-05 - val_loss: 1.7631e-05\n",
      "Epoch 80/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.3477e-05 - val_loss: 5.2061e-04\n",
      "Epoch 81/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.2846e-05 - val_loss: 2.3650e-04\n",
      "Epoch 82/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.0982e-05 - val_loss: 4.4897e-05\n",
      "Epoch 83/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.3873e-05 - val_loss: 2.1689e-04\n",
      "Epoch 84/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.4957e-05 - val_loss: 1.3999e-04\n",
      "Epoch 85/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.7514e-05 - val_loss: 3.3436e-04\n",
      "Epoch 86/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.7110e-05 - val_loss: 1.7331e-04\n",
      "Epoch 87/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.6746e-05 - val_loss: 1.1719e-04\n",
      "Epoch 88/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.4722e-05 - val_loss: 1.1679e-04\n",
      "Epoch 89/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.3999e-05 - val_loss: 1.0995e-04\n",
      "Epoch 90/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.9367e-05 - val_loss: 7.3879e-04\n",
      "Epoch 91/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.9586e-05 - val_loss: 1.4634e-04\n",
      "Epoch 92/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.8783e-05 - val_loss: 5.0543e-05\n",
      "Epoch 93/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.5137e-06 - val_loss: 4.8234e-05\n",
      "Epoch 94/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0175e-05 - val_loss: 1.6018e-04\n",
      "Epoch 95/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.9604e-05 - val_loss: 6.3689e-04\n",
      "Epoch 96/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.1292e-05 - val_loss: 7.1986e-04\n",
      "Epoch 97/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.3865e-05 - val_loss: 2.2952e-04\n",
      "Epoch 98/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.4973e-05 - val_loss: 6.0568e-05\n",
      "Epoch 99/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.5197e-05 - val_loss: 1.5281e-04\n",
      "Epoch 100/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.1914e-05 - val_loss: 1.2791e-04\n",
      "Epoch 101/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.1841e-05 - val_loss: 2.5615e-04\n",
      "Epoch 102/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.4395e-05 - val_loss: 4.9252e-04\n",
      "Epoch 103/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.7270e-05 - val_loss: 2.3084e-04\n",
      "Epoch 104/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.1500e-05 - val_loss: 8.8425e-05\n",
      "Epoch 105/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.5983e-05 - val_loss: 4.9324e-05\n",
      "Epoch 106/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.5651e-05 - val_loss: 1.9903e-04\n",
      "Epoch 107/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.4969e-05 - val_loss: 1.7858e-04\n",
      "Epoch 108/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.8411e-05 - val_loss: 1.4014e-05\n",
      "Epoch 109/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.1034e-05 - val_loss: 3.3983e-05\n",
      "Epoch 110/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.7367e-05 - val_loss: 3.7900e-05\n",
      "Epoch 111/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.8510e-05 - val_loss: 1.9292e-04\n",
      "Epoch 112/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.8973e-05 - val_loss: 9.3746e-05\n",
      "Epoch 113/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.0473e-05 - val_loss: 1.1270e-04\n",
      "Epoch 114/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.3185e-05 - val_loss: 1.3717e-05\n",
      "Epoch 115/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.9347e-05 - val_loss: 2.1288e-04\n",
      "Epoch 116/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.8457e-05 - val_loss: 3.4822e-05\n",
      "Epoch 117/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.9524e-05 - val_loss: 1.4770e-04\n",
      "Epoch 118/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6323e-05 - val_loss: 6.6747e-05\n",
      "Epoch 119/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.4579e-05 - val_loss: 3.9578e-04\n",
      "Epoch 120/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.6120e-05 - val_loss: 1.6253e-04\n",
      "Epoch 121/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.8455e-05 - val_loss: 1.2346e-04\n",
      "Epoch 122/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0947e-05 - val_loss: 6.0483e-05\n",
      "Epoch 123/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6997e-05 - val_loss: 2.0124e-05\n",
      "Epoch 124/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.3649e-05 - val_loss: 3.1669e-04\n",
      "Epoch 125/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 2.6157e-05 - val_loss: 1.7973e-05\n",
      "Epoch 126/150\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 2.8297e-05 - val_loss: 4.2489e-04\n",
      "Epoch 127/150\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 3.0223e-05 - val_loss: 4.2574e-04\n",
      "Epoch 128/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.6763e-05 - val_loss: 5.1447e-04\n",
      "Epoch 129/150\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 6.0349e-05 - val_loss: 0.0016\n",
      "Epoch 130/150\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 5.2973e-05 - val_loss: 3.8806e-05\n",
      "Epoch 131/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.8481e-05 - val_loss: 9.0353e-04\n",
      "Epoch 132/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 6.5893e-05 - val_loss: 0.0013\n",
      "Epoch 133/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.4553e-05 - val_loss: 7.2386e-05\n",
      "Epoch 134/150\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.7995e-05 - val_loss: 8.5276e-05\n",
      "Epoch 135/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.0274e-05 - val_loss: 1.2535e-05\n",
      "Epoch 136/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2065e-05 - val_loss: 3.7421e-05\n",
      "Epoch 137/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 2.1027e-05 - val_loss: 5.6134e-04\n",
      "Epoch 138/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3242e-05 - val_loss: 9.5228e-05\n",
      "Epoch 139/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.8487e-06 - val_loss: 7.0115e-06\n",
      "Epoch 140/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0983e-05 - val_loss: 1.9625e-04\n",
      "Epoch 141/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1992e-05 - val_loss: 4.9968e-05\n",
      "Epoch 142/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.0001e-05 - val_loss: 2.4882e-04\n",
      "Epoch 143/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.0184e-05 - val_loss: 1.6100e-04\n",
      "Epoch 144/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2609e-05 - val_loss: 8.0662e-06\n",
      "Epoch 145/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.9507e-06 - val_loss: 2.7793e-05\n",
      "Epoch 146/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3157e-05 - val_loss: 2.4410e-05\n",
      "Epoch 147/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0271e-05 - val_loss: 1.6296e-05\n",
      "Epoch 148/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.0727e-06 - val_loss: 1.4987e-05\n",
      "Epoch 149/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9073e-05 - val_loss: 4.1588e-04\n",
      "Epoch 150/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.0407e-05 - val_loss: 3.3016e-04\n",
      ">3: Score=0.00016784106264822185\n",
      "Epoch 1/150\n",
      "68/68 [==============================] - 11s 49ms/step - loss: 0.0031 - val_loss: 0.0109\n",
      "Epoch 2/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0094\n",
      "Epoch 3/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 8.8883e-04 - val_loss: 0.0075\n",
      "Epoch 4/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 8.1962e-04 - val_loss: 0.0057\n",
      "Epoch 5/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.0483e-04 - val_loss: 0.0039\n",
      "Epoch 6/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.4635e-04 - val_loss: 0.0025\n",
      "Epoch 7/150\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 3.2587e-04 - val_loss: 0.0012\n",
      "Epoch 8/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.7138e-04 - val_loss: 4.4696e-04\n",
      "Epoch 9/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.6154e-04 - val_loss: 3.0094e-04\n",
      "Epoch 10/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 9.1573e-05 - val_loss: 2.4527e-04\n",
      "Epoch 11/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.4571e-05 - val_loss: 3.2030e-04\n",
      "Epoch 12/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.7224e-05 - val_loss: 0.0023\n",
      "Epoch 13/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.1074e-04 - val_loss: 2.0087e-04\n",
      "Epoch 14/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 9.9784e-05 - val_loss: 7.9402e-04\n",
      "Epoch 15/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.0400e-04 - val_loss: 7.4379e-04\n",
      "Epoch 16/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.6700e-05 - val_loss: 2.4043e-04\n",
      "Epoch 17/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.4951e-05 - val_loss: 0.0014\n",
      "Epoch 18/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.9845e-05 - val_loss: 5.3040e-04\n",
      "Epoch 19/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.2182e-05 - val_loss: 3.6744e-04\n",
      "Epoch 20/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.4883e-05 - val_loss: 1.9426e-04\n",
      "Epoch 21/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.9349e-05 - val_loss: 5.0727e-04\n",
      "Epoch 22/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.1164e-05 - val_loss: 2.3838e-04\n",
      "Epoch 23/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 9.0275e-05 - val_loss: 2.7249e-04\n",
      "Epoch 24/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.0243e-04 - val_loss: 3.5848e-04\n",
      "Epoch 25/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.0264e-05 - val_loss: 0.0011\n",
      "Epoch 26/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.1070e-05 - val_loss: 0.0011\n",
      "Epoch 27/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.8802e-05 - val_loss: 1.9680e-04\n",
      "Epoch 28/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.4003e-05 - val_loss: 5.8771e-04\n",
      "Epoch 29/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.6132e-05 - val_loss: 4.6488e-04\n",
      "Epoch 30/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1816e-04 - val_loss: 1.9895e-04\n",
      "Epoch 31/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.2930e-05 - val_loss: 3.2586e-04\n",
      "Epoch 32/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2270e-04 - val_loss: 7.7747e-04\n",
      "Epoch 33/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2103e-04 - val_loss: 3.5775e-04\n",
      "Epoch 34/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 7.8968e-05 - val_loss: 6.3424e-04\n",
      "Epoch 35/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.0906e-05 - val_loss: 1.6422e-04\n",
      "Epoch 36/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.2176e-05 - val_loss: 1.1076e-04\n",
      "Epoch 37/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.4781e-05 - val_loss: 1.4336e-04\n",
      "Epoch 38/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.5012e-05 - val_loss: 7.6267e-05\n",
      "Epoch 39/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.3336e-05 - val_loss: 1.0307e-04\n",
      "Epoch 40/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 8.1803e-05 - val_loss: 2.3295e-04\n",
      "Epoch 41/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.4383e-05 - val_loss: 5.9937e-04\n",
      "Epoch 42/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.0014e-05 - val_loss: 8.0393e-04\n",
      "Epoch 43/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.8464e-05 - val_loss: 0.0014\n",
      "Epoch 44/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.4997e-05 - val_loss: 3.3882e-04\n",
      "Epoch 45/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.3006e-05 - val_loss: 2.7958e-04\n",
      "Epoch 46/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7633e-05 - val_loss: 5.7843e-05\n",
      "Epoch 47/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.3216e-05 - val_loss: 6.0570e-05\n",
      "Epoch 48/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.4229e-05 - val_loss: 1.3520e-04\n",
      "Epoch 49/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.5366e-05 - val_loss: 1.2619e-04\n",
      "Epoch 50/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.6820e-05 - val_loss: 3.9495e-04\n",
      "Epoch 51/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.0455e-05 - val_loss: 3.2062e-05\n",
      "Epoch 52/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.4946e-05 - val_loss: 4.1878e-05\n",
      "Epoch 53/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.3577e-05 - val_loss: 1.9651e-04\n",
      "Epoch 54/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3671e-05 - val_loss: 8.3715e-05\n",
      "Epoch 55/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2187e-05 - val_loss: 5.4245e-05\n",
      "Epoch 56/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0308e-05 - val_loss: 1.7486e-04\n",
      "Epoch 57/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.5786e-05 - val_loss: 4.4542e-04\n",
      "Epoch 58/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.7496e-05 - val_loss: 1.0244e-04\n",
      "Epoch 59/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.3563e-05 - val_loss: 6.5346e-05\n",
      "Epoch 60/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.5209e-05 - val_loss: 3.1134e-04\n",
      "Epoch 61/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.1039e-05 - val_loss: 6.5056e-04\n",
      "Epoch 62/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.5726e-05 - val_loss: 1.8220e-04\n",
      "Epoch 63/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.1516e-05 - val_loss: 1.9413e-04\n",
      "Epoch 64/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.1405e-05 - val_loss: 1.2917e-04\n",
      "Epoch 65/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.6253e-05 - val_loss: 7.1869e-05\n",
      "Epoch 66/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5203e-05 - val_loss: 8.8686e-05\n",
      "Epoch 67/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.4940e-05 - val_loss: 6.5081e-04\n",
      "Epoch 68/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.6407e-05 - val_loss: 3.6855e-04\n",
      "Epoch 69/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.4137e-05 - val_loss: 3.8147e-04\n",
      "Epoch 70/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.5247e-05 - val_loss: 0.0011\n",
      "Epoch 71/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.2740e-05 - val_loss: 3.4071e-04\n",
      "Epoch 72/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.2660e-05 - val_loss: 1.3846e-04\n",
      "Epoch 73/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.1209e-05 - val_loss: 2.3450e-04\n",
      "Epoch 74/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.4933e-05 - val_loss: 3.4365e-04\n",
      "Epoch 75/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.4490e-05 - val_loss: 1.3057e-04\n",
      "Epoch 76/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7172e-05 - val_loss: 7.2327e-05\n",
      "Epoch 77/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.4804e-05 - val_loss: 3.3250e-04\n",
      "Epoch 78/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.9912e-05 - val_loss: 2.2278e-05\n",
      "Epoch 79/150\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 3.4856e-05 - val_loss: 2.2615e-04\n",
      "Epoch 80/150\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 2.3052e-05 - val_loss: 9.6615e-05\n",
      "Epoch 81/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.3373e-05 - val_loss: 5.9770e-04\n",
      "Epoch 82/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.9754e-05 - val_loss: 1.2506e-04\n",
      "Epoch 83/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.8710e-05 - val_loss: 3.0472e-04\n",
      "Epoch 84/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.0087e-05 - val_loss: 1.3993e-04\n",
      "Epoch 85/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3084e-05 - val_loss: 7.3671e-04\n",
      "Epoch 86/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.5856e-05 - val_loss: 2.7422e-04\n",
      "Epoch 87/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.3756e-05 - val_loss: 1.2253e-04\n",
      "Epoch 88/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.0794e-05 - val_loss: 1.6813e-04\n",
      "Epoch 89/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.1321e-05 - val_loss: 8.1643e-05\n",
      "Epoch 90/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.4530e-05 - val_loss: 3.6450e-05\n",
      "Epoch 91/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.8483e-05 - val_loss: 6.5194e-04\n",
      "Epoch 92/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.3634e-05 - val_loss: 6.1885e-04\n",
      "Epoch 93/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.9301e-05 - val_loss: 2.8040e-04\n",
      "Epoch 94/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7337e-05 - val_loss: 2.1547e-04\n",
      "Epoch 95/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.3423e-05 - val_loss: 1.0513e-04\n",
      "Epoch 96/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.2434e-05 - val_loss: 1.2003e-04\n",
      "Epoch 97/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.5031e-05 - val_loss: 1.7656e-04\n",
      "Epoch 98/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.0279e-05 - val_loss: 0.0010\n",
      "Epoch 99/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.4745e-05 - val_loss: 6.3206e-05\n",
      "Epoch 100/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.3227e-05 - val_loss: 4.0108e-04\n",
      "Epoch 101/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7873e-05 - val_loss: 1.2800e-04\n",
      "Epoch 102/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.8117e-05 - val_loss: 1.3655e-04\n",
      "Epoch 103/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.9238e-05 - val_loss: 2.0724e-05\n",
      "Epoch 104/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.0171e-05 - val_loss: 8.0233e-05\n",
      "Epoch 105/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.1397e-05 - val_loss: 1.0099e-04\n",
      "Epoch 106/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.4082e-05 - val_loss: 2.6707e-04\n",
      "Epoch 107/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.6441e-05 - val_loss: 4.9912e-05\n",
      "Epoch 108/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.1496e-05 - val_loss: 3.5286e-04\n",
      "Epoch 109/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.1133e-05 - val_loss: 1.7924e-05\n",
      "Epoch 110/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.3489e-05 - val_loss: 8.1687e-05\n",
      "Epoch 111/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.6850e-05 - val_loss: 5.9243e-05\n",
      "Epoch 112/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.0542e-05 - val_loss: 8.2060e-06\n",
      "Epoch 113/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.1185e-05 - val_loss: 3.3582e-05\n",
      "Epoch 114/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.2088e-05 - val_loss: 4.6769e-04\n",
      "Epoch 115/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.1037e-05 - val_loss: 1.7252e-04\n",
      "Epoch 116/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.7623e-05 - val_loss: 8.5441e-05\n",
      "Epoch 117/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.5365e-05 - val_loss: 1.3672e-05\n",
      "Epoch 118/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.4084e-05 - val_loss: 2.9144e-04\n",
      "Epoch 119/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.4558e-05 - val_loss: 1.8890e-04\n",
      "Epoch 120/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.4615e-05 - val_loss: 3.5142e-05\n",
      "Epoch 121/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.6204e-05 - val_loss: 7.1334e-05\n",
      "Epoch 122/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.6279e-05 - val_loss: 2.4136e-04\n",
      "Epoch 123/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7341e-05 - val_loss: 3.7368e-04\n",
      "Epoch 124/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3713e-05 - val_loss: 3.4432e-05\n",
      "Epoch 125/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.5886e-05 - val_loss: 2.1601e-04\n",
      "Epoch 126/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.1204e-05 - val_loss: 2.3171e-04\n",
      "Epoch 127/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.1876e-05 - val_loss: 5.4108e-05\n",
      "Epoch 128/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.7639e-05 - val_loss: 2.7521e-05\n",
      "Epoch 129/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6283e-05 - val_loss: 1.8095e-05\n",
      "Epoch 130/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.0896e-05 - val_loss: 2.7506e-05\n",
      "Epoch 131/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.9958e-05 - val_loss: 1.6030e-04\n",
      "Epoch 132/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.7840e-05 - val_loss: 2.2230e-04\n",
      "Epoch 133/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.6039e-05 - val_loss: 1.2419e-04\n",
      "Epoch 134/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.8298e-05 - val_loss: 3.0414e-04\n",
      "Epoch 135/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.6820e-05 - val_loss: 1.0394e-05\n",
      "Epoch 136/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.3687e-05 - val_loss: 2.3636e-04\n",
      "Epoch 137/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.1880e-05 - val_loss: 1.3505e-05\n",
      "Epoch 138/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5422e-05 - val_loss: 1.3199e-04\n",
      "Epoch 139/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.4942e-05 - val_loss: 4.7332e-04\n",
      "Epoch 140/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.3105e-05 - val_loss: 9.1401e-04\n",
      "Epoch 141/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.7640e-05 - val_loss: 1.3068e-04\n",
      "Epoch 142/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.4500e-05 - val_loss: 8.8760e-05\n",
      "Epoch 143/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.3721e-05 - val_loss: 2.4260e-05\n",
      "Epoch 144/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.0417e-05 - val_loss: 3.6494e-05\n",
      "Epoch 145/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.8892e-05 - val_loss: 2.2041e-04\n",
      "Epoch 146/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5892e-05 - val_loss: 8.6436e-05\n",
      "Epoch 147/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.4785e-05 - val_loss: 1.0642e-04\n",
      "Epoch 148/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.0128e-05 - val_loss: 0.0014\n",
      "Epoch 149/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.6300e-05 - val_loss: 2.0501e-04\n",
      "Epoch 150/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7277e-05 - val_loss: 8.6412e-05\n",
      ">4: Score=5.990549470880069e-05\n",
      "Epoch 1/150\n",
      "68/68 [==============================] - 10s 36ms/step - loss: 0.0030 - val_loss: 0.0111\n",
      "Epoch 2/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0097\n",
      "Epoch 3/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 9.3476e-04 - val_loss: 0.0079\n",
      "Epoch 4/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.2323e-04 - val_loss: 0.0060\n",
      "Epoch 5/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.7915e-04 - val_loss: 0.0041\n",
      "Epoch 6/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 4.6836e-04 - val_loss: 0.0026\n",
      "Epoch 7/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.4929e-04 - val_loss: 0.0012\n",
      "Epoch 8/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.1518e-04 - val_loss: 6.8484e-04\n",
      "Epoch 9/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.2245e-04 - val_loss: 5.2440e-04\n",
      "Epoch 10/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.5518e-05 - val_loss: 2.5543e-04\n",
      "Epoch 11/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.5667e-05 - val_loss: 4.4481e-04\n",
      "Epoch 12/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.1488e-05 - val_loss: 1.7962e-04\n",
      "Epoch 13/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.3041e-04 - val_loss: 2.2110e-04\n",
      "Epoch 14/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2225e-04 - val_loss: 2.3331e-04\n",
      "Epoch 15/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9247e-04 - val_loss: 0.0014\n",
      "Epoch 16/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.4281e-04 - val_loss: 5.0578e-04\n",
      "Epoch 17/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3367e-04 - val_loss: 9.5402e-04\n",
      "Epoch 18/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.7653e-05 - val_loss: 1.9269e-04\n",
      "Epoch 19/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.8630e-05 - val_loss: 3.4859e-04\n",
      "Epoch 20/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.0596e-05 - val_loss: 0.0013\n",
      "Epoch 21/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.2298e-05 - val_loss: 2.8315e-04\n",
      "Epoch 22/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.9274e-05 - val_loss: 2.7806e-04\n",
      "Epoch 23/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.5157e-05 - val_loss: 2.2560e-04\n",
      "Epoch 24/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0376e-04 - val_loss: 7.8434e-05\n",
      "Epoch 25/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.7947e-05 - val_loss: 5.6258e-04\n",
      "Epoch 26/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.5163e-05 - val_loss: 8.2501e-04\n",
      "Epoch 27/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.1030e-05 - val_loss: 1.8651e-04\n",
      "Epoch 28/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.9140e-05 - val_loss: 3.2995e-04\n",
      "Epoch 29/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.0507e-04 - val_loss: 5.9714e-04\n",
      "Epoch 30/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0285e-04 - val_loss: 1.9067e-04\n",
      "Epoch 31/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.2175e-04 - val_loss: 3.6175e-04\n",
      "Epoch 32/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.1957e-05 - val_loss: 6.9147e-04\n",
      "Epoch 33/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.3449e-05 - val_loss: 2.5865e-04\n",
      "Epoch 34/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.7054e-05 - val_loss: 2.8453e-04\n",
      "Epoch 35/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.0324e-05 - val_loss: 5.0959e-04\n",
      "Epoch 36/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.8465e-05 - val_loss: 4.5259e-04\n",
      "Epoch 37/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.7383e-05 - val_loss: 2.7961e-04\n",
      "Epoch 38/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.0755e-05 - val_loss: 1.0795e-04\n",
      "Epoch 39/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.7880e-05 - val_loss: 7.7487e-04\n",
      "Epoch 40/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.4776e-05 - val_loss: 5.0330e-04\n",
      "Epoch 41/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.3961e-05 - val_loss: 2.9542e-04\n",
      "Epoch 42/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.5663e-05 - val_loss: 6.7449e-05\n",
      "Epoch 43/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9109e-05 - val_loss: 5.0261e-05\n",
      "Epoch 44/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.5542e-05 - val_loss: 1.7668e-04\n",
      "Epoch 45/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.4708e-05 - val_loss: 1.5770e-04\n",
      "Epoch 46/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1088e-05 - val_loss: 7.3090e-05\n",
      "Epoch 47/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.1682e-05 - val_loss: 2.0901e-04\n",
      "Epoch 48/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.7709e-05 - val_loss: 8.8771e-04\n",
      "Epoch 49/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7841e-05 - val_loss: 4.6183e-05\n",
      "Epoch 50/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.1500e-05 - val_loss: 1.4557e-04\n",
      "Epoch 51/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.0028e-05 - val_loss: 1.2120e-04\n",
      "Epoch 52/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.3466e-05 - val_loss: 2.2738e-04\n",
      "Epoch 53/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.2811e-05 - val_loss: 7.5510e-05\n",
      "Epoch 54/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.1724e-05 - val_loss: 7.4658e-05\n",
      "Epoch 55/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.1390e-05 - val_loss: 9.6942e-05\n",
      "Epoch 56/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.9015e-05 - val_loss: 1.1899e-04\n",
      "Epoch 57/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0232e-05 - val_loss: 3.0371e-04\n",
      "Epoch 58/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.5737e-05 - val_loss: 5.4177e-04\n",
      "Epoch 59/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.2978e-05 - val_loss: 1.5348e-04\n",
      "Epoch 60/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.2772e-05 - val_loss: 6.4931e-05\n",
      "Epoch 61/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.4175e-05 - val_loss: 4.4713e-04\n",
      "Epoch 62/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0346e-05 - val_loss: 1.2386e-04\n",
      "Epoch 63/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.8381e-05 - val_loss: 8.9670e-05\n",
      "Epoch 64/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.6553e-05 - val_loss: 6.5519e-04\n",
      "Epoch 65/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 6.7641e-05 - val_loss: 0.0012\n",
      "Epoch 66/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 8.5977e-05 - val_loss: 3.4894e-04\n",
      "Epoch 67/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.1197e-05 - val_loss: 1.4624e-04\n",
      "Epoch 68/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.4636e-05 - val_loss: 7.5371e-05\n",
      "Epoch 69/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.6112e-05 - val_loss: 1.5182e-04\n",
      "Epoch 70/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.6380e-05 - val_loss: 1.3105e-04\n",
      "Epoch 71/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.4999e-05 - val_loss: 3.1640e-04\n",
      "Epoch 72/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.5302e-05 - val_loss: 9.0402e-06\n",
      "Epoch 73/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.5488e-05 - val_loss: 7.0955e-05\n",
      "Epoch 74/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1632e-05 - val_loss: 1.8526e-04\n",
      "Epoch 75/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.2383e-05 - val_loss: 0.0012\n",
      "Epoch 76/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.8191e-05 - val_loss: 5.0836e-04\n",
      "Epoch 77/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.7697e-05 - val_loss: 8.1090e-05\n",
      "Epoch 78/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.1209e-05 - val_loss: 1.4723e-05\n",
      "Epoch 79/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.1525e-05 - val_loss: 1.1132e-04\n",
      "Epoch 80/150\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 3.3169e-05 - val_loss: 4.3827e-05\n",
      "Epoch 81/150\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 4.2242e-05 - val_loss: 9.2141e-04\n",
      "Epoch 82/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 5.8845e-05 - val_loss: 2.6253e-04\n",
      "Epoch 83/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.8193e-05 - val_loss: 1.8395e-05\n",
      "Epoch 84/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.7719e-05 - val_loss: 6.7861e-05\n",
      "Epoch 85/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.8217e-05 - val_loss: 5.1736e-05\n",
      "Epoch 86/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.1943e-05 - val_loss: 4.0111e-04\n",
      "Epoch 87/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3643e-05 - val_loss: 1.6452e-04\n",
      "Epoch 88/150\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 2.3176e-05 - val_loss: 2.3855e-05\n",
      "Epoch 89/150\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.6864e-05 - val_loss: 2.2991e-05\n",
      "Epoch 90/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5370e-05 - val_loss: 8.0394e-05\n",
      "Epoch 91/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.7897e-05 - val_loss: 1.8763e-04\n",
      "Epoch 92/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.9697e-05 - val_loss: 1.3851e-04\n",
      "Epoch 93/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 2.7352e-05 - val_loss: 3.5349e-04\n",
      "Epoch 94/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.1433e-05 - val_loss: 1.5307e-05\n",
      "Epoch 95/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5006e-05 - val_loss: 6.6154e-05\n",
      "Epoch 96/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.4774e-05 - val_loss: 2.5379e-05\n",
      "Epoch 97/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.9549e-05 - val_loss: 4.9303e-05\n",
      "Epoch 98/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.1018e-05 - val_loss: 1.6517e-04\n",
      "Epoch 99/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.1614e-05 - val_loss: 4.9201e-04\n",
      "Epoch 100/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.9711e-05 - val_loss: 2.9583e-04\n",
      "Epoch 101/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.5879e-05 - val_loss: 8.1639e-05\n",
      "Epoch 102/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.5032e-05 - val_loss: 2.1740e-04\n",
      "Epoch 103/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.1111e-05 - val_loss: 2.2502e-05\n",
      "Epoch 104/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.6467e-05 - val_loss: 3.0307e-04\n",
      "Epoch 105/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.1237e-05 - val_loss: 3.0423e-05\n",
      "Epoch 106/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.7139e-05 - val_loss: 4.4278e-04\n",
      "Epoch 107/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.0662e-05 - val_loss: 2.0786e-04\n",
      "Epoch 108/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.9561e-05 - val_loss: 1.6033e-04\n",
      "Epoch 109/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.7061e-05 - val_loss: 7.1878e-04\n",
      "Epoch 110/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2076e-05 - val_loss: 3.2242e-05\n",
      "Epoch 111/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.6227e-05 - val_loss: 2.4519e-04\n",
      "Epoch 112/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2713e-05 - val_loss: 3.7265e-04\n",
      "Epoch 113/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1497e-05 - val_loss: 7.8152e-04\n",
      "Epoch 114/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.4491e-05 - val_loss: 0.0011\n",
      "Epoch 115/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.9451e-05 - val_loss: 1.1263e-04\n",
      "Epoch 116/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.4210e-05 - val_loss: 1.8668e-04\n",
      "Epoch 117/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6047e-05 - val_loss: 3.7041e-04\n",
      "Epoch 118/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2422e-05 - val_loss: 7.8835e-05\n",
      "Epoch 119/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.4774e-05 - val_loss: 1.1897e-05\n",
      "Epoch 120/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2342e-05 - val_loss: 5.3164e-05\n",
      "Epoch 121/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.7331e-05 - val_loss: 5.2704e-04\n",
      "Epoch 122/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.4858e-05 - val_loss: 8.3876e-04\n",
      "Epoch 123/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.9213e-05 - val_loss: 5.3793e-05\n",
      "Epoch 124/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1606e-05 - val_loss: 2.0436e-04\n",
      "Epoch 125/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.8940e-05 - val_loss: 7.4397e-04\n",
      "Epoch 126/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.7772e-05 - val_loss: 2.3168e-04\n",
      "Epoch 127/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2392e-05 - val_loss: 8.1360e-05\n",
      "Epoch 128/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 9.8516e-06 - val_loss: 3.4358e-05\n",
      "Epoch 129/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.5311e-05 - val_loss: 4.0646e-05\n",
      "Epoch 130/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.1494e-05 - val_loss: 9.9814e-05\n",
      "Epoch 131/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.1139e-05 - val_loss: 9.9873e-06\n",
      "Epoch 132/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9284e-05 - val_loss: 5.9565e-05\n",
      "Epoch 133/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6557e-05 - val_loss: 2.1292e-05\n",
      "Epoch 134/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2242e-05 - val_loss: 1.1844e-04\n",
      "Epoch 135/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.0038e-05 - val_loss: 4.6798e-04\n",
      "Epoch 136/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7765e-05 - val_loss: 4.4991e-05\n",
      "Epoch 137/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.2909e-05 - val_loss: 1.2565e-04\n",
      "Epoch 138/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3250e-05 - val_loss: 7.8627e-04\n",
      "Epoch 139/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.9020e-05 - val_loss: 5.3006e-05\n",
      "Epoch 140/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 9.7352e-06 - val_loss: 1.1792e-04\n",
      "Epoch 141/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.8348e-05 - val_loss: 3.6943e-04\n",
      "Epoch 142/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1405e-05 - val_loss: 4.4903e-04\n",
      "Epoch 143/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.9479e-05 - val_loss: 6.6039e-04\n",
      "Epoch 144/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7992e-05 - val_loss: 1.8301e-05\n",
      "Epoch 145/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5695e-05 - val_loss: 4.2370e-05\n",
      "Epoch 146/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.9653e-06 - val_loss: 8.3914e-05\n",
      "Epoch 147/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0750e-05 - val_loss: 1.4299e-04\n",
      "Epoch 148/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.4036e-06 - val_loss: 1.3877e-04\n",
      "Epoch 149/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2922e-05 - val_loss: 4.1642e-05\n",
      "Epoch 150/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1058e-05 - val_loss: 1.4567e-05\n",
      ">5: Score=2.1163668861845508e-05\n",
      "Epoch 1/150\n",
      "68/68 [==============================] - 8s 29ms/step - loss: 0.0033 - val_loss: 0.0113\n",
      "Epoch 2/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0097\n",
      "Epoch 3/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 9.5383e-04 - val_loss: 0.0078\n",
      "Epoch 4/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.9230e-04 - val_loss: 0.0055\n",
      "Epoch 5/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.9758e-04 - val_loss: 0.0037\n",
      "Epoch 6/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.9812e-04 - val_loss: 0.0021\n",
      "Epoch 7/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.0505e-04 - val_loss: 0.0011\n",
      "Epoch 8/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1646e-04 - val_loss: 7.1139e-04\n",
      "Epoch 9/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0824e-04 - val_loss: 5.5115e-04\n",
      "Epoch 10/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0370e-04 - val_loss: 1.6872e-04\n",
      "Epoch 11/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.7404e-04 - val_loss: 4.4704e-04\n",
      "Epoch 12/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.6483e-04 - val_loss: 4.6020e-04\n",
      "Epoch 13/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.9054e-05 - val_loss: 4.2801e-04\n",
      "Epoch 14/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.0260e-04 - val_loss: 2.3674e-04\n",
      "Epoch 15/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.3739e-05 - val_loss: 6.7436e-04\n",
      "Epoch 16/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.1227e-05 - val_loss: 2.7992e-04\n",
      "Epoch 17/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.1751e-04 - val_loss: 6.2083e-04\n",
      "Epoch 18/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.6293e-05 - val_loss: 5.7080e-04\n",
      "Epoch 19/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 6.1708e-05 - val_loss: 1.4294e-04\n",
      "Epoch 20/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2629e-04 - val_loss: 2.9006e-04\n",
      "Epoch 21/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.0582e-05 - val_loss: 1.3915e-04\n",
      "Epoch 22/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 8.7753e-05 - val_loss: 7.0791e-04\n",
      "Epoch 23/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.0805e-04 - val_loss: 4.1423e-04\n",
      "Epoch 24/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.3572e-05 - val_loss: 3.6045e-04\n",
      "Epoch 25/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.9311e-05 - val_loss: 1.1112e-04\n",
      "Epoch 26/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.9960e-05 - val_loss: 2.8620e-04\n",
      "Epoch 27/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.4877e-05 - val_loss: 1.0324e-04\n",
      "Epoch 28/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.9295e-05 - val_loss: 1.7990e-04\n",
      "Epoch 29/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.3927e-05 - val_loss: 1.2832e-04\n",
      "Epoch 30/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 6.9684e-05 - val_loss: 9.8857e-05\n",
      "Epoch 31/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.6798e-05 - val_loss: 1.2162e-04\n",
      "Epoch 32/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.1005e-05 - val_loss: 2.7319e-04\n",
      "Epoch 33/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.5815e-05 - val_loss: 9.5297e-05\n",
      "Epoch 34/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.4987e-05 - val_loss: 5.3136e-04\n",
      "Epoch 35/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.5773e-05 - val_loss: 1.1165e-04\n",
      "Epoch 36/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.3148e-05 - val_loss: 5.2965e-04\n",
      "Epoch 37/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.9477e-05 - val_loss: 5.1388e-04\n",
      "Epoch 38/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.5551e-05 - val_loss: 4.9606e-05\n",
      "Epoch 39/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.6645e-05 - val_loss: 1.6587e-04\n",
      "Epoch 40/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.3263e-05 - val_loss: 4.7961e-04\n",
      "Epoch 41/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.0730e-05 - val_loss: 7.6466e-04\n",
      "Epoch 42/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.6748e-05 - val_loss: 8.7538e-04\n",
      "Epoch 43/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.1092e-05 - val_loss: 1.3262e-04\n",
      "Epoch 44/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.0602e-05 - val_loss: 2.3759e-04\n",
      "Epoch 45/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.8588e-05 - val_loss: 9.7250e-05\n",
      "Epoch 46/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.9248e-05 - val_loss: 8.6428e-05\n",
      "Epoch 47/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.9370e-05 - val_loss: 2.5960e-04\n",
      "Epoch 48/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.7639e-05 - val_loss: 9.3759e-04\n",
      "Epoch 49/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.5254e-05 - val_loss: 9.7672e-05\n",
      "Epoch 50/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 2.4560e-05 - val_loss: 1.2929e-04\n",
      "Epoch 51/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.6166e-05 - val_loss: 1.2567e-04\n",
      "Epoch 52/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.3144e-05 - val_loss: 2.6550e-05\n",
      "Epoch 53/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2371e-05 - val_loss: 3.0664e-05\n",
      "Epoch 54/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2438e-05 - val_loss: 5.1072e-04\n",
      "Epoch 55/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.6957e-05 - val_loss: 8.2155e-05\n",
      "Epoch 56/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.5961e-05 - val_loss: 2.2767e-04\n",
      "Epoch 57/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.1157e-05 - val_loss: 3.9973e-05\n",
      "Epoch 58/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.4069e-05 - val_loss: 3.7391e-04\n",
      "Epoch 59/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.9123e-05 - val_loss: 5.6120e-05\n",
      "Epoch 60/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.5019e-05 - val_loss: 5.0080e-04\n",
      "Epoch 61/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.7376e-05 - val_loss: 2.4664e-04\n",
      "Epoch 62/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.2341e-05 - val_loss: 1.4665e-04\n",
      "Epoch 63/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.5430e-05 - val_loss: 2.7951e-05\n",
      "Epoch 64/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.9154e-05 - val_loss: 1.1266e-04\n",
      "Epoch 65/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.6323e-05 - val_loss: 6.2697e-05\n",
      "Epoch 66/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.9124e-05 - val_loss: 8.4613e-05\n",
      "Epoch 67/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.0133e-05 - val_loss: 1.3423e-04\n",
      "Epoch 68/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.7160e-05 - val_loss: 4.3386e-05\n",
      "Epoch 69/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.0322e-05 - val_loss: 1.4482e-05\n",
      "Epoch 70/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.6855e-05 - val_loss: 1.2579e-05\n",
      "Epoch 71/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.3932e-05 - val_loss: 5.1707e-05\n",
      "Epoch 72/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.2999e-05 - val_loss: 1.0003e-04\n",
      "Epoch 73/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.6643e-05 - val_loss: 9.1865e-05\n",
      "Epoch 74/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.9563e-05 - val_loss: 1.2160e-05\n",
      "Epoch 75/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.5493e-05 - val_loss: 1.5340e-04\n",
      "Epoch 76/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.8690e-05 - val_loss: 5.3539e-05\n",
      "Epoch 77/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.1771e-05 - val_loss: 2.2073e-04\n",
      "Epoch 78/150\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 3.1557e-05 - val_loss: 1.6681e-04\n",
      "Epoch 79/150\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 4.5722e-05 - val_loss: 1.1741e-04\n",
      "Epoch 80/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.6682e-05 - val_loss: 2.9014e-04\n",
      "Epoch 81/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.0582e-05 - val_loss: 8.7242e-04\n",
      "Epoch 82/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.5777e-05 - val_loss: 2.2566e-04\n",
      "Epoch 83/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1210e-05 - val_loss: 1.6102e-04\n",
      "Epoch 84/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.9566e-05 - val_loss: 7.3923e-05\n",
      "Epoch 85/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.3612e-05 - val_loss: 1.3606e-04\n",
      "Epoch 86/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.8046e-05 - val_loss: 1.5208e-04\n",
      "Epoch 87/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.2797e-05 - val_loss: 2.3188e-04\n",
      "Epoch 88/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9743e-05 - val_loss: 1.9624e-04\n",
      "Epoch 89/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.0669e-05 - val_loss: 1.2354e-04\n",
      "Epoch 90/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.2358e-05 - val_loss: 4.9628e-05\n",
      "Epoch 91/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.9009e-05 - val_loss: 2.0512e-04\n",
      "Epoch 92/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.1605e-05 - val_loss: 3.3774e-04\n",
      "Epoch 93/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.5319e-05 - val_loss: 2.5144e-05\n",
      "Epoch 94/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.9846e-05 - val_loss: 3.9843e-04\n",
      "Epoch 95/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.9506e-05 - val_loss: 1.0156e-04\n",
      "Epoch 96/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.5313e-05 - val_loss: 3.4376e-04\n",
      "Epoch 97/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.9023e-05 - val_loss: 6.5239e-04\n",
      "Epoch 98/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.8626e-05 - val_loss: 2.1099e-04\n",
      "Epoch 99/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1891e-05 - val_loss: 1.2021e-04\n",
      "Epoch 100/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5606e-05 - val_loss: 1.6330e-05\n",
      "Epoch 101/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.5094e-05 - val_loss: 1.1967e-05\n",
      "Epoch 102/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.8963e-05 - val_loss: 1.9088e-04\n",
      "Epoch 103/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.4463e-05 - val_loss: 2.1881e-04\n",
      "Epoch 104/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.5308e-05 - val_loss: 9.0302e-04\n",
      "Epoch 105/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.3467e-05 - val_loss: 2.5121e-04\n",
      "Epoch 106/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9954e-05 - val_loss: 2.7837e-05\n",
      "Epoch 107/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7688e-05 - val_loss: 5.8243e-05\n",
      "Epoch 108/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1155e-05 - val_loss: 9.5826e-05\n",
      "Epoch 109/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.1490e-05 - val_loss: 3.3914e-04\n",
      "Epoch 110/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2443e-05 - val_loss: 3.0020e-05\n",
      "Epoch 111/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1387e-05 - val_loss: 5.8755e-05\n",
      "Epoch 112/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3808e-05 - val_loss: 1.2611e-04\n",
      "Epoch 113/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.7089e-05 - val_loss: 2.8791e-05\n",
      "Epoch 114/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.2864e-05 - val_loss: 2.7804e-05\n",
      "Epoch 115/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.4965e-05 - val_loss: 3.0024e-05\n",
      "Epoch 116/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.9713e-06 - val_loss: 1.0194e-04\n",
      "Epoch 117/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.7209e-06 - val_loss: 7.4452e-05\n",
      "Epoch 118/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.4200e-05 - val_loss: 3.3956e-05\n",
      "Epoch 119/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.0662e-05 - val_loss: 3.7845e-04\n",
      "Epoch 120/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9298e-05 - val_loss: 1.2450e-04\n",
      "Epoch 121/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.6148e-05 - val_loss: 3.4233e-05\n",
      "Epoch 122/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.8743e-05 - val_loss: 6.9189e-05\n",
      "Epoch 123/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.3264e-05 - val_loss: 3.2515e-05\n",
      "Epoch 124/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.2440e-05 - val_loss: 0.0011\n",
      "Epoch 125/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.2320e-05 - val_loss: 2.9004e-04\n",
      "Epoch 126/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.7084e-05 - val_loss: 1.6062e-04\n",
      "Epoch 127/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.5505e-05 - val_loss: 2.8252e-04\n",
      "Epoch 128/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.7586e-05 - val_loss: 2.2551e-04\n",
      "Epoch 129/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.6280e-05 - val_loss: 1.4425e-04\n",
      "Epoch 130/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 3.8717e-05 - val_loss: 1.3546e-05\n",
      "Epoch 131/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.1291e-05 - val_loss: 5.5697e-05\n",
      "Epoch 132/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.3907e-05 - val_loss: 6.0100e-04\n",
      "Epoch 133/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.3621e-05 - val_loss: 6.0149e-05\n",
      "Epoch 134/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.4199e-05 - val_loss: 6.3957e-05\n",
      "Epoch 135/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 9.0871e-06 - val_loss: 3.3549e-05\n",
      "Epoch 136/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.6506e-05 - val_loss: 8.9798e-05\n",
      "Epoch 137/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.6925e-05 - val_loss: 3.7693e-04\n",
      "Epoch 138/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.1307e-05 - val_loss: 1.6168e-04\n",
      "Epoch 139/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2330e-05 - val_loss: 3.4822e-05\n",
      "Epoch 140/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6115e-05 - val_loss: 2.4199e-04\n",
      "Epoch 141/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.2923e-05 - val_loss: 4.1890e-04\n",
      "Epoch 142/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.3482e-05 - val_loss: 6.0421e-04\n",
      "Epoch 143/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.3990e-05 - val_loss: 6.3340e-04\n",
      "Epoch 144/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.8832e-05 - val_loss: 2.4282e-04\n",
      "Epoch 145/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.0849e-05 - val_loss: 2.7022e-04\n",
      "Epoch 146/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.0423e-05 - val_loss: 1.5179e-04\n",
      "Epoch 147/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.2841e-05 - val_loss: 3.2966e-04\n",
      "Epoch 148/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.2998e-05 - val_loss: 8.1234e-04\n",
      "Epoch 149/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.6113e-05 - val_loss: 0.0011\n",
      "Epoch 150/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.3795e-05 - val_loss: 2.4985e-04\n",
      ">6: Score=0.00015520445595029742\n",
      "Epoch 1/150\n",
      "68/68 [==============================] - 8s 28ms/step - loss: 0.0034 - val_loss: 0.0119\n",
      "Epoch 2/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0104\n",
      "Epoch 3/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0086\n",
      "Epoch 4/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.8457e-04 - val_loss: 0.0060\n",
      "Epoch 5/150\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 6.0028e-04 - val_loss: 0.0037\n",
      "Epoch 6/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.4763e-04 - val_loss: 0.0024\n",
      "Epoch 7/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.1193e-04 - val_loss: 0.0013\n",
      "Epoch 8/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6673e-04 - val_loss: 4.7522e-04\n",
      "Epoch 9/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1983e-04 - val_loss: 2.0290e-04\n",
      "Epoch 10/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.0755e-04 - val_loss: 4.6330e-04\n",
      "Epoch 11/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 9.9146e-05 - val_loss: 2.8813e-04\n",
      "Epoch 12/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.7346e-04 - val_loss: 0.0017\n",
      "Epoch 13/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.9839e-04 - val_loss: 7.1088e-04\n",
      "Epoch 14/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 5.6658e-05 - val_loss: 5.8991e-04\n",
      "Epoch 15/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2963e-04 - val_loss: 5.1006e-04\n",
      "Epoch 16/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.4631e-04 - val_loss: 1.3062e-04\n",
      "Epoch 17/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.3588e-05 - val_loss: 2.4120e-04\n",
      "Epoch 18/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.3496e-05 - val_loss: 6.0299e-04\n",
      "Epoch 19/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.9782e-05 - val_loss: 2.4749e-04\n",
      "Epoch 20/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.3603e-05 - val_loss: 2.1358e-04\n",
      "Epoch 21/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.5566e-05 - val_loss: 1.7588e-04\n",
      "Epoch 22/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.0241e-05 - val_loss: 2.4649e-04\n",
      "Epoch 23/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.8637e-05 - val_loss: 3.0365e-04\n",
      "Epoch 24/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.7112e-05 - val_loss: 9.1296e-04\n",
      "Epoch 25/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.5466e-05 - val_loss: 0.0015\n",
      "Epoch 26/150\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 5.4110e-05 - val_loss: 6.3552e-04\n",
      "Epoch 27/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.8878e-05 - val_loss: 8.4515e-05\n",
      "Epoch 28/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.4874e-05 - val_loss: 4.8406e-04\n",
      "Epoch 29/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.0959e-05 - val_loss: 2.0171e-04\n",
      "Epoch 30/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.8031e-05 - val_loss: 2.9133e-04\n",
      "Epoch 31/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.1688e-05 - val_loss: 2.0242e-04\n",
      "Epoch 32/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.6651e-05 - val_loss: 1.1366e-04\n",
      "Epoch 33/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.9598e-05 - val_loss: 4.7625e-04\n",
      "Epoch 34/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.4523e-05 - val_loss: 3.6247e-04\n",
      "Epoch 35/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.8019e-05 - val_loss: 5.9367e-04\n",
      "Epoch 36/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.1359e-05 - val_loss: 1.4294e-04\n",
      "Epoch 37/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.3394e-05 - val_loss: 1.5209e-04\n",
      "Epoch 38/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.4430e-05 - val_loss: 1.4647e-04\n",
      "Epoch 39/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.7292e-05 - val_loss: 5.0947e-04\n",
      "Epoch 40/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.3155e-05 - val_loss: 8.6180e-05\n",
      "Epoch 41/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.2331e-05 - val_loss: 1.9910e-04\n",
      "Epoch 42/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.4126e-05 - val_loss: 2.0918e-04\n",
      "Epoch 43/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.9845e-05 - val_loss: 9.0914e-04\n",
      "Epoch 44/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.2109e-04 - val_loss: 8.8780e-04\n",
      "Epoch 45/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.1230e-05 - val_loss: 2.1854e-04\n",
      "Epoch 46/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.0889e-04 - val_loss: 6.9882e-05\n",
      "Epoch 47/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.0902e-05 - val_loss: 1.2520e-04\n",
      "Epoch 48/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.1120e-05 - val_loss: 4.3248e-04\n",
      "Epoch 49/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.6243e-05 - val_loss: 4.2058e-04\n",
      "Epoch 50/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.2909e-05 - val_loss: 3.7750e-04\n",
      "Epoch 51/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.4484e-05 - val_loss: 1.3151e-04\n",
      "Epoch 52/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.2590e-05 - val_loss: 1.9917e-04\n",
      "Epoch 53/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.0212e-05 - val_loss: 3.2465e-05\n",
      "Epoch 54/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.8559e-05 - val_loss: 2.1729e-04\n",
      "Epoch 55/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.4949e-05 - val_loss: 3.3271e-04\n",
      "Epoch 56/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.9744e-05 - val_loss: 7.8068e-05\n",
      "Epoch 57/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.8417e-05 - val_loss: 7.2818e-05\n",
      "Epoch 58/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.2949e-05 - val_loss: 1.3159e-04\n",
      "Epoch 59/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.9261e-05 - val_loss: 5.0993e-04\n",
      "Epoch 60/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.6557e-05 - val_loss: 7.3881e-05\n",
      "Epoch 61/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.6109e-05 - val_loss: 2.0003e-04\n",
      "Epoch 62/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.8300e-05 - val_loss: 2.8047e-04\n",
      "Epoch 63/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.3834e-05 - val_loss: 5.4291e-05\n",
      "Epoch 64/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.6791e-05 - val_loss: 1.3925e-04\n",
      "Epoch 65/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.9014e-05 - val_loss: 2.8295e-05\n",
      "Epoch 66/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.5979e-05 - val_loss: 1.4506e-04\n",
      "Epoch 67/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.9210e-05 - val_loss: 9.1068e-05\n",
      "Epoch 68/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.8611e-05 - val_loss: 1.9318e-04\n",
      "Epoch 69/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.1392e-05 - val_loss: 8.1344e-05\n",
      "Epoch 70/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.9116e-05 - val_loss: 3.9164e-04\n",
      "Epoch 71/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.4617e-05 - val_loss: 2.4999e-04\n",
      "Epoch 72/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2133e-05 - val_loss: 5.4072e-05\n",
      "Epoch 73/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.8652e-05 - val_loss: 1.6554e-04\n",
      "Epoch 74/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.5115e-05 - val_loss: 7.4118e-05\n",
      "Epoch 75/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.9225e-05 - val_loss: 3.7806e-04\n",
      "Epoch 76/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.1626e-05 - val_loss: 0.0010\n",
      "Epoch 77/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.8982e-05 - val_loss: 2.5419e-04\n",
      "Epoch 78/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.1049e-05 - val_loss: 4.1691e-04\n",
      "Epoch 79/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.7599e-05 - val_loss: 1.7969e-04\n",
      "Epoch 80/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7391e-05 - val_loss: 1.2301e-04\n",
      "Epoch 81/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.4875e-05 - val_loss: 4.1067e-05\n",
      "Epoch 82/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2475e-05 - val_loss: 6.7126e-05\n",
      "Epoch 83/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.7747e-05 - val_loss: 6.3469e-04\n",
      "Epoch 84/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.7141e-05 - val_loss: 1.3825e-04\n",
      "Epoch 85/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9706e-05 - val_loss: 2.8934e-04\n",
      "Epoch 86/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2709e-05 - val_loss: 1.5324e-04\n",
      "Epoch 87/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.5993e-05 - val_loss: 1.4737e-04\n",
      "Epoch 88/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2141e-05 - val_loss: 2.4857e-05\n",
      "Epoch 89/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.3711e-05 - val_loss: 6.6838e-05\n",
      "Epoch 90/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.0057e-05 - val_loss: 1.9786e-05\n",
      "Epoch 91/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2076e-05 - val_loss: 5.1360e-05\n",
      "Epoch 92/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2452e-05 - val_loss: 4.4438e-05\n",
      "Epoch 93/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.1867e-05 - val_loss: 1.9237e-04\n",
      "Epoch 94/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.6929e-05 - val_loss: 2.8495e-04\n",
      "Epoch 95/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.2427e-05 - val_loss: 1.3233e-04\n",
      "Epoch 96/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6424e-05 - val_loss: 5.0844e-05\n",
      "Epoch 97/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7495e-05 - val_loss: 4.3055e-05\n",
      "Epoch 98/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.3928e-05 - val_loss: 2.7069e-05\n",
      "Epoch 99/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.3218e-05 - val_loss: 1.1304e-04\n",
      "Epoch 100/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6481e-05 - val_loss: 5.6635e-05\n",
      "Epoch 101/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.4428e-05 - val_loss: 8.9049e-04\n",
      "Epoch 102/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.3885e-05 - val_loss: 4.4580e-05\n",
      "Epoch 103/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.8248e-05 - val_loss: 2.4104e-05\n",
      "Epoch 104/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.6939e-05 - val_loss: 3.8357e-05\n",
      "Epoch 105/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.5066e-05 - val_loss: 2.9979e-04\n",
      "Epoch 106/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.3477e-05 - val_loss: 6.8493e-05\n",
      "Epoch 107/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.6439e-05 - val_loss: 1.3600e-04\n",
      "Epoch 108/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6302e-05 - val_loss: 6.3310e-05\n",
      "Epoch 109/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.8344e-05 - val_loss: 1.3007e-04\n",
      "Epoch 110/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.1361e-05 - val_loss: 6.9553e-04\n",
      "Epoch 111/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.6508e-05 - val_loss: 9.8748e-05\n",
      "Epoch 112/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.1677e-05 - val_loss: 1.5171e-04\n",
      "Epoch 113/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2691e-05 - val_loss: 1.7071e-04\n",
      "Epoch 114/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3146e-05 - val_loss: 3.4403e-04\n",
      "Epoch 115/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.5747e-05 - val_loss: 0.0011\n",
      "Epoch 116/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.5770e-05 - val_loss: 2.1229e-04\n",
      "Epoch 117/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.3272e-05 - val_loss: 9.4132e-05\n",
      "Epoch 118/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.1000e-05 - val_loss: 4.2201e-04\n",
      "Epoch 119/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.2589e-05 - val_loss: 5.0259e-05\n",
      "Epoch 120/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6437e-05 - val_loss: 6.0317e-05\n",
      "Epoch 121/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.4937e-05 - val_loss: 1.8179e-04\n",
      "Epoch 122/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.7582e-05 - val_loss: 3.7892e-04\n",
      "Epoch 123/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.1778e-05 - val_loss: 4.1696e-05\n",
      "Epoch 124/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0166e-05 - val_loss: 4.6044e-05\n",
      "Epoch 125/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3840e-05 - val_loss: 3.2378e-04\n",
      "Epoch 126/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.3881e-05 - val_loss: 6.0442e-04\n",
      "Epoch 127/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0097e-05 - val_loss: 2.4621e-04\n",
      "Epoch 128/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.0410e-05 - val_loss: 4.8768e-05\n",
      "Epoch 129/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.4707e-05 - val_loss: 2.9520e-05\n",
      "Epoch 130/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.5279e-06 - val_loss: 4.4406e-05\n",
      "Epoch 131/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.2724e-05 - val_loss: 3.3049e-05\n",
      "Epoch 132/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3447e-05 - val_loss: 4.0521e-04\n",
      "Epoch 133/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9385e-05 - val_loss: 4.4230e-04\n",
      "Epoch 134/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.8698e-05 - val_loss: 2.0354e-05\n",
      "Epoch 135/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.0524e-05 - val_loss: 2.1991e-04\n",
      "Epoch 136/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.6254e-05 - val_loss: 6.3748e-04\n",
      "Epoch 137/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2299e-05 - val_loss: 7.5229e-04\n",
      "Epoch 138/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.8243e-05 - val_loss: 1.6542e-04\n",
      "Epoch 139/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9131e-05 - val_loss: 2.8771e-04\n",
      "Epoch 140/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.6898e-05 - val_loss: 2.5387e-05\n",
      "Epoch 141/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.4463e-05 - val_loss: 6.3491e-04\n",
      "Epoch 142/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.4544e-05 - val_loss: 4.9487e-05\n",
      "Epoch 143/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.1720e-05 - val_loss: 1.0089e-04\n",
      "Epoch 144/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.5335e-05 - val_loss: 1.6460e-05\n",
      "Epoch 145/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.0789e-06 - val_loss: 5.2023e-05\n",
      "Epoch 146/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.5028e-05 - val_loss: 3.7210e-04\n",
      "Epoch 147/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2942e-05 - val_loss: 9.9225e-05\n",
      "Epoch 148/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2302e-05 - val_loss: 2.0583e-04\n",
      "Epoch 149/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.5463e-05 - val_loss: 1.5152e-04\n",
      "Epoch 150/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.1201e-05 - val_loss: 1.5694e-04\n",
      ">7: Score=8.219217124860734e-05\n",
      "Epoch 1/150\n",
      "68/68 [==============================] - 9s 32ms/step - loss: 0.0032 - val_loss: 0.0112\n",
      "Epoch 2/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 3/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.4299e-04 - val_loss: 0.0081\n",
      "Epoch 4/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.0061e-04 - val_loss: 0.0060\n",
      "Epoch 5/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.8873e-04 - val_loss: 0.0043\n",
      "Epoch 6/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.2562e-04 - val_loss: 0.0028\n",
      "Epoch 7/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.3104e-04 - val_loss: 0.0014\n",
      "Epoch 8/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.4024e-04 - val_loss: 5.9500e-04\n",
      "Epoch 9/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5701e-04 - val_loss: 2.8699e-04\n",
      "Epoch 10/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1591e-04 - val_loss: 1.5186e-04\n",
      "Epoch 11/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.3349e-04 - val_loss: 1.7370e-04\n",
      "Epoch 12/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.8282e-05 - val_loss: 3.7967e-04\n",
      "Epoch 13/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.6647e-05 - val_loss: 4.1536e-04\n",
      "Epoch 14/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.1670e-05 - val_loss: 0.0010\n",
      "Epoch 15/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1904e-04 - val_loss: 5.3912e-04\n",
      "Epoch 16/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1125e-04 - val_loss: 4.2738e-04\n",
      "Epoch 17/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.1243e-05 - val_loss: 5.3769e-04\n",
      "Epoch 18/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6030e-04 - val_loss: 0.0022\n",
      "Epoch 19/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.5092e-04 - val_loss: 0.0018\n",
      "Epoch 20/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.4902e-05 - val_loss: 1.8870e-04\n",
      "Epoch 21/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.0202e-05 - val_loss: 4.2844e-04\n",
      "Epoch 22/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.0179e-05 - val_loss: 2.4594e-04\n",
      "Epoch 23/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.6834e-05 - val_loss: 1.5415e-04\n",
      "Epoch 24/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.9447e-05 - val_loss: 2.2257e-04\n",
      "Epoch 25/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.0880e-05 - val_loss: 7.0029e-04\n",
      "Epoch 26/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.4019e-05 - val_loss: 2.9814e-04\n",
      "Epoch 27/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.5771e-05 - val_loss: 4.5640e-04\n",
      "Epoch 28/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.9807e-05 - val_loss: 3.0214e-04\n",
      "Epoch 29/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 9.2582e-05 - val_loss: 5.1760e-04\n",
      "Epoch 30/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.0343e-04 - val_loss: 2.6624e-04\n",
      "Epoch 31/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.0340e-04 - val_loss: 1.7359e-04\n",
      "Epoch 32/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.5579e-05 - val_loss: 1.0758e-04\n",
      "Epoch 33/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 8.1004e-05 - val_loss: 5.0606e-04\n",
      "Epoch 34/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.5145e-05 - val_loss: 1.0588e-04\n",
      "Epoch 35/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.4449e-05 - val_loss: 2.3931e-04\n",
      "Epoch 36/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.1009e-05 - val_loss: 0.0010\n",
      "Epoch 37/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.9687e-05 - val_loss: 2.8695e-04\n",
      "Epoch 38/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.0778e-05 - val_loss: 1.6445e-04\n",
      "Epoch 39/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.1872e-05 - val_loss: 1.1487e-04\n",
      "Epoch 40/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.3464e-05 - val_loss: 8.5158e-04\n",
      "Epoch 41/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.6524e-05 - val_loss: 7.2501e-04\n",
      "Epoch 42/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 9.5209e-05 - val_loss: 2.3618e-04\n",
      "Epoch 43/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.3216e-05 - val_loss: 0.0013\n",
      "Epoch 44/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.9172e-05 - val_loss: 1.0128e-04\n",
      "Epoch 45/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.3223e-05 - val_loss: 2.2699e-04\n",
      "Epoch 46/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.9915e-05 - val_loss: 2.2902e-04\n",
      "Epoch 47/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9909e-05 - val_loss: 2.8118e-04\n",
      "Epoch 48/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.3196e-05 - val_loss: 4.3167e-04\n",
      "Epoch 49/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2219e-05 - val_loss: 5.3083e-05\n",
      "Epoch 50/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.6876e-05 - val_loss: 1.0956e-04\n",
      "Epoch 51/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.8664e-05 - val_loss: 6.4007e-05\n",
      "Epoch 52/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.7578e-05 - val_loss: 2.5975e-04\n",
      "Epoch 53/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.0263e-05 - val_loss: 1.2987e-04\n",
      "Epoch 54/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.6207e-05 - val_loss: 1.2634e-04\n",
      "Epoch 55/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.2473e-05 - val_loss: 4.3328e-04\n",
      "Epoch 56/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.1975e-05 - val_loss: 2.2676e-04\n",
      "Epoch 57/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.7659e-05 - val_loss: 1.2180e-04\n",
      "Epoch 58/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2510e-05 - val_loss: 4.5229e-05\n",
      "Epoch 59/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.3544e-05 - val_loss: 1.4032e-04\n",
      "Epoch 60/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.6885e-05 - val_loss: 2.6626e-05\n",
      "Epoch 61/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.9351e-05 - val_loss: 5.2068e-04\n",
      "Epoch 62/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 4.2401e-05 - val_loss: 4.0551e-04\n",
      "Epoch 63/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.4868e-05 - val_loss: 4.2780e-05\n",
      "Epoch 64/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.5155e-05 - val_loss: 2.9250e-04\n",
      "Epoch 65/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.5315e-05 - val_loss: 2.0962e-04\n",
      "Epoch 66/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.2650e-05 - val_loss: 1.0174e-04\n",
      "Epoch 67/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.1239e-05 - val_loss: 5.6582e-05\n",
      "Epoch 68/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7220e-05 - val_loss: 2.7414e-04\n",
      "Epoch 69/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.2711e-05 - val_loss: 2.6172e-04\n",
      "Epoch 70/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.7157e-05 - val_loss: 4.6482e-04\n",
      "Epoch 71/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.1503e-05 - val_loss: 4.7190e-04\n",
      "Epoch 72/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.2265e-05 - val_loss: 6.7617e-05\n",
      "Epoch 73/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.8435e-05 - val_loss: 3.3414e-04\n",
      "Epoch 74/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.1264e-05 - val_loss: 1.0500e-04\n",
      "Epoch 75/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.8890e-05 - val_loss: 1.5455e-04\n",
      "Epoch 76/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.1031e-05 - val_loss: 1.8506e-04\n",
      "Epoch 77/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.8902e-05 - val_loss: 1.5539e-04\n",
      "Epoch 78/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.6029e-05 - val_loss: 2.3557e-05\n",
      "Epoch 79/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.6174e-05 - val_loss: 4.0576e-05\n",
      "Epoch 80/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.4563e-05 - val_loss: 2.3911e-04\n",
      "Epoch 81/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.1663e-05 - val_loss: 8.9386e-05\n",
      "Epoch 82/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.0782e-05 - val_loss: 5.6618e-05\n",
      "Epoch 83/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.6600e-05 - val_loss: 3.4951e-04\n",
      "Epoch 84/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.9533e-05 - val_loss: 3.7521e-04\n",
      "Epoch 85/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.5083e-05 - val_loss: 1.0377e-04\n",
      "Epoch 86/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.0824e-05 - val_loss: 1.1607e-04\n",
      "Epoch 87/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.1826e-05 - val_loss: 3.4223e-04\n",
      "Epoch 88/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.9960e-05 - val_loss: 6.6605e-04\n",
      "Epoch 89/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.4667e-05 - val_loss: 4.1644e-04\n",
      "Epoch 90/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.9809e-05 - val_loss: 9.8037e-04\n",
      "Epoch 91/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.5920e-05 - val_loss: 4.3431e-05\n",
      "Epoch 92/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.3063e-05 - val_loss: 1.2995e-04\n",
      "Epoch 93/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.4925e-05 - val_loss: 3.3261e-05\n",
      "Epoch 94/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5680e-05 - val_loss: 2.7735e-04\n",
      "Epoch 95/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.4511e-05 - val_loss: 2.9553e-05\n",
      "Epoch 96/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.2131e-05 - val_loss: 6.0436e-05\n",
      "Epoch 97/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.8811e-05 - val_loss: 3.6620e-04\n",
      "Epoch 98/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2748e-05 - val_loss: 2.3135e-04\n",
      "Epoch 99/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5715e-05 - val_loss: 6.1308e-05\n",
      "Epoch 100/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.5403e-05 - val_loss: 4.4597e-05\n",
      "Epoch 101/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3044e-05 - val_loss: 1.7893e-04\n",
      "Epoch 102/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.4209e-05 - val_loss: 4.5701e-04\n",
      "Epoch 103/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.0858e-05 - val_loss: 2.1637e-04\n",
      "Epoch 104/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.4460e-05 - val_loss: 6.4467e-05\n",
      "Epoch 105/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.4056e-05 - val_loss: 1.8402e-04\n",
      "Epoch 106/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.5054e-05 - val_loss: 2.7095e-05\n",
      "Epoch 107/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9105e-05 - val_loss: 6.7369e-05\n",
      "Epoch 108/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7783e-05 - val_loss: 4.7038e-05\n",
      "Epoch 109/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.3330e-05 - val_loss: 5.0158e-05\n",
      "Epoch 110/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0989e-05 - val_loss: 6.5307e-05\n",
      "Epoch 111/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.7620e-05 - val_loss: 2.1819e-04\n",
      "Epoch 112/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7712e-05 - val_loss: 5.9515e-04\n",
      "Epoch 113/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.7258e-05 - val_loss: 2.0903e-04\n",
      "Epoch 114/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5320e-05 - val_loss: 1.0016e-04\n",
      "Epoch 115/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5503e-05 - val_loss: 2.5925e-05\n",
      "Epoch 116/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 9.9957e-06 - val_loss: 3.3935e-05\n",
      "Epoch 117/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 9.5633e-06 - val_loss: 2.1925e-05\n",
      "Epoch 118/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.3048e-05 - val_loss: 2.4221e-04\n",
      "Epoch 119/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.7913e-05 - val_loss: 8.3075e-05\n",
      "Epoch 120/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.8916e-05 - val_loss: 8.8579e-05\n",
      "Epoch 121/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.2953e-05 - val_loss: 2.2996e-05\n",
      "Epoch 122/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.3947e-05 - val_loss: 4.6363e-04\n",
      "Epoch 123/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.1489e-05 - val_loss: 1.3592e-04\n",
      "Epoch 124/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.1213e-05 - val_loss: 1.0260e-04\n",
      "Epoch 125/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6126e-05 - val_loss: 4.1220e-05\n",
      "Epoch 126/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7035e-05 - val_loss: 2.8423e-04\n",
      "Epoch 127/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6478e-05 - val_loss: 2.4364e-04\n",
      "Epoch 128/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.9605e-05 - val_loss: 8.3200e-04\n",
      "Epoch 129/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.4013e-05 - val_loss: 3.2185e-05\n",
      "Epoch 130/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.3653e-05 - val_loss: 2.1727e-04\n",
      "Epoch 131/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.9295e-05 - val_loss: 2.7816e-04\n",
      "Epoch 132/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.8573e-05 - val_loss: 1.3620e-04\n",
      "Epoch 133/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.7607e-05 - val_loss: 1.8396e-04\n",
      "Epoch 134/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3363e-05 - val_loss: 5.7358e-06\n",
      "Epoch 135/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.4972e-06 - val_loss: 9.1677e-05\n",
      "Epoch 136/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.2738e-05 - val_loss: 7.4443e-04\n",
      "Epoch 137/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.6086e-05 - val_loss: 4.2063e-05\n",
      "Epoch 138/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.5325e-05 - val_loss: 3.7208e-05\n",
      "Epoch 139/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.2624e-05 - val_loss: 1.6652e-05\n",
      "Epoch 140/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.0734e-05 - val_loss: 6.7670e-05\n",
      "Epoch 141/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5287e-05 - val_loss: 2.1048e-04\n",
      "Epoch 142/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1692e-05 - val_loss: 1.4933e-04\n",
      "Epoch 143/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.1208e-05 - val_loss: 5.1921e-04\n",
      "Epoch 144/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.8474e-05 - val_loss: 1.9904e-04\n",
      "Epoch 145/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.1411e-05 - val_loss: 4.7220e-05\n",
      "Epoch 146/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.7079e-05 - val_loss: 1.7532e-04\n",
      "Epoch 147/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.4966e-05 - val_loss: 3.5879e-04\n",
      "Epoch 148/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.1886e-06 - val_loss: 8.3801e-05\n",
      "Epoch 149/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.3055e-06 - val_loss: 2.2266e-05\n",
      "Epoch 150/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.6792e-05 - val_loss: 6.9791e-05\n",
      ">8: Score=4.909060589852743e-05\n",
      "Epoch 1/150\n",
      "68/68 [==============================] - 10s 35ms/step - loss: 0.0032 - val_loss: 0.0108\n",
      "Epoch 2/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 3/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 9.1837e-04 - val_loss: 0.0072\n",
      "Epoch 4/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.1589e-04 - val_loss: 0.0048\n",
      "Epoch 5/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.3324e-04 - val_loss: 0.0027\n",
      "Epoch 6/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.4125e-04 - val_loss: 0.0011\n",
      "Epoch 7/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2055e-04 - val_loss: 9.0005e-04\n",
      "Epoch 8/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.4177e-04 - val_loss: 4.5894e-04\n",
      "Epoch 9/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9561e-04 - val_loss: 9.7748e-04\n",
      "Epoch 10/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6004e-04 - val_loss: 2.8568e-04\n",
      "Epoch 11/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.3926e-04 - val_loss: 6.4440e-04\n",
      "Epoch 12/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1743e-04 - val_loss: 0.0012\n",
      "Epoch 13/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6299e-04 - val_loss: 2.7467e-04\n",
      "Epoch 14/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1031e-04 - val_loss: 6.1612e-04\n",
      "Epoch 15/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.7700e-05 - val_loss: 1.8270e-04\n",
      "Epoch 16/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.0366e-05 - val_loss: 7.8938e-04\n",
      "Epoch 17/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.3720e-05 - val_loss: 7.1844e-04\n",
      "Epoch 18/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.3262e-05 - val_loss: 1.9241e-04\n",
      "Epoch 19/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.4980e-05 - val_loss: 5.1592e-04\n",
      "Epoch 20/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.9837e-05 - val_loss: 3.6179e-04\n",
      "Epoch 21/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.4755e-05 - val_loss: 3.9805e-04\n",
      "Epoch 22/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.7363e-05 - val_loss: 1.2439e-04\n",
      "Epoch 23/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.9216e-05 - val_loss: 1.4599e-04\n",
      "Epoch 24/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 6.7810e-05 - val_loss: 7.4186e-04\n",
      "Epoch 25/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.7511e-05 - val_loss: 4.8541e-04\n",
      "Epoch 26/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.8952e-05 - val_loss: 2.3546e-04\n",
      "Epoch 27/150\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 5.0705e-05 - val_loss: 1.8423e-04\n",
      "Epoch 28/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.0195e-05 - val_loss: 5.2177e-04\n",
      "Epoch 29/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.4929e-05 - val_loss: 5.9901e-04\n",
      "Epoch 30/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 7.2414e-05 - val_loss: 3.0213e-04\n",
      "Epoch 31/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.5470e-05 - val_loss: 1.1501e-04\n",
      "Epoch 32/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.8633e-05 - val_loss: 2.7149e-04\n",
      "Epoch 33/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.6842e-05 - val_loss: 6.9792e-04\n",
      "Epoch 34/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.3315e-05 - val_loss: 6.3779e-05\n",
      "Epoch 35/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.1092e-05 - val_loss: 1.5029e-04\n",
      "Epoch 36/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.3291e-05 - val_loss: 8.6699e-05\n",
      "Epoch 37/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.2972e-05 - val_loss: 8.4989e-05\n",
      "Epoch 38/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.9637e-05 - val_loss: 7.1866e-04\n",
      "Epoch 39/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.6078e-05 - val_loss: 2.9510e-04\n",
      "Epoch 40/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.7595e-05 - val_loss: 3.7350e-05\n",
      "Epoch 41/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.9733e-05 - val_loss: 6.1129e-05\n",
      "Epoch 42/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.7373e-05 - val_loss: 5.2024e-05\n",
      "Epoch 43/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.1295e-05 - val_loss: 2.4421e-04\n",
      "Epoch 44/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.9529e-05 - val_loss: 3.0737e-04\n",
      "Epoch 45/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.6190e-05 - val_loss: 1.2294e-04\n",
      "Epoch 46/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.9947e-05 - val_loss: 1.8522e-04\n",
      "Epoch 47/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.2158e-05 - val_loss: 2.3908e-04\n",
      "Epoch 48/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.3282e-05 - val_loss: 1.6138e-04\n",
      "Epoch 49/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.4938e-05 - val_loss: 2.1155e-04\n",
      "Epoch 50/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.4737e-05 - val_loss: 1.4639e-04\n",
      "Epoch 51/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.1001e-05 - val_loss: 1.8429e-04\n",
      "Epoch 52/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.1563e-05 - val_loss: 2.9607e-04\n",
      "Epoch 53/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.3084e-05 - val_loss: 3.2961e-04\n",
      "Epoch 54/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.6917e-05 - val_loss: 3.4508e-05\n",
      "Epoch 55/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.5370e-05 - val_loss: 3.8519e-05\n",
      "Epoch 56/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.8994e-05 - val_loss: 3.4628e-04\n",
      "Epoch 57/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.5272e-05 - val_loss: 3.1163e-04\n",
      "Epoch 58/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.7866e-05 - val_loss: 6.9193e-05\n",
      "Epoch 59/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.7148e-05 - val_loss: 1.6679e-04\n",
      "Epoch 60/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.2501e-05 - val_loss: 4.0442e-05\n",
      "Epoch 61/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.6564e-05 - val_loss: 3.9656e-05\n",
      "Epoch 62/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.3714e-05 - val_loss: 9.6963e-05\n",
      "Epoch 63/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7347e-05 - val_loss: 2.6126e-04\n",
      "Epoch 64/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.8661e-05 - val_loss: 4.4342e-04\n",
      "Epoch 65/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.6673e-05 - val_loss: 1.4322e-04\n",
      "Epoch 66/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 4.0668e-05 - val_loss: 1.4543e-04\n",
      "Epoch 67/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.2184e-05 - val_loss: 3.6087e-05\n",
      "Epoch 68/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.9373e-05 - val_loss: 1.8272e-04\n",
      "Epoch 69/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.9175e-05 - val_loss: 2.4236e-04\n",
      "Epoch 70/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.2096e-05 - val_loss: 2.2815e-04\n",
      "Epoch 71/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7466e-05 - val_loss: 9.4384e-05\n",
      "Epoch 72/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.6634e-05 - val_loss: 8.4432e-04\n",
      "Epoch 73/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.7283e-05 - val_loss: 0.0011\n",
      "Epoch 74/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.2704e-05 - val_loss: 2.1222e-05\n",
      "Epoch 75/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.3621e-05 - val_loss: 8.2091e-05\n",
      "Epoch 76/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.8020e-05 - val_loss: 4.0285e-05\n",
      "Epoch 77/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.7856e-06 - val_loss: 3.7921e-05\n",
      "Epoch 78/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2721e-05 - val_loss: 1.3963e-04\n",
      "Epoch 79/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.8245e-05 - val_loss: 4.1688e-04\n",
      "Epoch 80/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.0299e-05 - val_loss: 1.0621e-04\n",
      "Epoch 81/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.8354e-05 - val_loss: 1.2058e-04\n",
      "Epoch 82/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7950e-05 - val_loss: 7.4784e-05\n",
      "Epoch 83/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.9839e-05 - val_loss: 1.1307e-04\n",
      "Epoch 84/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.0942e-05 - val_loss: 3.9545e-04\n",
      "Epoch 85/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.2017e-05 - val_loss: 5.6324e-04\n",
      "Epoch 86/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 3.1867e-05 - val_loss: 9.4455e-05\n",
      "Epoch 87/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.8403e-05 - val_loss: 6.4625e-04\n",
      "Epoch 88/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.8351e-05 - val_loss: 1.9405e-05\n",
      "Epoch 89/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.8826e-05 - val_loss: 6.6924e-04\n",
      "Epoch 90/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7457e-05 - val_loss: 1.5514e-05\n",
      "Epoch 91/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.1044e-05 - val_loss: 4.5326e-05\n",
      "Epoch 92/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.0415e-05 - val_loss: 1.0769e-04\n",
      "Epoch 93/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.1634e-05 - val_loss: 1.6861e-04\n",
      "Epoch 94/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.5638e-05 - val_loss: 8.5212e-05\n",
      "Epoch 95/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.1215e-05 - val_loss: 2.3584e-05\n",
      "Epoch 96/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.7657e-05 - val_loss: 5.0201e-05\n",
      "Epoch 97/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7032e-05 - val_loss: 6.2570e-04\n",
      "Epoch 98/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.5458e-05 - val_loss: 9.4304e-04\n",
      "Epoch 99/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.9394e-05 - val_loss: 3.3437e-04\n",
      "Epoch 100/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.0187e-05 - val_loss: 7.6828e-05\n",
      "Epoch 101/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.5001e-05 - val_loss: 3.3062e-05\n",
      "Epoch 102/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.4102e-05 - val_loss: 3.9721e-04\n",
      "Epoch 103/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.5241e-05 - val_loss: 1.2546e-04\n",
      "Epoch 104/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.6208e-05 - val_loss: 1.7407e-04\n",
      "Epoch 105/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.8554e-05 - val_loss: 6.4056e-05\n",
      "Epoch 106/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.5367e-05 - val_loss: 1.6442e-04\n",
      "Epoch 107/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.3265e-05 - val_loss: 7.5496e-06\n",
      "Epoch 108/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3978e-05 - val_loss: 4.1079e-05\n",
      "Epoch 109/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.0013e-05 - val_loss: 8.9176e-05\n",
      "Epoch 110/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7085e-05 - val_loss: 1.2814e-05\n",
      "Epoch 111/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1870e-05 - val_loss: 1.1925e-05\n",
      "Epoch 112/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2116e-05 - val_loss: 2.6623e-05\n",
      "Epoch 113/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.1633e-05 - val_loss: 2.5482e-04\n",
      "Epoch 114/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1542e-05 - val_loss: 4.9625e-05\n",
      "Epoch 115/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.7785e-05 - val_loss: 1.3793e-05\n",
      "Epoch 116/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 2.9876e-05 - val_loss: 1.9300e-04\n",
      "Epoch 117/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.4228e-05 - val_loss: 3.6269e-04\n",
      "Epoch 118/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.3881e-05 - val_loss: 5.1579e-05\n",
      "Epoch 119/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.1207e-05 - val_loss: 2.7320e-05\n",
      "Epoch 120/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.4892e-06 - val_loss: 7.6600e-05\n",
      "Epoch 121/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.3749e-05 - val_loss: 3.4835e-04\n",
      "Epoch 122/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2054e-05 - val_loss: 7.1238e-05\n",
      "Epoch 123/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.4820e-06 - val_loss: 1.5108e-05\n",
      "Epoch 124/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.2889e-05 - val_loss: 3.5257e-04\n",
      "Epoch 125/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.5591e-05 - val_loss: 1.9620e-04\n",
      "Epoch 126/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.3178e-05 - val_loss: 1.5072e-04\n",
      "Epoch 127/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6513e-05 - val_loss: 9.1105e-05\n",
      "Epoch 128/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.0601e-05 - val_loss: 4.2905e-05\n",
      "Epoch 129/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 9.0165e-06 - val_loss: 1.5906e-05\n",
      "Epoch 130/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1417e-05 - val_loss: 1.7715e-05\n",
      "Epoch 131/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.3434e-05 - val_loss: 2.7846e-04\n",
      "Epoch 132/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3466e-05 - val_loss: 2.3545e-05\n",
      "Epoch 133/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.8258e-05 - val_loss: 6.1598e-04\n",
      "Epoch 134/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.9908e-05 - val_loss: 1.2297e-04\n",
      "Epoch 135/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.5261e-05 - val_loss: 1.4192e-04\n",
      "Epoch 136/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7187e-05 - val_loss: 4.7774e-05\n",
      "Epoch 137/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.2155e-05 - val_loss: 1.5975e-05\n",
      "Epoch 138/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.9449e-05 - val_loss: 3.5441e-05\n",
      "Epoch 139/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.5918e-06 - val_loss: 2.9617e-05\n",
      "Epoch 140/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.5473e-06 - val_loss: 6.2247e-05\n",
      "Epoch 141/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.3266e-05 - val_loss: 7.3190e-05\n",
      "Epoch 142/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2891e-05 - val_loss: 1.0233e-05\n",
      "Epoch 143/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.0054e-05 - val_loss: 2.1315e-05\n",
      "Epoch 144/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.1104e-05 - val_loss: 3.8710e-04\n",
      "Epoch 145/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.5175e-05 - val_loss: 9.0312e-04\n",
      "Epoch 146/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.8960e-05 - val_loss: 9.1028e-05\n",
      "Epoch 147/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.0238e-05 - val_loss: 7.6767e-04\n",
      "Epoch 148/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.0853e-05 - val_loss: 2.5281e-04\n",
      "Epoch 149/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.2422e-05 - val_loss: 4.5503e-05\n",
      "Epoch 150/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.8981e-05 - val_loss: 3.1844e-05\n",
      ">9: Score=4.0671522583579645e-05\n",
      "Epoch 1/150\n",
      "68/68 [==============================] - 9s 29ms/step - loss: 0.0035 - val_loss: 0.0114\n",
      "Epoch 2/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0096\n",
      "Epoch 3/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.2129e-04 - val_loss: 0.0074\n",
      "Epoch 4/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.7120e-04 - val_loss: 0.0049\n",
      "Epoch 5/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.8228e-04 - val_loss: 0.0033\n",
      "Epoch 6/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.0233e-04 - val_loss: 0.0016\n",
      "Epoch 7/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.2901e-04 - val_loss: 5.5903e-04\n",
      "Epoch 8/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.4208e-04 - val_loss: 2.4594e-04\n",
      "Epoch 9/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.4130e-05 - val_loss: 2.1959e-04\n",
      "Epoch 10/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.4028e-05 - val_loss: 4.2107e-04\n",
      "Epoch 11/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.8229e-05 - val_loss: 4.5009e-04\n",
      "Epoch 12/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1529e-04 - val_loss: 4.3597e-04\n",
      "Epoch 13/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.0359e-04 - val_loss: 5.6101e-04\n",
      "Epoch 14/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1930e-04 - val_loss: 7.4144e-04\n",
      "Epoch 15/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.3451e-04 - val_loss: 7.1232e-04\n",
      "Epoch 16/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2127e-04 - val_loss: 9.7970e-05\n",
      "Epoch 17/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 7.2706e-05 - val_loss: 1.6907e-04\n",
      "Epoch 18/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.4966e-05 - val_loss: 4.0988e-04\n",
      "Epoch 19/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.2168e-05 - val_loss: 2.1208e-04\n",
      "Epoch 20/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.6737e-05 - val_loss: 1.8615e-04\n",
      "Epoch 21/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.3167e-05 - val_loss: 3.3365e-04\n",
      "Epoch 22/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.1232e-05 - val_loss: 2.9113e-04\n",
      "Epoch 23/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 8.7950e-05 - val_loss: 2.9148e-04\n",
      "Epoch 24/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 6.4526e-05 - val_loss: 3.2564e-04\n",
      "Epoch 25/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 5.5618e-05 - val_loss: 6.9595e-04\n",
      "Epoch 26/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.7379e-05 - val_loss: 4.8303e-04\n",
      "Epoch 27/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.6359e-05 - val_loss: 3.3439e-04\n",
      "Epoch 28/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.4882e-05 - val_loss: 0.0011\n",
      "Epoch 29/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 9.7652e-05 - val_loss: 9.4036e-05\n",
      "Epoch 30/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 7.4665e-05 - val_loss: 2.5723e-04\n",
      "Epoch 31/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 5.7564e-05 - val_loss: 2.7226e-04\n",
      "Epoch 32/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 9.1938e-05 - val_loss: 6.1633e-04\n",
      "Epoch 33/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 7.0921e-05 - val_loss: 1.0303e-04\n",
      "Epoch 34/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.6067e-05 - val_loss: 1.0643e-04\n",
      "Epoch 35/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.8681e-05 - val_loss: 5.1015e-04\n",
      "Epoch 36/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.5292e-05 - val_loss: 8.5700e-05\n",
      "Epoch 37/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.9747e-05 - val_loss: 1.6157e-04\n",
      "Epoch 38/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.8706e-05 - val_loss: 5.4567e-04\n",
      "Epoch 39/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.6673e-05 - val_loss: 6.7276e-04\n",
      "Epoch 40/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.5279e-05 - val_loss: 3.8293e-04\n",
      "Epoch 41/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.3839e-05 - val_loss: 5.3022e-04\n",
      "Epoch 42/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 4.7022e-05 - val_loss: 2.9630e-04\n",
      "Epoch 43/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 4.7831e-05 - val_loss: 3.2297e-04\n",
      "Epoch 44/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7346e-05 - val_loss: 2.1854e-04\n",
      "Epoch 45/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.7196e-05 - val_loss: 3.9635e-05\n",
      "Epoch 46/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7612e-05 - val_loss: 1.2716e-04\n",
      "Epoch 47/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 3.1153e-05 - val_loss: 4.6415e-04\n",
      "Epoch 48/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.2008e-05 - val_loss: 3.8964e-04\n",
      "Epoch 49/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.1721e-05 - val_loss: 1.8178e-04\n",
      "Epoch 50/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.1267e-05 - val_loss: 2.7730e-05\n",
      "Epoch 51/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.1430e-05 - val_loss: 3.0431e-04\n",
      "Epoch 52/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7767e-05 - val_loss: 3.9204e-04\n",
      "Epoch 53/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.8820e-05 - val_loss: 1.1945e-04\n",
      "Epoch 54/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.7061e-05 - val_loss: 8.7787e-05\n",
      "Epoch 55/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 6.4441e-05 - val_loss: 6.3527e-04\n",
      "Epoch 56/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.8858e-05 - val_loss: 6.4202e-05\n",
      "Epoch 57/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.3135e-05 - val_loss: 4.2347e-05\n",
      "Epoch 58/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.7664e-05 - val_loss: 3.5978e-05\n",
      "Epoch 59/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5549e-05 - val_loss: 2.0440e-05\n",
      "Epoch 60/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.6792e-05 - val_loss: 8.7872e-05\n",
      "Epoch 61/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.5644e-05 - val_loss: 2.4696e-04\n",
      "Epoch 62/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7233e-05 - val_loss: 3.5826e-05\n",
      "Epoch 63/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.6004e-05 - val_loss: 3.2988e-04\n",
      "Epoch 64/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.6218e-05 - val_loss: 5.3975e-05\n",
      "Epoch 65/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.9145e-05 - val_loss: 1.2684e-04\n",
      "Epoch 66/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.2586e-05 - val_loss: 3.1383e-05\n",
      "Epoch 67/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.7417e-05 - val_loss: 5.5659e-05\n",
      "Epoch 68/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.7979e-05 - val_loss: 1.3792e-04\n",
      "Epoch 69/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.3799e-05 - val_loss: 4.2348e-05\n",
      "Epoch 70/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0936e-05 - val_loss: 1.3897e-04\n",
      "Epoch 71/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1847e-05 - val_loss: 1.7048e-05\n",
      "Epoch 72/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.1874e-05 - val_loss: 6.2917e-04\n",
      "Epoch 73/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.5368e-05 - val_loss: 2.2414e-05\n",
      "Epoch 74/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.7884e-05 - val_loss: 3.9693e-04\n",
      "Epoch 75/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7351e-05 - val_loss: 6.3791e-05\n",
      "Epoch 76/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.0766e-05 - val_loss: 5.0600e-04\n",
      "Epoch 77/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 6.2238e-05 - val_loss: 2.1830e-04\n",
      "Epoch 78/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.9739e-05 - val_loss: 4.1524e-05\n",
      "Epoch 79/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.5376e-05 - val_loss: 1.6613e-04\n",
      "Epoch 80/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.7126e-05 - val_loss: 3.5033e-05\n",
      "Epoch 81/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.5767e-05 - val_loss: 6.0418e-05\n",
      "Epoch 82/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.1287e-05 - val_loss: 4.0526e-05\n",
      "Epoch 83/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.4116e-05 - val_loss: 9.1212e-05\n",
      "Epoch 84/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.0187e-05 - val_loss: 4.2366e-05\n",
      "Epoch 85/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.7419e-05 - val_loss: 7.3283e-05\n",
      "Epoch 86/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.9691e-05 - val_loss: 5.6368e-05\n",
      "Epoch 87/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.2715e-05 - val_loss: 4.1767e-04\n",
      "Epoch 88/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.7728e-05 - val_loss: 8.5169e-06\n",
      "Epoch 89/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.6392e-05 - val_loss: 1.1942e-04\n",
      "Epoch 90/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.3430e-05 - val_loss: 9.4251e-05\n",
      "Epoch 91/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.6295e-05 - val_loss: 2.1475e-05\n",
      "Epoch 92/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.0755e-05 - val_loss: 2.1042e-04\n",
      "Epoch 93/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.5329e-05 - val_loss: 7.9128e-05\n",
      "Epoch 94/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.8543e-05 - val_loss: 4.0300e-04\n",
      "Epoch 95/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.9345e-05 - val_loss: 2.5501e-05\n",
      "Epoch 96/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0109e-05 - val_loss: 1.4737e-04\n",
      "Epoch 97/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.7372e-05 - val_loss: 0.0013\n",
      "Epoch 98/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.1500e-05 - val_loss: 6.8961e-05\n",
      "Epoch 99/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.9930e-05 - val_loss: 1.4572e-04\n",
      "Epoch 100/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.1313e-05 - val_loss: 2.2947e-04\n",
      "Epoch 101/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.1563e-05 - val_loss: 9.2211e-05\n",
      "Epoch 102/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.7141e-05 - val_loss: 7.5345e-05\n",
      "Epoch 103/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3223e-05 - val_loss: 4.2908e-05\n",
      "Epoch 104/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.4065e-05 - val_loss: 8.4548e-05\n",
      "Epoch 105/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.7786e-05 - val_loss: 3.6439e-04\n",
      "Epoch 106/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.7519e-05 - val_loss: 1.2625e-04\n",
      "Epoch 107/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.0785e-05 - val_loss: 2.9384e-05\n",
      "Epoch 108/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.4440e-05 - val_loss: 1.1182e-04\n",
      "Epoch 109/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.9866e-05 - val_loss: 1.8303e-04\n",
      "Epoch 110/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.0010e-05 - val_loss: 2.4770e-05\n",
      "Epoch 111/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.2922e-05 - val_loss: 1.2970e-04\n",
      "Epoch 112/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 1.3387e-05 - val_loss: 1.7100e-05\n",
      "Epoch 113/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1880e-05 - val_loss: 1.6978e-04\n",
      "Epoch 114/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3116e-05 - val_loss: 7.4363e-05\n",
      "Epoch 115/150\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 2.2352e-05 - val_loss: 4.6730e-04\n",
      "Epoch 116/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.5166e-05 - val_loss: 5.5309e-04\n",
      "Epoch 117/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.5312e-05 - val_loss: 2.4576e-05\n",
      "Epoch 118/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.7490e-05 - val_loss: 1.2591e-04\n",
      "Epoch 119/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 8.7806e-06 - val_loss: 6.2889e-05\n",
      "Epoch 120/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1.3124e-05 - val_loss: 1.0369e-05\n",
      "Epoch 121/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1116e-05 - val_loss: 1.3004e-05\n",
      "Epoch 122/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.0437e-05 - val_loss: 2.6658e-04\n",
      "Epoch 123/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.7971e-05 - val_loss: 2.5193e-04\n",
      "Epoch 124/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.1493e-05 - val_loss: 1.1814e-04\n",
      "Epoch 125/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.8681e-05 - val_loss: 2.6327e-04\n",
      "Epoch 126/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 9.7069e-06 - val_loss: 9.8837e-06\n",
      "Epoch 127/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.8388e-05 - val_loss: 4.1026e-04\n",
      "Epoch 128/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.8520e-05 - val_loss: 3.3592e-04\n",
      "Epoch 129/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.7353e-05 - val_loss: 7.5371e-05\n",
      "Epoch 130/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.7977e-05 - val_loss: 2.5883e-04\n",
      "Epoch 131/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.8043e-05 - val_loss: 4.5012e-05\n",
      "Epoch 132/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 1.6262e-05 - val_loss: 3.0441e-04\n",
      "Epoch 133/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.2571e-05 - val_loss: 1.2322e-04\n",
      "Epoch 134/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.0463e-05 - val_loss: 5.0024e-04\n",
      "Epoch 135/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.5125e-05 - val_loss: 6.5431e-04\n",
      "Epoch 136/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3203e-05 - val_loss: 3.6051e-04\n",
      "Epoch 137/150\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2.4561e-05 - val_loss: 1.3049e-04\n",
      "Epoch 138/150\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 4.1408e-05 - val_loss: 2.4161e-04\n",
      "Epoch 139/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3088e-05 - val_loss: 1.6757e-04\n",
      "Epoch 140/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.8066e-05 - val_loss: 5.6566e-05\n",
      "Epoch 141/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1.6267e-05 - val_loss: 1.3264e-05\n",
      "Epoch 142/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2262e-05 - val_loss: 7.5982e-05\n",
      "Epoch 143/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 3.0793e-05 - val_loss: 1.7020e-04\n",
      "Epoch 144/150\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 2.2639e-05 - val_loss: 1.8109e-04\n",
      "Epoch 145/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 3.4539e-05 - val_loss: 3.1757e-04\n",
      "Epoch 146/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2.9282e-05 - val_loss: 5.6548e-05\n",
      "Epoch 147/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 4.9885e-05 - val_loss: 5.7699e-04\n",
      "Epoch 148/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.1375e-05 - val_loss: 6.0512e-05\n",
      "Epoch 149/150\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.1786e-05 - val_loss: 5.5513e-04\n",
      "Epoch 150/150\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 5.4289e-05 - val_loss: 4.9286e-04\n",
      ">10: Score=0.00038397370371967554\n",
      "[9.20531601877883e-06, 7.865702355047688e-05, 0.00016784106264822185, 5.990549470880069e-05, 2.1163668861845508e-05, 0.00015520445595029742, 8.219217124860734e-05, 4.909060589852743e-05, 4.0671522583579645e-05, 0.00038397370371967554]\n",
      "Loss: Mean = 0.000, Std = 0.000\n"
     ]
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = 85, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = 85))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=9, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=9)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print(f'Loss: Mean = {m:.3f}, Std = {s:.3f}')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(repeats = 10):\n",
    "    # repetindo o experimento\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(X_train, y_train, X_test, y_test)\n",
    "        score = score\n",
    "        scores.append(score)\n",
    "        print(f'>{r+1}: Score={score}')\n",
    "    # resumindo os resultados\n",
    "    summarize_results(scores)\n",
    "\n",
    "# Rodando o experimento\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(units, dropout):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = units, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units = units))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = create_model(85, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    history = model.fit(X_train, y_train, epochs=150, batch_size=5, validation_split = 0.2, shuffle=False, callbacks=[early_stop])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 8s 18ms/step - loss: 0.0025 - val_loss: 0.0107\n",
      "Epoch 2/150\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0088\n",
      "Epoch 3/150\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 8.3288e-04 - val_loss: 0.0062\n",
      "Epoch 4/150\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 6.6735e-04 - val_loss: 0.0041\n",
      "Epoch 5/150\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 5.3216e-04 - val_loss: 0.0029\n",
      "Epoch 6/150\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3.4325e-04 - val_loss: 0.0013\n",
      "Epoch 7/150\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2.8885e-04 - val_loss: 0.0015\n",
      "Epoch 8/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2.2547e-04 - val_loss: 6.7898e-04\n",
      "Epoch 9/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.7449e-04 - val_loss: 9.9445e-05\n",
      "Epoch 10/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.8672e-05 - val_loss: 1.5509e-04\n",
      "Epoch 11/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.6578e-04 - val_loss: 0.0023\n",
      "Epoch 12/150\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1.1347e-04 - val_loss: 0.0023\n",
      "Epoch 13/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.2401e-04 - val_loss: 1.8313e-04\n",
      "Epoch 14/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.0929e-04 - val_loss: 2.6091e-04\n",
      "Epoch 15/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.1351e-04 - val_loss: 1.6895e-04\n",
      "Epoch 16/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1.3820e-04 - val_loss: 2.6478e-04\n",
      "Epoch 17/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.2737e-05 - val_loss: 2.0420e-04\n",
      "Epoch 18/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 8.2460e-05 - val_loss: 3.0570e-04\n",
      "Epoch 19/150\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 7.3815e-05 - val_loss: 2.0700e-04\n"
     ]
    }
   ],
   "source": [
    "history_lstm = fit_model(model_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvamento do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: receitas_2013_2022\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: receitas_2013_2022\\assets\n"
     ]
    }
   ],
   "source": [
    "model_lstm.save('receitas_2013_2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga do modelo salvo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = tf.keras.models.load_model('receitas_2013_2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-processamento e predição da base de testes com a utilização do modelo carregado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = scaler_y.inverse_transform(y_test)\n",
    "y_train = scaler_y.inverse_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_lstm = prediction(model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_future(prediction, y_test):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    range_future = len(prediction)\n",
    "    plt.plot(np.arange(range_future), np.array(y_test), label='Dados reais')\n",
    "    plt.plot(np.arange(range_future), np.array(prediction),label='Predição')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Mês')\n",
    "    plt.ylabel('Valor Arrecadado')\n",
    "    plt.title('Predição de Receitas - LSTM')\n",
    "    plt.savefig('figura[1].png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_future(prediction_lstm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo do erro médio absoluto e raiz quadrática média:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(prediction_lstm, actual, model_name):\n",
    "    errors = prediction_lstm - actual\n",
    "    mse = np.square(errors).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.abs(errors).mean()\n",
    "    print(f'{model_name}:')\n",
    "    print(f'MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n",
      "MSE: 385392166.90, RMSE: 19631.41, MAE: 10497.85\n"
     ]
    }
   ],
   "source": [
    "evaluate_prediction(prediction_lstm, y_test, 'LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-processamento dos dados e aplicação do modelo em toda a base de dados (treino + teste):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_amostrado.drop(['VALOR_ARRECADADO'], axis=1)\n",
    "y = df_amostrado.loc[:, ['VALOR_ARRECADADO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm = output_scaler.transform(y)\n",
    "X_norm = input_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_norm.reshape((X_norm.shape[0], 1, X_norm.shape[1]))\n",
    "y = y_norm.reshape((y_norm.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = scaler_y.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_lstm = prediction(model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_future(prediction, y):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    range_future = len(prediction)\n",
    "    plt.plot(np.arange(range_future), np.array(y), label='Dados reais')\n",
    "    plt.plot(np.arange(range_future), np.array(prediction),label='Predição')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Mês')\n",
    "    plt.ylabel('Valor Arrecadado')\n",
    "    plt.title('Predição de Receitas - LSTM')\n",
    "    plt.savefig('figura[2].png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_future(prediction_lstm, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo do erro médio percentual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = y.flatten()\n",
    "previsto = prediction_lstm.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro médio percentual: 1.03%\n"
     ]
    }
   ],
   "source": [
    "tabela = pd.DataFrame([real, previsto]).T\n",
    "tabela = tabela.rename(columns={0: 'Real', 1: 'Previsto'})\n",
    "tabela['Diferenca'] = 1 - (tabela['Real'] / tabela['Previsto'])\n",
    "media_tabela = tabela['Diferenca'].mean()\n",
    "print(f'Erro médio percentual: {media_tabela:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribuição de erros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Diferenca', ylabel='Count'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=tabela, x='Diferenca', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = df_amostrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>VALOR_ARRECADADO</th>\n",
       "      <th>SMA(12)</th>\n",
       "      <th>SMA(6)</th>\n",
       "      <th>SMA(3)</th>\n",
       "      <th>SMA(2)</th>\n",
       "      <th>lag(12)</th>\n",
       "      <th>lag(6)</th>\n",
       "      <th>lag(4)</th>\n",
       "      <th>lag(3)</th>\n",
       "      <th>lag(2)</th>\n",
       "      <th>lag(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>734998</td>\n",
       "      <td>7.30</td>\n",
       "      <td>24851.269167</td>\n",
       "      <td>40243.668333</td>\n",
       "      <td>236.965</td>\n",
       "      <td>236.965</td>\n",
       "      <td>923.08</td>\n",
       "      <td>1924.43</td>\n",
       "      <td>247018.51</td>\n",
       "      <td>469.33</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>735030</td>\n",
       "      <td>46152.90</td>\n",
       "      <td>28689.010833</td>\n",
       "      <td>53411.605000</td>\n",
       "      <td>23080.100</td>\n",
       "      <td>23080.100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>-32854.72</td>\n",
       "      <td>469.33</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>735025</td>\n",
       "      <td>831.28</td>\n",
       "      <td>28321.970833</td>\n",
       "      <td>12380.400000</td>\n",
       "      <td>23492.090</td>\n",
       "      <td>23492.090</td>\n",
       "      <td>5235.76</td>\n",
       "      <td>247018.51</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.30</td>\n",
       "      <td>46152.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>735046</td>\n",
       "      <td>6718.14</td>\n",
       "      <td>28832.641667</td>\n",
       "      <td>13421.868333</td>\n",
       "      <td>3774.710</td>\n",
       "      <td>3774.710</td>\n",
       "      <td>590.09</td>\n",
       "      <td>469.33</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.30</td>\n",
       "      <td>46152.90</td>\n",
       "      <td>831.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>735047</td>\n",
       "      <td>0.95</td>\n",
       "      <td>24765.379167</td>\n",
       "      <td>9029.533333</td>\n",
       "      <td>3359.545</td>\n",
       "      <td>3359.545</td>\n",
       "      <td>48808.10</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>7.30</td>\n",
       "      <td>46152.90</td>\n",
       "      <td>831.28</td>\n",
       "      <td>6718.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101772</th>\n",
       "      <td>738273</td>\n",
       "      <td>144240.11</td>\n",
       "      <td>42472.112500</td>\n",
       "      <td>42872.793333</td>\n",
       "      <td>116336.410</td>\n",
       "      <td>116336.410</td>\n",
       "      <td>5079.69</td>\n",
       "      <td>250000.00</td>\n",
       "      <td>899.32</td>\n",
       "      <td>20347.52</td>\n",
       "      <td>914.60</td>\n",
       "      <td>88432.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101794</th>\n",
       "      <td>738243</td>\n",
       "      <td>322140.88</td>\n",
       "      <td>69306.652500</td>\n",
       "      <td>96162.523333</td>\n",
       "      <td>233190.495</td>\n",
       "      <td>233190.495</td>\n",
       "      <td>126.40</td>\n",
       "      <td>2402.50</td>\n",
       "      <td>20347.52</td>\n",
       "      <td>914.60</td>\n",
       "      <td>88432.71</td>\n",
       "      <td>144240.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101814</th>\n",
       "      <td>738182</td>\n",
       "      <td>148323.76</td>\n",
       "      <td>81656.465833</td>\n",
       "      <td>120733.263333</td>\n",
       "      <td>235232.320</td>\n",
       "      <td>235232.320</td>\n",
       "      <td>126.00</td>\n",
       "      <td>899.32</td>\n",
       "      <td>914.60</td>\n",
       "      <td>88432.71</td>\n",
       "      <td>144240.11</td>\n",
       "      <td>322140.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102033</th>\n",
       "      <td>738357</td>\n",
       "      <td>83.60</td>\n",
       "      <td>81500.096667</td>\n",
       "      <td>117355.943333</td>\n",
       "      <td>74203.680</td>\n",
       "      <td>74203.680</td>\n",
       "      <td>1960.03</td>\n",
       "      <td>20347.52</td>\n",
       "      <td>88432.71</td>\n",
       "      <td>144240.11</td>\n",
       "      <td>322140.88</td>\n",
       "      <td>148323.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102040</th>\n",
       "      <td>738355</td>\n",
       "      <td>5559.77</td>\n",
       "      <td>81946.339167</td>\n",
       "      <td>118130.138333</td>\n",
       "      <td>2821.685</td>\n",
       "      <td>2821.685</td>\n",
       "      <td>204.86</td>\n",
       "      <td>914.60</td>\n",
       "      <td>144240.11</td>\n",
       "      <td>322140.88</td>\n",
       "      <td>148323.76</td>\n",
       "      <td>83.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATA  VALOR_ARRECADADO       SMA(12)         SMA(6)      SMA(3)  \\\n",
       "1406    734998              7.30  24851.269167   40243.668333     236.965   \n",
       "1508    735030          46152.90  28689.010833   53411.605000   23080.100   \n",
       "1583    735025            831.28  28321.970833   12380.400000   23492.090   \n",
       "1619    735046           6718.14  28832.641667   13421.868333    3774.710   \n",
       "1669    735047              0.95  24765.379167    9029.533333    3359.545   \n",
       "...        ...               ...           ...            ...         ...   \n",
       "101772  738273         144240.11  42472.112500   42872.793333  116336.410   \n",
       "101794  738243         322140.88  69306.652500   96162.523333  233190.495   \n",
       "101814  738182         148323.76  81656.465833  120733.263333  235232.320   \n",
       "102033  738357             83.60  81500.096667  117355.943333   74203.680   \n",
       "102040  738355           5559.77  81946.339167  118130.138333    2821.685   \n",
       "\n",
       "            SMA(2)   lag(12)     lag(6)     lag(4)     lag(3)     lag(2)  \\\n",
       "1406       236.965    923.08    1924.43  247018.51     469.33   26354.96   \n",
       "1508     23080.100    100.00  -32854.72     469.33   26354.96     466.63   \n",
       "1583     23492.090   5235.76  247018.51   26354.96     466.63       7.30   \n",
       "1619      3774.710    590.09     469.33     466.63       7.30   46152.90   \n",
       "1669      3359.545  48808.10   26354.96       7.30   46152.90     831.28   \n",
       "...            ...       ...        ...        ...        ...        ...   \n",
       "101772  116336.410   5079.69  250000.00     899.32   20347.52     914.60   \n",
       "101794  233190.495    126.40    2402.50   20347.52     914.60   88432.71   \n",
       "101814  235232.320    126.00     899.32     914.60   88432.71  144240.11   \n",
       "102033   74203.680   1960.03   20347.52   88432.71  144240.11  322140.88   \n",
       "102040    2821.685    204.86     914.60  144240.11  322140.88  148323.76   \n",
       "\n",
       "           lag(1)  \n",
       "1406       466.63  \n",
       "1508         7.30  \n",
       "1583     46152.90  \n",
       "1619       831.28  \n",
       "1669      6718.14  \n",
       "...           ...  \n",
       "101772   88432.71  \n",
       "101794  144240.11  \n",
       "101814  322140.88  \n",
       "102033  148323.76  \n",
       "102040      83.60  \n",
       "\n",
       "[1011 rows x 12 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "periodo = 10  # escolha o período de previsão à frente será executado\n",
    "\n",
    "for i in range(periodo):\n",
    "    # Crie uma nova linha de dados vazia\n",
    "    row = pd.DataFrame(columns=previsao.columns)\n",
    "\n",
    "    # Calcule as médias e valores de atraso\n",
    "    row.loc[0, 'SMA(12)'] = previsao['VALOR_ARRECADADO'].iloc[-12:].mean()\n",
    "    row.loc[0, 'SMA(6)'] = previsao['VALOR_ARRECADADO'].iloc[-6:].mean()\n",
    "    row.loc[0, 'SMA(3)'] = previsao['VALOR_ARRECADADO'].iloc[-3:].mean()\n",
    "    row.loc[0, 'SMA(2)'] = previsao['VALOR_ARRECADADO'].iloc[-2:].mean()\n",
    "    row.loc[0, 'lag(12)'] = previsao['VALOR_ARRECADADO'].iloc[-12]\n",
    "    row.loc[0, 'lag(6)'] = previsao['VALOR_ARRECADADO'].iloc[-6]\n",
    "    row.loc[0, 'lag(4)'] = previsao['VALOR_ARRECADADO'].iloc[-4]\n",
    "    row.loc[0, 'lag(3)'] = previsao['VALOR_ARRECADADO'].iloc[-3]\n",
    "    row.loc[0, 'lag(2)'] = previsao['VALOR_ARRECADADO'].iloc[-2]\n",
    "    row.loc[0, 'lag(1)'] = previsao['VALOR_ARRECADADO'].iloc[-1]\n",
    "\n",
    "    # Incremente a data\n",
    "    row.loc[0, 'DATA'] = previsao['DATA'].iloc[-1]+1\n",
    "    \n",
    "    # Excluindo a coluna de valor arrecadado\n",
    "    row = row.drop(['VALOR_ARRECADADO'], axis=1)\n",
    "    \n",
    "    # Transforme a linha em um array e normalize\n",
    "    row = np.array(row.iloc[-1]).reshape(1, -1)\n",
    "    row_norm = input_scaler.transform(row)\n",
    "\n",
    "    # Preveja usando o modelo LSTM\n",
    "    to_prev = row_norm.reshape((row_norm.shape[0], 1, row_norm.shape[1]))\n",
    "    prev = model_lstm.predict(to_prev)\n",
    "    prev = scaler_y.inverse_transform(prev)\n",
    "\n",
    "    # Crie um DataFrame com a previsão e adicione ao DataFrame principal\n",
    "    row_['VALOR_ARRECADADO'] = prev[0]\n",
    "    previsao = pd.concat([previsao, row_], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>VALOR_ARRECADADO</th>\n",
       "      <th>SMA(12)</th>\n",
       "      <th>SMA(6)</th>\n",
       "      <th>SMA(3)</th>\n",
       "      <th>SMA(2)</th>\n",
       "      <th>lag(12)</th>\n",
       "      <th>lag(6)</th>\n",
       "      <th>lag(4)</th>\n",
       "      <th>lag(3)</th>\n",
       "      <th>lag(2)</th>\n",
       "      <th>lag(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>734998</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>24851.269167</td>\n",
       "      <td>40243.668333</td>\n",
       "      <td>236.965</td>\n",
       "      <td>236.965</td>\n",
       "      <td>923.08</td>\n",
       "      <td>1924.43</td>\n",
       "      <td>247018.51</td>\n",
       "      <td>469.33</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>735030</td>\n",
       "      <td>46152.900000</td>\n",
       "      <td>28689.010833</td>\n",
       "      <td>53411.605</td>\n",
       "      <td>23080.1</td>\n",
       "      <td>23080.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-32854.72</td>\n",
       "      <td>469.33</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>735025</td>\n",
       "      <td>831.280000</td>\n",
       "      <td>28321.970833</td>\n",
       "      <td>12380.4</td>\n",
       "      <td>23492.09</td>\n",
       "      <td>23492.09</td>\n",
       "      <td>5235.76</td>\n",
       "      <td>247018.51</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.3</td>\n",
       "      <td>46152.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>735046</td>\n",
       "      <td>6718.140000</td>\n",
       "      <td>28832.641667</td>\n",
       "      <td>13421.868333</td>\n",
       "      <td>3774.71</td>\n",
       "      <td>3774.71</td>\n",
       "      <td>590.09</td>\n",
       "      <td>469.33</td>\n",
       "      <td>466.63</td>\n",
       "      <td>7.3</td>\n",
       "      <td>46152.9</td>\n",
       "      <td>831.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>735047</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>24765.379167</td>\n",
       "      <td>9029.533333</td>\n",
       "      <td>3359.545</td>\n",
       "      <td>3359.545</td>\n",
       "      <td>48808.1</td>\n",
       "      <td>26354.96</td>\n",
       "      <td>7.3</td>\n",
       "      <td>46152.9</td>\n",
       "      <td>831.28</td>\n",
       "      <td>6718.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>738356</td>\n",
       "      <td>9373.322266</td>\n",
       "      <td>81946.339167</td>\n",
       "      <td>118130.138333</td>\n",
       "      <td>51322.376667</td>\n",
       "      <td>2821.685</td>\n",
       "      <td>11.3</td>\n",
       "      <td>88432.71</td>\n",
       "      <td>322140.88</td>\n",
       "      <td>148323.76</td>\n",
       "      <td>83.6</td>\n",
       "      <td>5559.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>738356</td>\n",
       "      <td>11512.037109</td>\n",
       "      <td>81946.339167</td>\n",
       "      <td>118130.138333</td>\n",
       "      <td>51322.376667</td>\n",
       "      <td>2821.685</td>\n",
       "      <td>11.3</td>\n",
       "      <td>88432.71</td>\n",
       "      <td>322140.88</td>\n",
       "      <td>148323.76</td>\n",
       "      <td>83.6</td>\n",
       "      <td>5559.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>738356</td>\n",
       "      <td>10594.389648</td>\n",
       "      <td>81946.339167</td>\n",
       "      <td>118130.138333</td>\n",
       "      <td>51322.376667</td>\n",
       "      <td>2821.685</td>\n",
       "      <td>11.3</td>\n",
       "      <td>88432.71</td>\n",
       "      <td>322140.88</td>\n",
       "      <td>148323.76</td>\n",
       "      <td>83.6</td>\n",
       "      <td>5559.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>738356</td>\n",
       "      <td>11038.994141</td>\n",
       "      <td>81946.339167</td>\n",
       "      <td>118130.138333</td>\n",
       "      <td>51322.376667</td>\n",
       "      <td>2821.685</td>\n",
       "      <td>11.3</td>\n",
       "      <td>88432.71</td>\n",
       "      <td>322140.88</td>\n",
       "      <td>148323.76</td>\n",
       "      <td>83.6</td>\n",
       "      <td>5559.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>738356</td>\n",
       "      <td>13109.886719</td>\n",
       "      <td>81946.339167</td>\n",
       "      <td>118130.138333</td>\n",
       "      <td>51322.376667</td>\n",
       "      <td>2821.685</td>\n",
       "      <td>11.3</td>\n",
       "      <td>88432.71</td>\n",
       "      <td>322140.88</td>\n",
       "      <td>148323.76</td>\n",
       "      <td>83.6</td>\n",
       "      <td>5559.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATA  VALOR_ARRECADADO       SMA(12)         SMA(6)        SMA(3)  \\\n",
       "0     734998          7.300000  24851.269167   40243.668333       236.965   \n",
       "1     735030      46152.900000  28689.010833      53411.605       23080.1   \n",
       "2     735025        831.280000  28321.970833        12380.4      23492.09   \n",
       "3     735046       6718.140000  28832.641667   13421.868333       3774.71   \n",
       "4     735047          0.950000  24765.379167    9029.533333      3359.545   \n",
       "...      ...               ...           ...            ...           ...   \n",
       "1016  738356       9373.322266  81946.339167  118130.138333  51322.376667   \n",
       "1017  738356      11512.037109  81946.339167  118130.138333  51322.376667   \n",
       "1018  738356      10594.389648  81946.339167  118130.138333  51322.376667   \n",
       "1019  738356      11038.994141  81946.339167  118130.138333  51322.376667   \n",
       "1020  738356      13109.886719  81946.339167  118130.138333  51322.376667   \n",
       "\n",
       "        SMA(2)  lag(12)     lag(6)     lag(4)     lag(3)    lag(2)   lag(1)  \n",
       "0      236.965   923.08    1924.43  247018.51     469.33  26354.96   466.63  \n",
       "1      23080.1    100.0  -32854.72     469.33   26354.96    466.63      7.3  \n",
       "2     23492.09  5235.76  247018.51   26354.96     466.63       7.3  46152.9  \n",
       "3      3774.71   590.09     469.33     466.63        7.3   46152.9   831.28  \n",
       "4     3359.545  48808.1   26354.96        7.3    46152.9    831.28  6718.14  \n",
       "...        ...      ...        ...        ...        ...       ...      ...  \n",
       "1016  2821.685     11.3   88432.71  322140.88  148323.76      83.6  5559.77  \n",
       "1017  2821.685     11.3   88432.71  322140.88  148323.76      83.6  5559.77  \n",
       "1018  2821.685     11.3   88432.71  322140.88  148323.76      83.6  5559.77  \n",
       "1019  2821.685     11.3   88432.71  322140.88  148323.76      83.6  5559.77  \n",
       "1020  2821.685     11.3   88432.71  322140.88  148323.76      83.6  5559.77  \n",
       "\n",
       "[1021 rows x 12 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
