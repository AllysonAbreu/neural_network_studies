{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexão com o DB local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "driver = os.environ[\"Driver\"]\n",
    "server = os.environ[\"Server\"]\n",
    "database = os.environ[\"Database\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_conexao = (\n",
    "    f\"Driver={driver};\"\n",
    "    f\"Server={server};\"\n",
    "    f\"Database={database};\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_banco(query, dados_conexao):\n",
    "    engine = create_engine(f'mssql+pyodbc:///?odbc_connect={dados_conexao}')\n",
    "    return pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_fato</th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>2911694.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_fato  valor_fixado  valor_empenhado  valor_liquidado  valor_pago  \\\n",
       "0 2013-12-31     2911694.0           5120.0           5120.0         0.0   \n",
       "1 2013-12-31      107000.0           6950.0           6950.0         0.0   \n",
       "2 2013-12-31      107000.0            800.0            800.0         0.0   \n",
       "3 2013-12-31      107000.0            400.0            400.0         0.0   \n",
       "4 2013-12-31      107000.0            600.0            600.0         0.0   \n",
       "\n",
       "    saldo  \n",
       "0  5120.0  \n",
       "1  6950.0  \n",
       "2   800.0  \n",
       "3   400.0  \n",
       "4   600.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas = query_banco(\"SELECT * FROM Fato_Despesa\", dados_conexao)\n",
    "df_despesas.drop(columns=['id','uid_fato_despesa','credor_despesa', 'fonte_recurso', 'orgao_interno', 'orgao_vinculado', 'cod_elemento', 'cod_subelemento', 'cod_funcao', 'cod_subfuncao', 'cod_natureza'], inplace=True)\n",
    "df_despesas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>porcentagem_variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>porcentagem_aceleracao_variacao_anual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>51273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992</td>\n",
       "      <td>51530</td>\n",
       "      <td>257</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>51965</td>\n",
       "      <td>435</td>\n",
       "      <td>0,84</td>\n",
       "      <td>178</td>\n",
       "      <td>69,26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994</td>\n",
       "      <td>52279</td>\n",
       "      <td>314</td>\n",
       "      <td>0,6</td>\n",
       "      <td>-121</td>\n",
       "      <td>-27,82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>52586</td>\n",
       "      <td>307</td>\n",
       "      <td>0,59</td>\n",
       "      <td>-7</td>\n",
       "      <td>-2,23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>51396</td>\n",
       "      <td>-1190</td>\n",
       "      <td>-2,26</td>\n",
       "      <td>-1497</td>\n",
       "      <td>-487,62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997</td>\n",
       "      <td>51575</td>\n",
       "      <td>179</td>\n",
       "      <td>0,35</td>\n",
       "      <td>1369</td>\n",
       "      <td>-115,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998</td>\n",
       "      <td>51726</td>\n",
       "      <td>151</td>\n",
       "      <td>0,29</td>\n",
       "      <td>-28</td>\n",
       "      <td>-15,64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999</td>\n",
       "      <td>51878</td>\n",
       "      <td>152</td>\n",
       "      <td>0,29</td>\n",
       "      <td>1</td>\n",
       "      <td>0,66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000</td>\n",
       "      <td>54715</td>\n",
       "      <td>2837</td>\n",
       "      <td>5,47</td>\n",
       "      <td>2685</td>\n",
       "      <td>1766,45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001</td>\n",
       "      <td>55132</td>\n",
       "      <td>417</td>\n",
       "      <td>0,76</td>\n",
       "      <td>-2420</td>\n",
       "      <td>-85,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002</td>\n",
       "      <td>55439</td>\n",
       "      <td>307</td>\n",
       "      <td>0,56</td>\n",
       "      <td>-110</td>\n",
       "      <td>-26,38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2003</td>\n",
       "      <td>55775</td>\n",
       "      <td>336</td>\n",
       "      <td>0,61</td>\n",
       "      <td>29</td>\n",
       "      <td>9,45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004</td>\n",
       "      <td>56481</td>\n",
       "      <td>706</td>\n",
       "      <td>1,27</td>\n",
       "      <td>370</td>\n",
       "      <td>110,12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2005</td>\n",
       "      <td>56871</td>\n",
       "      <td>390</td>\n",
       "      <td>0,69</td>\n",
       "      <td>-316</td>\n",
       "      <td>-44,76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2006</td>\n",
       "      <td>57259</td>\n",
       "      <td>388</td>\n",
       "      <td>0,68</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0,51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2007</td>\n",
       "      <td>56051</td>\n",
       "      <td>-1208</td>\n",
       "      <td>-2,11</td>\n",
       "      <td>-1596</td>\n",
       "      <td>-411,34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008</td>\n",
       "      <td>57627</td>\n",
       "      <td>1576</td>\n",
       "      <td>2,81</td>\n",
       "      <td>2784</td>\n",
       "      <td>-230,46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2009</td>\n",
       "      <td>57875</td>\n",
       "      <td>248</td>\n",
       "      <td>0,43</td>\n",
       "      <td>-1328</td>\n",
       "      <td>-84,26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2010</td>\n",
       "      <td>58446</td>\n",
       "      <td>571</td>\n",
       "      <td>0,99</td>\n",
       "      <td>323</td>\n",
       "      <td>130,24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011</td>\n",
       "      <td>58794</td>\n",
       "      <td>348</td>\n",
       "      <td>0,6</td>\n",
       "      <td>-223</td>\n",
       "      <td>-39,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012</td>\n",
       "      <td>59130</td>\n",
       "      <td>336</td>\n",
       "      <td>0,57</td>\n",
       "      <td>-12</td>\n",
       "      <td>-3,45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>2,51</td>\n",
       "      <td>1146</td>\n",
       "      <td>341,07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014</td>\n",
       "      <td>61030</td>\n",
       "      <td>418</td>\n",
       "      <td>0,69</td>\n",
       "      <td>-1064</td>\n",
       "      <td>-71,79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015</td>\n",
       "      <td>61431</td>\n",
       "      <td>401</td>\n",
       "      <td>0,66</td>\n",
       "      <td>-17</td>\n",
       "      <td>-4,07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016</td>\n",
       "      <td>61816</td>\n",
       "      <td>385</td>\n",
       "      <td>0,63</td>\n",
       "      <td>-16</td>\n",
       "      <td>-3,99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>62187</td>\n",
       "      <td>371</td>\n",
       "      <td>0,6</td>\n",
       "      <td>-14</td>\n",
       "      <td>-3,64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>61776</td>\n",
       "      <td>-411</td>\n",
       "      <td>-0,66</td>\n",
       "      <td>-782</td>\n",
       "      <td>-210,78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019</td>\n",
       "      <td>61993</td>\n",
       "      <td>217</td>\n",
       "      <td>0,35</td>\n",
       "      <td>628</td>\n",
       "      <td>-152,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020</td>\n",
       "      <td>62289</td>\n",
       "      <td>296</td>\n",
       "      <td>0,48</td>\n",
       "      <td>79</td>\n",
       "      <td>36,41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021</td>\n",
       "      <td>62576</td>\n",
       "      <td>287</td>\n",
       "      <td>0,46</td>\n",
       "      <td>-9</td>\n",
       "      <td>-3,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>1,05</td>\n",
       "      <td>376</td>\n",
       "      <td>56,71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ano  populacao variacao_anual porcentagem_variacao_anual  \\\n",
       "0   1991      51273              0                          0   \n",
       "1   1992      51530            257                        0,5   \n",
       "2   1993      51965            435                       0,84   \n",
       "3   1994      52279            314                        0,6   \n",
       "4   1995      52586            307                       0,59   \n",
       "5   1996      51396          -1190                      -2,26   \n",
       "6   1997      51575            179                       0,35   \n",
       "7   1998      51726            151                       0,29   \n",
       "8   1999      51878            152                       0,29   \n",
       "9   2000      54715           2837                       5,47   \n",
       "10  2001      55132            417                       0,76   \n",
       "11  2002      55439            307                       0,56   \n",
       "12  2003      55775            336                       0,61   \n",
       "13  2004      56481            706                       1,27   \n",
       "14  2005      56871            390                       0,69   \n",
       "15  2006      57259            388                       0,68   \n",
       "16  2007      56051          -1208                      -2,11   \n",
       "17  2008      57627           1576                       2,81   \n",
       "18  2009      57875            248                       0,43   \n",
       "19  2010      58446            571                       0,99   \n",
       "20  2011      58794            348                        0,6   \n",
       "21  2012      59130            336                       0,57   \n",
       "22  2013      60612           1482                       2,51   \n",
       "23  2014      61030            418                       0,69   \n",
       "24  2015      61431            401                       0,66   \n",
       "25  2016      61816            385                       0,63   \n",
       "26  2017      62187            371                        0,6   \n",
       "27  2018      61776           -411                      -0,66   \n",
       "28  2019      61993            217                       0,35   \n",
       "29  2020      62289            296                       0,48   \n",
       "30  2021      62576            287                       0,46   \n",
       "31  2022      63239            663                       1,05   \n",
       "\n",
       "   aceleracao_variacao_anual porcentagem_aceleracao_variacao_anual  \n",
       "0                          0                                     0  \n",
       "1                          0                                     0  \n",
       "2                        178                                 69,26  \n",
       "3                       -121                                -27,82  \n",
       "4                         -7                                 -2,23  \n",
       "5                      -1497                               -487,62  \n",
       "6                       1369                               -115,04  \n",
       "7                        -28                                -15,64  \n",
       "8                          1                                  0,66  \n",
       "9                       2685                               1766,45  \n",
       "10                     -2420                                 -85,3  \n",
       "11                      -110                                -26,38  \n",
       "12                        29                                  9,45  \n",
       "13                       370                                110,12  \n",
       "14                      -316                                -44,76  \n",
       "15                        -2                                 -0,51  \n",
       "16                     -1596                               -411,34  \n",
       "17                      2784                               -230,46  \n",
       "18                     -1328                                -84,26  \n",
       "19                       323                                130,24  \n",
       "20                      -223                                -39,05  \n",
       "21                       -12                                 -3,45  \n",
       "22                      1146                                341,07  \n",
       "23                     -1064                                -71,79  \n",
       "24                       -17                                 -4,07  \n",
       "25                       -16                                 -3,99  \n",
       "26                       -14                                 -3,64  \n",
       "27                      -782                               -210,78  \n",
       "28                       628                                -152,8  \n",
       "29                        79                                 36,41  \n",
       "30                        -9                                 -3,04  \n",
       "31                       376                                 56,71  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_populacao = query_banco(\"SELECT * FROM Dim_Populacao\", dados_conexao)\n",
    "df_populacao.drop(columns=['id'], inplace=True)\n",
    "df_populacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>4,1</td>\n",
       "      <td>2,8</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>4,1</td>\n",
       "      <td>2,8</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>4,4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>4,4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>4,8</td>\n",
       "      <td>3,5</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>4,8</td>\n",
       "      <td>3,5</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>5,3</td>\n",
       "      <td>4,1</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>5,3</td>\n",
       "      <td>4,1</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>5,1</td>\n",
       "      <td>4,9</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano ideb_5ano ideb_9ano   idhm\n",
       "0  2013       4,1       2,8  0,679\n",
       "1  2014       4,1       2,8  0,679\n",
       "2  2015       4,4         3  0,679\n",
       "3  2016       4,4         3  0,679\n",
       "4  2017       4,8       3,5  0,679\n",
       "5  2018       4,8       3,5  0,679\n",
       "6  2019       5,3       4,1  0,679\n",
       "7  2020       5,3       4,1  0,679\n",
       "8  2021       5,1       4,9  0,679"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idhm = query_banco(\"SELECT ano, ideb_5ano, ideb_9ano, idhm FROM Dim_IDHM\", dados_conexao)\n",
    "df_idhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun_def</th>\n",
       "      <th>desp_recp_saude_pc_mun_def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>16,56</td>\n",
       "      <td>464,3</td>\n",
       "      <td>114,1</td>\n",
       "      <td>744,7674653</td>\n",
       "      <td>183,0238376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>23,4</td>\n",
       "      <td>448,73</td>\n",
       "      <td>186,19</td>\n",
       "      <td>676,4489043</td>\n",
       "      <td>280,676624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>22,48</td>\n",
       "      <td>468,65</td>\n",
       "      <td>190,19</td>\n",
       "      <td>638,3468516</td>\n",
       "      <td>259,057266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>21,23</td>\n",
       "      <td>439,37</td>\n",
       "      <td>202,37</td>\n",
       "      <td>563,0595289</td>\n",
       "      <td>259,3403211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>18,6</td>\n",
       "      <td>468,37</td>\n",
       "      <td>178,28</td>\n",
       "      <td>583,0388706</td>\n",
       "      <td>221,9274716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>18,26</td>\n",
       "      <td>705,23</td>\n",
       "      <td>190,43</td>\n",
       "      <td>846,1933549</td>\n",
       "      <td>228,4936837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>16,13</td>\n",
       "      <td>559,08</td>\n",
       "      <td>187,04</td>\n",
       "      <td>643,1360678</td>\n",
       "      <td>215,1609253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>16,23</td>\n",
       "      <td>668,07</td>\n",
       "      <td>187,35</td>\n",
       "      <td>735,277842</td>\n",
       "      <td>206,19741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>19,02</td>\n",
       "      <td>790,59</td>\n",
       "      <td>272,68</td>\n",
       "      <td>790,59</td>\n",
       "      <td>272,68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano pct_desp_recp_saude_mun desp_tot_saude_pc_mun desp_recp_saude_pc_mun  \\\n",
       "0  2013                   16,56                 464,3                  114,1   \n",
       "1  2014                    23,4                448,73                 186,19   \n",
       "2  2015                   22,48                468,65                 190,19   \n",
       "3  2016                   21,23                439,37                 202,37   \n",
       "4  2017                    18,6                468,37                 178,28   \n",
       "5  2018                   18,26                705,23                 190,43   \n",
       "6  2019                   16,13                559,08                 187,04   \n",
       "7  2020                   16,23                668,07                 187,35   \n",
       "8  2021                   19,02                790,59                 272,68   \n",
       "\n",
       "  desp_tot_saude_pc_mun_def desp_recp_saude_pc_mun_def  \n",
       "0               744,7674653                183,0238376  \n",
       "1               676,4489043                 280,676624  \n",
       "2               638,3468516                 259,057266  \n",
       "3               563,0595289                259,3403211  \n",
       "4               583,0388706                221,9274716  \n",
       "5               846,1933549                228,4936837  \n",
       "6               643,1360678                215,1609253  \n",
       "7                735,277842                  206,19741  \n",
       "8                    790,59                     272,68  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_saude = query_banco(\"SELECT ano, pct_desp_recp_saude_mun, desp_tot_saude_pc_mun,desp_recp_saude_pc_mun, desp_tot_saude_pc_mun_def, desp_recp_saude_pc_mun_def FROM Dim_Saude\", dados_conexao)\n",
    "df_saude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserindo colunas que tratam do tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_colunas_tempo(df, coluna_data):\n",
    "    df[coluna_data] = pd.to_datetime(df[coluna_data])\n",
    "    df['ano_mes'] = df[coluna_data].dt.strftime('%Y-%m')\n",
    "    df['ano'] = df[coluna_data].dt.strftime('%Y')\n",
    "    return df\n",
    "\n",
    "def transforma_data_em_ordinal(df, coluna_referencia):\n",
    "    df['ano_mes_ordinal'] = pd.to_datetime(df[coluna_referencia])\n",
    "    df['ano_mes_ordinal'] = df['ano_mes_ordinal'].map(dt.datetime.toordinal)\n",
    "    return df\n",
    "\n",
    "def transforma_coluna_em_datetime(df, coluna):\n",
    "    df[coluna] = pd.to_datetime(df[coluna], format='%Y')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação de IQR - Interquartile Range\n",
    "def remove_outliers(df, coluna):\n",
    "    Q1 = df[coluna].quantile(0.25)\n",
    "    print(f'Q1: {Q1}')\n",
    "    Q3 = df[coluna].quantile(0.75)\n",
    "    print(f'Q3: {Q3}')\n",
    "    IQR = Q3 - Q1\n",
    "    print(f'IQR: {IQR}')\n",
    "    print(f'Limite inferior: {Q1 - 1.5 * IQR}')\n",
    "    print(f'Limite superior: {Q3 + 1.5 * IQR}')\n",
    "    df = df[(df[coluna] >= Q1 - 1.5*IQR) & (df[coluna] <= Q3 + 1.5*IQR)]\n",
    "    print(f'Quantidade de registros sem outliers: {df.shape[0]}')\n",
    "    return df\n",
    "\n",
    "# Gráfico de dispersão\n",
    "def box_plot(df, coluna_referencia, coluna_visao):\n",
    "    print(f'Quantidade de registros: {df.shape[0]}')\n",
    "    df.boxplot(by=coluna_referencia, column=coluna_visao, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series_data(df, coluna_referencia):\n",
    "    train_size = int(len(df) * 0.8)\n",
    "    train_dataset, test_dataset = df.iloc[:train_size], df.iloc[train_size:]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(train_dataset[coluna_referencia])\n",
    "    plt.plot(test_dataset[coluna_referencia])\n",
    "    plt.xlabel('Período')\n",
    "    plt.ylabel('Valor Arrecadado')\n",
    "    plt.legend(['Treino', 'Teste'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('../../src/static/images/dados_treinamento.png')\n",
    "    print('Dimension of train data: ', train_dataset.shape)\n",
    "    print('Dimension of test data: ', test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversão de tipos de dados nas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_tipo_dados(df, colunas, tipo):\n",
    "    for coluna in colunas:\n",
    "        df[coluna] = df[coluna].astype(tipo)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise exploratória dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Despesas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86841 entries, 0 to 86840\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   data_fato        86841 non-null  datetime64[ns]\n",
      " 1   valor_fixado     86841 non-null  float64       \n",
      " 2   valor_empenhado  86841 non-null  float64       \n",
      " 3   valor_liquidado  86841 non-null  float64       \n",
      " 4   valor_pago       86841 non-null  float64       \n",
      " 5   saldo            86841 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_despesas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_fato</th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86841</td>\n",
       "      <td>86841.00</td>\n",
       "      <td>86841.00</td>\n",
       "      <td>86841.00</td>\n",
       "      <td>86841.00</td>\n",
       "      <td>86841.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018-03-12 20:45:52.451031040</td>\n",
       "      <td>336082.00</td>\n",
       "      <td>14906.00</td>\n",
       "      <td>14448.91</td>\n",
       "      <td>13163.63</td>\n",
       "      <td>1500.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2013-01-02 00:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-396163.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2015-08-20 00:00:00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>240.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018-03-26 00:00:00</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>990.86</td>\n",
       "      <td>880.00</td>\n",
       "      <td>613.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020-10-15 00:00:00</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>5244.05</td>\n",
       "      <td>4995.00</td>\n",
       "      <td>3800.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022-12-30 00:00:00</td>\n",
       "      <td>14400000.00</td>\n",
       "      <td>2795000.00</td>\n",
       "      <td>2795000.00</td>\n",
       "      <td>2795000.00</td>\n",
       "      <td>1639155.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1010914.22</td>\n",
       "      <td>71460.78</td>\n",
       "      <td>70443.38</td>\n",
       "      <td>67964.15</td>\n",
       "      <td>19966.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           data_fato  valor_fixado  valor_empenhado  \\\n",
       "count                          86841      86841.00         86841.00   \n",
       "mean   2018-03-12 20:45:52.451031040     336082.00         14906.00   \n",
       "min              2013-01-02 00:00:00          0.00             0.00   \n",
       "25%              2015-08-20 00:00:00       1000.00           250.00   \n",
       "50%              2018-03-26 00:00:00      50000.00           990.86   \n",
       "75%              2020-10-15 00:00:00     200000.00          5244.05   \n",
       "max              2022-12-30 00:00:00   14400000.00       2795000.00   \n",
       "std                              NaN    1010914.22         71460.78   \n",
       "\n",
       "       valor_liquidado  valor_pago       saldo  \n",
       "count         86841.00    86841.00    86841.00  \n",
       "mean          14448.91    13163.63     1500.68  \n",
       "min               0.00        0.00  -396163.17  \n",
       "25%             240.00      150.00        0.00  \n",
       "50%             880.00      613.00        0.00  \n",
       "75%            4995.00     3800.00        0.00  \n",
       "max         2795000.00  2795000.00  1639155.73  \n",
       "std           70443.38    67964.15    19966.49  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_fato</th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>2911694.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_fato  valor_fixado  valor_empenhado  valor_liquidado  valor_pago  \\\n",
       "0 2013-12-31     2911694.0           5120.0           5120.0         0.0   \n",
       "1 2013-12-31      107000.0           6950.0           6950.0         0.0   \n",
       "2 2013-12-31      107000.0            800.0            800.0         0.0   \n",
       "3 2013-12-31      107000.0            400.0            400.0         0.0   \n",
       "4 2013-12-31      107000.0            600.0            600.0         0.0   \n",
       "\n",
       "    saldo  ano_mes   ano  \n",
       "0  5120.0  2013-12  2013  \n",
       "1  6950.0  2013-12  2013  \n",
       "2   800.0  2013-12  2013  \n",
       "3   400.0  2013-12  2013  \n",
       "4   600.0  2013-12  2013  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas_com_outliers = cria_colunas_tempo(df_despesas,'data_fato')\n",
    "df_despesas_com_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de registros: 86841\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "box_plot(df_despesas_com_outliers, 'ano', 'valor_pago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 150.0\n",
      "Q3: 3800.0\n",
      "IQR: 3650.0\n",
      "Limite inferior: -5325.0\n",
      "Limite superior: 9275.0\n",
      "Quantidade de registros sem outliers: 72498\n"
     ]
    }
   ],
   "source": [
    "df_despesas_sem_outliers = remove_outliers(df_despesas_com_outliers, 'valor_pago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de registros: 72498\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAAIxCAYAAAArN9tCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACaIklEQVR4nOzdd3RU1f428Cd10gMJJCEQQuiEKkWIIBBBUBAE5NpQwYsdRFTg2i4C+rteESugWK6gIgiC2CjSixgUQpEaWgg1gVDSe877B28OM5lJOMPeOVPO81nL5ZQnkz2bycx8z9nFQ1EUBURERERERFTjPB3dACIiIiIiIqNgAUZERERERKQTFmBEREREREQ6YQFGRERERESkExZgREREREREOmEBRkREREREpBMWYERERERERDphAUZERERERKQTFmBEREREREQ6YQFGRER28/DwwJQpUxzdDLe3ceNGeHh4YOPGjdXmpkyZAg8PD2RmZurTMCIiumEswIiInMi8efPg4eFh8V9ERAQSExOxcuVKRzdP2IEDBzBlyhScOHHC0U0hIiJyCG9HN4CIiKxNmzYNcXFxUBQFGRkZmDdvHgYMGIBffvkFd911l6Obd8MOHDiAqVOnonfv3mjUqJGjm0NERKQ7FmBERE7ozjvvROfOndXro0ePRmRkJBYuXOjSBZieSktLUV5eDl9fX0c3hYiISMUhiERELqBWrVrw9/eHt7flcbO8vDy8+OKLiImJgclkQosWLTBjxgwoigIAKCgoQMuWLdGyZUsUFBSoP3fp0iXUq1cPt9xyC8rKygAAo0aNQlBQEI4fP47+/fsjMDAQ0dHRmDZtmvp41dm1axfuvPNOhISEICgoCH369MG2bdvU++fNm4d//OMfAIDExER1iOX15jd9//33iI+Ph5+fH9q0aYNly5Zh1KhRFmfQTpw4AQ8PD8yYMQMffPABmjRpApPJhAMHDgAA1q9fj1tvvRWBgYGoVasW7r77bhw8eNDi91R+zAoV86vMeXh4YOzYsfj222/RokUL+Pn5oVOnTti8ebPVz585cwb//Oc/ERkZCZPJhNatW+PLL7+0yp0+fRpDhgxBYGAgIiIi8Pzzz6OoqKjavqksMzMT9957L0JCQhAeHo7nnnsOhYWF6v29evVC+/btbf5sixYt0L9//2of/6effsLAgQMRHR0Nk8mEJk2a4I033lBfQxV69+6NNm3a4MCBA0hMTERAQADq16+P6dOnWz3m+fPn1QMMfn5+aN++Pb766iu7njcRkSvhGTAiIieUlZWFzMxMKIqC8+fPY+bMmcjNzcVDDz2kZhRFweDBg7FhwwaMHj0aHTp0wG+//YaJEyfizJkzeP/99+Hv74+vvvoK3bt3x6uvvor33nsPADBmzBhkZWVh3rx58PLyUh+zrKwMd9xxB7p164bp06dj1apVeP3111FaWopp06ZV2d79+/fj1ltvRUhICCZNmgQfHx98+umn6N27NzZt2oSuXbuiZ8+eGDduHD766CO88soraNWqFQCo/7dl+fLluO+++9C2bVu89dZbuHz5MkaPHo369evbzM+dOxeFhYV44oknYDKZEBYWhrVr1+LOO+9E48aNMWXKFBQUFGDmzJno3r07du7cecNDITdt2oRFixZh3LhxMJlM+Pjjj3HHHXfgr7/+Qps2bQAAGRkZ6Natm1qw1a1bFytXrsTo0aORnZ2N8ePHA7haKPfp0wcnT57EuHHjEB0djW+++Qbr16+3q0333nsvGjVqhLfeegvbtm3DRx99hMuXL+Prr78GADz88MN4/PHHsW/fPrWNALB9+3YcPnwYr732WrWPP2/ePAQFBeGFF15AUFAQ1q9fj8mTJyM7OxvvvPOORfby5cu44447MGzYMNx7771YsmQJ/vWvf6Ft27a488471efdu3dvHD16FGPHjkVcXBy+//57jBo1CleuXMFzzz1n1/MnInIJChEROY25c+cqAKz+M5lMyrx58yyyP/74owJAefPNNy1uHz58uOLh4aEcPXpUve3ll19WPD09lc2bNyvff/+9AkD54IMPLH5u5MiRCgDl2WefVW8rLy9XBg4cqPj6+ioXLlxQbwegvP766+r1IUOGKL6+vsqxY8fU286ePasEBwcrPXv2VG+r+N0bNmzQ1B9t27ZVGjRooOTk5Ki3bdy4UQGgxMbGqrelpqYqAJSQkBDl/PnzFo/RoUMHJSIiQrl48aJ62549exRPT0/lkUcesXj+5o9Z4fXXX1cqf1xW/Lvs2LFDvS0tLU3x8/NThg4dqt42evRopV69ekpmZqbFz99///1KaGiokp+fryiKonzwwQcKAGXx4sVqJi8vT2natKmm/qpo4+DBgy1uf+aZZxQAyp49exRFUZQrV64ofn5+yr/+9S+L3Lhx45TAwEAlNze32t9T0V5zTz75pBIQEKAUFhaqt/Xq1UsBoHz99dfqbUVFRUpUVJRyzz33qLdVPO/58+ertxUXFysJCQlKUFCQkp2dXW17iIhcEYcgEhE5odmzZ2PNmjVYs2YN5s+fj8TERDz22GP44Ycf1MyKFSvg5eWFcePGWfzsiy++CEVRLFZNnDJlClq3bo2RI0fimWeeQa9evax+rsLYsWPVyxVnboqLi7F27Vqb+bKyMqxevRpDhgxB48aN1dvr1auHBx98EL///juys7Pt7oOzZ89i7969eOSRRxAUFKTe3qtXL7Rt29bmz9xzzz2oW7euev3cuXPYvXs3Ro0ahbCwMPX2du3a4fbbb8eKFSvsbleFhIQEdOrUSb3esGFD3H333fjtt99QVlYGRVGwdOlSDBo0CIqiIDMzU/2vf//+yMrKws6dOwFc/besV68ehg8frj5eQEAAnnjiCbvaNGbMGIvrzz77rPr4ABAaGoq7774bCxcuVIeVlpWVYdGiRerwx+r4+/url3NycpCZmYlbb70V+fn5OHTokEU2KCjI4oytr68vbr75Zhw/fly9bcWKFYiKisIDDzyg3ubj44Nx48YhNzcXmzZtsufpExG5BBZgRERO6Oabb0bfvn3Rt29fjBgxAsuXL0d8fLxaDAFAWloaoqOjERwcbPGzFUP60tLS1Nt8fX3x5ZdfIjU1FTk5OZg7d67VvCYA8PT0tCiiAKB58+YAUOXS8RcuXEB+fj5atGhhdV+rVq1QXl6OU6dOaX/y/19F+5s2bWp1n63bACAuLs7mY1TVtszMTOTl5dndNgBo1qyZ1W3NmzdHfn4+Lly4gAsXLuDKlSv47LPPULduXYv/Hn30UQBX5z9VtLNp06ZW/ya22m1Pm5o0aQJPT0+Lf7tHHnkEJ0+exJYtWwAAa9euRUZGBh5++OHrPv7+/fsxdOhQhIaGIiQkBHXr1lWLrKysLItsgwYNrJ5P7dq1cfnyZfV6WloamjVrBk9Py68jtl7DRETugnPAiIhcgKenJxITE/Hhhx/iyJEjaN26td2P8dtvvwEACgsLceTIEatixR2Yn6Gxl62CFIDVAhNalZeXAwAeeughjBw50mamXbt2N/TYWtl6Tv3790dkZCTmz5+Pnj17Yv78+YiKikLfvn2rfawrV66gV69eCAkJwbRp09CkSRP4+flh586d+Ne//qU+3wrmcwvNKRoWdCEicmcswIiIXERpaSkAIDc3FwAQGxuLtWvXIicnx+IsWMVQsNjYWPW2v//+G9OmTcOjjz6K3bt347HHHsPevXsRGhpq8TvKy8tx/Phx9awXABw+fBgAqlysom7duggICEBKSorVfYcOHYKnpydiYmIAVF3k2FLR/qNHj1rdZ+u26h6jqrbVqVNHHXZXu3ZtXLlyxSpX1VmYI0eOWN12+PBhBAQEqMMgg4ODUVZWdt3iJjY2Fvv27YOiKBZ9ZKvd1alcWB89ehTl5eUW/3ZeXl548MEHMW/ePLz99tv48ccf8fjjj1dZMFXYuHEjLl68iB9++AE9e/ZUb09NTbWrjeZiY2Px999/o7y83OIsmK3XMBGRu+AQRCIiF1BSUoLVq1fD19dXHZ41YMAAlJWVYdasWRbZ999/Hx4eHupKcyUlJRg1ahSio6Px4YcfYt68ecjIyMDzzz9v83eZP56iKJg1axZ8fHzQp08fm3kvLy/069cPP/30k8VQt4yMDCxYsAA9evRASEgIAKjFjq1Cp7Lo6Gi0adMGX3/9tVp0AldXH9y7d+91fx64Og+tQ4cO+Oqrryx+5759+7B69WoMGDBAva1JkybIysrC33//rd527tw5LFu2zOZjJyUlqXO4AODUqVP46aef0K9fP3h5ecHLywv33HMPli5din379ln9/IULF9TLAwYMwNmzZ7FkyRL1tvz8fHz22WeanmeF2bNnW1yfOXMmAKivhQoPP/wwLl++jCeffNJqdc2qVBRo5mewiouL8fHHH9vVRnMDBgxAeno6Fi1apN5WWlqKmTNnIigoCL169brhxyYiclY8A0ZE5IRWrlypngU4f/48FixYgCNHjuCll15Si5lBgwYhMTERr776Kk6cOIH27dtj9erV+OmnnzB+/Hg0adIEAPDmm29i9+7dWLduHYKDg9GuXTtMnjwZr732GoYPH25RhPj5+WHVqlUYOXIkunbtipUrV2L58uV45ZVXLBa3qOzNN9/EmjVr0KNHDzzzzDPw9vbGp59+iqKiIou9nzp06AAvLy+8/fbbyMrKgslkwm233YaIiAibj/uf//wHd999N7p3745HH30Uly9fxqxZs9CmTRuLoqw677zzDu68804kJCRg9OjR6jL0oaGhmDJlipq7//778a9//QtDhw7FuHHjkJ+fj08++QTNmze3KLQqtGnTBv3797dYhh4Apk6dqmb++9//YsOGDejatSsef/xxxMfH49KlS9i5cyfWrl2LS5cuAQAef/xxzJo1C4888giSk5NRr149fPPNNwgICND0HCukpqZi8ODBuOOOO5CUlIT58+fjwQcftNr766abbkKbNm3w/fffo1WrVujYseN1H/uWW25B7dq1MXLkSIwbNw4eHh745ptvhIYUPvHEE/j0008xatQoJCcno1GjRliyZAm2bt2KDz74wGp+IxGRW3DY+otERGTF1jL0fn5+SocOHZRPPvlEKS8vt8jn5OQozz//vBIdHa34+PgozZo1U9555x01l5ycrHh7e1ssLa8oilJaWqp06dJFiY6OVi5fvqwoytVl2AMDA5Vjx44p/fr1UwICApTIyEjl9ddfV8rKyix+HpWWoVcURdm5c6fSv39/JSgoSAkICFASExOVP/74w+o5fv7550rjxo0VLy8vTUusf/fdd0rLli0Vk8mktGnTRvn555+Ve+65R2nZsqWaqViG/p133rH5GGvXrlW6d++u+Pv7KyEhIcqgQYOUAwcOWOVWr16ttGnTRvH19VVatGihzJ8/v8pl6MeMGaPMnz9fadasmWIymZSbbrrJ5nPJyMhQxowZo8TExCg+Pj5KVFSU0qdPH+Wzzz6zyKWlpSmDBw9WAgIClDp16ijPPfecsmrVKruWoT9w4IAyfPhwJTg4WKldu7YyduxYpaCgwObPTJ8+XQGg/Oc//6n2sc1t3bpV6datm+Lv769ER0crkyZNUn777TerNvbq1Utp3bq11c/bWuo/IyNDefTRR5U6deoovr6+Stu2bZW5c+dqbhMRkavxUBTOhiUiImDUqFFYsmSJ5jNLjtShQwfUrVsXa9asccjv9/DwwJgxY6yGf7qSDz/8EM8//zxOnDiBhg0bOro5RESGwTlgRETktEpKStTFRyps3LgRe/bsQe/evR3TKDegKAr+97//oVevXiy+iIh0xjlgRETktM6cOYO+ffvioYceQnR0NA4dOoQ5c+YgKioKTz31lKOb53Ly8vLw888/Y8OGDdi7dy9++uknRzeJiMhwWIAREZHTql27Njp16oQvvvgCFy5cQGBgIAYOHIj//ve/CA8Pd3TzXM6FCxfw4IMPolatWnjllVcwePBgRzeJiMhwOAeMiIiIiIhIJ5wDRkREREREpBMWYERERERERDphAUZERERERKQTFmBEREREREQ6YQFGRERERESkExZgREREREREOmEBRkREREREpBMWYERE5FLmzZsHDw8PnDhxwtFNISIishsLMCIiIiIiIp2wACMiIiIiItIJCzAiIjK0/Px8RzeBiIgMhAUYERHVqCVLlsDDwwObNm2yuu/TTz+Fh4cH9u3bh7///hujRo1C48aN4efnh6ioKPzzn//ExYsXNf2ejz/+GK1bt4bJZEJ0dDTGjBmDK1euWGR69+6NNm3aIDk5GT179kRAQABeeeUVTY8/ZcoUeHh44NChQ7j33nsREhKC8PBwPPfccygsLLTIzp07F7fddhsiIiJgMpkQHx+PTz75xOoxy8vLMWXKFERHRyMgIACJiYk4cOAAGjVqhFGjRllkjx8/jn/84x8ICwtDQEAAunXrhuXLl2tqOxEROQ9vRzeAiIjc28CBAxEUFITFixejV69eFvctWrQIrVu3Rps2bfDuu+/i+PHjePTRRxEVFYX9+/fjs88+w/79+7Ft2zZ4eHhU+TumTJmCqVOnom/fvnj66aeRkpKCTz75BNu3b8fWrVvh4+OjZi9evIg777wT999/Px566CFERkba9XzuvfdeNGrUCG+99Ra2bduGjz76CJcvX8bXX3+tZj755BO0bt0agwcPhre3N3755Rc888wzKC8vx5gxY9Tcyy+/jOnTp2PQoEHo378/9uzZg/79+1sVdBkZGbjllluQn5+PcePGITw8HF999RUGDx6MJUuWYOjQoXY9ByIiciCFiIiohj3wwANKRESEUlpaqt527tw5xdPTU5k2bZqiKIqSn59v9XMLFy5UACibN29Wb5s7d64CQElNTVUURVHOnz+v+Pr6Kv369VPKysrU3KxZsxQAypdffqne1qtXLwWAMmfOHLufw+uvv64AUAYPHmxx+zPPPKMAUPbs2aPeZuu59O/fX2ncuLF6PT09XfH29laGDBlikZsyZYoCQBk5cqR62/jx4xUAypYtW9TbcnJylLi4OKVRo0YWz5uIiJwbhyASEVGNu++++3D+/Hls3LhRvW3JkiUoLy/HfffdBwDw9/dX7yssLERmZia6desGANi5c2eVj7127VoUFxdj/Pjx8PS89rH2+OOPIyQkxGqYnslkwqOPPnrDz8X8DBYAPPvsswCAFStWqLeZP5esrCxkZmaiV69eOH78OLKysgAA69atQ2lpKZ555hmbj2duxYoVuPnmm9GjRw/1tqCgIDzxxBM4ceIEDhw4cMPPh4iI9MUCjIiIatwdd9yB0NBQLFq0SL1t0aJF6NChA5o3bw4AuHTpEp577jlERkbC398fdevWRVxcHACoRYstaWlpAIAWLVpY3O7r64vGjRur91eoX78+fH19b/i5NGvWzOJ6kyZN4OnpabEv2datW9G3b18EBgaiVq1aqFu3rjrXrOK5VLSradOmFo8XFhaG2rVrW9yWlpZm9fwAoFWrVhaPRUREzo9zwIiIqMaZTCYMGTIEy5Ytw8cff4yMjAxs3boV//nPf9TMvffeiz/++AMTJ05Ehw4dEBQUhPLyctxxxx0oLy+X1hbzs1MyVJ6bduzYMfTp0wctW7bEe++9h5iYGPj6+mLFihV4//33pT4XIiJyPSzAiIhIF/fddx+++uorrFu3DgcPHoSiKOrww8uXL2PdunWYOnUqJk+erP7MkSNHrvu4sbGxAICUlBQ0btxYvb24uBipqano27ev1Odx5MgR9cwcABw9ehTl5eVo1KgRAOCXX35BUVERfv75ZzRs2FDNbdiwwWa7jx49avF4Fy9exOXLl62yKSkpVm05dOiQxWMREZHz4xBEIiLSRd++fREWFoZFixZh0aJFuPnmm9XCw8vLCwCgKIrFz3zwwQeaHtfX1xcfffSRxc//73//Q1ZWFgYOHCjvSQCYPXu2xfWZM2cCAO68804Atp9LVlYW5s6da/Fzffr0gbe3t9Xy9LNmzbL6nQMGDMBff/2FpKQk9ba8vDx89tlnaNSoEeLj4wWeERER6YlnwIiISBc+Pj4YNmwYvvvuO+Tl5WHGjBnqfSEhIejZsyemT5+OkpIS1K9fH6tXr0Zqaup1H7du3bp4+eWXMXXqVNxxxx0YPHgwUlJS8PHHH6NLly546KGHpD6P1NRUDB48GHfccQeSkpIwf/58PPjgg2jfvj0AoF+/fvD19cWgQYPw5JNPIjc3F59//jkiIiJw7tw59XEiIyPx3HPP4d1331Ufb8+ePVi5ciXq1KljMbTxpZdewsKFC3HnnXdi3LhxCAsLw1dffYXU1FQsXbrUYvERIiJybnzHJiIi3dx3333Izc0FcHXOl7kFCxagf//+mD17Nl5++WX4+Phg5cqVmh53ypQpmDVrFk6ePInnn38eixcvxhNPPIHVq1db7AEmw6JFi2AymfDSSy9h+fLlGDt2LP73v/+p97do0ULdfHrChAmYM2cOnnjiCTz33HNWj/X222/j3//+N7Zv344JEybg6NGjWL16NRRFgZ+fn5qLjIzEH3/8gdtvvx0zZ87Eyy+/DF9fX/zyyy/cA4yIyMV4KJXHexAREZGVis2eL1y4gDp16tTY77ly5Qpq166NN998E6+++mqN/R4iInIMngEjIiJykIKCAqvbKua99e7dW9/GEBGRLjgHjIiIDC03N1cdFlmVunXr1sjvXrRoEebNm4cBAwYgKCgIv//+OxYuXIh+/fqhe/fuNfI7iYjIsViAERGRoc2YMQNTp06tNqNlMZAb0a5dO3h7e2P69OnIzs5WF+Z48803a+T3ERGR43EOGBERGdrx48dx/PjxajM9evSwWBSDiIjoRrEAIyIiIiIi0gkX4SAiIiIiItKJ284BKy8vx9mzZxEcHGyxmSUREREREZFsiqIgJycH0dHR8PSs+jyX2xZgZ8+eRUxMjKObQUREREREBnLq1Ck0aNCgyvvdtgALDg4GcLUDQkJCHNwaayUlJVi9ejX69esHHx8fRzfH5bD/xLD/xLD/xLD/xLD/xLD/xLD/xLD/xDh7/2VnZyMmJkatQ6ritgVYxbDDkJAQpy3AAgICEBIS4pQvIGfH/hPD/hPD/hPD/hPD/hPD/hPD/hPD/hPjKv13velPXISDiIiIiIhIJyzAiIiIiIiIdMICjIiIiIiISCcswIiIiIiIiHTCAoyIiIiIiEgnLMCIiIiIiIh0wgKMiIiIiIhIJyzAiIiIiIiIdMICjIiIiIiISCcswIiIiIiIiHTCAoyIiIiIiEgnLMCIiIiIiIh0wgKMXE5xcTE++ugjfPbZZ/joo49QXFzs6CYREZELKCsrw6ZNm7B582Zs2rQJZWVljm6SS2H/iWH/iXGn/mMBRi5l0qRJCAwMxIQJE7BixQpMmDABgYGBmDRpkqOb5jJYwIph/4lxpw9Qci0//PADmjZtittvvx3vvfcebr/9djRt2hQ//PCDo5vmEth/Yn744Qc0adLEov+aNGnC/tPI7V5/ipvKyspSAChZWVmObopNxcXFyo8//qgUFxc7uikuY+LEiQoAJTIyUpkzZ44yd+5cZc6cOUpkZKQCQJk4caKjm+j0Jk6cqHh7eysA1P+8vb3Zdxqx/8QsXbpUadSokUX/NWrUSFm6dKmjm+YycnJylEGDBimxsbHKoEGDlJycHEc3ySUsXbpU8fDwUAYNGqRs2bJFWbhwobJlyxZl0KBBioeHB1+D11HRf/7+/hZ/v/7+/uw/DZYuXaoAUHx9fS36r+I6+696Fa+/AQMGKEOHDlXatm2rDB06VBkwYIDTvf601h8eiqIoulZ8OsnOzkZoaCiysrIQEhLi6OZYKSkpwYoVKzBgwAD4+Pg4ujlOr7i4GIGBgQgPD8fp06ehKIrafx4eHmjQoAEuXryIvLw8+Pr6Orq5TmnSpEl455134OnpifLycvX2iusTJ07E9OnTHdhC51bRfxERERgxYgTy8/MREBCAb7/9FufPn2f/XccPP/yA4cOHY+DAgbj99ttx5MgRNGvWDGvWrMHy5cuxZMkSDBs2zNHNdGo333wztm/fbnV7ly5d8NdffzmgRa6hrKwMTZs2Rdu2bbF48WLMnj0b69evx2233YYxY8bg3nvvxb59+3DkyBF4eXk5urlOp6ysDNHR0Th//jwGDBiAJk2aICUlBS1atMCxY8ewYsUKRERE4OzZs+w/G8rKylCvXj1cuHChygz7r2oVf78FBQXIyMiwuj8yMhIBAQFO8/eruf7Qoxp0BGc+A1ZaWqqsWbNGeeGFF5Q1a9YopaWljm6S03v//fcVAMrnn3+uKIr1GcRPP/1UAaC8//77Dmyl8yoqKlI8PT0VAMrAgQMtjgAPHDhQAaB4enoqRUVFjm6qUyoqKlK8vb2V0NBQJTY21uIIZmxsrBIaGqp4e3uz/6pQWlqqNGrUSOncubMSExNj0X8xMTFK586dlbi4OL4XVqNLly4W/Vb5vy5duji6iU5rw4YNCgBlxIgRipeXl0W/eXl5KQ8++KACQNmwYYOjm+qU1q5dqwBQ6tevb3MEQP369RUAytq1ax3dVKdU0X/X+4/9Z1vF3+/1/nOWv1+t9QfngOnM7caw6uTYsWMAgLvuusvm/RW3V+TI0syZM1FeXo527dphyZIl+PPPP/HNN9/gzz//xJIlS9C2bVuUl5dj5syZjm6qU/r4449RWlqKrKwsqyNwGRkZyMrKQmlpKT7++GMHtdC5bdmyBSdOnMCOHTtw6tQpi/tOnTqFHTt2IDU1FVu2bHFQC51bbm6uzTNf5rZv347c3FydWuRazp07BwD49ttvoVQa9KMoChYsWGCRI0sbN24EAJw5cwbh4eGYM2cO5s6dizlz5iA8PBxnzpyxyJGllStXSs0ZTVpamtScs2ABpqOKITjp6ekWt6enp2P48OEswqrRpEkTAMCvv/5qcxL/r7/+apEjS7///juAq/0TFBRksYhJUFAQmjZtapEjS0eOHFEvFxUVWdxnft08R9dUfEGTlTOa+++/X2rOaMLDw9XLAwYMwJYtW7Bw4UJs2bIFAwYMsJmjayoWyqlduzbS0tLQpEkT7N27F02aNEFaWhpq165tkSNLCxculJozmvnz50vNOQtvRzfAKMrKyvD0009DURSbR+AURcHTTz+Nu+++2ynGsDqbZ555BhMnTsSECRMwbdo09Sj6e++9h5iYGGRnZ8Pb2xvPPPOMg1vqnIKCggAAy5Ytg6en5XEXRVGwbNkyixxZMp8z5+HhYfE3bH7dPEfXnD171uJ6ZGQkOnfujB07dlicUayco6u2bt0qNWc0e/bsAQAEBwdj2bJlUBQFFy9eRNeuXbFs2TKEhYUhJycHe/bsQb9+/RzcWudz5coVAIDJZEKLFi3UMw3vvfceYmNjYTKZLHJkSWu/sP9sW79+vcX1jh07IiAgAPn5+di5c2eVOWfHM2A62bhxI86fPw8AVstWV1w/f/48T+FXwdfXFwMHDkRWVpbNIUxZWVkYOHAgF+Cown333ade7t+/v8UR4P79+9vM0TXmhWm/fv3w4YcfYuzYsfjwww8tvrCxgLUtKSlJvRwTE4OMjAwsX74cGRkZiImJsZmja8zPslY+gGJ+vfLZWbrqjz/+AADk5ORg2LBh2LZtGwoKCrBt2zYMGzYMOTk5Fjmy5OHhAeDqaJ3CwkJ88skn+PLLL/HJJ5+gsLBQHdVTkSNLWrcq4ZYmtlU+sLlz5078/vvvFsWXrZyz4xkwnZhX5tUdQV+/fj369Omje/ucXVlZ2XU/HJOSklBWVsYziDYcPHhQvZycnIxXX30VmZmZqFOnDg4dOmSRq2qenZHt3r1bvbx69WqsWrVKvW7+Bdg8R9csX75cvWzrAIqtHF1j/nlR+UuG+fXKoyvoquDgYADAY489hjVr1qBnz57qfY0aNcI///lPfPnll2qOLJkP7c/OzsbTTz+tXvf397eZo2t8fHxQWlqqKUfVq2oVZ1fEM2A6OX78uHq58h+Z+XXzHF2zceNGXLhwAX5+fjbv9/Pz4xnEapgXr+fPn8fmzZtx4MABbN68WT0zWzlH1xQUFKiXq/sCbJ6ja7R8+bAnZzRav2C46heRmvbwww8DAL755hucPHnS4r60tDR8++23Fjmy1LZtWwCAl5eX1XtcQUGBetCzIkckU506ddTL1X3+mudcAQswnZh/ya1uEr95jq6pKKwKCwsBXB1G99///lcdPldxOwsw27QOjeMQOttiY2PVy9UNATPP0TVazyzwDIRtVR14utGc0dx2223w9fVFUVGRzTnYRUVFMJlMuO222xzUQueWmZkJoOpFNipur8iRJf79iomIiJCacxYswHSi9cg4j6Dblp+fr14+ePAgtm7dipdffhlbt261GF5nnqNrhg8frl4+duwYIiMj4ePjg8jISIul+81zdE27du3Uy9UdgTPP0TWJiYlSc0ajdXU+ruJnW1lZGUpKSqrNFBcXcxW/KoSFhUnNGU3FKpGyckbTvXt3qTlnwQJMJzwCIsZ8zk2rVq2Qm5sLRVGQm5uLVq1a2czRNeb90qRJE2RkZKCkpAQZGRkW4/bZf7ZxFSsxWs/scwSAbVoX1+AiHLbNmjXruvPjFEXBrFmzdGqRa6lYJVdWzmhCQkKk5oxG6+JqrrYIGwswnVy+fFlqzmiys7Ol5oxG69xCzkG07fTp01JzRlMxRFhWzmi0Ts7nJH7bNm3aZHHdz88PMTExVgc8K+foqh07dkjNEdmja9euUnPOggWYTnJzc6XmjKZu3bpSc0YTGRkpNWc05it9ycgZTVRUlNSc0YSGhkrNGY35MGsvLy8UFhbi1KlTKCwstFg11zxH11xv+Ka9OaPhCAox7jqH3UNx03Vrs7OzERoaiqysLKc4rdukSRNNZxcaN27MDwEbAgMD1fldPj4+Fm/05tcDAgKQl5fnkDY6s9jYWHX1rwEDBqB///44cuQImjVrht9++w0rVqwAADRs2FDdZJOu8fX1VV9jJpPJYqiX+XUfHx/u5WJDfHy8xVzNqrRq1QoHDhzQoUWuJSoqymLD6qpERkaqezLRNd7e3ur8ruqWsfby8uJKnDbUqVMHFy9evG4uPDycC3HYYM/+aG76lVxI69atNX0uxMfHY//+/Tq0qHpa6w/uA6YTngETY764RuWjbObXuQiHbeZf3tasWYP4+Hi0atUKqampWLNmjc0cXWP+GqtuFVMeAbZN698l/35t4xwwMeaLa1S3iA4X4bCN31/Ikcz3irzjjjvQtGlTHD58GM2bN8fRo0fVueuV95h0dizAdMKd0MVU3ry6uhxZqzhL4+/vj4KCAsyYMcPifj8/PxQWFsJkMjmohc6t8lnX6nJkjQWEmLi4OOzatUtTjqxVvL9pyZG1ymf9q8sRyVZxYKRWrVo4ePCgWnCtXr0ajRo1Us82udoBFM4B0wmXERbTrVs39bKnpyeio6NRq1YtREdHW+zDZJ6ja0aNGgXg6jYHqampiI+PR3BwMOLj45Gamqp+OanIkaXnn39eas5ouAiHmMmTJ0vNGU3Pnj2l5oymXr16UnNGwzmcYpo2bQrg6hy5ykVWaWkpsrKyLHKuggWYTmJiYqTmjMZ8qfny8nIUFhZi+PDhKCwstBhCYp6jawYPHqxejouLw4EDB5CTk4MDBw5YHDU3z9E1WufFcf6cbVrnNXD+g21Hjx6VmjOaysMORXNGU3nzedGc0URHR0vNGc0tt9yiXq680rD5dfOcK+Bfi054BETMX3/9ZXH90qVL+OKLL3Dp0qVqc3RV7969r7tHhslkQu/evfVpkIvZu3ev1JzR8P1PzJYtW6TmjKZWrVpSc0bDVfzExMbGSs0ZzTvvvCM15yxYgOkkISFBas5oOIdOTHFx8XX7pqioiP1XBa0re3EFMNu4DL0Y7kMnhvsgiikoKJCaM5qKFYhl5YwmKSlJas5ZsAAjl6D1zAzP4Nj2wgsvSM0ZDb+AiOEqiGLq168vNWc0Whdn4iJOtmldmp9L+NvGM4hi/ve//0nNOQsWYDr5448/pOaMZvr06VJzRqN1aCaHcNrm7a1twVitOaPhRuBieAZRTIcOHdTLlf9Gza+b5+gavv+J4UbWYv7880+pOWfBAkwnZ86ckZozmpkzZ0rNGY3W/b24D5htnIQupnPnzlJzRlOxypesnNGY/11WPktjfp1/v7ZxDp0YngETY16Y1qlTB7169UJ8fDx69eqFOnXq2My5Ar7b6ISr4Ij56KOPpOaMRuv+LNzHxTat+3txHzDbuA2HmG3btknNGQ1XMRXTpUsXqTmj4RBOMeZFVmZmJjZt2oQDBw5g06ZNFvOuzXOugAWYTho0aCA1ZzQXL16UmjMazoEQwwMoYiqvViqaMxr2n5gmTZpIzRkNz4CJ4TYcYsLCwqTmnAULMJ1wI0NyJI5BF/Paa69JzRkNz0CIMd9Cwt/f3+I+8+vX22rCqHr06KFePnbsGAYNGoTY2FgMGjQIx44ds5mja86dOyc1ZzQ8AComICBAas5ZsADTyeTJk6XmjIYbaYqpvHu8aM5ozL+kycgZzeHDh6XmjMbPz0+9XHmlTfPr5jm65umnn1YvN2nSBL/88gvS0tLwyy+/WJz1Ms/RNSkpKVJzRuOuBYRe3HUEAAswIgPgB4AYboQrhkNwxEREREjNGQ23kRCTl5cnNWc0t956q9Sc0VQ+6y+acxYswByguiEkZJuXl5fUnNG0bNlSas5oKja4rWqRjYrll7kRrm1cxERMw4YNpeaMpmJuiKenJzIyMhAfH4/g4GDEx8cjIyNDXf3Q1eaQ6KW4uFhqzmj49ysmMDBQas5ZsADTifkGt5WHeZlf50a4trGAEMONrMVUDO2qao5cxepVHAJmW3Z2tnq58lLf5tfNc3TNsGHDpOaMZtasWQCuDlGPjIzEgQMHkJOTgwMHDiAyMlIdul6RI0vcSF0MRwCIadGihdScs2ABphPzDR4rHyUyv86NIG27cOGC1JzRPPHEE1JzRhMTEyM1ZzTmhVXleZrm11mA2cYhiGK4CJEYFhBi3HUjYb246z66LMB0wmXUxfAInBjuoyYmJydHas5oKgqD663yxQLCto8//lhqzmi4jDo50vHjx6XmjMZdD8CzANMJNyIVo3VoF4eA2TZz5kypOaPhMsxi+vXrB+DqEfJatWqhcePGqF27Nho3bmzxpbciR5Z27NghNWc0y5Ytk5ozGq3bG3AbBNuKioqk5ozGfHGwO++8E0OGDEHbtm0xZMgQ3HnnnTZzrsDb0Q0wCnet4PVSr149ix3Pq8uRNfPVvW677Tb88ccfKCoqgslkwi233IL169db5egangETc/vtt+Ptt98GAFy5cgVXrlwBAFy+fNkqR9Z4AErMpk2bpOaMhvtYiak871U0ZzT169dXL2/cuFH9nrJ3716Loss85wr4r62TjIwMqTmj4SpMYqKjo9XL69evR2FhIRRFQWFhoVp8Vc7RNRWrHALVLyJhnqNrevfufd2jkwEBAVwEpgqPPfaY1JzRFBYWSs0ZTVRUlNSc0Wj9XODnh20JCQnq5cpziM0XsTPPuQIWYDpZu3atxfWYmBg0bdrUatJ+5RxdlZaWJjVnNAMGDLC4HhwcjD59+iA4OLjaHF1lvsGjh4cH2rdvj5YtW6J9+/YWR31dbSNIvZSVlalfbiufpam4XlhYyI3Aq8AvcGIqH5jz9PREkyZNrA6m8ACebVrPLLjaGQi98Ay2GPPvyZWHaZpfd7VFsFiA6aRiyE2FU6dO4ejRozh16lS1ObqKZ8DEVF7dKycnB+vWrbMaMsdVwGwzLwzKysqwZ88eHDp0CHv27LG6j6x9/PHHKC8vx9NPP211lLxevXp48sknUV5ezkUkqrB161apOaOpfGarvLwcx44dszqazjNgtrVt21ZqzmhCQkKk5ozm1ltvRd26davNREREuNxG1izAdJKVlSU1ZzTcyFXMN998IzVnNJGRkVJzRnPs2DEAwOTJk5GSkoIZM2ZgwIABmDFjBg4dOoTJkydb5MjSvn37pOaMRuuBTR4AtY3LqIvhAWRxlecLV+aKo09YgOnEXXfy1guPIInJy8uTmjOahx56SGrOaJo0aQIAmDZtGlq0aIEJEyZgxYoVmDBhAlq0aIE33njDIkeWKs8N9vPzQ3BwsNWQJc4hppqgdX8+7uNnG/fxE7Ny5UqUlpZWmyktLcXKlSt1apEcLMB0EhQUJDVnNFwGVwwPAIjhEUwxzzzzDDw9PfHJJ59YLdV/7tw5zJkzB56ennjmmWcc1ELnVnloa2FhIXJycqyGzHEILNUE87nClVc6NL9eeU4xXdW+fXupOaP597//rV6uag5x5ZwrYAGmE62TA11tEqFebrrpJqk5o5k6darUnNFwI1wxXl5eMJlMAK7Ov0lMTETPnj2RmJiozsMxmUzw8vJyZDOd1vWO/tqbM5quXbtKzRlNxd8uYP0dpWHDhjZzdA1XwRaTkpKiXq5uEQ7znCvgkkk62bt3r9Sc0dxyyy349ddfNeXIGl9/YsznZnp4eEBRFJvXOYfTtoq9W4KCgpCbm4sNGzZY3F9x+8aNG9GnTx8HtdJ5eXp6ajq7xX2EbNOyh6Q9OaMxP2t98uRJ9OnTB1FRUUhPT8e6dets5uiapKQkqTmjMf+8DQ8PR2JiIi5evIjw8HBs2LBB/bs1z7kCFmA64SIcYg4fPiw1ZzRbtmyRmjMaf39/9UhbZmYmRo0ahb///hvt2rXDvHnzEB4erubI2saNGwEAubm5Nu+vuJ0FmG0mk0nTCqU8A2Gb1sKABYRtMTExOHz4MHx8fFBSUmJRdAFQb+cIHts4h05MVFQUTpw4AeDq5+/3339fZc6V8HCZTrR+MeMXONu0nP2yJ2c0J0+eVC9XXinS/Lp5jq4xH5sfHh6OX375BWlpafjll1/U4qtyjq4xHxpXp04dDB8+HH369MHw4cNRp04dmzm6Ji4uTmrOaMznKVUe5mp+vfL8Jrpq4sSJAKrepqTi9oockUyNGjWSmnMWLMB0cvPNN0vNGU3F8JuqhthU3M5J6LaZ73dT+UPU/HrlfXHoqoSEBKk5ozFfIvjy5ctYsmQJ1q1bhyVLllgsL+yKSwnrgdtwiDH/Ylb5M8L8uqt9gdNL3759r1ucenh4oG/fvjq1yLWEhoZKzRmN1sVdXG0RGBZgOmnRooXUnNE0b94cwLUCoU6dOggNDVWPnlfcXpEjS1wGV0zPnj2l5oxm//796uXqvgCb5+ia3r17S80ZTeU5h6I5oykoKLju/BpFUVBQUKBTi1wLPz/EaJ3b5WpzwFiA6WT58uVSc0YzcuRIi+uZmZnIysqymjRdOUdX9erVS2rOaLgRrhh3/QDVS35+vtSc0fz9999Sc0bz8MMPq5crT5Mwv26eo2s2bdokNUfugQWYTrgIh5hvv/1Was5o9uzZIzVnNFu3blUvV7cPjnmOrgkLC5OaMxqtQ4M5hNi2ikVgZOWM5ujRowCABg0aWO09V1hYiAYNGljkyBK//4k5c+aM1JyzYAGmE3cdw6oX83kiMnJGc+zYMak5o6lYpS8iIsLmPjgVQzerWuXP6LQubsBFEGzjGRwx5ou71K5dG8HBwfD29kZwcDBq165tM0fXVMxNOn36tM37K27nHCbbzM/s+/r6Wtxnfp0jAGyrvPeXaM5ZsADTScURIlk5o+EQHDEcAiamosAqKCjAvn378NRTT6FDhw546qmnsHfvXnXuA+fQ2aZ1bgjnkNhmvjppdV/guIqpbRcvXlQvZ2dnIycnB6WlpcjJybFY+ts8R9eYD+2vvNWB+XVOAbDNvDCtfJba/DoLWNvc9QAeCzCduGsFrxcuwyyGq6iJqXhd5eTkICQkBHPmzMHu3bsxZ84chISEICcnxyJHlmrVqiU1ZzTmZ1aLi4st7jO/zjOwtnERGDE7d+5UL9sagmgrR9dMmDBBvVz5LKv5dfMcXWO+VYmMnLNgAaaTvLw8qTmj4SqSYsz3qpKRM5rbbrtNas5ojh8/LjVnNObD5GTkjMb8zH51czg5AsC2s2fPSs0ZzaRJk6TmjMZdp6CwANOJ1qEhHEJiW+V5N6I5o6lqA80bzRnNLbfcIjVHZI+uXbtKzRmN+eIuDRs2tLgvNjbWZo6u0XpmlWdgbdO6Pyn3MbWtqrmHN5pzFizAdMJVrMSsWLFCas5oKg9bEs0ZzaefflrlfeZH0KvLGVlUVJTUnNHwDJgYLy8v9XJaWprFfSdOnLCZI5Jl4sSJUnNGUzHEX1bOWdhVgJWVleHf//434uLi4O/vjyZNmuCNN96wOG2vKAomT56MevXqwd/fH3379sWRI0csHufSpUsYMWIEQkJCUKtWLYwePdrqyMnff/+NW2+9FX5+foiJicH06dMFnqbjVZ64KpozmkuXLknNGQ0X4RBT8R5Wt25dq/sURVFvr/xeR1edO3dOas5o3HUSul5CQkKk5oyGc4jFHD58WGrOaNz1DKJdBdjbb7+NTz75BLNmzcLBgwfx9ttvY/r06Zg5c6aamT59Oj766CPMmTMHf/75JwIDA9G/f3+LiZojRozA/v37sWbNGvz666/YvHkznnjiCfX+7Oxs9OvXD7GxsUhOTsY777yDKVOm4LPPPpPwlB0jKChIas5oKk/8Fc0ZjdYjuzwCbFvFF9sLFy7YvL/idn4Btu3KlStSc0bDAlbMgw8+KDVnNLt27ZKaMxo/Pz+pOaNx1wMA3vaE//jjD9x9990YOHAgAKBRo0ZYuHAh/vrrLwBXjwR/8MEHeO2113D33XcDAL7++mtERkbixx9/xP3334+DBw9i1apV2L59Ozp37gwAmDlzJgYMGIAZM2YgOjoa3377LYqLi/Hll1/C19cXrVu3xu7du/Hee+9ZFGquxF0reL2YLxUsI2c0np7ajrVozRlNp06dpOaMpkmTJkhNTdWUI2tcRVeM+QgbHx8ftG7dGgUFBfD398f+/fvVua+cw2Qb54CJ4QgoMRERETh16pSmnCuxqwC75ZZb8Nlnn+Hw4cNo3rw59uzZg99//x3vvfceACA1NRXp6eno27ev+jOhoaHo2rUrkpKScP/99yMpKQm1atVSiy8A6Nu3Lzw9PfHnn39i6NChSEpKQs+ePS32N+nfvz/efvttXL582eY496KiIosPn4ov4iUlJU6xsIA9Q+icob3Oxp4PAPafNXuOoLP/rP3++++acw899FANt8b1bNu2TXOOrz9r9mzEzP6zNn78ePVySUkJdu/eXWVuyJAhurTJldizDydff9YqTlJoybH/rGkpvipyztB/WttgVwH20ksvITs7Gy1btoSXlxfKysrwf//3fxgxYgQAID09HQAQGRlp8XORkZHqfenp6VZVqre3N8LCwiwylffTqXjM9PR0mwXYW2+9halTp1rdvnr1agQEBNjzNGuEPcvQcyEJa/YcAWb/WbNnERj2n7VffvlFc27w4ME13BrXY88BFL7+rNlzAI/9Zy0zM1O97O3tbbH3kvn1zMxM9p8g9p81/v3qxxn6T+sBC7sKsMWLF+Pbb7/FggUL1GGB48ePR3R0tMN3QH/55ZfxwgsvqNezs7MRExODfv36udzE2gEDBji6CS6N/Wet4oCJlhz7z5o9cxDZf2LYf9YCAwM1vQYDAwPZfzbUqVNH3aOquo2Y69Spw/4TxP6zFhwcrOkgVHBwMPtPkDP0n9apMHYVYBMnTsRLL72E+++/HwDQtm1bpKWl4a233sLIkSPVJYQzMjJQr1499ecyMjLQoUMHAFeXGT5//rzF45aWluLSpUvqz0dFRSEjI8MiU3G9qmWKTSaTzfGzPj4+TjExz9PTU9MXYE9PT6dor7OpfNSyuhz7z1pwcLCmBQ6Cg4PZfzb4+flpWuLWz8+P/WdDcHCwpv7j68+2xo0b4+LFi5py7D9rTz75JF5//XUA1iu9ml9/8skn2X82xMTEaBoGFhMTw/6zwZ4RUOw/ayaTSdMoKJPJ5BT9p7UNds24z8/Pt5qk7+XlpQ5viouLQ1RUFNatW6fen52djT///BMJCQkAgISEBFy5cgXJyclqZv369SgvL1c3kUxISMDmzZstxlGuWbMGLVq0cNl9Try9tdW6WnNGw1X8xBQUFEjNGU3lYdWiOaPhRupibG1/IJIzGvPNlmXkjOaee+6RmjMarXOCnGH+kjMyX1dCRs5Z2FWADRo0CP/3f/+H5cuX48SJE1i2bBnee+89DB06FMDVJZjHjx+PN998Ez///DP27t2LRx55BNHR0erE1latWuGOO+7A448/jr/++gtbt27F2LFjcf/99yM6OhrA1aVgfX19MXr0aOzfvx+LFi3Chx9+aDHE0NUEBgZKzRkNNxIWw/4T464bQeqlquX7bzRnNJVHhIjmjObPP/+UmjMabgMjRus6BM6wXoEzevzxx6XmnIVdBdjMmTMxfPhwPPPMM2jVqhUmTJiAJ598Em+88YaamTRpEp599lk88cQT6NKlC3Jzc7Fq1SqL/Q2+/fZbtGzZEn369MGAAQPQo0cPiz2+QkNDsXr1aqSmpqJTp0548cUXMXnyZJddgh64OrRGZs5ouBGpGG7ELEbL8Fd7ckaTlZUlNWc07roPjl4q5n/JyhkNtzEREx8fLzVnNN99953UnLOwa7xbcHAwPvjgA3zwwQdVZjw8PDBt2jRMmzatykxYWBgWLFhQ7e9q164dtmzZYk/znFpcXBzS0tI05ciaj4+PpjHA/AJCNaFu3bo4c+aMphyRbDyDLSYoKEhqzmgaN24sNWc0tWrVkpozmn379knNOQsertCJ1pUYXW3FRr00atRIas5ozM9Ay8gZTdOmTaXmjIZH0MWY74kpI2c0bdu2VS9XHiVhft08R9c0b95cas5oeABFjPk2OpU/I8yva91ux1lwxQedrFy5UmrOaNq3b4+UlBRNObLGL8Bijh8/LjVHZA8uoiPGfGirj48Phg4dioCAAOTn52PZsmXqF18OgbVt5syZ6mVfX18MGTJE7b8ff/xR7b+ZM2di0KBBjmqm06pq4+8bzRmN+QrnXl5e+Mc//oHAwEDk5eXhhx9+UAsvWyuhOzMWYDrhKjhiOnfujMWLF2vKkTV7NrIma1yEgxxJyxYS9uSM5uTJk+rl4uJiLFq06Lo5uqZiI+HIyEhkZmZafBZ7eXkhIiIC58+f17zhsNHwAIqY6Oho7Nq1C8DV78hV/f1WLOTnKni4WyecRC0mLCxMao7IHlzFVIzW7UNcdZuRmqZlD0l7ckYVHh5ucyud8PBwB7XINTRo0ABA1ftZ5efnW+TIEueAiXHXETyu1VoX1qVLF6k5o/niiy+k5ozGXd/A9MI5nGJYwIpp1qyZ1JzRVOzvZWsza0VR1Nu5D5htFVsN5ebmWhX5ZWVlyM3NtciRpdatW0vNGU29evWk5pwFv22RSzh48KDUnNGEhoZKzRnNkSNHpOaMhpP4xSQmJkrNGU3v3r2l5ozGXb8A64VTUMS46zZELMB04u/vLzVnNNwIUkyrVq2k5ozm3LlzUnNGc/nyZak5o9mwYYPUnNGY729YeaU08+vcB9E2LiIhpkOHDlJzRmN+5rq6VUxtneF2ZizAdMIhiGI4B0yMt7e29Xa05ozMy8ur2utkjQdQxGhZAdaenNGY7yla3TLW7rT3qEw//vij1JzRVAzRBK5+xgYEBMDLywsBAQEWn7nmObrG/O8yPDwcPXv2RHx8PHr27Gkxf9PV/n5ZgOnk1ltvlZozGh5BEpORkSE1Z2S25kBQ9bKzs6XmjIaLcIipOMvVvHlzxMTEWNzXsGFDde6cq+0jpBeOABBz9uxZ9XJpaSny8/NRVlaG/Px8lJaW2szRNRWrM/v5+SEzMxObN2/GgQMHsHnzZmRmZqr7l7raKs4swHSiZQl1e3JGw0n8YqpavepGc0Zz9913S80ZDTciFWN+Zr9OnTpo164d6tevj3bt2qFOnTo2c3RNRb8UFxdbDTMsLy9XX3fsP9siIyOl5oymYpVIWTmjiYuLA1D1CImK2ytyroIFmE6+++47qTmj2bFjh9QckT0eeeQRqTmj4T44YswXN8jMzMTff/+NM2fO4O+//0ZmZqbNHF0TFRUFADhx4gQKCgowfPhw3HbbbRg+fDgKCgqQlpZmkSOSqV27dlJzRjNt2jSpOWfBCR864RFgMRzCJIZnEMXMmzdPc27YsGE12xgXFBgYaFEoVJcjaxEREVJzRmNeWF24cAFLliy5bo6u0brBMjdito2r6Ipx1znsPAOmE62rK3EVJtuysrKk5oyGQ0jEnDhxQmrOaDp37iw1ZzSV5y2J5ojswWXUxZw5c0ZqzmgWLFggNecsWICRS+AkdDFaJ6e62iRWvWjdoJUbudrGIYhi9u7dKzVnNOaLG3h7eyMxMRG9evVCYmKixVFzLoJgG9//xJh/rlZeRt18FU5+/tqmZfSEPTlnwQKMyAC2b98uNWc03EZCDPcRErN161apOaOp6Bdvb2+UlZVhw4YN2LRpEzZs2ICysjK1CGP/2cYRKGKOHj2qXra1CIytHF2zbds2qTlnwQKMyADMl7qVkTOa1atXS80ZzYULF6TmjIZDwMTs27cPwNX3N5PJZHGfyWRS3/cqcmSJq+iK4eevGPPVIT08PNT90wICAizOKLraKpKuNWONiG6Ir6+vpuENvr6+OrTG9fALiBgWEGJq166taY+l2rVr69Aa1xYSEoKnn34aeXl5CAwMxLfffssNwK8jICBAas5ogoODceXKFU05qp6iKGqh5eoFK8+A6YSLIIjR+sWCX0Bsa9WqldSc0ezZs0dqjsge4eHhUnNGEx8fD+Dq0fPz58/j/fffx2effYb3338f58+fV4+iV+TIEhcREzNmzBj1cuWV+nx8fGzm6JpatWpJzTkLFmA64RuYmNtuu01qzmiOHz8uNWc0/PsVU3niuWjOaLiIjpiKwrSqv8+K21nA2qZ1cRIuYmLbpk2b1MuVz9qYn/U3z9E1oaGhUnPOggWYTrQO7eIQMNu0DhHhUBLbuIokOdJzzz0nNWc0WocmcQiTbeYrzcnIGQ0PQImp6BcvLy+b91fczv6zzV2X8ee7jU74Bibm9OnTUnNGYz7MQUbOaIKCgqTmjIbLqItp2rSp1JzRhISESM0ZjbuegdDLkCFDAFw9wF55s++oqCj1wHtFjiy56wgAFmA64TKuYtz1CIheGjZsKDVnNMXFxVJzRnPy5EmpOaPhEE4x5oV93bp1MXz4cNx2220YPnw46tatazNH1/AAnphx48YBuLrPYXp6usV96enp6v6HFTkyBq6CqBMOgRBjPm7aZDJZHOnw8/NThx66+qo4NYXLgIvhKn5izPe6kZEzmoyMDKk5o8nNzVUv5+TkYMmSJep1f39/mzm6hq8/MV5eXvD19a32AJ2vr2+VQxSNLjAwUNPJicDAQB1aIw8LMJ3UqlUL2dnZmnJkLSQkRF3GVVEU3HvvvQgICEB+fj5+/PFHixxZ4zLqYry8vDQV9/wAtc18bmvt2rXRp08fXLp0CWFhYVi3bh0uX75slaNrUlNTpeaMpl69egCuDfcyP9MaERGBoqIipKenqzmyxANQYtatW3fd0RHFxcVYt24d+vXrp1OrXIe7noHl6RadRERESM0ZjfmbUnFxMRYvXox58+Zh8eLFFm9sfPOyzfzMqqenJ0wmEzw8PGAymazuI2vcRkKM+evq8uXLWLJkCdavX48lS5aoxVflHF3DAyhibrnlFgBXh3udP3/e4r6MjAx1WFhFjiyZnyWUkTOaefPmAbi6SE52djaeeuopdOjQAU899RSys7PVucMVObJUed6caM5Z8NNOJ6dOnZKaM5qePXtKzRmN+ZGh8vJyFBUVQVEUFBUVWQz7crUjSHpx10nAemEBK4ZD2MXExMSolyuvlGt+3TxH10RHR0vNGU3F3MIePXqgXbt2mDNnDnbv3o05c+agXbt26NGjh0WOLLnrFAq+W+vEXU+h6kXrByM/QG2rU6eO1JzRVN48UzRnNF26dJGaMxr+/Yq55ZZbrlucenp68gxYFbiNiZiK1SFXrlyJNm3aYMuWLVi4cCG2bNmCNm3aYNWqVRY5slT5rLVozlmwANNJ/fr1peaMpnXr1lJzRsNlrMVwFTox3MdKTLNmzaTmjGbLli3qmX6TyWRxX8X18vJybNmyRfe2uQKtc9M5h922QYMGqZfLysqwaNEizJ07F4sWLbIoWs1z5P5YgOnkr7/+kpozGvOhhZXHmZtf5xBE2zgETAwnoYv54YcfpOaMZt26dVJzRrNx40b1cuVhwubXzXN0zcCBA6XmjOamm25SL69cuRKzZs3C6tWrMWvWLKxcudJmjq5x1xEoLMB0wo2YxRw7dky9XLFnhq3r5jm6Jjk5WWrOaPz8/KTmjObixYtSc0ZTed6SaM5ouA2CGM5BFMP3PzHuuogd/1rIJXAImJi0tDSpOaOJj4+XmjOailW+ZOWMRuv+Nq62D45ezIe2Vj5IYn6dQ2BtS0pKkpozmvDwcKk5o9GyhZM9OWfBAswBKh8l4lGj62vfvr3UnNHk5+dLzRnN8ePHpeaM5uabb1YvV/cF2DxH13AREzFr165VL1e3CqJ5jq5x1y/AeuEUFDHuOoKM3/x1Yn5ko/IwB/PrPAJiW9euXaXmjIZnEMVUbAIuK2c027dvVy9X9wXYPEfXaB1azSHYtnEbGDFcBVHMrFmz1MvVHYA3z9E1tWvXlppzFizAdJKYmCg1ZzRaNyjkRoa2aV3elsvg2la3bl2pOaPhHBwx7joJXS/cSFhMSkqK1JzRmM/tqu4APOeA2dapUyepOWfBAkwnjRs3lpozmtzcXKk5o+EXODGVz0zXqlULderUsVp2mWewbeMBADEcgi2m8pl9Ly8vREVFwcvLq9ocXcXPXzGVX2eiOaPZvXu31Jyz4LctnZw9e1Zqjsgely9flpozmspv7FUNNXS1DwC9BAQESM0ZTeWj5hEREWjQoAFOnz5tsfkozyDaVnl7iLKyMqSnp183R1f5+PhIzRlNRESEpuGtrraKn15s/a2K5JyFh+Jqs9Y0ys7ORmhoKLKyshASEuLo5sBkMqG4uPi6OV9fX6t9Ssi+I5Nu+pIWwv4T4+XlpenLraenJ+dB2MDXn5jQ0FBNCxyEhIQgKytLhxa5Fk9PT02vKw8PDxaxNvDvVwz7T4yr9Z/W+oNDEHWipfiyJ0dE+uERYHIkDgET466rqBGR6+IQRAfw9PS0OMpW+ToROZe4uDgcOnRIU46q179/f+Tm5uLkyZNo2LAhgoKC8Ntvvzm6WU5N6xlYziGxTetnLLeEISK98N1GJ+YfjNWtgsMPUNu4ipWYyotFiOaM5o477pCaM5qwsDD18urVq7F161acOnUKW7duxerVq23m6JrWrVtLzRkNFzERw43oxXTu3FlqzmjcdSNrFmA6adWqldSc0XAfKzH16tWTmjOajIwMqTmjadGihXq58jAv8+vmObrG19dXas5otM6r5vxr27p37y41ZzQcwi7GXRdxYgGmE61DkziEybbS0lKpOaPhFzgxZ86ckZozmqFDh0rNGU1aWprUnNGYTCapOaNp0KCB1JzRFBQUSM0ZzYULF6TmnAULMJ1wI1cx/AAVExgYKDVnNFrmf9mTM5rnnntOas5ogoKCpOaMxs/PT73s5eWlzvXy9PS0GPZvnqNrFi1aJDVnNHl5eVJzRqN1ZWFXW4GYBZhOduzYITVnNFzFSkxMTIzUnNFcvHhRas5ovLy8rrvJt7e3N+fAVoEH8MSYzw0uKytT512Xl5dbfGnjHGLbzPeak5EzmpMnT0rNGY27fv9jAaaTY8eOSc0ZzfW+vNmbMxotewjZkzMad/0A0MvatWuvOzy4tLQUa9eu1alFrqVt27ZSc0YTGRkpNWc0nAIgRusq11wN2zZ3nULBAkwn/AMUw0msYvbs2SM1ZzRaN3N3hk3fndGMGTMAAI0bN0ZBQQFmzJiBAQMGYMaMGSgoKFDnvlbkyFJ6errUnNE0atRIas5oKg9Nj4yMRKdOnawKVg5ht03r9gbcBsG2kpISqTlnwX9tnQQHB0vNGQ0LMDFZWVlSc0bDMxBiKobWjB49Gj4+Pmjfvj1atmyJ9u3bw8fHB48++qhFjizxAJ4YbsMhpnHjxhbXMzIykJycbLXqa+UcXcXvf2LctYDleC2dxMbGahofHRsbq0NrXI+7/gHqJTQ0VNME39DQUB1a43o4hFNMw4YNcfjwYXz44YeYM2cOTp06BQB47733EBMToy7/3bBhQ0c202mdO3dOas5odu/eLTVnNJmZmVJzRsNFxMS46xBYflvVCfexEtOnTx+pOaO58847peaMhl9AxEyYMAHA1Un6FcVXhVOnTqkHpypyZKl+/fpSc0bDRRDE8ACUGK0bzHMjetvcdQQACzCdnD59WmrOaHgGTMyAAQOk5oyGB1DEJCYmSs0ZTeUN0uvUqYPIyEjUqVOn2hxdZV6YVj7LYH6dBaxtXARLzIkTJ6TmjMZdF8Hit1WdFBcXS80Zze+//y41ZzSzZ8+WmjMaLkMvZuPGjVJzRnP58mWL65mZmcjIyLA641o5R1eZz+3q1asX2rRpg7CwMLRp0wa9evWymaNrWrVqpV6uPM/a/Lp5jq7hRsxkCw9X6KR+/fqahifxCJxtOTk5UnNG8/fff0vNGU3FHCVZOaP56quvNOf69etXw61xPdu3b5eaMxrzxSJWr16tXr506RL27dtnM0fXmK8uV3mlueruo6t8fHw0zU/iImLGwjNgOmnZsqXUnNHUrl1bas5o3HUSq160btDKjVxtS0tLk5ozGg4BE8NV6MRERERIzRlNz549peaMxl1ffyzAdMIhiGK4kaaYK1euSM0ZzdChQ6XmjMZdN9LUi/lcr8rzXM2vV54TRlcNGzZMas5oKq/ObDKZ4OHhYTWfjqs428ZFOMS46wEUFmA6WbVqldSc0XAfK3KkwsJCqTmj4QEAMeb7y1Ve6cv8Ovehs23evHlSc0YTHh5ucb2oqAiKolgNua6co6uWLl0qNUfugQWYTjgJU0xubq7UHJE9Nm/eLDVnNFzGWoyXl5fUnNEcO3ZMas5otC7uwkVgbOMIKLKFBZhOuIy1mKCgIKk5o9G6wTI3YraNi3CI4RkwMQEBAVJzRuOu+wjpReviGlyEwzZ+/xPjrgdQWIDphJP4xWjd34b74NjWrFkzqTmjKSsrk5ozGn6BE/PLL79IzRnNpUuXpOaMxvzMfuWFXsxX7uMIANtatGghNUfuwUNxtZ3LNMrOzkZoaCiysrIQEhLi6ObYdWTDTf9JhLD/xDRv3hxHjhy5bq5Zs2Y4fPiwDi1yLUFBQcjLy7tuLjAwkMNgbfD19dVUXPn4+HAYjg18/xPD/hMTFhamaXhh7dq1WcTawNefGFfrP631B8+AERlAYGCg1JzRaH1Td4Y3f2dUeeU+0RwR6YdDOInk46cdkQFwCJgYLiMshl/gyFl4e3sjODgYvr6+CA4O5t5pGrRq1Upqjsge7noAz7Va68K4EbMYLsIhpm7dulJzRsN9rMRU3i9INGc0nEMiplGjRurl0tJS5OTkoLi4GDk5ORabz5vn6Jo///xTao7IHu76+csCTCdchlkMCwgxFy5ckJozGnc9AqeXmJgYqTmjyczMlJozmsaNG0vNGQ2HYIvhKsRi3HUVYn5b0AlXURPDIUxi3PUIkl64jLCYhIQEqTmj0bIAjD05o7npppuk5ojskZWVJTVnNO56AIAFmE5q164tNWc06enpUnNGExwcLDVnNOHh4VJzRnP69GmpOaPhASgxWld25Qqw11d5mDCHDRPdGBZgOvHz85OaMxp3PQWtFy1L0NuTMxrOQRTToEEDqTmj0bqVijNsueKM0tLSpOaMrPJnLD9ziW4MCzCdaN3bhnvgUE04d+6c1JzRdOzYUWrOaJKSkqTmjIZnYMUcO3ZMas5omjVrJjVnNFyESIy7TqFgAaYTdx3DSmQEFy9elJozmoyMDKk5o+EiMGLMVzqsPE/T/Lp5jq7hASgx7lpA6KVWrVpSc86C79Y64RkwMRzCSY60bt06qTmj4SqmYnJycqTmjMb8zELlg5zm13kGwrb27dtLzRkNp1CIcdcClgWYTriKmhhuBClG62aj3JTUtvz8fKk5o2nYsKHUnNFwGXUx/PwQs2bNGqk5owkMDJSaM5pLly5JzTkLFmA64Rc4MWfOnJGaM5qAgACpOaPhGVgxe/futbjesGFDDBo0yKrgqpyjq7gIh5jWrVtLzRnN33//LTVnNGPHjpWaM5qSkhKpOWfBw906KSgokJozGu6jJiY2NlbTl9vY2FgdWuN6fHx8pOaMpvKwr5MnT+LkyZPXzdFVHMIkhnM4xbjrF2C9cBVdMe66DQfPgOmEBYQYnsIXs3//fqk5o8nNzZWaM5r4+HipOaNp1KiR1JzR8PNXjPniBpXn2Zhfd7VFEPSydetWqTmj8fLykppzFizAdMJFOMSEhYVJzRmNux5B0ou7TgLWS5cuXaTmjIafH2LS09Ol5ozG/HO18mvM/Do/f22zdbZfJGc07vr5ywJMJzyFL4ZzcMRwERgx7D8x7rqMsF6WL18uNWc09erVk5ozGm6kLsZ8aHD9+vUt7jO/ziHExsICTCccAiGmsLBQas5obrrpJqk5o+EQRDFcxl8M54CJ6dmzp3rZx8cHHTp0QIsWLdChQweLeZvmObqmTp06UnNGY74/X+WFwsyvcx8/29z1ACj/tcklcBVJMZGRkVJzRnPlyhWpOaM5deqU1JzRcB81MW3atFEvl5SUYPfu3UhJScHu3bstRp2Y5+gazmES065dO6k5o3HXObB2F2BnzpzBQw89hPDwcPj7+6Nt27bYsWOHer+iKJg8eTLq1asHf39/9O3bF0eOHLF4jEuXLmHEiBEICQlBrVq1MHr0aKsjx3///TduvfVW+Pn5ISYmBtOnT7/Bp+gc3LWC18vhw4el5oxm9erVUnNGwzl0YjgETEx0dLTUnNGwgBDDA1BiOnToIDVnNO46AsCuAuzy5cvo3r07fHx8sHLlShw4cADvvvsuateurWamT5+Ojz76CHPmzMGff/6JwMBA9O/f32Jo2IgRI7B//36sWbMGv/76KzZv3ownnnhCvT87Oxv9+vVDbGwskpOT8c4772DKlCn47LPPJDxlx3DXVVzINXAILDlScHCw1JzRHDp0SGrOaHgARQyHIIq5fPmy1JzRnD59WmrOWdi1D9jbb7+NmJgYzJ07V70tLi5OvawoCj744AO89tpruPvuuwEAX3/9NSIjI/Hjjz/i/vvvx8GDB7Fq1Sps374dnTt3BgDMnDkTAwYMwIwZMxAdHY1vv/0WxcXF+PLLL+Hr64vWrVtj9+7deO+99ywKNSIicn6cwykmMzNTas5ouJG1mD59+uDgwYOacmTt+PHjUnNGo3V/SFfbR9KuM2A///wzOnfujH/84x+IiIjATTfdhM8//1y9PzU1Fenp6ejbt696W2hoKLp27YqkpCQAQFJSEmrVqqUWXwDQt29feHp64s8//1QzPXv2tFhSsn///khJSXHZIwQ8AkdERnXs2DGpOSJ7vPTSS1JzRjNr1iypOaNZvHix1JzRFBQUSM05C7vOgB0/fhyffPIJXnjhBbzyyivYvn07xo0bB19fX4wcOVLdQ6PyRP7IyEj1vvT0dERERFg2wtsbYWFhFhnzM2vmj5menm4x5LFCUVGRxfjP7OxsAFcn3DrD0u72FGDO0F5Xxv4Tw/4Tw/6zlpqaqjnH/hPD/queh4eHxZHyytfZf2LYf9fXqVMnNGvWDEeOHEFycrLFfey/6/P19UVgYCDy8vKs9qVzhv7T2ga7CrDy8nJ07twZ//nPfwBcXbJ63759mDNnDkaOHGl/KyV66623MHXqVKvbV69ejYCAAAe06MatWLHC0U1waew/Mew/Mew/Mew/Mey/6lUeplT5OvtPDPuveh4eHkhOTlYLr8oHANh/11dcXFzlpvPO0H9aV+O2qwCrV68e4uPjLW5r1aoVli5dCgCIiooCAGRkZFisZpWRkaGu7hIVFYXz589bPEZpaSkuXbqk/nxUVBQyMjIsMhXXKzKVvfzyy3jhhRfU69nZ2YiJiUG/fv1cblz3gAEDHN0El8b+E8P+E8P+E8P+E8P+E8P+E8P+q971DgCw/8Q4Q/9VjMC7HrsKsO7duyMlJcXitsOHDyM2NhbA1QU5oqKisG7dOrXgys7Oxp9//omnn34aAJCQkIArV64gOTkZnTp1AgCsX78e5eXl6Nq1q5p59dVXUVJSom6SuGbNGrRo0cLm8EMAMJlMMJlMVrf7+PhYbLToKL6+vlVW7JVzztBeV8b+E8P+sxYcHIycnBxNOfafNb7/6Yf9Zy0gIEDTUemAgAD2nyD2nxj2nxhn6D+tbbBrEY7nn38e27Ztw3/+8x8cPXoUCxYswGeffYYxY8YAuHoqdfz48XjzzTfx888/Y+/evXjkkUcQHR2NIUOGALh6xuyOO+7A448/jr/++gtbt27F2LFjcf/996t7mDz44IPw9fXF6NGjsX//fixatAgffvihxRkuV8NlmMmRtL4hOMOblzPi368Y7mMlpkmTJlJzRqN1dT6u4mdbxcFxWTmj6devn9Sc0cTExEjNOQu7CrAuXbpg2bJlWLhwIdq0aYM33ngDH3zwAUaMGKFmJk2ahGeffRZPPPEEunTpgtzcXKxatQp+fn5q5ttvv0XLli3Rp08fDBgwAD169LDY4ys0NBSrV69GamoqOnXqhBdffBGTJ0926SXoqzpzd6M5ItJP5YWFRHNGc9ttt0nNGU3lYfuiOaM5deqU1JzRVJ4SIpozGr7+xISFhUnNOQu7hiACwF133YW77rqryvs9PDwwbdo0TJs2rcpMWFgYFixYUO3vadeuHbZs2WJv85xWrVq1pOaMxp4hJGTNw8NDas5o+vbti127dmnKkTXzLUVk5IxGy/BXe3JGwwJWjL+/v9Sc0bCAFWO+wrmMnLOw6wwY3ThuxEeO5OXlJTVnNHXr1pWaMxpuhEvkujiEXUxQUJDUnNEcOnRIas5ZsADTCY9giuEZRDGentr+1LXmjObChQtSc0Zz+vRpqTmj4QEUMaGhoVJzRnP58mWpOaOpWKhOVo7cA79t6YQfoGLM5xDKyBlNaWmp1JzRrFmzRmrOaCovtSyaMxqtQ6s5BNs2fgEWk5mZKTVnNPZsRE/GwQJMJz179pSaMxqeQRTDRWDEcAixGM5BFOPtrW26ttac0Rw4cEBqzmjKysqk5oyGq+iKcdchsCzAdNKwYUOpOaNx10mYemnQoIHUnNHwDI6Y8vJyqTmjYf+J4RA6ciT+/YphAUZCtm/fLjVnNFxFTQxXYRLDRTjEcBlmMSUlJVJzRsMzOGJMJpPUnNHw/U+Mu46gYAGmk2PHjknNGU1eXp7UnNFcuXJFas5oeAZRzLZt26TmjEbLFhz25IyGc7DFcASKGPafGHf9/scCTCe5ublSc0bDfUjEcBVJMTwDIYZnIMiR3HUIk16Ki4ul5oyG739ieAaMpAoLC8NTTz3lcjt3O0pgYKDUnNFERUVJzRlNYWGh1BwR6YcHoMiRuA2MGHc9gMJ/bQe5dOkS5syZg0uXLjm6KS6hXr16UnNGwzM4Ytx1CIReeAabHIl/v2Lc9QuwXrgPnZiJEydKzTkLFmDkEriIhBhOAhZz5swZqTmj4TLq5EjuOoRJL5UPjHh5eSEgIMBqzhwPoNjGM7Bi3HUZfxZgOuEkYDFZWVlSc0bDI8BiuAy9GHf9ANULN6IXw42YxVTe4LusrAz5+flWc5a4Ebht3MhajLsu4sQCTCf169eXmjMafgEWwyPAYjiETgy3kRDDOYhiYmJipOaMprS0VGrOaAoKCqTmjMZdP39ZgOlkx44dUnNGExcXJzVnNBEREVJzRlOnTh2pOaNJSEiQmiOyx8GDB6XmjIaLYInhCCgxlbfH8fb2RmBgoNWQdVfbRocFmE64DL2Y6OhoqTmj6dKli9Sc0XAfJjH333+/1JzRcA6JGI6gENOyZUupOaPhRtZidu7caXG9tLQUeXl5VmdcK+ecHQswncTHx0vNGc2KFSuk5ozm5MmTUnNGc+7cOak5o1m5cqXUnNGwABPDM9hiTpw4ITVnNJyDLcZdF2FjAaYTjuEnR0pJSZGaMxpupCmGQ7DFXLhwQWrOaI4cOSI1ZzQswMTwDCzZwgKMyACys7Ol5ojsERISIjVnNFzERIzWuSGuNodEL1yEQ0xQUJDUnNG46zYmLMDIJWhd3pbL4NrGI3BiOIlajPnqcg0aNLC4z/w6V6GzjXNgxbCAEFO7dm2pOaNp166d1JzR1KtXT2rOWbhWuUiGxUUQyJH4BU7Mpk2b1MunT59Gs2bN4OHhAUVRLIZ9mefompycHKk5o/Hx8UFJSYmmHFnz9NR2rF5rzmh+//13qTmjSU9Pl5pzFizAiIioRlWe21rVXBvOgbWNBwDE+Pr6ajo4xyGctnEVPyL5eLiCXAKHQJAjuesYdL00atRIao7IHjyDI4YjUMR4eHiolxMTE9UNg/39/ZGYmGgzR9e46+cv3210onVoA4dA2MZJrORIkZGRUnNGM2rUKKk5o+EcWDFFRUVSc0YTGhoqNWc0TZs2VS9v2LABBQUFAICCggJs2LDBZo6ucdczsCzAdMJlrMVcvHhRao7IHlyEQ8zy5cul5owmODhYas5otMz/sidnNFrPzPAMjm1aFxfiIkS2uevnLwswcgn8ABDDIThiuIqkmNOnT0vNGQ2X8RfDEShi2H9iOnfuLDVnNDwDRkIqxvzKyhmNn5+f1JzRREVFSc0ZTXFxsdSc0XAVPzEZGRlSc0bDzw8x7roKnV5q1aolNWc07joFgAWYTngGQkzlvYNEc0bTpEkTqTmjcddJwHoJDw+XmjOas2fPSs0ZDc8giuEBKDFr1qyRmjMad90Hkd/2ySXwCKaYo0ePSs0ZDQsIMZzDKYaLSIjRur0Bt0GwrWLRCFk5o0lJSZGaM5pLly5JzTkLFmA64Rc4MRzCJCYrK0tqzmg4BExMbm6u1ByRPTiHWAznwIrJzs6WmjOav/76S2rOWbAA0wk/AMRwFSsxPIIp5sKFC1JzRsMzOGK4DYcYrRsscyNmqgksYMWUl5dLzTkLFmA64UaGYrgRsxh+AIhx1w8AvXARIjGcxC+ma9euUnNGwzl0YjgCSkzltRHq16+PevXqoX79+tXmnJ1rtdaFcR8XMefOnZOaMxp33UeDXAMPoIjhF2Axd955p9Sc0fAAgJgWLVpIzRlNWFiYxfUzZ87g3LlzOHPmTLU5Z8cCTCdcBlwMh4CJ0frG5GpvYOQaDh48KDVnNHv37pWaM5qnnnpKas5ouIquGO6DKKa0tFRqzlmwANMJP0DFlJWVSc0ZDRdBEMNtJMRwCKcYvv+J4SqIYurVqyc1ZzSVz9SI5ozGXQ8g89uCTvLy8qTmjMZdj4DohV/gxHAIpxguQiSGi0iI4QEUMREREVJzRsNFiMTEx8dLzTkLvtvohF9AxHARCTE+Pj5Sc0bDVTjFtG7dWmrOaBITE6XmjOb222+XmjOaBQsWSM0ZDT9/xdxzzz1Sc86CBZhO+AWOHInL0JMj8QuImFWrVknNGc2uXbuk5ozm/PnzUnNE9pg/f77UnLPwUNz0lEF2djZCQ0ORlZXlFCtD2XNmy03/SYSw/8Sw/8Sw/8Sw/8Sw/8Sw/8Sw/8Sw/8S4Wv9prT94BoyIiIiIrqvyPEPOOyS6MSzAiIiIiOi6iouLq71ORNqwACMygKZNm0rNERGRMcTGxkrNGY27LqNOYliAERmA1qOUPJpJNYFfQMR4e3tLzRkNX39i3HUVOr3ExMRIzRmN1nUcnGG9B3uwACMygKysLKk5IntkZ2dLzRkNt+EQ4+fnJzVnNIcOHZKaMxqugi3GXfcxZQGmE24ESY4UGBgoNUdkD26kLoYFmJjMzEypOaP5+++/peaMJj8/X2rOaNx1I2t+29dJw4YNpeaI7BEdHS01R2QPbkQvJiAgQGqOyB7l5eVSc0YTEREhNUfugQWYTsLDw6XmiOxx8uRJqTkie/j7+0vNEdkjODhYas5oOIRdzNmzZ6XmjMZdR1CwANNJSkqK1ByRPa5cuSI1R2QPdx3Dr5eCggKpOaOJi4uTmjMaLuIkhgUY2cICTCccA0yOxEnA5Eicw0SOxANQYjiEWAzf/8gWFmDkEry8vKTmjIYfAGKaN28uNWc0nEMipkmTJlJzRsM5dGJq164tNWc0XASLbGEBphPOgRDDAoIcictYi2EBJubmm2+WmjOac+fOSc0ZTeX3NW9vbwQGBlrtO8f3P9uioqKk5sg9cNdGnURFReHYsWOackTkGPn5+Tb3srHnC9zOnTutbm/ZsqWhj657eXlpKq54Btu29evXS80ZzeXLl6XmjKZWrVpIS0tTr5eWltpc8KBWrVo6tsp1nDp1SmqO3AMLMJ3Ur19fUwFWv359HVrjery9vTVN8K18RI6u8vf31zRB3+hnYA8dOoROnTrd8M9fuHDB5s8nJyejY8eOIk1zaQ0aNEBqaqqmHFljASHGXVdR0wv7Twz7T4ynp6emA3iuto8uv63qxPzokYwckT18fHw0FWA+Pj46tMZ5tWzZEsnJyVa3f/XVV/joo48AAL6+vhYHA8yvjxs3DiNHjrT5uEbWqFEjTQVYo0aNar4xLohzYMV4eHhoGp7ORSRsCwkJkZozmsDAQGRnZ2vKkTWTyaTp+4vJZNKhNfKwANMJl2EWw1WYxGgtrIxegAUEBNg8U9WmTRvMnDkTiqJYnYmtuO7h4YF33nkHvr6+urTVlXAfJjE8gk6OFBYWJjVnNFo/E/jZYVtgYKCmAszVCljXOl/nwpo1ayY1ZzT8AidGy9E3e3JG4+vriwkTJlSbmTBhAj9Aq6B1aDWHYNtWVFQkNWc0Woemcwi7bRcvXpSaM5rMzEypOaNx1210WIDp5Pbbb5eaM5ro6GipOaPhEXRx06dPx8SJE62GeXl7e2PixImYPn26g1rm/Lp27So1ZzRcBVaM1sUhuIiEbenp6VJzRPZw1xFkLMB0kpWVJTVnNO56BEQv/AInx/Tp05Gfn48J/34DwR3vwoR/v4G8vDwWX9fBRSTIkVq3bi01ZzT8/CBHKiwslJpzFjzfrpO//vpLas5o8vPzpeaIbpSvry9GjH4a3xffhBGju3HYoQbh4eFSc0YTHh6uaXgX+882vv7EsAAjR/Ly8tI0OsfVFiHiGTCdHD58WGrOaLQsQW9Pjoj0c/78eak5o2natKnUnNHw81cMV+EkR3LXObA8A6aTyhu5hoaGQlEUeHh4WAw71Lrhq9HYsxEuETmXjIwMqTmj2bNnj9Sc0bAAE6NlCwl7ckTEAkw3lU/NVzXXi6fwicjdrF27VmrOaNx1DoRe3HUSPxG5Lg5B1AlP4RORUXEIohhPT20f1VpzRsONhInI2fDdWieRkZFSc0bDZYTFaN2g0NU2MiTXwANQYqKioqTmjCYxMVFqzmg6deokNUdkD3fdx48FmE64jDo5Uu3ataXmiOzBfejEmEwmqTmjcdcvcHrhHGwx/PsV465/vyzAdOLn5yc1ZzQcgiOGX4DJkdx1FSu9nD59WmrOaFJSUqTmjIarEItp0KCB1JzRuOv3F9cqF12Y1r2CuKeQbZyELubSpUtSc0T24D5+YjiCQkxaWprUnNHUqlULmZmZmnJGlp+fj0OHDlnd3qFDBxw7duy6P9+hQwfs3LnT6vaWLVsiICBAShtdEQswEhIdHY2jR49qypE1d/0D1AvPIJIjBQQEoKCgQFOOrHl5eWlaoY9z6GzLzs6WmjOaU6dOSc25q0OHDgnNg1u6dCmWLl1qdXtycjI6duwo0jRyQizAdKLl6JE9OaPhEWAxWrc34DYIVBMiIyNx8eJFTTmyFhUVhTNnzmjKkTW+/4nhEERtWrZsieTkZJv3vfDCC9i0aVOVP9urVy+89957VT6ukfn4+Gj6bufj46NDa+RhAaaTvLw8qTmj8fDw0PTh6OHhoUNrXI/JZNI0v4aTgKkm9O7dGwcOHNCUI2uNGzfWVIA1btxYh9a4nvLycqk5o/H29tb0BdjVFkGQLSAgoMozVRs3bsSQIUPw008/Wd13991348cff6zh1rmuuLg4TZukx8XF6dAaeTjeSCecAyGGy6iL4TLg5Ei2vnSI5IzmyJEjUnNE9tB6YIQHUKr3448/Ij8/H/c+/E/4NboJ9z78T+Tn57P4uo6mTZtKzTkLYx+u0FFubq7UnNFEREQgJydHU46scRlcciQuAiMmPT1dao7IHvz8kMff3x8vvzEdf36yDS8/3Q3+/v6ObhI5CM+A6UTLBGp7ckZTp04dqTmj4SR0ciQOASNH0npgjgfwbOMcOnKkqubV3WjOWbAA0wlXoRPDScBiuIgJORJXMSVH4j50YmwtrS6SI7JHRkaG1Jyz4Ld9nQQHB0vNGQ03shbDL8DkSDyCLkbr4kJchMg2vv7EZGVlSc0REeeA6SYsLAwXLlzQlDOyqjYy1LrBY61atbiRoQ38AkKO5Ovrq2mTdG5Eb5vJZNLUf5yDYxunAIjhEGIi+ViA6UTLAhL25NyV6EaGK1euxMqVK61u50aGRI5Tq1YtTQtEaD3QYjQNGzbUtAxzw4YNdWiN6+EZRDGhoaGaFsgJDQ3VoTVkNNwHjIRwGXptqtrIsKysDImJicjLy7PaE8zT0xPl5eUICgrC+vXrbS6lbvSNDIkciauoieEcWDE8AyaG+5iSI/n5+WkqwFxtCgoLMJ3wA0Cb6jYy/Prrr3HPPfdY3V5RjH311Vfo0qVLjbaPiOyn9cg4j6DbFhUVhRMnTmjKkTUugiWGiziRI2kZfm1PzlkIvdv897//hYeHB8aPH6/eVlhYiDFjxiA8PBxBQUG45557rFYmOXnyJAYOHIiAgABERERg4sSJVpP/N27ciI4dO8JkMqFp06aYN2+eSFMdjkcwxQ0bNgxLly5FTEyMxe0NGzbE0qVLMWzYMAe1jIiqk5mZKTVnNFrnBht9DnFVuBG9mPDwcKk5IhIowLZv345PP/0U7dq1s7j9+eefxy+//ILvv/8emzZtwtmzZy2+GJeVlWHgwIEoLi7GH3/8ga+++grz5s3D5MmT1UxqaioGDhyIxMRE7N69G+PHj8djjz2G33777Uab63A8giTHsGHDcPz4cXy+8EfUGTQRny/8EceOHWPxReTEzp07JzVnNKmpqVJzRpObmys1ZzTt27eXmiOyh7seQLmhAiw3NxcjRozA559/jtq1a6u3Z2Vl4X//+x/ee+893HbbbejUqRPmzp2LP/74A9u2bQMArF69GgcOHMD8+fPRoUMH3HnnnXjjjTcwe/Zs9ezPnDlzEBcXh3fffRetWrXC2LFjMXz4cLz//vsSnrJjcBUheby8vNA5oQcC43uhc0IPl/ujIzIarsIphvswieHnr5gNGzZIzRHZw12HIN7QHLAxY8Zg4MCB6Nu3L95880319uTkZJSUlKBv377qbS1btkTDhg2RlJSEbt26ISkpCW3btkVkZKSa6d+/P55++mns378fN910E5KSkiweoyJjPtSxsqKiIotNFLOzswFcPaPkameVXK29jlAxZLW0tJT9JRn78/r4+qs57E9r9hSw7D8x7D9rWlZArMix/66Pnx81xxn6U2sb7C7AvvvuO+zcuRPbt2+3ui89PR2+vr5WSwlHRkaqSxCnp6dbFF8V91fcV10mOzsbBQUF8Pf3t/rdb731FqZOnWp1++rVq11u/6cVK1Y4uglO71QuAHhj27ZtOLPP0a1xL3z9XR9ffzWHrz8x7D8x7D8x7L/r4+dHzXGG15/W1cztKsBOnTqF5557DmvWrHG65R5ffvllvPDCC+r17OxsxMTEoF+/fggJCXFgy+w3YMAARzfB6e05eQnYuwPdunVD+4aceC4TX3/Xx9dfzeHrTwz7Twz7Twz77/r4+VFznOH1VzEC73rsKsCSk5Nx/vx5i2XCy8rKsHnzZsyaNQu//fYbiouLceXKFYuzYBkZGeryuFFRUfjrr78sHrdilUTzTOWVEzMyMhASEmLz7Bdwdf8YW3vI+Pj4OMXmbHXr1sWFCxc05Zyhvc7O29tb/T/7Sy725/Xx9Wcfk8lkMUS8uhz701rlvQ+ry7H/xLD/xLD/ro+fHzXHGfpTaxvsWoSjT58+2Lt3L3bv3q3+17lzZ4wYMUK97OPjg3Xr1qk/k5KSgpMnTyIhIQEAkJCQgL179+L8+fNqZs2aNQgJCUF8fLyaMX+MikzFY7ii6OhoqTkiIlfBbTjEcCNrMR4eHlJzRqN1FJGrjTYiciS7zoAFBwejTZs2FrcFBgYiPDxcvX306NF44YUXEBYWhpCQEDz77LNISEhAt27dAAD9+vVDfHw8Hn74YUyfPh3p6el47bXXMGbMGPXD46mnnsKsWbMwadIk/POf/8T69euxePFiLF++XMZzdgitY0K15oiIXAVXQRTDbUzE8PUnJi8vT2qOyB6+vr6aDs75+vrq0Bp5pG/7/v777+Ouu+7CPffcg549eyIqKgo//PCDer+Xlxd+/fVXeHl5ISEhAQ899BAeeeQRTJs2Tc3ExcVh+fLlWLNmDdq3b493330XX3zxBfr37y+7ubo5efKk1ByRPSIiIqTmiOzBMxBi2H/kSCxgyZHc9fV3Q8vQm9u4caPFdT8/P8yePRuzZ8+u8mdiY2Ovu1JJ7969sWvXLtHmOQ0t8x/syRHZkp+fb3MvoNGjR+Ott9667s+PHj0aO3futLq9ZcuWLreaKDkPb29vTWdnKuZGkCXuYyXG09NTU994eko/Ju0WQkJCcOXKFU05ItncdQQAP+0kq+oLsD2TqPkFmG7UoUOH0KlTpxv++bfeestmoZacnGyx+A6RPdz1A1QvLMDEBAYGIicnR1OOrHXo0MHqYHtVOSLShgWYZKJfgBVFsfnz/AJMWrRs2RLJyclWt5eVlWHIkCG4cOGCzS+5Pj4+iIiIwLJly+Dl5WXzcYmIXJGW4suenNHs2LFDao6IWIBJV9UX4EuXLuH222+/7s+vWbMGYWHW+0LwCzBpERAQUGWhPnPmTAwfPhz9+/fH3gMHce78RdSLCEfb+FZYvXo1PvroI3Tp0kXnFpMR+Pj4aDq75QxLCBORpdzcXKk5ImIBJl11X4AjIyOt9jerfH/fvn1rqmlkcMOGDcOSJUvw4osv4uypq4u9nD2VB5O3F5YsWYJhw4Y5uIXkrriIBBER0TWccaqj9PR0REZG2rwvMjIS6enpOreIjGbYsGE4evQoPl/4I+oMmojPF/6II0eOsPiiGlVWViY1ZzQtWrSQmiMiIsdiAaaz9PR0XLx4EU2at4SHXzCaNG+Jixcvsvgi3Xh5eaFzQg8ExvdC54QeNud8EcmkdWghhyDadu7cOak5o9H6Hsf3QiLSCwswBwgLC8OS1b+j4XMLsWT17zbnfBERuQsWYGKys7Ol5oyGZ2CJyNlwDhgREdUonoEgPVS1DYw9uA2MNe6jRiQfCzAiIqpRWvZAtCdHZIvoNjAAuA2MDV27dkVSUpKmHBFpwwKMiIhqVFZWltQckS1VbQNz6NAhjBgx4ro//+2339rc8sXo28CUlpZaXPfw8IC3tzdKS0stDppUzhFR1ViAERERkcurahuYjh07airAHnzwwZpolss7evSoxXVFUWzu61c5R0RV44BdIiIicmvXG97K4a9VKy4ulpojIhZgRERUw/z9/aXmjKZ27dpSc0alKAr279+vLhbh6emJ/fv3s/i6jpiYGPVyVFSUxX316tWzmSOi6nEIIhER1aiOHTti69atmnJkjXPo5ImPj0fy8fMY8sk2/Ph0N8THhju6SU6jqlUk4+Pj1dvT09PRqXNn+IfWQUFWJpJ37LDIcRVJIm1YgBERUY3KycmRmjMaLUuA25MjskXrKpLmRZe5H374AT/88IN13uCrSBLZwgKMiIhq1JEjR6TmiEi+qlaR3LFjB5588snr/vynn36Kzp0723xcIrLEAoyIiGqU1uWpuYw1keNUtYpk+/bt8dZbb8HLywupqakWZ1o9PT0RFxeH8vJyjB49mpupE2nEAoyIiGqUh4eH1BwR6cfLywvvvvsuhg8fjgEDBiCkbjR+3nUKg2+KQfaFs1ixYgWWLFnC4ovIDizAiIioRnEZayLXNmzYMCxZsgQvvvgiTpxYDgBYuAeIi4vDkiVLMGzYMAe3kMi1cBl6IiKqUTwDRuT6hg0bhqNHj+LzhT+izqCJ+Hzhjzhy5AiLL6IbwDNgRERUo7y9vVFSUqIpR0TOy8vLC50TeiBwtzc6J3TjsEOiG8QzYEREVKO0FF/25IiIiFwZDzcSERE5gao2wrUHN8IlInJ+LMCIiIicgNaNcKtj6+e5ES4RkXNhAUZERDXKZDKhqKhIU87IqtoId/ny5Zg8efJ1f37atGkYOHCgzcclIiLnwQKMiIhqFOeAaVPdRrhaCrBXXnmFiyIQEbkALsJBREQ1qry8XGrOaLy8vLB06dJqM0uXLmXxRUTkIliAERFRjdK6vDyXoa/asGHDsHTpUkRFRVncXq9ePSxdupR7MRERuRB+2hERUY0qKyuTmjOqYcOG4e6778bc73/Fywu24q0Hu+PRf9zFM19E5PKMtgosCzAiIqpRHh4eUBRFU46qx41wicgdGW0VWBZgRERUo3x9fVFYWKgpR0RExlPVKrAnT57E0KFDr/vzy5YtQ8OGDW0+rjNiAUZERDVKS/FlT46IiNxLVavAduzYEd7e3igtLa3yZ729vTFkyJAabJ18XISDiIiIiIicUklJSZWLNHl7e7vkFiYswIiIiIiIyGmVlJQgLS0NAQGBADwQEBCItLQ0lyy+ABZgRERUw7QursFFOIiIqCoNGzbE1gNpiP3XL9h6IM3mnC9XwQKMiIhqlJYVEO3JERERuTIWYERERERERDphAUZERERERKQTFmBEREREREQ6YQFGRERERESkExZgREREREREOmEBRkREREREpBMWYERERERERDphAUZERERERKQTFmBEREREREQ6YQFGRERERESkExZgREREREREOmEBRkREREREpBMWYEREVKNiYmKk5oiIiFwZCzAiIqpR9evXl5ojIiJyZd6ObgAREbmH/Px8HDp0yOr2K1euaPr5K1euYOfOnVa3t2zZEgEBAaLNIyIicgoswIiISIpDhw6hU6dO0n8+OTkZHTt2FGkaERGR02ABRkREUrRs2RLJyclWt8+fPx/vv/8+AMDT0xPl5eXqfebXn3/+eTz00EM2H5eIiMhdsAAjIiIpAgICbJ6patOmDT788EOUl5dbFF8A1Ouenp7473//C19fX13aSkRE5ChchIOIiGqUr68vXnzxRQBXCy1zFddffPFFFl9ERGQIPANGREQ1bvr06QCA9957z+J2T09PvPjii+r9RERE7o5nwIiISBfTp09Hfn4+Jvz7DQR3vAsT/v0G8vLyWHwREZGh8AwYERHpxtfXFyNGP43vi2/CiNHdOOyQiIgMh2fAiIiIiIiIdMICjIiIiIiISCcswIiIiIiIiHTCAoyIiIiIiEgnLMCIiIiIiIh0wgKMiIiIiIhIJyzAiIiIiIiIdMICjIiIiIiISCcswIiIiIiIiHTCAoyIiIiIiEgnLMCIiIiIiIh0wgKMiIiIiIhIJyzAiIiIiIiIdMICjIiIiIiISCcswIiIiIiIiHTCAoyIiIiIiEgnLMCIiIiIiIh0wgKMiIiIiIhIJyzAiIiIiIiIdGJXAfbWW2+hS5cuCA4ORkREBIYMGYKUlBSLTGFhIcaMGYPw8HAEBQXhnnvuQUZGhkXm5MmTGDhwIAICAhAREYGJEyeitLTUIrNx40Z07NgRJpMJTZs2xbx5827sGRIRERERETkJuwqwTZs2YcyYMdi2bRvWrFmDkpIS9OvXD3l5eWrm+eefxy+//ILvv/8emzZtwtmzZzFs2DD1/rKyMgwcOBDFxcX4448/8NVXX2HevHmYPHmymklNTcXAgQORmJiI3bt3Y/z48Xjsscfw22+/SXjKREREREREjuFtT3jVqlUW1+fNm4eIiAgkJyejZ8+eyMrKwv/+9z8sWLAAt912GwBg7ty5aNWqFbZt24Zu3bph9erVOHDgANauXYvIyEh06NABb7zxBv71r39hypQp8PX1xZw5cxAXF4d3330XANCqVSv8/vvveP/999G/f39JT52IiIiIiEhfdhVglWVlZQEAwsLCAADJyckoKSlB37591UzLli3RsGFDJCUloVu3bkhKSkLbtm0RGRmpZvr374+nn34a+/fvx0033YSkpCSLx6jIjB8/vsq2FBUVoaioSL2enZ0NACgpKUFJSYnI06wRFUMuS0tLnbJ9zo79J8aI/XfiYh7yisqkPNbh9CyL/8sQaPJCo/BAaY/nzIz4+pOJ/SeG/SeG/SeG/SfG2ftPa5tuuAArLy/H+PHj0b17d7Rp0wYAkJ6eDl9fX9SqVcsiGxkZifT0dDVjXnxV3F9xX3WZ7OxsFBQUwN/f36o9b731FqZOnWp1++rVqxEQEHBjT7IGncoFAG9s27YNZ/Y5ujWuh/0nxmj9d74A+L/dQsebbJq07KDUx3u1QykirN/e3I7RXn+ysf/EsP/EsP/EsP/EOHv/5efna8rd8DeSMWPGYN++ffj9999v9CGkevnll/HCCy+o17OzsxETE4N+/fohJCTEgS2zbc/JS8DeHejWrRvaNwxzdHNcDvtPjNH6b//ZbGD3NswY3hZN64qfZcorLMKqLdtxx61dEOhnEn68oxfyMGHJXnRJ6IHW0c73fiWb0V5/srH/xLD/xLD/xLD/xDh7/1WMwLueGyrAxo4di19//RWbN29GgwYN1NujoqJQXFyMK1euWJwFy8jIQFRUlJr566+/LB6vYpVE80zllRMzMjIQEhJi8+wXAJhMJphM1l+EfHx84OPjY/+TrGHe3t7q/52xfc6O/SfGaP1X8Xxb1gtFm/qhwo9XUlKCzEPAzY3rSuk/o/57GOX5ysb+E8P+E8P+E8P+E+Ps/ae1TXatgqgoCsaOHYtly5Zh/fr1iIuLs7i/U6dO8PHxwbp169TbUlJScPLkSSQkJAAAEhISsHfvXpw/f17NrFmzBiEhIYiPj1cz5o9Rkal4DCIiIiIiIldk1xmwMWPGYMGCBfjpp58QHBysztkKDQ2Fv78/QkNDMXr0aLzwwgsICwtDSEgInn32WSQkJKBbt24AgH79+iE+Ph4PP/wwpk+fjvT0dLz22msYM2aMegbrqaeewqxZszBp0iT885//xPr167F48WIsX75c8tMnIiIiIqpaamYe8opKrx/U4NiFPPX/FWdzRAWavBFXxxiLOLkLu/7lP/nkEwBA7969LW6fO3cuRo0aBQB4//334enpiXvuuQdFRUXo378/Pv74YzXr5eWFX3/9FU8//TQSEhIQGBiIkSNHYtq0aWomLi4Oy5cvx/PPP48PP/wQDRo0wBdffMEl6ImIiIhIN6mZeUicsVH64764ZK/Ux9swoTeLMBdiVwGmKMp1M35+fpg9ezZmz55dZSY2NhYrVqyo9nF69+6NXbt22dM8IiIiIiJpKs58fXBfBzSNCBJ/vIIi/LoxCXf1TkCgv4RFnM7nYvyi3dLO0JE+5K/LTERERETkRppGBElbxCm9LtAxtrZTLiJB+rBrEQ4iIiIiIiK6cSzAiIiIiIiIdMICjIiIiIiISCecA0a64TKuRERERGR0LMBIF1zGlYiIiIiIBRjphMu4EhERERGxACOdcRlXIiIiIjIyLsJBRERERESkExZgREREREREOuEQRDtwFT9yJL7+iIiIiFwfCzCNuIofORJff0RERETugQWYRlzFjxyJrz8iIiIi98ACzE5cxY8cia8/IiIiItfGAoyIiIjIjXEOMZFzYQFGRERETo0FxI3jHGIi58MCjIiIiJwWCwgxnENM5HxYgBEREZHTYgEhB+cQEzkPFmBERETk9FhAELkmDiG2xgKMiIiIiIik4xBi21iAERERERGRdBxCbBsLMCIiohrGIThEZGQcQmyJBRgREVEN4hAcIiIyxwKMiIioBnEIDhERmWMBRkREpAMOwSEiIgDwdHQDiIiIiIiIjIIFGBERERERkU5YgBEREREREemEBRgREREREZFOWIARERERERHphAUYERERERGRTrgMPRERXVdqZp60faKOXchT/+/tLedjKNDkzU2EiYjIJbAAIyKiaqVm5iFxxkbpj/vikr1SH2/DhN4swoiIyOmxACMiompVnPn64L4OaBoRJP54BUX4dWMS7uqdgEB/k/DjHT2fi/GLdks7Q0dERFSTWIAREZEmTSOC0KZ+qPDjlJSUIL0u0DG2Nnx8fCS0jIiIyHVwEQ4iIiIiIiKdsAAjIiIiIiLSCQswIiIiIiIinbAAIyIiIiIi0gkLMCIiIiIiIp2wACMiIiIiItIJCzAiIiIiIiKdsAAjIiIiIiLSCTdiJiK3V1RWCE+/M0jNToGnX5Dw45WWluJs6VkcvHQQ3t7ib6Op2bnw9DuDorJCAOIbHRMREZHzYgFGRG7vbF4aAuNm4pW/5D7ux6s+lvZYgXHA2bwO6IRIaY9JREREzocFGBG5vejAWOSlPosP7+uAJhFyzoBt/X0ruvfoLuUM2LHzuXhu0W5EJ8YKPxYRERE5NxZgROT2TF5+KC+sj7iQFogPFx/iV1JSglTvVLQKawUfHx/hxysvzEJ54QWYvPyEH4uIiIicGxfhICIiIiIi0gkLMCIiIiIiIp2wACMiIiIiItIJCzAiIiIiIiKdsAAjIiIiIiLSCQswIiIiIiIinbAAIyIiIiIi0gkLMCIiIiIiIp2wACMiIiIiItIJCzAiIiIiIiKdsAAjIiIiIiLSibejG0BERERE5IyKygrh6XcGqdkp8PQLEn680tJSnC09i4OXDsLbW/xreGp2Ljz9zqCorBBAqPDjkT5YgBERERER2XA2Lw2BcTPxyl9yH/fjVR9Le6zAOOBsXgd0QqS0x6SaxQKMiIiIiMiG6MBY5KU+iw/v64AmEXLOgG39fSu69+gu5QzYsfO5eG7RbkQnxgo/FumHBZhGPAVNREREZCwmLz+UF9ZHXEgLxIeLf78qKSlBqncqWoW1go+Pj/DjlRdmobzwAkxefsKPRfphAaYRT0ETEREREWnHExi2sQDTiKegiYiIiIi04wkM21iAacRT0GJ4BISIiIjIWHgCwzYWYKQLHgEhIiLSHw+AkiPxBIZtLMBIFzwCIoYfoERkVHz/E8MDoETOhwUY6YJHQMTwA5TIdbGAEMP3PzE8AErkfFiAEbkAfoCSI7GAEMMCQgzf/8TwACiR82EBRuQC+AFKjsQCQgwLCDF8/yMid8MCjIiIqsUCQgwLCCIiMscCjIjcXkFJGQBg35ksKY+XV1CEHReAqLTLCPQ3CT/e0fO5ElpVc1hAEJFR8fNDDPvPNhZgROT2jv3/N9iXftgr8VG98c3R7RIfDwg08S2ZiMiZ8PNDDPvPNuf81yIikqhf6ygAQJOIIPj7eAk/Xsq5LLy4ZC/eHd4WLerJWfQh0OSNuDqBUh6LiIjk4OeHGPafbSzAiMjthQX64v6bG0p7vNLSUgBAk7qBaFPf+VbdIyKqwCFgYvj5IYb9ZxsLMCIiIiI3xSFgRM6Hr3aNeARJDPtPDPuPiIhuBIeAETkfpy7AZs+ejXfeeQfp6elo3749Zs6ciZtvvtkhbeERJDHsPzHsPyIiuhEcAkbkfJz229KiRYvwwgsvYM6cOejatSs++OAD9O/fHykpKYiIiNC9PTyCJIb9J4b9R47EM7BERETyOG0B9t577+Hxxx/Ho48+CgCYM2cOli9fji+//BIvvfSS7u3hESQx7D8x7D9yJJ6BFcMCloiIzDnlp1VxcTGSk5Px8ssvq7d5enqib9++SEpKsvkzRUVFKCoqUq9nZ2cDuLrhZ0lJSc022Ex+fj5SUlKumzt8LgtF6Uexb7cvijOu/wW4RYsWCAgIkNFEp8b+E8P+E8P+sy2xeTj+7+54NK4bWO0Z2IKCfJw4duS6j5eWmYsPN6TiucQ4xNYJum6+UZNm8Pevvv8CTV5oEOqr6/u9VofPXS28rlfAlpcUouTiac2P+8XvJzTlfMIbwNPn+ptUm7wUp+y/nIKrn+17Tl5SDx7ZovX1V1Zahr17jyEHG+Hlff0RBdd7/R29kAfg6oEtZ+w/rfj+J4b9J8Zd+k/re4CHoihKDbfFbmfPnkX9+vXxxx9/ICEhQb190qRJ2LRpE/7880+rn5kyZQqmTp1qdfuCBQt07fhjx47hxRdflP647777Lpo0aSL9cZ0N+08M+08M+08M+8+23BJg7yUPRPgr8PWsOncq9Rim/1t+/016413ExFXffyYvIMJf+q+WIinDA98dv36hVJR+FOlfjZf++6NGfgBTVNPr5l7tUOq0fagF/37FsP/EuEv/5efn48EHH0RWVhZCQkKqzLlNAWbrDFhMTAwyMzOr7QDZtFbwuQVF+G3LdvS/tQuCNAwh4REQS+w/29h/Yth/Yth/Yth/tl3KK8bag+elnYG9egZsL9q2bSvlDBhw9Qxso3DXngPL158Y9p8Yd+m/7Oxs1KlT57oFmFMOQaxTpw68vLyQkZFhcXtGRgaioqJs/ozJZILJZP0P4ePjAx8fnxpppy2hoaGaVmosKSlBzpVLuPWWbrq2z9mx/8Sw/8Sw/8Sw/8Sw/2yLrOWDEQlxGpLhSGgZc91USUkJgpGPAQN6G6L/tOLrTwz7T4y79J/WNlUzGMJxfH190alTJ6xbt069rby8HOvWrbM4I0ZERERERORKnPIMGAC88MILGDlyJDp37oybb74ZH3zwAfLy8tRVEYmIiIiIiFyN0xZg9913Hy5cuIDJkycjPT0dHTp0wKpVqxAZGenophEREREREd0Qpy3AAGDs2LEYO3aso5tBREREREQkhVPOASMiIiIiInJHLMCIiIiIiIh0wgKMiIiIiIhIJyzAiIiIiIiIdMICjIiIiIiISCcswIiIiIiIiHTCAoyIiIiIiEgnLMCIiIiIiIh0wgKMiIiIiIhIJyzAiIiIiIiIdMICjIiIiIiISCcswIiIiIiIiHTCAoyIiIiIiEgn3o5uQE1RFAUAkJ2d7eCW2FZSUoL8/HxkZ2fDx8fH0c1xOew/Mew/Mew/Mew/Mew/Mew/Mew/Mew/Mc7efxV1R0UdUhW3LcBycnIAADExMQ5uCRERERERGUVOTg5CQ0OrvN9DuV6J5qLKy8tx9uxZBAcHw8PDw9HNsZKdnY2YmBicOnUKISEhjm6Oy2H/iWH/iWH/iWH/iWH/iWH/iWH/iWH/iXH2/lMUBTk5OYiOjoanZ9Uzvdz2DJinpycaNGjg6GZcV0hIiFO+gFwF+08M+08M+08M+08M+08M+08M+08M+0+MM/dfdWe+KnARDiIiIiIiIp2wACMiIiIiItIJCzAHMZlMeP3112EymRzdFJfE/hPD/hPD/hPD/hPD/hPD/hPD/hPD/hPjLv3ntotwEBERERERORueASMiIiIiItIJCzAiIiIiIiKdsAAjIiIiIiLSCQswIiIiIiIinbAAu0FvvfUWunTpguDgYERERGDIkCFISUmxyBQWFmLMmDEIDw9HUFAQ7rnnHmRkZFhkxo0bh06dOsFkMqFDhw5WvyclJQWJiYmIjIyEn58fGjdujNdeew0lJSU1+fRqnF79Z+7o0aMIDg5GrVq1JD8b/enVfydOnICHh4fVf9u2bavJp1fj9Hz9KYqCGTNmoHnz5jCZTKhfvz7+7//+r6aemi706r8pU6bYfP0FBgbW5NOrcXq+/n777Td069YNwcHBqFu3Lu655x6cOHGihp6ZPvTsv8WLF6NDhw4ICAhAbGws3nnnnZp6WrqR0X979uzBAw88gJiYGPj7+6NVq1b48MMPrX7Xxo0b0bFjR5hMJjRt2hTz5s2r6adX4/Tqv3PnzuHBBx9E8+bN4enpifHjx+vx9GqcXv33ww8/4Pbbb0fdunUREhKChIQE/Pbbb7o8Ry1YgN2gTZs2YcyYMdi2bRvWrFmDkpIS9OvXD3l5eWrm+eefxy+//ILvv/8emzZtwtmzZzFs2DCrx/rnP/+J++67z+bv8fHxwSOPPILVq1cjJSUFH3zwAT7//HO8/vrrNfbc9KBX/1UoKSnBAw88gFtvvVX6c3EEvftv7dq1OHfunPpfp06dpD8nPenZf8899xy++OILzJgxA4cOHcLPP/+Mm2++uUael1706r8JEyZYvO7OnTuH+Ph4/OMf/6ix56YHvfovNTUVd999N2677Tbs3r0bv/32GzIzM20+jivRq/9WrlyJESNG4KmnnsK+ffvw8ccf4/3338esWbNq7LnpQUb/JScnIyIiAvPnz8f+/fvx6quv4uWXX7bom9TUVAwcOBCJiYnYvXs3xo8fj8cee8ypvgTfCL36r6ioCHXr1sVrr72G9u3b6/oca5Je/bd582bcfvvtWLFiBZKTk5GYmIhBgwZh165duj7fKikkxfnz5xUAyqZNmxRFUZQrV64oPj4+yvfff69mDh48qABQkpKSrH7+9ddfV9q3b6/pdz3//PNKjx49pLTbWdR0/02aNEl56KGHlLlz5yqhoaGym+9wNdV/qampCgBl165dNdV0p1BT/XfgwAHF29tbOXToUI213Rno9f63e/duBYCyefNmaW13BjXVf99//73i7e2tlJWVqbf9/PPPioeHh1JcXCz/iThITfXfAw88oAwfPtzito8++khp0KCBUl5eLvdJOJBo/1V45plnlMTERPX6pEmTlNatW1tk7rvvPqV///6Sn4Fj1VT/mevVq5fy3HPPSW23s9Cj/yrEx8crU6dOldNwQTwDJklWVhYAICwsDMDV6rykpAR9+/ZVMy1btkTDhg2RlJR0w7/n6NGjWLVqFXr16iXWYCdTk/23fv16fP/995g9e7a8BjuZmn79DR48GBEREejRowd+/vlnOY12IjXVf7/88gsaN26MX3/9FXFxcWjUqBEee+wxXLp0Se4TcDC93v+++OILNG/e3G3OZFeoqf7r1KkTPD09MXfuXJSVlSErKwvffPMN+vbtCx8fH7lPwoFqqv+Kiorg5+dncZu/vz9Onz6NtLQ0CS13DrL6LysrS30MAEhKSrJ4DADo37+/0HuAM6qp/jMKvfqvvLwcOTk5TtPHLMAkKC8vx/jx49G9e3e0adMGAJCeng5fX1+r+UaRkZFIT0+3+3fccsst8PPzQ7NmzXDrrbdi2rRpMpruFGqy/y5evIhRo0Zh3rx5CAkJkdlsp1GT/RcUFIR3330X33//PZYvX44ePXpgyJAhblWE1WT/HT9+HGlpafj+++/x9ddfY968eUhOTsbw4cNlPgWH0uP9D7g6J+Dbb7/F6NGjRZvsVGqy/+Li4rB69Wq88sorMJlMqFWrFk6fPo3FixfLfAoOVZP9179/f/zwww9Yt24dysvLcfjwYbz77rsArs7PcQey+u+PP/7AokWL8MQTT6i3paenIzIy0uoxsrOzUVBQIPeJOEhN9p8R6Nl/M2bMQG5uLu69915p7Rfh7egGuIMxY8Zg3759+P3332vsdyxatAg5OTnYs2cPJk6ciBkzZmDSpEk19vv0VJP99/jjj+PBBx9Ez549pT+2s6jJ/qtTpw5eeOEF9XqXLl1w9uxZvPPOOxg8eLD03+cINdl/5eXlKCoqwtdff43mzZsDAP73v/+hU6dOSElJQYsWLaT/Tr3p8f4HAMuWLUNOTg5GjhxZo79HbzXZf+np6Xj88ccxcuRIPPDAA8jJycHkyZMxfPhwrFmzBh4eHtJ/p95q+vPj2LFjuOuuu1BSUoKQkBA899xzmDJlCjw93eP4tYz+27dvH+6++268/vrr6Nevn8TWOT/2nxi9+m/BggWYOnUqfvrpJ0RERNzw75LJPd5BHGjs2LH49ddfsWHDBjRo0EC9PSoqCsXFxbhy5YpFPiMjA1FRUXb/npiYGMTHx+OBBx7Af//7X0yZMgVlZWWizXe4mu6/9evXY8aMGfD29oa3tzdGjx6NrKwseHt748svv5T1NBxGr9efua5du+Lo0aNCj+Esarr/6tWrB29vb7X4AoBWrVoBAE6ePCnWeCeg5+vviy++wF133WV1RN2V1XT/zZ49G6GhoZg+fTpuuukm9OzZE/Pnz8e6devw559/ynoaDlPT/efh4YG3334bubm5SEtLQ3p6urqATuPGjaU8B0eS0X8HDhxAnz598MQTT+C1116zuC8qKspq5cmMjAyEhITA399f7pNxgJruP3enV/999913eOyxx7B48WKrIbGOxALsBimKgrFjx2LZsmVYv3494uLiLO7v1KkTfHx8sG7dOvW2lJQUnDx5EgkJCUK/u7y8HCUlJSgvLxd6HEfSq/+SkpKwe/du9b9p06YhODgYu3fvxtChQ6U9H7058vW3e/du1KtXT+gxHE2v/uvevTtKS0tx7Ngx9bbDhw8DAGJjYwWfhePo/fpLTU3Fhg0b3Gb4oV79l5+fb3WmxsvLCwD4+WEHLy8v1K9fH76+vli4cCESEhJQt25d4efhKLL6b//+/UhMTMTIkSNtbq2RkJBg8RgAsGbNGuHPIEfTq//clZ79t3DhQjz66KNYuHAhBg4cWDNP6EY5avUPV/f0008roaGhysaNG5Vz586p/+Xn56uZp556SmnYsKGyfv16ZceOHUpCQoKSkJBg8ThHjhxRdu3apTz55JNK8+bNlV27dim7du1SioqKFEVRlPnz5yuLFi1SDhw4oBw7dkxZtGiREh0drYwYMULX5yubXv1XmbusgqhX/82bN09ZsGCBcvDgQeXgwYPK//3f/ymenp7Kl19+qevzlU2v/isrK1M6duyo9OzZU9m5c6eyY8cOpWvXrsrtt9+u6/OVTe+/39dee02Jjo5WSktLdXl+NU2v/lu3bp3i4eGhTJ06VTl8+LCSnJys9O/fX4mNjbX4Xa5Gr/67cOGC8sknnygHDx5Udu3apYwbN07x8/NT/vzzT12fr2wy+m/v3r1K3bp1lYceesjiMc6fP69mjh8/rgQEBCgTJ05UDh48qMyePVvx8vJSVq1apevzlU2v/lMURX1NdurUSXnwwQeVXbt2Kfv379ftudYEvfrv22+/Vby9vZXZs2dbZK5cuaLr860KC7AbBMDmf3PnzlUzBQUFyjPPPKPUrl1bCQgIUIYOHaqcO3fO4nF69epl83FSU1MVRVGU7777TunYsaMSFBSkBAYGKvHx8cp//vMfpaCgQMdnK59e/VeZuxRgevXfvHnzlFatWikBAQFKSEiIcvPNN1ssDeuq9Hz9nTlzRhk2bJgSFBSkREZGKqNGjVIuXryo0zOtGXr2X1lZmdKgQQPllVde0enZ1Tw9+2/hwoXKTTfdpAQGBip169ZVBg8erBw8eFCnZ1oz9Oq/CxcuKN26dVMCAwOVgIAApU+fPsq2bdt0fKY1Q0b/vf766zYfIzY21uJ3bdiwQenQoYPi6+urNG7c2OJ3uCo9+09LxtXo1X9V/X2PHDlSvydbDQ9FURQQERERERFRjeMcMCIiIiIiIp2wACMiIiIiItIJCzAiIiIiIiKdsAAjIiIiIiLSCQswIiIiIiIinbAAIyIiIiIi0gkLMCIiIiIiIp2wACMiIiIiItIJCzAiIiIiIiKdsAAjIiIiIiLSCQswIiIyhFWrVqFHjx6oVasWwsPDcdddd+HYsWMAgBMnTsDDwwM//PADEhMTERAQgPbt2yMpKcniMZYuXYrWrVvDZDKhUaNGePfddx3xVIiIyIWxACMiIkPIy8vDCy+8gB07dmDdunXw9PTE0KFDUV5ermZeffVVTJgwAbt370bz5s3xwAMPoLS0FACQnJyMe++9F/fffz/27t2LKVOm4N///jfmzZvnoGdERESuyENRFMXRjSAiItJbZmYm6tati7179yIoKAhxcXH44osvMHr0aADAgQMH0Lp1axw8eBAtW7bEiBEjcOHCBaxevVp9jEmTJmH58uXYv3+/o54GERG5GJ4BIyIiQzhy5AgeeOABNG7cGCEhIWjUqBEA4OTJk2qmXbt26uV69eoBAM6fPw8AOHjwILp3727xmN27d8eRI0dQVlZWw60nIiJ34e3oBhAREelh0KBBiI2Nxeeff47o6GiUl5ejTZs2KC4uVjM+Pj7qZQ8PDwCwGKJIREQkigUYERG5vYsXLyIlJQWff/45br31VgDA77//btdjtGrVClu3brW4bevWrWjevDm8vLyktZWIiNwbCzAiInJ7tWvXRnh4OD777DPUq1cPJ0+exEsvvWTXY7z44ovo0qUL3njjDdx3331ISkrCrFmz8PHHH9dQq4mIyB1xDhgREbk9T09PfPfdd0hOTkabNm3w/PPP45133rHrMTp27IjFixfju+++Q5s2bTB58mRMmzYNo0aNqplGExGRW+IqiERERERERDrhGTAiIiIiIiKdsAAjIiIiIiLSCQswIiIiov/Xfh0LAAAAAAzyt57FrrIIYCJgAAAAEwEDAACYCBgAAMBEwAAAACYCBgAAMBEwAACAiYABAABMBAwAAGAiYAAAAJMAugRYbNMXyzYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "box_plot(df_despesas_sem_outliers, 'ano', 'valor_pago')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## População"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                 Non-Null Count  Dtype \n",
      "---  ------                                 --------------  ----- \n",
      " 0   ano                                    32 non-null     int64 \n",
      " 1   populacao                              32 non-null     int64 \n",
      " 2   variacao_anual                         32 non-null     object\n",
      " 3   porcentagem_variacao_anual             32 non-null     object\n",
      " 4   aceleracao_variacao_anual              32 non-null     object\n",
      " 5   porcentagem_aceleracao_variacao_anual  32 non-null     object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_populacao.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>populacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>57024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1991.0</td>\n",
       "      <td>51273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>52509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>57065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>61130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>63239.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ano  populacao\n",
       "count    32.0       32.0\n",
       "mean   2006.0    57024.0\n",
       "std       9.0     4073.0\n",
       "min    1991.0    51273.0\n",
       "25%    1999.0    52509.0\n",
       "50%    2006.0    57065.0\n",
       "75%    2014.0    61130.0\n",
       "max    2022.0    63239.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_populacao.describe().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_populacao_dados_copy = df_populacao.copy()\n",
    "df_populacao_dados_convertidos = df_populacao_dados_copy\n",
    "df_populacao_dados_convertidos['ano'] = df_populacao_dados_convertidos['ano'].astype(object)\n",
    "df_populacao_dados_convertidos = transforma_coluna_em_datetime(df_populacao, 'ano')\n",
    "df_populacao_dados_convertidos = cria_colunas_tempo(df_populacao, 'ano')\n",
    "df_populacao_dados_convertidos['porcentagem_variacao_anual'] = df_populacao_dados_convertidos['porcentagem_variacao_anual'].str.replace(',','.').astype(float)\n",
    "df_populacao_dados_convertidos['porcentagem_aceleracao_variacao_anual'] = df_populacao_dados_convertidos['porcentagem_aceleracao_variacao_anual'].str.replace(',','.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   ano                                    32 non-null     object \n",
      " 1   populacao                              32 non-null     int64  \n",
      " 2   variacao_anual                         32 non-null     object \n",
      " 3   porcentagem_variacao_anual             32 non-null     float64\n",
      " 4   aceleracao_variacao_anual              32 non-null     object \n",
      " 5   porcentagem_aceleracao_variacao_anual  32 non-null     float64\n",
      " 6   ano_mes                                32 non-null     object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_populacao_dados_convertidos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   ano                                    32 non-null     object \n",
      " 1   populacao                              32 non-null     int64  \n",
      " 2   variacao_anual                         32 non-null     int64  \n",
      " 3   porcentagem_variacao_anual             32 non-null     float64\n",
      " 4   aceleracao_variacao_anual              32 non-null     int64  \n",
      " 5   porcentagem_aceleracao_variacao_anual  32 non-null     float64\n",
      " 6   ano_mes                                32 non-null     object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_populacao_dados_convertidos = converte_tipo_dados(df_populacao_dados_convertidos, ['variacao_anual', 'aceleracao_variacao_anual'], 'int64')\n",
    "df_populacao_dados_convertidos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>porcentagem_variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>porcentagem_aceleracao_variacao_anual</th>\n",
       "      <th>ano_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>51273</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1991-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992</td>\n",
       "      <td>51530</td>\n",
       "      <td>257</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1992-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>51965</td>\n",
       "      <td>435</td>\n",
       "      <td>0.84</td>\n",
       "      <td>178</td>\n",
       "      <td>69.26</td>\n",
       "      <td>1993-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994</td>\n",
       "      <td>52279</td>\n",
       "      <td>314</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-121</td>\n",
       "      <td>-27.82</td>\n",
       "      <td>1994-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>52586</td>\n",
       "      <td>307</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-7</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>1995-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>51396</td>\n",
       "      <td>-1190</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-1497</td>\n",
       "      <td>-487.62</td>\n",
       "      <td>1996-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997</td>\n",
       "      <td>51575</td>\n",
       "      <td>179</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1369</td>\n",
       "      <td>-115.04</td>\n",
       "      <td>1997-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998</td>\n",
       "      <td>51726</td>\n",
       "      <td>151</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-28</td>\n",
       "      <td>-15.64</td>\n",
       "      <td>1998-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999</td>\n",
       "      <td>51878</td>\n",
       "      <td>152</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1999-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000</td>\n",
       "      <td>54715</td>\n",
       "      <td>2837</td>\n",
       "      <td>5.47</td>\n",
       "      <td>2685</td>\n",
       "      <td>1766.45</td>\n",
       "      <td>2000-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001</td>\n",
       "      <td>55132</td>\n",
       "      <td>417</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-2420</td>\n",
       "      <td>-85.30</td>\n",
       "      <td>2001-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002</td>\n",
       "      <td>55439</td>\n",
       "      <td>307</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-110</td>\n",
       "      <td>-26.38</td>\n",
       "      <td>2002-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2003</td>\n",
       "      <td>55775</td>\n",
       "      <td>336</td>\n",
       "      <td>0.61</td>\n",
       "      <td>29</td>\n",
       "      <td>9.45</td>\n",
       "      <td>2003-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004</td>\n",
       "      <td>56481</td>\n",
       "      <td>706</td>\n",
       "      <td>1.27</td>\n",
       "      <td>370</td>\n",
       "      <td>110.12</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2005</td>\n",
       "      <td>56871</td>\n",
       "      <td>390</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-316</td>\n",
       "      <td>-44.76</td>\n",
       "      <td>2005-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2006</td>\n",
       "      <td>57259</td>\n",
       "      <td>388</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>2006-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2007</td>\n",
       "      <td>56051</td>\n",
       "      <td>-1208</td>\n",
       "      <td>-2.11</td>\n",
       "      <td>-1596</td>\n",
       "      <td>-411.34</td>\n",
       "      <td>2007-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008</td>\n",
       "      <td>57627</td>\n",
       "      <td>1576</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2784</td>\n",
       "      <td>-230.46</td>\n",
       "      <td>2008-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2009</td>\n",
       "      <td>57875</td>\n",
       "      <td>248</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-1328</td>\n",
       "      <td>-84.26</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2010</td>\n",
       "      <td>58446</td>\n",
       "      <td>571</td>\n",
       "      <td>0.99</td>\n",
       "      <td>323</td>\n",
       "      <td>130.24</td>\n",
       "      <td>2010-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011</td>\n",
       "      <td>58794</td>\n",
       "      <td>348</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-223</td>\n",
       "      <td>-39.05</td>\n",
       "      <td>2011-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012</td>\n",
       "      <td>59130</td>\n",
       "      <td>336</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-12</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>2012-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1146</td>\n",
       "      <td>341.07</td>\n",
       "      <td>2013-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014</td>\n",
       "      <td>61030</td>\n",
       "      <td>418</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-1064</td>\n",
       "      <td>-71.79</td>\n",
       "      <td>2014-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015</td>\n",
       "      <td>61431</td>\n",
       "      <td>401</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-17</td>\n",
       "      <td>-4.07</td>\n",
       "      <td>2015-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016</td>\n",
       "      <td>61816</td>\n",
       "      <td>385</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-16</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>2016-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>62187</td>\n",
       "      <td>371</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-14</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>2017-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>61776</td>\n",
       "      <td>-411</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-782</td>\n",
       "      <td>-210.78</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019</td>\n",
       "      <td>61993</td>\n",
       "      <td>217</td>\n",
       "      <td>0.35</td>\n",
       "      <td>628</td>\n",
       "      <td>-152.80</td>\n",
       "      <td>2019-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020</td>\n",
       "      <td>62289</td>\n",
       "      <td>296</td>\n",
       "      <td>0.48</td>\n",
       "      <td>79</td>\n",
       "      <td>36.41</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021</td>\n",
       "      <td>62576</td>\n",
       "      <td>287</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-9</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>2021-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>1.05</td>\n",
       "      <td>376</td>\n",
       "      <td>56.71</td>\n",
       "      <td>2022-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ano  populacao  variacao_anual  porcentagem_variacao_anual  \\\n",
       "0   1991      51273               0                        0.00   \n",
       "1   1992      51530             257                        0.50   \n",
       "2   1993      51965             435                        0.84   \n",
       "3   1994      52279             314                        0.60   \n",
       "4   1995      52586             307                        0.59   \n",
       "5   1996      51396           -1190                       -2.26   \n",
       "6   1997      51575             179                        0.35   \n",
       "7   1998      51726             151                        0.29   \n",
       "8   1999      51878             152                        0.29   \n",
       "9   2000      54715            2837                        5.47   \n",
       "10  2001      55132             417                        0.76   \n",
       "11  2002      55439             307                        0.56   \n",
       "12  2003      55775             336                        0.61   \n",
       "13  2004      56481             706                        1.27   \n",
       "14  2005      56871             390                        0.69   \n",
       "15  2006      57259             388                        0.68   \n",
       "16  2007      56051           -1208                       -2.11   \n",
       "17  2008      57627            1576                        2.81   \n",
       "18  2009      57875             248                        0.43   \n",
       "19  2010      58446             571                        0.99   \n",
       "20  2011      58794             348                        0.60   \n",
       "21  2012      59130             336                        0.57   \n",
       "22  2013      60612            1482                        2.51   \n",
       "23  2014      61030             418                        0.69   \n",
       "24  2015      61431             401                        0.66   \n",
       "25  2016      61816             385                        0.63   \n",
       "26  2017      62187             371                        0.60   \n",
       "27  2018      61776            -411                       -0.66   \n",
       "28  2019      61993             217                        0.35   \n",
       "29  2020      62289             296                        0.48   \n",
       "30  2021      62576             287                        0.46   \n",
       "31  2022      63239             663                        1.05   \n",
       "\n",
       "    aceleracao_variacao_anual  porcentagem_aceleracao_variacao_anual  ano_mes  \n",
       "0                           0                                   0.00  1991-01  \n",
       "1                           0                                   0.00  1992-01  \n",
       "2                         178                                  69.26  1993-01  \n",
       "3                        -121                                 -27.82  1994-01  \n",
       "4                          -7                                  -2.23  1995-01  \n",
       "5                       -1497                                -487.62  1996-01  \n",
       "6                        1369                                -115.04  1997-01  \n",
       "7                         -28                                 -15.64  1998-01  \n",
       "8                           1                                   0.66  1999-01  \n",
       "9                        2685                                1766.45  2000-01  \n",
       "10                      -2420                                 -85.30  2001-01  \n",
       "11                       -110                                 -26.38  2002-01  \n",
       "12                         29                                   9.45  2003-01  \n",
       "13                        370                                 110.12  2004-01  \n",
       "14                       -316                                 -44.76  2005-01  \n",
       "15                         -2                                  -0.51  2006-01  \n",
       "16                      -1596                                -411.34  2007-01  \n",
       "17                       2784                                -230.46  2008-01  \n",
       "18                      -1328                                 -84.26  2009-01  \n",
       "19                        323                                 130.24  2010-01  \n",
       "20                       -223                                 -39.05  2011-01  \n",
       "21                        -12                                  -3.45  2012-01  \n",
       "22                       1146                                 341.07  2013-01  \n",
       "23                      -1064                                 -71.79  2014-01  \n",
       "24                        -17                                  -4.07  2015-01  \n",
       "25                        -16                                  -3.99  2016-01  \n",
       "26                        -14                                  -3.64  2017-01  \n",
       "27                       -782                                -210.78  2018-01  \n",
       "28                        628                                -152.80  2019-01  \n",
       "29                         79                                  36.41  2020-01  \n",
       "30                         -9                                  -3.04  2021-01  \n",
       "31                        376                                  56.71  2022-01  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_populacao_dados_convertidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ano        9 non-null      int64 \n",
      " 1   ideb_5ano  9 non-null      object\n",
      " 2   ideb_9ano  9 non-null      object\n",
      " 3   idhm       9 non-null      object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 420.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_idhm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>4,1</td>\n",
       "      <td>2,8</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4,1</td>\n",
       "      <td>2,8</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4,4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4,4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4,8</td>\n",
       "      <td>3,5</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4,8</td>\n",
       "      <td>3,5</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>5,3</td>\n",
       "      <td>4,1</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5,3</td>\n",
       "      <td>4,1</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>5,1</td>\n",
       "      <td>4,9</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ano ideb_5ano ideb_9ano   idhm\n",
       "0 2013-01-01       4,1       2,8  0,679\n",
       "1 2014-01-01       4,1       2,8  0,679\n",
       "2 2015-01-01       4,4         3  0,679\n",
       "3 2016-01-01       4,4         3  0,679\n",
       "4 2017-01-01       4,8       3,5  0,679\n",
       "5 2018-01-01       4,8       3,5  0,679\n",
       "6 2019-01-01       5,3       4,1  0,679\n",
       "7 2020-01-01       5,3       4,1  0,679\n",
       "8 2021-01-01       5,1       4,9  0,679"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforma_coluna_em_datetime(df_idhm, 'ano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idhm_dados_copy = df_idhm.copy()\n",
    "df_idhm_dados_convertidos = df_idhm_dados_copy\n",
    "df_idhm_dados_convertidos['ideb_5ano'] = df_idhm['ideb_5ano'].str.replace(',','.').astype(float)\n",
    "df_idhm_dados_convertidos['ideb_9ano'] = df_idhm['ideb_9ano'].str.replace(',','.').astype(float)\n",
    "df_idhm_dados_convertidos['idhm'] = df_idhm['idhm'].str.replace(',','.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimar valores para o ano de 2022 usando a média das variações anuais\n",
    "variacao_anual_ideb_5ano = df_idhm_dados_convertidos.groupby('ano')['ideb_5ano'].last().pct_change().mean()\n",
    "variacao_anual_ideb_9ano = df_idhm_dados_convertidos.groupby('ano')['ideb_9ano'].last().pct_change().mean()\n",
    "valor_2022_ideb_5ano = df_idhm_dados_convertidos['ideb_5ano'].values[-1]\n",
    "valor_2022_ideb_9ano = df_idhm_dados_convertidos['ideb_9ano'].values[-1]\n",
    "valor_2022_ideb_5ano_estimado = valor_2022_ideb_5ano * (1 + variacao_anual_ideb_5ano)\n",
    "valor_2022_ideb_9ano = valor_2022_ideb_9ano * (1 + variacao_anual_ideb_9ano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ano  ideb_5ano  ideb_9ano   idhm\n",
       "0 2013-01-01   4.100000   2.800000  0.679\n",
       "1 2014-01-01   4.100000   2.800000  0.679\n",
       "2 2015-01-01   4.400000   3.000000  0.679\n",
       "3 2016-01-01   4.400000   3.000000  0.679\n",
       "4 2017-01-01   4.800000   3.500000  0.679\n",
       "5 2018-01-01   4.800000   3.500000  0.679\n",
       "6 2019-01-01   5.300000   4.100000  0.679\n",
       "7 2020-01-01   5.300000   4.100000  0.679\n",
       "8 2021-01-01   5.100000   4.900000  0.679\n",
       "9 2022-01-01   5.246951   5.270346  0.679"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar um novo DataFrame com as linhas para 2021 e 2022\n",
    "novas_linhas = pd.DataFrame({'ano': [2022], 'ideb_5ano': [valor_2022_ideb_5ano_estimado], 'ideb_9ano': [valor_2022_ideb_9ano], 'idhm': [df_idhm_dados_convertidos['idhm'].values[-1]]})\n",
    "novas_linhas = transforma_coluna_em_datetime(novas_linhas, 'ano')\n",
    "\n",
    "# Concatenar as novas linhas ao DataFrame original\n",
    "df_idhm_convertido = pd.concat([df_idhm_dados_convertidos, novas_linhas], ignore_index=True)\n",
    "df_idhm_convertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idhm_convertido = cria_colunas_tempo(df_idhm_convertido, 'ano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ano        10 non-null     object \n",
      " 1   ideb_5ano  10 non-null     float64\n",
      " 2   ideb_9ano  10 non-null     float64\n",
      " 3   idhm       10 non-null     float64\n",
      " 4   ano_mes    10 non-null     object \n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 532.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_idhm_convertido.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "      <th>ano_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2013-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2014-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2015-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2016-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2017-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2019-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2021-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2022-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano  ideb_5ano  ideb_9ano   idhm  ano_mes\n",
       "0  2013   4.100000   2.800000  0.679  2013-01\n",
       "1  2014   4.100000   2.800000  0.679  2014-01\n",
       "2  2015   4.400000   3.000000  0.679  2015-01\n",
       "3  2016   4.400000   3.000000  0.679  2016-01\n",
       "4  2017   4.800000   3.500000  0.679  2017-01\n",
       "5  2018   4.800000   3.500000  0.679  2018-01\n",
       "6  2019   5.300000   4.100000  0.679  2019-01\n",
       "7  2020   5.300000   4.100000  0.679  2020-01\n",
       "8  2021   5.100000   4.900000  0.679  2021-01\n",
       "9  2022   5.246951   5.270346  0.679  2022-01"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idhm_convertido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saúde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 6 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   ano                         9 non-null      object\n",
      " 1   pct_desp_recp_saude_mun     9 non-null      object\n",
      " 2   desp_tot_saude_pc_mun       9 non-null      object\n",
      " 3   desp_recp_saude_pc_mun      9 non-null      object\n",
      " 4   desp_tot_saude_pc_mun_def   9 non-null      object\n",
      " 5   desp_recp_saude_pc_mun_def  9 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 564.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_saude.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun_def</th>\n",
       "      <th>desp_recp_saude_pc_mun_def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>16,56</td>\n",
       "      <td>464,3</td>\n",
       "      <td>114,1</td>\n",
       "      <td>744,7674653</td>\n",
       "      <td>183,0238376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>23,4</td>\n",
       "      <td>448,73</td>\n",
       "      <td>186,19</td>\n",
       "      <td>676,4489043</td>\n",
       "      <td>280,676624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>22,48</td>\n",
       "      <td>468,65</td>\n",
       "      <td>190,19</td>\n",
       "      <td>638,3468516</td>\n",
       "      <td>259,057266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>21,23</td>\n",
       "      <td>439,37</td>\n",
       "      <td>202,37</td>\n",
       "      <td>563,0595289</td>\n",
       "      <td>259,3403211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>18,6</td>\n",
       "      <td>468,37</td>\n",
       "      <td>178,28</td>\n",
       "      <td>583,0388706</td>\n",
       "      <td>221,9274716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>18,26</td>\n",
       "      <td>705,23</td>\n",
       "      <td>190,43</td>\n",
       "      <td>846,1933549</td>\n",
       "      <td>228,4936837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>16,13</td>\n",
       "      <td>559,08</td>\n",
       "      <td>187,04</td>\n",
       "      <td>643,1360678</td>\n",
       "      <td>215,1609253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>16,23</td>\n",
       "      <td>668,07</td>\n",
       "      <td>187,35</td>\n",
       "      <td>735,277842</td>\n",
       "      <td>206,19741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>19,02</td>\n",
       "      <td>790,59</td>\n",
       "      <td>272,68</td>\n",
       "      <td>790,59</td>\n",
       "      <td>272,68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ano pct_desp_recp_saude_mun desp_tot_saude_pc_mun  \\\n",
       "0 2013-01-01                   16,56                 464,3   \n",
       "1 2014-01-01                    23,4                448,73   \n",
       "2 2015-01-01                   22,48                468,65   \n",
       "3 2016-01-01                   21,23                439,37   \n",
       "4 2017-01-01                    18,6                468,37   \n",
       "5 2018-01-01                   18,26                705,23   \n",
       "6 2019-01-01                   16,13                559,08   \n",
       "7 2020-01-01                   16,23                668,07   \n",
       "8 2021-01-01                   19,02                790,59   \n",
       "\n",
       "  desp_recp_saude_pc_mun desp_tot_saude_pc_mun_def desp_recp_saude_pc_mun_def  \n",
       "0                  114,1               744,7674653                183,0238376  \n",
       "1                 186,19               676,4489043                 280,676624  \n",
       "2                 190,19               638,3468516                 259,057266  \n",
       "3                 202,37               563,0595289                259,3403211  \n",
       "4                 178,28               583,0388706                221,9274716  \n",
       "5                 190,43               846,1933549                228,4936837  \n",
       "6                 187,04               643,1360678                215,1609253  \n",
       "7                 187,35                735,277842                  206,19741  \n",
       "8                 272,68                    790,59                     272,68  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforma_coluna_em_datetime(df_saude, 'ano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saude_dados_copy = df_saude.copy()\n",
    "df_saude_dados_convertido = df_saude_dados_copy\n",
    "df_saude_dados_convertido['pct_desp_recp_saude_mun'] = df_saude['pct_desp_recp_saude_mun'].str.replace(',','.').astype(float)\n",
    "df_saude_dados_convertido['desp_tot_saude_pc_mun'] = df_saude['desp_tot_saude_pc_mun'].str.replace(',','.').astype(float)\n",
    "df_saude_dados_convertido['desp_recp_saude_pc_mun'] = df_saude['desp_recp_saude_pc_mun'].str.replace(',','.').astype(float)\n",
    "df_saude_dados_convertido['desp_tot_saude_pc_mun_def'] = df_saude['desp_tot_saude_pc_mun_def'].str.replace(',','.').astype(float)\n",
    "df_saude_dados_convertido['desp_recp_saude_pc_mun_def'] = df_saude['desp_recp_saude_pc_mun_def'].str.replace(',','.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 6 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   ano                         9 non-null      datetime64[ns]\n",
      " 1   pct_desp_recp_saude_mun     9 non-null      float64       \n",
      " 2   desp_tot_saude_pc_mun       9 non-null      float64       \n",
      " 3   desp_recp_saude_pc_mun      9 non-null      float64       \n",
      " 4   desp_tot_saude_pc_mun_def   9 non-null      float64       \n",
      " 5   desp_recp_saude_pc_mun_def  9 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 564.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df_saude_dados_convertido.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimar valores para o ano de 2022 usando a média das variações anuais\n",
    "variacao_anual_pct_desp_recp_saude_mun = df_saude_dados_convertido.groupby('ano')['pct_desp_recp_saude_mun'].last().pct_change().mean()\n",
    "variacao_anual_desp_tot_saude_pc_mun = df_saude_dados_convertido.groupby('ano')['desp_tot_saude_pc_mun'].last().pct_change().mean()\n",
    "variacao_anual_desp_recp_saude_pc_mun = df_saude_dados_convertido.groupby('ano')['desp_recp_saude_pc_mun'].last().pct_change().mean()\n",
    "variacao_anual_desp_tot_saude_pc_mun_def = df_saude_dados_convertido.groupby('ano')['desp_tot_saude_pc_mun_def'].last().pct_change().mean()\n",
    "variacao_anual_desp_recp_saude_pc_mun_def = df_saude_dados_convertido.groupby('ano')['desp_recp_saude_pc_mun_def'].last().pct_change().mean()\n",
    "\n",
    "valor_2022_pct_desp_recp_saude_mun = df_saude_dados_convertido['pct_desp_recp_saude_mun'].values[-1]\n",
    "valor_2022_desp_tot_saude_pc_mun = df_saude_dados_convertido['desp_tot_saude_pc_mun'].values[-1]\n",
    "valor_2022_desp_recp_saude_pc_mun = df_saude_dados_convertido['desp_recp_saude_pc_mun'].values[-1]\n",
    "valor_2022_desp_tot_saude_pc_mun_def = df_saude_dados_convertido['desp_tot_saude_pc_mun_def'].values[-1]\n",
    "valor_2022_desp_recp_saude_pc_mun_def = df_saude_dados_convertido['desp_recp_saude_pc_mun_def'].values[-1]\n",
    "\n",
    "valor_2022_pct_desp_recp_saude_mun_estimado = valor_2022_pct_desp_recp_saude_mun * (1 + variacao_anual_pct_desp_recp_saude_mun)\n",
    "valor_2022_desp_tot_saude_pc_mun_estimado = valor_2022_desp_tot_saude_pc_mun * (1 + variacao_anual_desp_tot_saude_pc_mun)\n",
    "valor_2022_desp_recp_saude_pc_muno_estimado = valor_2022_desp_recp_saude_pc_mun * (1 + variacao_anual_desp_recp_saude_pc_mun)\n",
    "valor_2022_desp_tot_saude_pc_mun_def_estimado = valor_2022_desp_tot_saude_pc_mun_def * (1 + variacao_anual_desp_tot_saude_pc_mun_def)\n",
    "valor_2022_desp_recp_saude_pc_mun_def_estimado = valor_2022_desp_recp_saude_pc_mun_def * (1 + variacao_anual_desp_recp_saude_pc_mun_def)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun_def</th>\n",
       "      <th>desp_recp_saude_pc_mun_def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>448.730000</td>\n",
       "      <td>186.190000</td>\n",
       "      <td>676.448904</td>\n",
       "      <td>280.676624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>22.480000</td>\n",
       "      <td>468.650000</td>\n",
       "      <td>190.190000</td>\n",
       "      <td>638.346852</td>\n",
       "      <td>259.057266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>21.230000</td>\n",
       "      <td>439.370000</td>\n",
       "      <td>202.370000</td>\n",
       "      <td>563.059529</td>\n",
       "      <td>259.340321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>468.370000</td>\n",
       "      <td>178.280000</td>\n",
       "      <td>583.038871</td>\n",
       "      <td>221.927472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>705.230000</td>\n",
       "      <td>190.430000</td>\n",
       "      <td>846.193355</td>\n",
       "      <td>228.493684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>16.130000</td>\n",
       "      <td>559.080000</td>\n",
       "      <td>187.040000</td>\n",
       "      <td>643.136068</td>\n",
       "      <td>215.160925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>16.230000</td>\n",
       "      <td>668.070000</td>\n",
       "      <td>187.350000</td>\n",
       "      <td>735.277842</td>\n",
       "      <td>206.197410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>19.020000</td>\n",
       "      <td>790.590000</td>\n",
       "      <td>272.680000</td>\n",
       "      <td>790.590000</td>\n",
       "      <td>272.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ano  pct_desp_recp_saude_mun  desp_tot_saude_pc_mun  \\\n",
       "0 2013-01-01                16.560000             464.300000   \n",
       "1 2014-01-01                23.400000             448.730000   \n",
       "2 2015-01-01                22.480000             468.650000   \n",
       "3 2016-01-01                21.230000             439.370000   \n",
       "4 2017-01-01                18.600000             468.370000   \n",
       "5 2018-01-01                18.260000             705.230000   \n",
       "6 2019-01-01                16.130000             559.080000   \n",
       "7 2020-01-01                16.230000             668.070000   \n",
       "8 2021-01-01                19.020000             790.590000   \n",
       "9 2022-01-01                19.584458             858.896682   \n",
       "\n",
       "   desp_recp_saude_pc_mun  desp_tot_saude_pc_mun_def  \\\n",
       "0              114.100000                 744.767465   \n",
       "1              186.190000                 676.448904   \n",
       "2              190.190000                 638.346852   \n",
       "3              202.370000                 563.059529   \n",
       "4              178.280000                 583.038871   \n",
       "5              190.430000                 846.193355   \n",
       "6              187.040000                 643.136068   \n",
       "7              187.350000                 735.277842   \n",
       "8              272.680000                 790.590000   \n",
       "9              310.369965                 810.291935   \n",
       "\n",
       "   desp_recp_saude_pc_mun_def  \n",
       "0                  183.023838  \n",
       "1                  280.676624  \n",
       "2                  259.057266  \n",
       "3                  259.340321  \n",
       "4                  221.927472  \n",
       "5                  228.493684  \n",
       "6                  215.160925  \n",
       "7                  206.197410  \n",
       "8                  272.680000  \n",
       "9                  291.950175  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar um novo DataFrame com as linhas para 2021 e 2022\n",
    "novas_linhas = pd.DataFrame({'ano': [2022],\n",
    "                              'pct_desp_recp_saude_mun': [valor_2022_pct_desp_recp_saude_mun_estimado],\n",
    "                                'desp_tot_saude_pc_mun': [valor_2022_desp_tot_saude_pc_mun_estimado],\n",
    "                                  'desp_recp_saude_pc_mun': [valor_2022_desp_recp_saude_pc_muno_estimado],\n",
    "                                    'desp_tot_saude_pc_mun_def': [valor_2022_desp_tot_saude_pc_mun_def_estimado],\n",
    "                                      'desp_recp_saude_pc_mun_def': [valor_2022_desp_recp_saude_pc_mun_def_estimado]})\n",
    "novas_linhas = transforma_coluna_em_datetime(novas_linhas, 'ano')\n",
    "\n",
    "# Concatenar as novas linhas ao DataFrame original\n",
    "df_saude_convertido = pd.concat([df_saude_dados_convertido, novas_linhas], ignore_index=True)\n",
    "df_saude_convertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saude_convertido = cria_colunas_tempo(df_saude_convertido, 'ano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ano                         10 non-null     object \n",
      " 1   pct_desp_recp_saude_mun     10 non-null     float64\n",
      " 2   desp_tot_saude_pc_mun       10 non-null     float64\n",
      " 3   desp_recp_saude_pc_mun      10 non-null     float64\n",
      " 4   desp_tot_saude_pc_mun_def   10 non-null     float64\n",
      " 5   desp_recp_saude_pc_mun_def  10 non-null     float64\n",
      " 6   ano_mes                     10 non-null     object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 692.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_saude_convertido.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun_def</th>\n",
       "      <th>desp_recp_saude_pc_mun_def</th>\n",
       "      <th>ano_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "      <td>2013-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>448.730000</td>\n",
       "      <td>186.190000</td>\n",
       "      <td>676.448904</td>\n",
       "      <td>280.676624</td>\n",
       "      <td>2014-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>22.480000</td>\n",
       "      <td>468.650000</td>\n",
       "      <td>190.190000</td>\n",
       "      <td>638.346852</td>\n",
       "      <td>259.057266</td>\n",
       "      <td>2015-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>21.230000</td>\n",
       "      <td>439.370000</td>\n",
       "      <td>202.370000</td>\n",
       "      <td>563.059529</td>\n",
       "      <td>259.340321</td>\n",
       "      <td>2016-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>468.370000</td>\n",
       "      <td>178.280000</td>\n",
       "      <td>583.038871</td>\n",
       "      <td>221.927472</td>\n",
       "      <td>2017-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>705.230000</td>\n",
       "      <td>190.430000</td>\n",
       "      <td>846.193355</td>\n",
       "      <td>228.493684</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>16.130000</td>\n",
       "      <td>559.080000</td>\n",
       "      <td>187.040000</td>\n",
       "      <td>643.136068</td>\n",
       "      <td>215.160925</td>\n",
       "      <td>2019-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>16.230000</td>\n",
       "      <td>668.070000</td>\n",
       "      <td>187.350000</td>\n",
       "      <td>735.277842</td>\n",
       "      <td>206.197410</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>19.020000</td>\n",
       "      <td>790.590000</td>\n",
       "      <td>272.680000</td>\n",
       "      <td>790.590000</td>\n",
       "      <td>272.680000</td>\n",
       "      <td>2021-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "      <td>2022-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano  pct_desp_recp_saude_mun  desp_tot_saude_pc_mun  \\\n",
       "0  2013                16.560000             464.300000   \n",
       "1  2014                23.400000             448.730000   \n",
       "2  2015                22.480000             468.650000   \n",
       "3  2016                21.230000             439.370000   \n",
       "4  2017                18.600000             468.370000   \n",
       "5  2018                18.260000             705.230000   \n",
       "6  2019                16.130000             559.080000   \n",
       "7  2020                16.230000             668.070000   \n",
       "8  2021                19.020000             790.590000   \n",
       "9  2022                19.584458             858.896682   \n",
       "\n",
       "   desp_recp_saude_pc_mun  desp_tot_saude_pc_mun_def  \\\n",
       "0              114.100000                 744.767465   \n",
       "1              186.190000                 676.448904   \n",
       "2              190.190000                 638.346852   \n",
       "3              202.370000                 563.059529   \n",
       "4              178.280000                 583.038871   \n",
       "5              190.430000                 846.193355   \n",
       "6              187.040000                 643.136068   \n",
       "7              187.350000                 735.277842   \n",
       "8              272.680000                 790.590000   \n",
       "9              310.369965                 810.291935   \n",
       "\n",
       "   desp_recp_saude_pc_mun_def  ano_mes  \n",
       "0                  183.023838  2013-01  \n",
       "1                  280.676624  2014-01  \n",
       "2                  259.057266  2015-01  \n",
       "3                  259.340321  2016-01  \n",
       "4                  221.927472  2017-01  \n",
       "5                  228.493684  2018-01  \n",
       "6                  215.160925  2019-01  \n",
       "7                  206.197410  2020-01  \n",
       "8                  272.680000  2021-01  \n",
       "9                  291.950175  2022-01  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_saude_convertido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparo dos df para implementação dos modelos de RN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados das despesas + população + idhm/educacao + saude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allys\\AppData\\Local\\Temp\\ipykernel_22472\\1558106391.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_despesas_sem_outliers.drop(columns=['valor_fixado','valor_empenhado','valor_liquidado','saldo'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_despesas_sem_outliers.drop(columns=['valor_fixado','valor_empenhado','valor_liquidado','saldo'], inplace=True)\n",
    "df_populacao_dados_convertidos.drop(columns=['porcentagem_variacao_anual', 'porcentagem_aceleracao_variacao_anual','ano_mes'], inplace=True)\n",
    "df_idhm_convertido.drop(columns=['ano_mes'], inplace=True)\n",
    "df_saude_convertido.drop(columns=['ano_mes'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_fato</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86836</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86837</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86838</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86839</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86840</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72498 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       data_fato  valor_pago  ano_mes   ano\n",
       "0     2013-12-31         0.0  2013-12  2013\n",
       "1     2013-12-31         0.0  2013-12  2013\n",
       "2     2013-12-31         0.0  2013-12  2013\n",
       "3     2013-12-31         0.0  2013-12  2013\n",
       "4     2013-12-31         0.0  2013-12  2013\n",
       "...          ...         ...      ...   ...\n",
       "86836 2022-12-30         0.0  2022-12  2022\n",
       "86837 2022-12-30         0.0  2022-12  2022\n",
       "86838 2022-12-30         0.0  2022-12  2022\n",
       "86839 2022-12-30         0.0  2022-12  2022\n",
       "86840 2022-12-30         0.0  2022-12  2022\n",
       "\n",
       "[72498 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas_sem_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun_def</th>\n",
       "      <th>desp_recp_saude_pc_mun_def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-02</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-03</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>732833.15</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-05</td>\n",
       "      <td>800601.05</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08</td>\n",
       "      <td>1034448.16</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09</td>\n",
       "      <td>1140401.16</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10</td>\n",
       "      <td>748572.06</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-11</td>\n",
       "      <td>665162.97</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>851121.10</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ano  ano_mes  valor_pago  populacao  variacao_anual  \\\n",
       "0    2013  2013-01   297340.29      60612            1482   \n",
       "1    2013  2013-02   556608.68      60612            1482   \n",
       "2    2013  2013-03   637551.20      60612            1482   \n",
       "3    2013  2013-04   732833.15      60612            1482   \n",
       "4    2013  2013-05   800601.05      60612            1482   \n",
       "..    ...      ...         ...        ...             ...   \n",
       "115  2022  2022-08  1034448.16      63239             663   \n",
       "116  2022  2022-09  1140401.16      63239             663   \n",
       "117  2022  2022-10   748572.06      63239             663   \n",
       "118  2022  2022-11   665162.97      63239             663   \n",
       "119  2022  2022-12   851121.10      63239             663   \n",
       "\n",
       "     aceleracao_variacao_anual  ideb_5ano  ideb_9ano   idhm  \\\n",
       "0                         1146   4.100000   2.800000  0.679   \n",
       "1                         1146   4.100000   2.800000  0.679   \n",
       "2                         1146   4.100000   2.800000  0.679   \n",
       "3                         1146   4.100000   2.800000  0.679   \n",
       "4                         1146   4.100000   2.800000  0.679   \n",
       "..                         ...        ...        ...    ...   \n",
       "115                        376   5.246951   5.270346  0.679   \n",
       "116                        376   5.246951   5.270346  0.679   \n",
       "117                        376   5.246951   5.270346  0.679   \n",
       "118                        376   5.246951   5.270346  0.679   \n",
       "119                        376   5.246951   5.270346  0.679   \n",
       "\n",
       "     pct_desp_recp_saude_mun  desp_tot_saude_pc_mun  desp_recp_saude_pc_mun  \\\n",
       "0                  16.560000             464.300000              114.100000   \n",
       "1                  16.560000             464.300000              114.100000   \n",
       "2                  16.560000             464.300000              114.100000   \n",
       "3                  16.560000             464.300000              114.100000   \n",
       "4                  16.560000             464.300000              114.100000   \n",
       "..                       ...                    ...                     ...   \n",
       "115                19.584458             858.896682              310.369965   \n",
       "116                19.584458             858.896682              310.369965   \n",
       "117                19.584458             858.896682              310.369965   \n",
       "118                19.584458             858.896682              310.369965   \n",
       "119                19.584458             858.896682              310.369965   \n",
       "\n",
       "     desp_tot_saude_pc_mun_def  desp_recp_saude_pc_mun_def  \n",
       "0                   744.767465                  183.023838  \n",
       "1                   744.767465                  183.023838  \n",
       "2                   744.767465                  183.023838  \n",
       "3                   744.767465                  183.023838  \n",
       "4                   744.767465                  183.023838  \n",
       "..                         ...                         ...  \n",
       "115                 810.291935                  291.950175  \n",
       "116                 810.291935                  291.950175  \n",
       "117                 810.291935                  291.950175  \n",
       "118                 810.291935                  291.950175  \n",
       "119                 810.291935                  291.950175  \n",
       "\n",
       "[120 rows x 14 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas_agrupado = df_despesas_sem_outliers.groupby(['ano', 'ano_mes'])[['valor_pago']].sum().reset_index()\n",
    "df_despesas_agrupado = pd.merge(df_despesas_agrupado, df_populacao_dados_convertidos, on='ano', how='left')\n",
    "df_despesas_agrupado = pd.merge(df_despesas_agrupado, df_idhm_convertido, on='ano', how='left')\n",
    "df_despesas_agrupado = pd.merge(df_despesas_agrupado, df_saude_convertido, on='ano', how='left')\n",
    "df_despesas_agrupado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elaborando metadados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA(12)_pago</th>\n",
       "      <th>SMA(6)_pago</th>\n",
       "      <th>SMA(3)_pago</th>\n",
       "      <th>SMA(2)_pago</th>\n",
       "      <th>lag(12)_pago</th>\n",
       "      <th>lag(6)_pago</th>\n",
       "      <th>lag(4)_pago</th>\n",
       "      <th>lag(3)_pago</th>\n",
       "      <th>lag(2)_pago</th>\n",
       "      <th>lag(1)_pago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-02</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>426974.485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297340.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-03</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>497166.723333</td>\n",
       "      <td>597079.940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>732833.15</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>642331.010000</td>\n",
       "      <td>685192.175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-05</td>\n",
       "      <td>800601.05</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>723661.800000</td>\n",
       "      <td>766717.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>732833.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano  ano_mes  valor_pago  populacao  variacao_anual  \\\n",
       "0  2013  2013-01   297340.29      60612            1482   \n",
       "1  2013  2013-02   556608.68      60612            1482   \n",
       "2  2013  2013-03   637551.20      60612            1482   \n",
       "3  2013  2013-04   732833.15      60612            1482   \n",
       "4  2013  2013-05   800601.05      60612            1482   \n",
       "\n",
       "   aceleracao_variacao_anual  ideb_5ano  ideb_9ano   idhm  \\\n",
       "0                       1146        4.1        2.8  0.679   \n",
       "1                       1146        4.1        2.8  0.679   \n",
       "2                       1146        4.1        2.8  0.679   \n",
       "3                       1146        4.1        2.8  0.679   \n",
       "4                       1146        4.1        2.8  0.679   \n",
       "\n",
       "   pct_desp_recp_saude_mun  ...  SMA(12)_pago  SMA(6)_pago    SMA(3)_pago  \\\n",
       "0                    16.56  ...           NaN          NaN            NaN   \n",
       "1                    16.56  ...           NaN          NaN            NaN   \n",
       "2                    16.56  ...           NaN          NaN  497166.723333   \n",
       "3                    16.56  ...           NaN          NaN  642331.010000   \n",
       "4                    16.56  ...           NaN          NaN  723661.800000   \n",
       "\n",
       "   SMA(2)_pago  lag(12)_pago  lag(6)_pago  lag(4)_pago  lag(3)_pago  \\\n",
       "0          NaN           NaN          NaN          NaN          NaN   \n",
       "1   426974.485           NaN          NaN          NaN          NaN   \n",
       "2   597079.940           NaN          NaN          NaN          NaN   \n",
       "3   685192.175           NaN          NaN          NaN    297340.29   \n",
       "4   766717.100           NaN          NaN    297340.29    556608.68   \n",
       "\n",
       "   lag(2)_pago  lag(1)_pago  \n",
       "0          NaN          NaN  \n",
       "1          NaN    297340.29  \n",
       "2    297340.29    556608.68  \n",
       "3    556608.68    637551.20  \n",
       "4    637551.20    732833.15  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample dos dados para as despesas mensais do município\n",
    "df_despesas_agrupado['SMA(12)_pago'] = df_despesas_agrupado['valor_pago'].rolling(window=12).mean()\n",
    "df_despesas_agrupado['SMA(6)_pago'] = df_despesas_agrupado['valor_pago'].rolling(window=6).mean()\n",
    "df_despesas_agrupado['SMA(3)_pago'] = df_despesas_agrupado['valor_pago'].rolling(window=3).mean()\n",
    "df_despesas_agrupado['SMA(2)_pago'] = df_despesas_agrupado['valor_pago'].rolling(window=2).mean()\n",
    "df_despesas_agrupado['lag(12)_pago'] = df_despesas_agrupado['valor_pago'].shift(12)\n",
    "df_despesas_agrupado['lag(6)_pago'] = df_despesas_agrupado['valor_pago'].shift(6)\n",
    "df_despesas_agrupado['lag(4)_pago'] = df_despesas_agrupado['valor_pago'].shift(4)\n",
    "df_despesas_agrupado['lag(3)_pago'] = df_despesas_agrupado['valor_pago'].shift(3)\n",
    "df_despesas_agrupado['lag(2)_pago'] = df_despesas_agrupado['valor_pago'].shift(2)\n",
    "df_despesas_agrupado['lag(1)_pago'] = df_despesas_agrupado['valor_pago'].shift(1)\n",
    "df_despesas_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA(12)_pago</th>\n",
       "      <th>SMA(6)_pago</th>\n",
       "      <th>SMA(3)_pago</th>\n",
       "      <th>SMA(2)_pago</th>\n",
       "      <th>lag(12)_pago</th>\n",
       "      <th>lag(6)_pago</th>\n",
       "      <th>lag(4)_pago</th>\n",
       "      <th>lag(3)_pago</th>\n",
       "      <th>lag(2)_pago</th>\n",
       "      <th>lag(1)_pago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-02</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>426974.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-03</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497166.723333</td>\n",
       "      <td>597079.940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>732833.15</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>642331.010000</td>\n",
       "      <td>685192.175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-05</td>\n",
       "      <td>800601.05</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723661.800000</td>\n",
       "      <td>766717.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>732833.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano  ano_mes  valor_pago  populacao  variacao_anual  \\\n",
       "0  2013  2013-01   297340.29      60612            1482   \n",
       "1  2013  2013-02   556608.68      60612            1482   \n",
       "2  2013  2013-03   637551.20      60612            1482   \n",
       "3  2013  2013-04   732833.15      60612            1482   \n",
       "4  2013  2013-05   800601.05      60612            1482   \n",
       "\n",
       "   aceleracao_variacao_anual  ideb_5ano  ideb_9ano   idhm  \\\n",
       "0                       1146        4.1        2.8  0.679   \n",
       "1                       1146        4.1        2.8  0.679   \n",
       "2                       1146        4.1        2.8  0.679   \n",
       "3                       1146        4.1        2.8  0.679   \n",
       "4                       1146        4.1        2.8  0.679   \n",
       "\n",
       "   pct_desp_recp_saude_mun  ...  SMA(12)_pago  SMA(6)_pago    SMA(3)_pago  \\\n",
       "0                    16.56  ...           0.0          0.0       0.000000   \n",
       "1                    16.56  ...           0.0          0.0       0.000000   \n",
       "2                    16.56  ...           0.0          0.0  497166.723333   \n",
       "3                    16.56  ...           0.0          0.0  642331.010000   \n",
       "4                    16.56  ...           0.0          0.0  723661.800000   \n",
       "\n",
       "   SMA(2)_pago  lag(12)_pago  lag(6)_pago  lag(4)_pago  lag(3)_pago  \\\n",
       "0        0.000           0.0          0.0         0.00         0.00   \n",
       "1   426974.485           0.0          0.0         0.00         0.00   \n",
       "2   597079.940           0.0          0.0         0.00         0.00   \n",
       "3   685192.175           0.0          0.0         0.00    297340.29   \n",
       "4   766717.100           0.0          0.0    297340.29    556608.68   \n",
       "\n",
       "   lag(2)_pago  lag(1)_pago  \n",
       "0         0.00         0.00  \n",
       "1         0.00    297340.29  \n",
       "2    297340.29    556608.68  \n",
       "3    556608.68    637551.20  \n",
       "4    637551.20    732833.15  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas_agrupado.fillna(0, inplace=True)\n",
    "df_despesas_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA(6)_pago</th>\n",
       "      <th>SMA(3)_pago</th>\n",
       "      <th>SMA(2)_pago</th>\n",
       "      <th>lag(12)_pago</th>\n",
       "      <th>lag(6)_pago</th>\n",
       "      <th>lag(4)_pago</th>\n",
       "      <th>lag(3)_pago</th>\n",
       "      <th>lag(2)_pago</th>\n",
       "      <th>lag(1)_pago</th>\n",
       "      <th>ano_mes_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297340.29</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>464.3</td>\n",
       "      <td>114.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>734869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>556608.68</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>464.3</td>\n",
       "      <td>114.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>426974.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>734900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>637551.20</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>464.3</td>\n",
       "      <td>114.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497166.723333</td>\n",
       "      <td>597079.940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>734928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>732833.15</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>464.3</td>\n",
       "      <td>114.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>642331.010000</td>\n",
       "      <td>685192.175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>734959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800601.05</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.56</td>\n",
       "      <td>464.3</td>\n",
       "      <td>114.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723661.800000</td>\n",
       "      <td>766717.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>732833.15</td>\n",
       "      <td>734989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   valor_pago  populacao  variacao_anual  aceleracao_variacao_anual  \\\n",
       "0   297340.29      60612            1482                       1146   \n",
       "1   556608.68      60612            1482                       1146   \n",
       "2   637551.20      60612            1482                       1146   \n",
       "3   732833.15      60612            1482                       1146   \n",
       "4   800601.05      60612            1482                       1146   \n",
       "\n",
       "   ideb_5ano  ideb_9ano   idhm  pct_desp_recp_saude_mun  \\\n",
       "0        4.1        2.8  0.679                    16.56   \n",
       "1        4.1        2.8  0.679                    16.56   \n",
       "2        4.1        2.8  0.679                    16.56   \n",
       "3        4.1        2.8  0.679                    16.56   \n",
       "4        4.1        2.8  0.679                    16.56   \n",
       "\n",
       "   desp_tot_saude_pc_mun  desp_recp_saude_pc_mun  ...  SMA(6)_pago  \\\n",
       "0                  464.3                   114.1  ...          0.0   \n",
       "1                  464.3                   114.1  ...          0.0   \n",
       "2                  464.3                   114.1  ...          0.0   \n",
       "3                  464.3                   114.1  ...          0.0   \n",
       "4                  464.3                   114.1  ...          0.0   \n",
       "\n",
       "     SMA(3)_pago  SMA(2)_pago  lag(12)_pago  lag(6)_pago  lag(4)_pago  \\\n",
       "0       0.000000        0.000           0.0          0.0         0.00   \n",
       "1       0.000000   426974.485           0.0          0.0         0.00   \n",
       "2  497166.723333   597079.940           0.0          0.0         0.00   \n",
       "3  642331.010000   685192.175           0.0          0.0         0.00   \n",
       "4  723661.800000   766717.100           0.0          0.0    297340.29   \n",
       "\n",
       "   lag(3)_pago  lag(2)_pago  lag(1)_pago  ano_mes_ordinal  \n",
       "0         0.00         0.00         0.00           734869  \n",
       "1         0.00         0.00    297340.29           734900  \n",
       "2         0.00    297340.29    556608.68           734928  \n",
       "3    297340.29    556608.68    637551.20           734959  \n",
       "4    556608.68    637551.20    732833.15           734989  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas_agrupado.drop(columns=['ano'], inplace=True)\n",
    "df_despesas_agrupado = transforma_data_em_ordinal(df_despesas_agrupado, 'ano_mes')\n",
    "df_despesas_agrupado.drop(columns=['ano_mes'], inplace=True)\n",
    "df_despesas_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABlUAAANQCAYAAACxZek3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOz9d5wsd33n+787Tk8OJ+csIaHAETkZWAMCY9mGZWH3tzyAtbH3+hpjIyfwLiKD7Z+Esa/ti9c2aHEAg3cX22BABINABgwogSWko5PzOZND5+66f1R9q3tip6qu6u7X8/HQY1pzZnpKZ0Y93fWp9+cdsSzLEgAAAAAAAAAAADYUDfoAAAAAAAAAAAAAOgFDFQAAAAAAAAAAgDowVAEAAAAAAAAAAKgDQxUAAAAAAAAAAIA6MFQBAAAAAAAAAACoA0MVAAAAAAAAAACAOjBUAQAAAAAAAAAAqANDFQAAAAAAAAAAgDowVAEAAAAAAAAAAKgDQxUAAAAAAAAAAIA69PRQ5d5779Vtt92mnTt3KhKJ6DOf+UzD92FZlu68805dc8016uvr065du/T+97/f+4MFAAAAAAAAAACBigd9AEFaWlrSzTffrJ/92Z/Vq171qqbu41d+5Vd0zz336M4779SNN96o6elpTU9Pe3ykAAAAAAAAAAAgaBHLsqygDyIMIpGI/s//+T/6mZ/5Gfd9uVxO/+2//Td94hOf0OzsrG644Qb97u/+rl74whdKkh599FHddNNN+uEPf6hrr702mAMHAAAAAAAAAABt0dPrv2p585vfrG9961v65Cc/qYcfflj/4T/8B73sZS/TsWPHJEn/+I//qIMHD+qzn/2sDhw4oP379+tNb3oTSRUAAAAAAAAAALoQQ5V1nDlzRh/72Mf06U9/Ws9//vN16NAh/fqv/7qe97zn6WMf+5gk6cSJEzp9+rQ+/elP6+Mf/7juvvtuff/739erX/3qgI8eAAAAAAAAAAB4rac7VTbygx/8QKVSSddcc82y9+dyOW3atEmSVC6Xlcvl9PGPf9z9uL/4i7/QU5/6VD322GOsBAMAAAAAAAAAoIswVFnH4uKiYrGYvv/97ysWiy37s6GhIUnSjh07FI/Hlw1errvuOkl20oWhCgAAAAAAAAAA3YOhyjqOHj2qUqmkK1eu6PnPf/6aH/Pc5z5XxWJRx48f16FDhyRJjz/+uCRp3759bTtWAAAAAAAAAADgv4hlWVbQBxGUxcVFPfHEE5LsIcqHPvQhvehFL9LExIT27t2r173udbrvvvt011136ejRo7p69aq+8pWv6KabbtIrXvEKlctlPf3pT9fQ0JA+/OEPq1wu65d+6Zc0MjKie+65J+D/OgAAAAAAAAAA4KWeHqp87Wtf04te9KJV73/DG96gu+++W4VCQe973/v08Y9/XOfPn9fmzZv1rGc9S+9+97t14403SpIuXLigX/7lX9Y999yjwcFBvfzlL9ddd92liYmJdv/nAAAAAAAAAAAAH/X0UAUAAAAAAAAAAKBe0aAPAAAAAAAAAAAAoBMwVAEAAAAAAAAAAKhDPOgDaLdyuawLFy5oeHhYkUgk6MMBAAAAAAAAAAABsixLCwsL2rlzp6LRjbMoPTdUuXDhgvbs2RP0YQAAAAAAAAAAgBA5e/asdu/eveHH9NxQZXh4WJL9lzMyMhLw0QAAAAAAAAAAgCDNz89rz5497vxgIz03VDErv0ZGRhiqAAAAAAAAAAAASaqrMoSiegAAAAAAAAAAgDowVAEAAAAAAAAAAKgDQxUAAAAAAAAAAIA69FynSj0sy1KxWFSpVAr6ULpWLBZTPB6va0cdAAAAAAAAAABhwFBlhXw+r4sXLyqdTgd9KF1vYGBAO3bsUDKZDPpQAAAAAAAAAACoiaFKlXK5rJMnTyoWi2nnzp1KJpMkKXxgWZby+byuXr2qkydP6siRI4pG2UQHAAAAAAAAAAg3hipV8vm8yuWy9uzZo4GBgaAPp6v19/crkUjo9OnTyufzSqVSQR8SAAAAAAAAAAAbIh6wBlIT7cHfMwAAAAAAAACgk3BWGwAAAAAAAAAAoA4MVQAAAAAAAAAAAOrAUAVr+trXvqZIJKLZ2dmgDwUAAAAAAAAAgFBgqNIFIpHIhv+8613vavg+n/Oc5+jixYsaHR31/oABAAAAAAAAAOhA8aAPAK27ePGie/tv//Zvdccdd+ixxx5z3zc0NOTetixLpVJJ8fjG3/pkMqnt27d7f7AAAAAAAAAAAHQokio1WJaldL4YyD+WZdV1jNu3b3f/GR0dVSQScf/9Rz/6kYaHh/X5z39eT33qU9XX16dvfvObKpfL+uAHP6gDBw6ov79fN998s/7u7/7Ovc+V67/uvvtujY2N6Ytf/KKuu+46DQ0N6WUve9mygU65XNZ73vMe7d69W319fXrKU56iL3zhC55+PwAAAAAAAAAACApJlRoyhZKuv+OLgXztR95zqwaS3nyL3va2t+nOO+/UwYMHNT4+rg9+8IP6q7/6K33kIx/RkSNHdO+99+p1r3udtmzZohe84AVr3kc6ndadd96pv/zLv1Q0GtXrXvc6/fqv/7r++q//WpL0B3/wB7rrrrv0p3/6pzp69Kg++tGP6qd+6qf0b//2bzpy5Ign/x0AAAAAAAAAAASFoUqPeM973qOXvOQlkqRcLqcPfOAD+vKXv6xnP/vZkqSDBw/qm9/8pv70T/903aFKoVDQRz7yER06dEiS9OY3v1nvec973D+/88479Vu/9Vv6j//xP0qSfvd3f1f//M//rA9/+MP64z/+Yz//8wAAAAAAAAAA8B1DlRr6EzE98p5bA/vaXnna057m3n7iiSeUTqfdIYuRz+d19OjRde9jYGDAHahI0o4dO3TlyhVJ0vz8vC5cuKDnPve5yz7nuc99rh566CEv/hMAAAAAAAAAAAgUQ5UaIpGIZyu4gjQ4OOjeXlxclCR97nOf065du5Z9XF9f37r3kUgklv17JBKpu/cFAAAAAAAAAIBO1/nTAjTs+uuvV19fn86cObPuqq9GjYyMaOfOnbrvvvuW3ed9992nZzzjGZ58DQAAAAAAAAAAgsRQpQcNDw/r13/91/XWt75V5XJZz3ve8zQ3N6f77rtPIyMjesMb3tDU/f7Gb/yG3vnOd+rQoUN6ylOeoo997GN68MEH3SJ7AAAAAAAAAAA6GUOVHvXe975XW7Zs0Qc/+EGdOHFCY2NjuuWWW/Tbv/3bTd/nW97yFs3NzenXfu3XdOXKFV1//fX6h3/4Bx05csTDIwcAAAAAAAAAIBgRq8dKMebn5zU6Oqq5uTmNjIws+7NsNquTJ0/qwIEDSqVSAR1h7+DvGwAAAAAAAAAQtI3mBitF23RMAAAAAAAAAAAAHY2hCgAAAAAAAAAAQB0YqgAAAAAAAAAAANSBoQoAAAAAAAAAAEAdGKoAAAAAAAAAAADUgaEKAAAAAAAAAABAHRiqAAAAAAAAAAAA1IGhCgAAAAAAAAAAQB0YqgAAAAAAAAAAwmvyCWnufNBHAUhiqAIAAAAAAAAACKvcgvSnz5c++rKgjwSQxFClK0QikQ3/ede73tXSfX/mM5/x7FgBAAAAAAAAoG7pKamQlubOSOVS0EcDKB70AaB1Fy9edG//7d/+re644w499thj7vuGhoaCOCwAAAAAAAAAaE0xX7ldyEh9nOtEsEiq1GJZUn4pmH8sq65D3L59u/vP6OioIpHIsvd98pOf1HXXXadUKqUnPelJ+pM/+RP3c/P5vN785jdrx44dSqVS2rdvnz74wQ9Kkvbv3y9JeuUrX6lIJOL+uyT9/d//vW655RalUikdPHhQ7373u1UsFj37awcAAAAAAAAAlXKV24VMcMcBOEiq1FJISx/YGczX/u0LUnKwpbv467/+a91xxx36oz/6Ix09elQPPPCAfv7nf16Dg4N6wxveoD/8wz/UP/zDP+hTn/qU9u7dq7Nnz+rs2bOSpO9+97vaunWrPvaxj+llL3uZYrGYJOkb3/iGXv/61+sP//AP9fznP1/Hjx/XL/zCL0iS3vnOd7b23wwAAAAAAAAAxrKkSjq44wAcDFW63Dvf+U7dddddetWrXiVJOnDggB555BH96Z/+qd7whjfozJkzOnLkiJ73vOcpEolo37597udu2bJFkjQ2Nqbt27e773/3u9+tt73tbXrDG94gSTp48KDe+9736jd/8zcZqgAAAAAAAADwzrKkCkMVBI+hSi2JATsxEtTXbsHS0pKOHz+un/u5n9PP//zPu+8vFosaHR2VJL3xjW/US17yEl177bV62ctepp/8yZ/US1/60g3v96GHHtJ9992n97///e77SqWSstms0um0BgZaO24AAAAAAAAAkCQVGaogXBiq1BKJtLyCKyiLi4uSpD/7sz/TM5/5zGV/ZlZ53XLLLTp58qQ+//nP68tf/rJe85rX6MUvfrH+7u/+bsP7ffe73+2mX6qlUikP/wsAAAAAAAAA9LTSiqJ6IGAMVbrYtm3btHPnTp04cUL/+T//53U/bmRkRK997Wv12te+Vq9+9av1spe9TNPT05qYmFAikVCpVFr28bfccosee+wxHT582O//BAAAAAAAAAC9jKEKQoahSpd797vfrbe85S0aHR3Vy172MuVyOX3ve9/TzMyMbr/9dn3oQx/Sjh07dPToUUWjUX3605/W9u3bNTY2Jknav3+/vvKVr+i5z32u+vr6ND4+rjvuuEM/+ZM/qb179+rVr361otGoHnroIf3whz/U+973vmD/gwEAAAAAAAB0D9Z/IWSiQR8A/PWmN71Jf/7nf66PfexjuvHGG/WCF7xAd999tw4cOCBJGh4e1u/93u/paU97mp7+9Kfr1KlT+qd/+idFo/aPxl133aUvfelL2rNnj44ePSpJuvXWW/XZz35W99xzj57+9KfrWc96ln7/939/Wck9AAAAAAAAALSsOqmSZ6iC4EUsy7KCPoh2mp+f1+joqObm5jQyMrLsz7LZrE6ePKkDBw7QDdIG/H0DAAAAAAAA2ND3PiZ99lft26/4kPT0nwv0cNCdNpobrERSBQAAAAAAAAAQTnSqIGQYqgAAAAAAAAAAwmlZpwpDFQSPoQoAAAAAAAAAIJxKFNUjXBiqAAAAAAAAAADCqcj6L4QLQ5U1WJYV9CH0BP6eAQAAAAAAAGxoWafKUnDHATgYqlRJJBKSpHSaGFk7mL9n8/cOAAAAAAAAAMtQVI+QiQd9AGESi8U0NjamK1euSJIGBgYUiUQCPqruY1mW0um0rly5orGxMcVisaAPCQAAAAAAAEAYUVSPkGGossL27dslyR2swD9jY2Pu3zcAAAAAAAAArEJRPUKGocoKkUhEO3bs0NatW1UoFII+nK6VSCRIqAAAAAAAAADYGEX1CBmGKuuIxWKc9AcAAAAAAACAIFUnVfIU1SN4FNUDAAAAAAAAAMKJpApChqEKAAAAAAAAACCcSgxVEC4MVQAAAAAAAAAA4bRsqEJRPYLHUAUAAAAAAAAAEE7Fqk4VkioIAYYqAAAAAAAAAIBwqi6qL2akcjm4YwHEUAUAAAAAAAAAEFbVRfWSPVgBAsRQBQAAAAAAAAAQTtVJFYkVYAgcQxUAAAAAAAAAQDitTKpQVo+AMVQBAAAAAAAAAIRTaeVQhaQKgsVQBQAAAAAAAAAQTqvWf5FUQbAYqgAAAAAAAAAAwsms/4ol7bd5hioIFkMVAAAAAAAAAEA4maRKasx+y/ovBIyhCgAAAAAAAAAgfEpFySrbt/vH7bes/0LAGKoAAAAAAAAAAMKnuk+lf8x+S1IFAWOoAgAAAAAAAAAIn2LVUMVd/0VSBcFiqAIAAAAAAAAACJ9SwX4biUp9w/ZtkioIGEMVAAAAAAAAAED4mPVfsaSU6LdvF5aCOx5ADFUAwBflsqW3/a+H9fFvnQr6UAAAAAAAADpTMW+/jfVJiQH7NkkVBCwe9AEAQDc6dmVRn/zuWY0NJPT6Z+8P+nAAAAAAAAA6j0mqxJNSkqEKwoGkCgD4YDFXlCTNZQoql62AjwYAAAAAAKADmaL6ZUkViuoRLIYqAOCDTL4kSbIsaSFbDPhoAAAAAAAAOlDJWf8Vr+5UIamCYDFUAQAfZAol9/ZsJh/gkQAAAAAAAHSoZUkVZ6iSp6gewWKoAgA+SOcr6ZS5TCHAIwEAAAAAAOhQy5IqdKogHBiqAIAPzPoviaEKAAAAAABAU8xQJcb6L4QHQxUA8MGy9V9phioAAAAAAAANW7b+a9C+TVE9AsZQBQB8kCapAgAAAAAA0BqK6hFCDFUAwAfZAkMVAAAAAACAlixLqtCpgnBgqAIAPiCpAgAAAAAA0KI1kypLwR0PIIYqAOCL5Z0q+QCPBAAAAAAAoEMtS6qw/gvhwFAFAHyQIakCAAAAAADQmpIzVIknq9Z/pSXLCu6Y0PMYqgCAD6qHKrNphioAAAAAAAANKznnVGJJKTlQeX8xG8zxAGKoAgC+SFNUDwAAAAAA0Jrq9V/x/sr7WQGGADFUAQAfZFn/BQAAAAAA0JrqovpY3E6sSPYKMCAgDFUAwAfpQtG9zVAFAAAAAACgCdVJFalSVp9nqILgMFQBAB+kq5Iq6XxJ+WI5wKMBAAAAAADoQNVF9dLysnogIAxVAMAH1eu/JNIqAAAAAAAADSs667/cpIoZqtCpguAwVAEAH1QX1UvSXCYf0JEAAAAAAAB0KDepsnKoQlIFwWGoAgA+yDhJlUQsIomkCgAAAAAAQMNKzvmUWMJ+azpVSKogQAxVAMBjpbKlnNOhsm0kJYmhCgAAAAAAQMPWK6onqYIAMVQBAI9lq1Z/7Ri1hyqzaYYqAAAAAAAADWH9F0KIoQoAeCxdVVK/laQKAAAAAABAc9yi+qT9lvVfCAGGKgDgMZNU6U/ENNZv7/wkqQIAAAAAANCglUmVJEkVBI+hCgB4zCRVBpIxjTpDFZIqAAAAAAAADVqVVDFDFZIqCA5DFQDwWDpflCSlEjGNDTBUAQAAAAAAaMqqThXWfyF4DFUAwGOZAkkVAAAAAACAlpXWSarkl4I5HkAMVQDAcxln/Vd/MqbRfvuX/mw6H+QhAQAAAAAAdB6K6hFCDFUAwGOZqqJ6kioAAAAAAABNWrX+i6J6BI+hCgB4rLqonk4VAAAAAACAJlFUjxBiqAIAHssWqtd/VYYqlmUFeVgAAAAAAACdhaJ6hBBDFQDwmEmq9CfiblKlULLc9wMAAAAAAKCGclkqF+3bsZXrvyiqR3AYqgCAxypF9VH1J2JKxCKSWAEGAAAAAABQN5NSkaQ4RfUID4YqAOAxU1Q/kIwrEolotN/+xc9QBQAAAAAAoE7FqqHKqk4ViuoRHIYqAOAxk1RJJWKSpNH+uCRpNs1QBQAAAAAAoC6lqvMoZqiSpKgewWOoAgAeM90pA0l7qDI2QFIFAAAAAACgIWb9VywpRezV6qz/QhgwVAEAj2UKdolav5tUscvq5zL5wI4JAAAAAACgo5j1X6akXlq+/suy2n9MgBiqAIDnKkX1K4cqJFUAAAAAAADqUnIuTjUl9VIlqWKVl3euAG3EUAUAPGbWf61MqtCpAgAAAAAAUKeNkioSZfUIDEMVAPBYtrC8U4WkCgAAAAAAQIPWSqrEElI0bt+mVwUBYagCAB5Lr1j/NTbgJFUYqgAAAAAAANRnraSKJCUG7bcMVRAQhioA4LFMYe31X/MMVQAAAAAAAOpjkiqx5PL3m14V1n8hIAxVAMBjpqh+IGnHUd2kCp0qAAAAAAAA9Vlr/ZfEUAWBY6gCAB5bL6lCpwoAAAAAAECd1l3/5ZTVM1RBQBiqAICHLMuqDFXconr7iorZdD6w4wIAAAAAAOgoNZMqdKogGAxVAMBD2UJZlmXfrgxV7KTKQq6oUtkK6tAAAAAAAAA6x3pJlaRJqjBUQTACHarce++9uu2227Rz505FIhF95jOf2fDj//f//t96yUteoi1btmhkZETPfvaz9cUvfrE9BwsAdTApFWn1+i/LkhayrAADAAAAAACoqeQMVVYlVVj/hWAFOlRZWlrSzTffrD/+4z+u6+PvvfdeveQlL9E//dM/6fvf/75e9KIX6bbbbtMDDzzg85ECQH3S+aIkKRmPKhaNuLcHnNQKvSoAAAAAAAB1KDrrv1Z1qrD+C8GKB/nFX/7yl+vlL3953R//4Q9/eNm/f+ADH9Df//3f6x//8R919OhRj48OABqXdZIqZohijPUnlM6XGKoAAAAAAADUw3SqxNZJquSX2ns8gCPQoUqryuWyFhYWNDExse7H5HI55XI599/n5+fbcWgAelQ67wxVEsuHKiP9CV2Yy2o2zVAFAAAAAACgJorqEVIdXVR/5513anFxUa95zWvW/ZgPfvCDGh0ddf/Zs2dPG48QQK/JOEOV1MqkyoDdq0JSBQAAAAAAoA7rFdW7QxU6VRCMjh2q/M3f/I3e/e5361Of+pS2bt267se9/e1v19zcnPvP2bNn23iUAHpNep31X6asfpahCgAAAAAAQG3rFtUP2m9JqiAgHbn+65Of/KTe9KY36dOf/rRe/OIXb/ixfX196uvr2/BjAMArWSep0p9Ye6gyz1AFAAAAAACgNorqEVIdl1T5xCc+of/yX/6LPvGJT+gVr3hF0IcDAMuYTpX+5PKZ9diAfVXFbDrf9mMCAAAAAADoOG5SZeVQxSmqL1BUj2AEmlRZXFzUE0884f77yZMn9eCDD2piYkJ79+7V29/+dp0/f14f//jHJdkrv97whjfoD/7gD/TMZz5Tly5dkiT19/drdHQ0kP8GAKhm1n/1J5bPrE1ShU4VAAAAAACAOrhJFYrqES6BJlW+973v6ejRozp69Kgk6fbbb9fRo0d1xx13SJIuXryoM2fOuB//P/7H/1CxWNQv/dIvaceOHe4/v/IrvxLI8QPASmb918CKpIrbqZJmqAIAAAAAAFBTiaEKwinQpMoLX/hCWZa17p/ffffdy/79a1/7mr8HBAAtMuu/Uut0qpBUAQAAAAAAqMN6RfVJU1Sfbu/xAI6O61QBgDDLFExSZflQZWyAoQoAAAAAAEDdKKpHSDFUAQAPZfJFSVI/SRUAAAAAAIDm1SyqJ6mCYDBUAQAPmaRK/8qkSr8dVaVTBQAAAAAAoA61iurzDFUQDIYqAOChdH7t9V8mqZIplJQvltt+XAAAAAAAAB2lZlKF9V8IBkMVAPBQ1iRVVqz/Gk7FFYnYt1kBBgAAAAAAUEOtpEohLVlWe48JEEMVAPCUSaqsXP8VjUY0kjK9Kvm2HxcAAAAAAEBHMUmVVUMVJ6lilaQSF66i/RiqAICHMuskVSRpbICyegAAAAAAgLqUnItS11v/JVFWj0AwVAEAD2XcTpX4qj8zvSqU1QMAAAAAANSw3vqvWEKKOBez0quCADBUAQAPVdZ/rX54NUMVkioAAAAAAAA1rFdUH4lUldWTVEH7MVQBAA9V1n+RVAEAAAAAAGjaekkVaXlZPdBmDFUAwEOZdYrqJZIqAAAAAAAAdVsvqSJVDVVY/4X2Y6gCAB6xLMtNqgysMVShqB4AAAAAAKAOllUpqo+tMVRJDtpvSaogAAxVAMAj+VJZpbIliaQKAAAAAABA08xARbKL6VciqYIAMVQBAI9k82X3dn9ijaRKv70DdDadX/VnAAAAAAAAcFQPVdZc/+UU1eeX2nM8QBWGKgDgkXShKElKxCJKxFY/vI6QVAEAAAAAAKitWJ1UoVMF4cJQBQA8YkrqU2ukVKRKp8osQxUAAAAAAID1mZL6aFyKrnEKm6EKAsRQBQA8ks6vX1IvVTpV5hmqAAAAAAAArK/oDFXWSqlIUoKiegSHoQoAeCRTsIcqa/WpSFVJlXRBlmW17bgAAAAAAAA6iulUiSfX/nOSKggQQxUA8IhZ/9WfjK/55yapUixbbqoFAAAAAAAAK9RMqpihCkkVtB9DFQDwiBmU9CfWfmjtT8SUdArsKasHAAAAAABYh0mqxNZLqgzYbxmqIAAMVQDAI9mC6VRZO6kSiUQ00l9ZAQYAAAAAAIA1sP4LIcZQBQA84iZV1imql6TRfnvgQlIFAAAAAABgHTXXf3mcVKH7Fg1gqAIAHqlVVC9JYwP2FRZzmXxbjgkAAAAAAKDj1EqqJM1QxYOkyrnvS7+7T/rXP2v9vtATGKoAgEcy+aIkaWDDpIq9/oukCgAAAAAAwDramVQ5da+UnZMe+fvW7ws9gaEKAHjEJFVSGyVV6FQBAAAAAADYWL2dKnkPhiqZWfvt1BOt3xd6AkMVAPCI6VTZKKkyQlIFAAAAAABgYzWTKh4W1Wfn7LcLF6XcQuv3h67HUAUAPJLJ19Op4iRVGKoAAAAAAACsreQMVeJtWP+Vna3cnjre+v2h6zFUAQCPuEX1dKoAAAAAAAA0r+ScN4kl1v7zhIdF9Wb9l8QKMNSFoQoAeMSs/9poqGKSKnN0qgAAAAAAAKyt7qJ6L9Z/zVZuM1RBHRiqAIBHsoXanSokVQAAAAAAAGpw13/VKKr3Yv1XdVJl8ljr94eux1AFADySrqNTZbTffjIwm8m35ZgAAAAAAAA6TtE5b1KrqL5cqKwKa1Y7kiqW5c/9IhAMVQDAI25RfTK+7se4SRXWfwEAAAAAAKyt3qJ6qbW0SrksZecq/z71hPcDkK//nvT/PyRNslqsWzBUAQCPZOpY/2U6VeazRZXKXKUAAAAAAACwiptUWWf9V7xPUsS+3UqvSn5BssrOv0Sk/KK0eLn5+1vLw5+S0lPS+e95e78IDEMVAPBIpq71Xwn39kKWtAoAAAAAAMAqtZIqkYiUHLRvt5JUMX0q8ZQ0vt++7WWvSiErTZ+wb+cXvbtfBIqhCgB4JJ0vSpL6N0iqJGJRN8lCWT0AAAAAAMAa3KRKYv2PccvqW0iqmD6V1Ji06bB928telaljkmVfhKv8knf3i0AxVAEAj2QLdlx0o6SKJI05aZVZelUAAAAAAABWK9UoqpcqQ5W8B0mV/jFp8xH7tpdDlSs/qtxu5TgRKgxVAMADxVJZ+ZI9VNmoU0WSRkxZPUkVAAAAAACA1Wqt/5IqZfWtrP9allQ5ZN/2dKjySOU267+6BkMVAPBA2impl6RUraSKU1Y/y1AFAAAAAABgtVpF9ZI367+qkyqbnKSKl50qV6uTKqz/6hYMVQDAA1mnpD4akfriGz+0jpJUAQAAAAAAWF9dSRUPiurX6lSZOSWVPDpnsyypwlClWzBUAQAPpJ2hSn8ipkgksuHHjvXbV1nMpfO+HxcAAAAAAEDHCSKpMrLTXilmlezBSqvyS9LM6cq/tzL8QagwVAEAD2Sc9V/9yXjNjx0dIKkCAAAAAACwrrqSKmao4lFSJRLxtlfl6mOSrMq/06nSNRiqAIAHTFKlVkm9VFn/NZtmqAIAAAAAALBK0RmqbJhU8aCovjqpInnbq1LdpyKx/quLMFQBAA9kC5X1X7XQqQIAAAAAALAB02ni9/qv6qSKVOlV8SKpYvpUNl9rv2Wo0jUYqgCAB9xOlTqSKmPO+q9ZhioAAAAAAACr1bX+y4ekymYnqeLJUMVJqux+mv2WoUrXYKgCAB7INJFUmWeoAgAAAAAAsFo9RfVJM1TxMqniYafKlUftt7uear9lqNI1GKoAgAcy+aKk+jpVxvrtJwR0qgAAAAAAAKyhXUX1qzpVnPVfi5el7Hzz95udl+bP2bdJqnQdhioA4AGz/ivVQFE9nSoAAAAAAABrcJMqdaz/yjc5VLEsKTtn3zZJldSoNLjVvt1KWsWU1A/vkEZ22beLGalcav4+ERoMVQDAA2b910A967+cTpVMoaRckV+mAAAAAAAAy7hJFR+L6nMLkuWclzFJFcmbXhWz+mvrdVJysPL+VlI1CA2GKgDggUwDRfXDfXFFIvZt0ioAAAAAAABVLEsqOkOVjTpVWi2qN30qsb7KgEbyplfFDFW2XCfFU1LEOQ3PCrCuwFAFADzQyFAlGo1oJEVZPQAAAAB0Asuy9Et/c7/u+PsfBn0oQG8olyRZ9u0NhyotJlVW9qkYm5ykyuSx5u5Xkq5WJVUiESk5ZP87Q5WuwFAFADyQdtd/xev6+DFnBRhl9QAAAAAQbpfms/rcwxf18W+dVqlsBX04QPczq7+kGkX1JqnS5FDFJFVMn4phyuq9Wv8lVfW/LDZ/nwgNhioA4IGsm1Sp72GVsnoAAAAA6AwL2aJ7O18sB3gkQI8oVg1V6imqb3b9l0mqpEaXv9/tVDluryJrVHpaWrxs395yrf3W9Krk6VTpBgxVAMADaXeoUl9SxQxVSKoAAAAAQLhVD1VyxVKARwL0iFLefhuJSrENzrO4679a7FRZuf5rbJ8UiUmFJWnhYuP3a1Iqo3ulvmH7tjtUYf1XN2CoAgAeyDjrv/oTtTtVJJIqAAAAANApFnOVoUq2QFIF8J1bUr9BSkXyMKkytvz98aQ0vt++3UyvytUVq7+kqk4V1n91A4YqAOABU1Q/UEdRvVTVqcJQBQAAAABCbZGkCtBeJqkS36CkXmq9qH69pIrUWq+K26fypMr7kqZThaRKN2CoAgAeSBfsJ9mNJlXmGaoAAAAAQKgt5iqv23J0qgD+c5MqNYYqZqVWKS+Viht/7FrWS6pIVb0qzQxVfmS/3Xp95X3mWJtN1SBUGKoAgAcybqdKnUmVfvuJwWw679sxAQAAAABaV92pki2QVAF8Z5IqNdd/9VduF5tIq/iRVLEs6coj9u0t1UkV1n91E4YqAOABd6hCpwoAAAAAdJXlRfUkVQDf1bv+K56q3G5mBdhGSRUzVGm0U2XpqpSZlhSRtlxbeT9F9V2FoQoAeMAU1dfbqTJKpwoAAAAAdITqovocRfWA/+otqo9EKmX1zQwrNkqqmPVfs6elYgNbRkyfysSB5UkahipdhaEKAHgg7SRVUiRVAAAAAKCrUFSPUCqXpH/9s0p/RzepN6kitVZWv1FSZWibvbLLKkszJ+u/T7ek/vrl708wVOkmDFUAoEXlsuVGwOtNqow5SZW5NEMVAAAAAAiz6qRKlqQKwuKJL0v/9OvSF34r6CPxXr1JFamSVGlmqLJRUiUSaa5X5aozVKnuU5FIqnQZhioA0KJMVVHhQDJe1+dUJ1Usy/LluAAAAAAArZvPVi6GI6mC0LjqJFSWJoM9Dj+UnKFKvJGhSrqxr2FZGydVpOZ6VdykynXL389QpaswVAGAFlUPVfri9T2smqFKsWy5q8MAAAAAAOGzrFOFonqExbSzkqobT9KbDpNYovbHNrv+K78oWc75mLWSKlKlV6XepIplVdaxrTtUWWzoMBFODFUAoEUZZyjSn4gpGo3U9Tn9iZiSMfshmLJ6AAAAAAiv6k6VbIGL4hASpuej0YRGJyg1s/6rweGSSalEE5X7WKnR9V/zF6TcnBSNS5uOLP8zM1Tpxu9XD2KoAgAtMkmV/jr7VCQpEolopJ9eFQAAAAAIO5IqCKWZU/bbfBeepC8550n8LKqv7lOJrHOBbKNDFdOnMnFo9bGz/qurMFQBgBalq5IqjTBl9bOZvOfHBAAAAADwRnVSJUdRPcKgVJBmz9q384v22qlu0lBRvRmqNDhcqtWnIkmbDtlvl65WPn4j6/WpSAxVugxDFQBoUTpvP8FuJKkiVXpV5ln/BQAAAAChVC5bWsxXJ1VY/4UQmDtb6QORJRWzgR6O59yi+jqSKu5arUaTKnP22/X6VCSpb1ga3mHfnjpe+z7X61ORpOSQ/ZZOla7AUAUAWmR26g40OFQZc4Yqs6z/AgAAAIBQWsoXl4UAsiRVEAampN7othVgblF9I0mVJtd/bZRUkapWgB2rfZ9XHrHfrjVUMb0t3fa96lEMVQCgRWb9V6rB9V8mqTJHUgUAAAAAQqm6T0UiqYKQmFkxVGm0pD3s3KRKI0X1Ta7/2iipItXfq1IuS1cfs29v2WD9VylX6YxBx2KoAgAtyuSbS6qMup0q/DJFxf954Jy+8MNLQR8GAAAAAC3vU5EoqkdImJJ6o9t6OtykSqL2x5qkSqMJkEaTKpM1kipzZ+zhViwpTRxc/edm/ZfUfd+vHsRQBQBalGly/RdJFaw0tZjT7Z96SG/5xAPuWjkAAAAAwVlYkVTheTpCodvXf5XaWFRfK6my+Yj9tlaniulT2XyNFIuv/vN4Uoo6QyKGKh2PoQoAtCjT5Pov06kyR6cKHGdnMrIsKV8q6+QkT7IAAACAoC2QVEEYrUyqdN36LyepUk9Rvbv+y+9OlSfsFV/rMX0qW560/sckm1xVhtBhqAIALUq3uP6LpAqMC7OVJ4HHry4GeCQAAAAAJNZ/IYQsq5JU6Ru133ZbUqWhovomhyr1JlXG9knRuFTMSAsX1v+4q05SZa2SesOsAMvzer/TMVQBgBaZ+Hd/w0kV+4qL2Uze82NCZzo/UzVUudJlVxoBAAAAHWgxt/wiONZ/IXBLV51kSkTa6qQiuu0kfTuK6utNqsTi0vgB+/ZGvSomqbLhUMUpq2f9V8djqAIALTJJlf7kGjszNzBCpwpWOE9SBQAAAAgVs/5r0NlMQFIFgTOrv0Z2VQYC3bZOyk2q1LP+y+dOFamqV+WJtf+8XJKuPm7fZqjSExiqAECL3KFKg0mVUTpVsAJDFQAAACBcFp2i+s3D9hXzOZIqCJpZ/TVxoOokfZcNVcKUVJGkTYfst+sNVaZP2scc75fG9q9/Pwnz/eL1fqdjqAIALTLx70Y7VcacTpX5bFGlsuX5caHzVHeqnLi6pDI/FwAAAECgTKfKpkH7ivk8SRUEbcYZqozvryo+77LkQ9EZqjSUVGmgU8WyGkuqbKqRVLn6qP12y7VSdIPT7d06BOtBDFUAoEXpvP0ku9mkiiQtZEmrYPlQJVMo6eJ8NsCjAQAAAGDWf20esq+Yp1MFgatOqiS6dJ1UqZn1Xw0MVQppqeych6krqXLYfrtep8oVZ6iy0eovifVfXYShCgC0KGOK6htMqiRiUXcv7ywrwHpeOl/UjPNzsNVZLXCCFWAAAABAoFat/yKpgqCZTpXxA5WkSrclH8xQpZ71X2ZQ0cj6L5NSicYrn78R06kye6aSoqnW8FCF1/qdjqEKALQo02SnilTVq0JZfc8zKZXhvriesmdMknT8Ck+0AAAAgCAtmKGKs/6LoQoCt2z9lxkodFnyoami+gaSKtV9KpFI7Y8f3CL1jUiypOkTq//cDFW2kFTpFQxVAKBFmSY7VSRpdMB+gjDLUKXnnZuxnwDuGu/Xoa1DkqTjV3miBQAAAARp0VnVvIn1XwiD/JK0eNm+vWz9V7clVZooqi9mpXKd/3820qci2YMXswJsZa9KMS9NOWvB6k2qNJKqQSgxVAGAFqXzza3/kqTR/rgkkiqQLsza/Sk7x/p1aIsZqpBUAQAAAILkrv9yhirFsqViibQKAmJWf6XGpP7xqvVfXXZBnptUqWeo0l+5XW9apTqpUq/1elWmj0vlopQclkZ3b3wfrP/qGgxVAKBF2SY7VSRprN9Oqsyl854eEzqPWf+1cyylQ1vsJ1oMVQAAAIBgVYrqK2uI8gxVEJTqknqpklTptvVfblKljvVf8SaGKo0mVaRKr8rU8eXvd/tUnlR7lVjSvoCy64ZgPYihCgC0yCRVBhLxhj+XThUY552hyq6xAR10kiqX53NayPKzAQAAAARl0RmqbKoaquQKDFUQELekfr/9Ntml679MGXw9SZVotDJYqXetVlNJlUP226kVSRW3T+VJte+DTpWuwVAFAFpgWZbbqZJKNv6QOjZgD1Vm05w473Xnq5Iqo/0JbRm2nzyeoFcFAAAACES5bGkxbw9VRvuTikftq9CzRXpVEBC3pN5Jqpj1X93W0VEy678S9X18o2X1zSRVNpmkyopOlasmqXJ97fsw/S/dNgTrQQxVAKAFuWJZlmXfHkg2nlQZIakCx3mnqH73uP1kkBVgAAAAQLDShZL7em84FVcqYa98JqmCwKy3/qvbOjrMUKWeonqpMqyodw1aK0mV9JSUnq68v3r9Vy3u+q8u+371IIYqANACs/pLkvoTTXSqmKQKQ5WeVipbujRfKaqX5K4AY6gCAAAABMOs/opHI+qLR9UXt0+j5YoMVRCQ9ZIq3ZR8KJft4nepvvVfUnuSKslBaWSXfdv0qhSy0vQJ+3Y9SRXWf3UNhioA0AKz+isZjyoWrVFItgY6VSBJl+ezKpUtxaMRbR1OSZIOOUMV1n8BAAAAwTD9hsOpuCKRiDtUyRZY/4UAlEvS7Bn79spOlW5a/2VK6qX6iuqlxocqzSRVpNW9KpOPS1bZvp+hbbU/n6FK12CoAgAtyDj7dZtJqUhVQxU6VXraBadPZftoyh3Osf4LnWoxV9RHv3lSF+fqfEEDAAAQUgs5+/XeUMpe9dxn1n+RVEEQ5s7ZCY5YUhrZab8vUTVUKXfJz2WxaqhSd1KlwW6ZZpIq0upelas/st9uvV6K1HGhrTsEY6jS6RiqAEALMnn7SctAsrmhyli/fdUFSZXeVimp73ffZ5IqpybTKpa65MkxesInvnNG7/nsI/rjf36i9gcDAACEmFn/NdRnXwxXWf9FUgUBMKu/xvZJUecchFn/JXVPWsX0qUj1F9WbvwffkyqH7beTTlLlyiP223r6VKTlSRVT2ISOxFAFAFqQNkmVJocqrP+CVBmq7K4aquwa61dfPKp8qaxzM1zxj87x6KV5SdKluVyNjwQAAAi3RSepMty3IqlCUT2CsLKkXpLildeQXTNUMUmVWF996Q+pfUmVzSap4nSqXKlKqtTDDFXKxeXDI3QchioA0ALTqdL0+i+nqD5TKHG1Uw+7sEZSJRqNUFaPjnTc6QGaZ1gMAAA6nJtUMeu/TKcKr90QBLekfn/lfdFoZQVYt/R0mGFDrM4+FanSqZKvY6hiWa0nVaaP2+vWTFJlS51JFfO9krrn+9WjGKoAQAsyefvJdLPrv4b74u6FF6RVetf5mdVDFYleFXQey7J0wvl5nc/ymAYAADrbfFVRvSSlSKogSDOn7LfjB5a/P9lgSiPsTFKl3pJ6qbGi+kKmMrhpNKkyttce9hSzdkn97Gn7/Vuvq+/zY/FKTwxDlY7GUAUAWmCSKqkmkyrRaISyeujCbFaStGt85VDFSapc4ckWOsPVxZwWnCs6GRQDAIBOZ9Z/DfUtT6pQVI9ArLX+S6qsvuqWk/RuUqXOknqpsfVfJqUSiUnJoYYOTdGYNHHQvv2jz9pvB7dIg5vrv49klyWLehRDFQBoQbrFpIpErwoq6792jaWWvf8gSRV0mOoBII9pAACg0627/qvA+i+0mWVtkFTpspP0ZqjSUFKlgaL66j6VejtbqpkVYI/+o/223pSKYQY53fL96lEMVQCgBWb9V7OdKpI05gxVZkmq9KS5TEELzhVwq9d/0amCznJisvKzms6XVChxFScAAOhcK4vq3fVfJFXQbulpKTdv3x7ft/zPzFCl29Z/+Z1UabRPxTBDlYsP2m+3NDpUMUMwXud3MoYqANACt6g+GW/6PkZIqvQ0k1IZH0hoYMXPkUmqzKQLml7Kt/3YgEatXFXH4xoAAOhkC+uu/yKpgjYzKZXhHZX+EMNd/9UlQ5VSK50qdfwdVCdVmmGGKkbDSZUu68DpUQxVAKAFaS+SKgP2E4VZTj72pPVK6iVpIBnXLuf9J0iroANUJ1UkhioAAKCzLbjrv+wL4fri9uu+LEX1aLcZp09l5eovqfuSD8VmOlUaKKp3kyqjDR2Wa/OR5f/e8FCly9a19SiGKgDQArNLt7VOFfuqJ04+9qYLc6ZPZfVQRaJXBZ1l5c/pPI9rAACggy1m7ecyw6ZTJUFSBQFZr6Reamz1VScwSZVYM50qDSRVWl3/ZWx5UmOf73aq8Bq/kzFUAYAWpPP2lUv9LQxVxvrtJwpzadY79aLzs+snVaTqXhWuYkG4ZQslnXOSV1uH7avKGBYDAIBOtqpTJU6nCgJSV1KlS4YqxWaK6ptIqjS7/mtgU2UgM7yz8fshqdIVGKoAQAsyTuy7lfVfo3Sq9DSz/mv3+DpDla3OUOUKV7Eg3E5NLcmypJFU3B0G8rgGAAA62aK7/mtFUoX1X2g3k1QZ37/6z9yi+i45SV9qYv2X+3fQhqRKJFJJq2xtMKUidV8HTo9iqAIALcg4SZWW1n8N2EMVOlV604WaSRXWf/Wi+WxBpyY760WRKak/uGXIHRaz/gsAAHSy9Yrqs6z/QruZovqN1n91S/KhpaL6NiRVJGnzNfbbrdc3/rms/+oKDFUAoAUZp1OllfVfJFV6m1n/tV6nirni/8x0mt3NPeT//qv79eIPfV2PX14I+lDqdsIZ/B2qGqrwuAYAADpVuWy5679MUiXlbCggqYK2KmSkhQv27TXXf3VZ8qGVovp6/g5aTapI0jP/q3TdbdJT/0vjn8v6r67AUAUAWpDOO0MV1n+hCfliWVcW7Ktw1kuqbB3u01BfXGVLOj3VJU+SsaHJxZy++cSkimVL3zg2GfTh1M2kqQ5uGdRIv33igcc1AADQqdKFkizLvj2Ssl+zmaQKFzuhrWZO22/7RqSBidV/bpIPXbP+yyRVGhmqNFBU70VSZedTpNf+lbT5cM0PXYWhSldgqAIALcjkW0+qjDnrv+bSnHzsNZfns7IsKRmPatPg2tHmSCRSWQFGr0pP+GbVIOXhc7PBHUiDTjjryg4tW/9VDPKQAAAAmmb6VOLRiDtM6YuTVEEA3JL6fXafx0rd1tHhJlV8Wv/lRVKlFd3WgdOjGKoAQAvM+q+WOlWqkiqWuRQKPeHcTGX1VzS6xpNjh1kBdqLDOjbQnHsfv+refvjcnC9f4+8fPK9/ecK7FIxlWe7Q7/DWQRJ4AACg4y3m7OcxQ6m4Is6JbJIqCITpU1lr9ZdUtf6rS14vmqRKQ0MV5++gmJHKNYaeXiRVWkFSpSswVAGAFpj1X6kW1n+N9dtPFIplS0t5npz3kkpJfWrDjzu01R6qkFTpfuWypXuPVYYqJyeXPB9MHLu8oF/55IP6r3/5fZXK3gxyL8/ntJQvKRaNaO/EoEYYqgAAgA63kF1eUi9VdaoUSaqgjaadpMpaJfWSlOiy5EOxmaL6garPz278sWFJqjBU6WgMVYA6PHJhXvNZTgxhtWzeJFXiNT5yfalEVMmY/XDMCcjeUquk3nDXf11lqNLtHrk4r8nFvAaSMe0ctYdtP/A4rfLdUzOSpIVc0bOfKVNSv3diQMl4lKQKAADoeGsNVfoSJqnCUAVt5K7/Wi+pYk7Sd8n6r5LzGqKZonpp4xVghWwlCRN4UoXX952MoQpQw7HLC/qJP/yGXvUn/6JsgRQBKizLUrrQelF9JBLRqNOrMpvOe3Js6AyVpEqtoYqTVLm6xIq4Lvd1Z/XXcw5t1tF945KkhzzuVbn/zIx726uBjVtSv9l+gcBQBQAAdLrFnD1UMSX1UmX9F+cG0Fa1kirJBkraO0EzRfXRWGUIs1Fix6z+ikSl5HBTh9eyRJcNwXoUQxWghscuL0iSnriyqD/52vGAjwZhUihZ7uqcVorqJU5A9qrzdQ5V9m4aUCwa0WKuqCsLuXYcGgJi+lRecM1m3bx7VJL3ZfXLhirnvRqqOCX1zqq6Ebeonsc0AADQmUxR/VCK9V8IULkkzZ62b4/vX/tjEl2WfGimqF6qr6zeXf01KkUDOi3O+q+uwFAFqGFqsZIc+H+/9oSOOUMWIFPVf9JKUb0kjZmhSpoTkL3EDFV21xiq9MVj2jthX31Er0r3WsgW9P3T9sDjBdds1U27xyR5W1Y/m87rxNXKk/cfejZUsX8uzao6MyheyBU9620BAABop4XcGuu/TFE9SRW0y8JFqZSXonFpZPfaH+MW1XdJ8qGZpIpU6VXZKLFjkipB9alIDFW6BEMVoIapxcpV4YWSpbf/7x+ozAkiSMo4T6Tj0YgSsdYeTkmq9B7Lsupe/yVV1irRq9K9vnV8SsWypf2bBrR304Bu2DWqSES6OJfVlYUaZYt1euDMrKTKIPiRi/OeDD3MoOags6rOPKZJ9rAIAACg06yVVOmL28+hsiRV0C5m9dfYXim2Tpdr0n4OrlLOTrZ0OlNU32hSxV2DVkdSJag+Fany/covSqz37lgMVYAaJpfspMprnrZbA8mYvnd6Rp/47pmAjwphkM7bT7JbXf0lqdKpwlClZ0wv5ZUt2C/Gdoylan68Wat0/CpXs3Srr7urv7ZIsq+KPOwMKR4+602i5AFn9ddLr9+m/kRM6XxJJydbG9Rl8iU3dWX6fxKxqDu4YVgMAAA6kbkwZHiNpEqpbKlYYrCCNqhVUi9VEhpSd6QfSq2u/+qQpIosqejNxXNoP4YqQA0mqXLj7jH9+kuvlST9zud/pCvzPPD1unS+9ZJ6g6RK77kwaz+GbBnuc69424hZq0RSpTtZluUOVX7MGapIcleAeVVWf7+TVHna/gldv3NEUuu9Kiecocz4QEITg5UXPjyuAQCATmaK6ofX6FSR6FVBm5ikynp9KpK9JivinOLthqFKscX1XxutQQtDUqXbhmA9iqEKUIPpVNk8mNQbnrNfN+0e1UK2qHf/4yMBHxmClnXWf7XapyJJY/32ichZOlV6xvlZ+4lePau/pEoC4ARJla50cnJJ52YySsaietbBTe77b95jl9U/5EGvSqls6cGzs5KkW/aO68Zd9n3/4Nx8S/e7cvWXwVAFAAB0srU6VZLxymk0hipoi5lT9tuJDZIqkUilrH6jlEanKDmvH/woqg9DUiUarRoAcdFkp2KoAtQw5az/2jTUp1g0og++6kbFohF97gcX9eVHLgd8dAiSSaqkPEmq2E/U5zn52DPOO0mVWiX1hhmqnJ/NuKvn0D3udVIqT9s/rsGqF+43u2X1s7Ja3Ld77MqCFnNFDSRjunb7sG5whiqtltWvLKk3RlIMVQAAQOeqdKpUuuJi0YgSsYikykV2gK/qWf8ldVf5uZ9F9WFIqkjd9f3qUQxVgBrM+q9NQ/aE/Mk7R/Wm59u/zO74+x+6kWD0noyHSRXTqTKTzrd8X+gMlZL62n0qkjQ+mHRXK5FW6T4r+1SMJ+0YViIW0Wy6oLPTG1xxVQdTUn/z7jHFohE3qfJvF+ZUbqGs/vg6SZURkioAAKCDLa6RVJGklLO6l6QK2sKs/9ooqSJVlbR3QVKl2GqnSsiTKhJDlS7AUAXYQL5Y1rxzdcrmwcqE/Fd//BrtmejXhbms7rrnsaAODwHLmE4VD4Yqu8ftJ0CcLO8d52fsJ3q76kyqSPSqdKtsoaRvn5iWtLxPRZL64jFdt8PuPmm1V+X+03ZJ/S37xiTZP0+pRFRL+ZJOTDb/2HPCTaqsvf5rPsPFBwAAoPO4RfWp5UOVvoR9Ki1XJKkCn2VmKkOAsX0bf6xZ/9UN66R6IamSYKjS6RiqABuYdlZ/xaMRjfRXnkj1J2N6/8/cKEm6+19OuTvq0VtMUqU/Ea/xkbU9afuwJOnSfNZNR6G7XZgzSZVGhir2SevjDN+6yvdOzShTKGnrcJ/7WFDtpt12ouThVocqZ5yhyt5xSVI8FtX1zsDm3y40twKsXLbcYfDK9V90qgAAgE5m1n+tGqo4SZVsgaQKfGZSKoNbpb6hjT82WUdJe6cwRfWxZocqJFXgP4YqwAYmq1Z/RSKRZX/2Y9ds0SuP7pJlSW//3z9QocQTql5jOlW8WP81nEpo3yb7CcCjFxdavj+En5tUGa9/qHKQpEpXuveYvfrrx67Zsup3jSTd5PSqtFJWP5vOu8O4o85QRVJVWX1z931pPqtMoaR4NKI9EwPL/oyhCgAA6GRrFdVLVUkVOlXgt3pK6o1kNxXVm/VfiY0/biV3/VcHJFUYqnS8QIcq9957r2677Tbt3LlTkUhEn/nMZ2p+zte+9jXdcsst6uvr0+HDh3X33Xf7fpzoXW5J/eDa0/H//orrNDaQ0KMX5/UX3zzZzkNDCGTdpErrQxVJ7hXjj1xsrTQa4ZctlNzHl8bWfzlJlSsMVbrJ1x9bu0/FMGX1Pzw/p1KT3ScmUXlg86DbzSNJTzZDlSbL6s2Ab9+mASViy59WjjoJz3mGKgAAoMNYllXpVFknqUKnCnxXb0m9VElpdMNJ+qKP679Cl1ThtX2nCnSosrS0pJtvvll//Md/XNfHnzx5Uq94xSv0ohe9SA8++KB+9Vd/VW9605v0xS9+0ecjRa9aWVK/0qahPv23n7hOkvThLz+u01Nd8MsLdUvn7SfZXnSqSJWhCkmV7mdK6geSMfdq/nqYocrJyaWmT64jXC7NZfXY5QVFItLzDm9e82MObx3SQDKmdL7UdErpfqek/uiesWXvr5TVzzdVVm8GfCtL6iWK6gEAQOdK50uynKdGw33Ln6/3xe1TaVmSKvCbWf81vr/2x3ZT8qHkY1F92JIq3ZAs6lGBDlVe/vKX633ve59e+cpX1vXxH/nIR3TgwAHddddduu666/TmN79Zr371q/X7v//7Ph8petXUov1Avnlo/en4q5+6W88+uEnZQln//TM/lGVxorNXZPL2lUmeDVV2OkmVC/Oe3B/C6/xspaR+rXVP69k93q9kLKpcsewOZtDZ7n3cTqncvHtM44Nrv2iIRSO6Yac9/HioyQ6vB5w+laP7xpe9/8jWIfXFo1rMFXWqiQsDTMH9ypJ6ifVfAACgcy04fSqxaESpxPJTZ2aoQlIFvmtk/Vc9KY1OYYYqjSZVkjX+Doo5qei8jg5NUqULhmA9qqM6Vb71rW/pxS9+8bL33XrrrfrWt7617ufkcjnNz88v+weo1+SSk1RZ50SXJEUiEX3gVTcqGY/qG8cm9ZkHz7fr8BCwTMF+oj3g1fovZ6jyxNVFrnrqcmYg0khJvWQXi+/fbD9RpFelO3y9qk9lI5Wy+sbXdJXLlh50kiq37B1b9mfxWFTXOSm5ZlaAmZ/DlSX1UmWoMp9lqAIAADrLYs5+/jKciq+6CCqVYP0X2sQMVepZ/9UtJ+ktqyqp4nFRvUmpKCL1jTRzdN5h/VfH66ihyqVLl7Rt27Zl79u2bZvm5+eVyaz9P8wHP/hBjY6Ouv/s2bOnHYeKLmGSKps2SKpI9o76X/nxI5Kk9372UU07XQnobqao3qukyvaRlMYHEiqVLR27zC/WbtZMSb3h9qpc7fAny1CpbOmbxyYlrd+nYtzkrO16+Nxsw1/niauLWsgVNZCM6dptw6v+3KwA+2ETQ5UTzs/hWuu/SKoAAIBOZZIqK0vqpeqkChfCwUfFnDR3zr7dS0X1parzafEm13/l1/k7cPtURqVowKfEk87rp04fgvWwjhqqNOPtb3+75ubm3H/Onj0b9CGhg9TqVKn2888/qGu3DWt6Ka/3f+5Rvw8NIZDxeKgSiUQqK8Aoq+9q52ezkhorqTcqQxUGb53uoXOzmssUNJKK62YnibIe8+ePXJxv+AX8/aft1V837R5VPLb6qV9lqNJYmncxV9TFOftnecOkSqbQVF8LAABAUNyS+rWGKk5SJVsgqQIfzZ6RZEmJQWlw4wuwJHVPUb0pqZdaSKqsM1QJS5+KVPX96vAhWA/rqKHK9u3bdfny5WXvu3z5skZGRtTfv/aJqb6+Po2MjCz7B6jX1JLpVKk9VEnGo/rAq25UJCL9r/vP6b4nJv0+PAQs46zo6vdo/ZdUKaunV6W7VdZ/pRr+3ENb7ZPXpiAcnevrj9mrv55/ZMuaw45qeycGNDaQUKFk6UcXFxr6Ovc7fSq37B1f889vMEOVC3MN9YKddFIqmwaTGhtY/XvSFNWXLWkxX2zomAEAAIK06CRVhlOrhyopkipoh+qS+np6OLtl/Vd1UsXrono3qTLW6FF5j/VfHa+jhirPfvaz9ZWvfGXZ+770pS/p2c9+dkBHhG5n1n9NDNY3HX/qvnH9p2fslSR94l/P+HZcCAeTVBnwKKkiye02eOQiQ5VuVimqH2j4cw9uZv1Xt7jX7VPZXPNjI5GIbto9JqnxFWD3u30qaw9VjmwbUjIe1UK2qNNT9V8pdWLS9KmsXv0l2fvGk85Jh7k0K8AAAEDn2HD9l1NcnyOpAj/NOEOVelZ/Sd2z/sskVaLxxld01dupEoakCuu/Ol6gQ5XFxUU9+OCDevDBByVJJ0+e1IMPPqgzZ+yT0W9/+9v1+te/3v34/+v/+r904sQJ/eZv/qZ+9KMf6U/+5E/0qU99Sm9961uDOHx0OcuyNLlYu6h+pWcd3CRJurqQq/GR6HSVTpXVT7SbZdZ/PXpxgXU5XapctnRxrvmkykFnzdLkYo4T1R1sNp3XQ2dnJdUuqTfMCrCHGiirn8sU9ISTajq6oqTeSMSium673bXSSFm9SUuZ9NRa6FUBAACdaCFnkiqJVX/WF3fWf5FUgZ/ckvr99X18t6yTKjnn0hpd/SXVXv8VyqQKQ5VOFehQ5Xvf+56OHj2qo0ePSpJuv/12HT16VHfccYck6eLFi+6ARZIOHDigz33uc/rSl76km2++WXfddZf+/M//XLfeemsgx4/utpQvKVe0rzypp1PFMAMYyuq7X9aH9V+HtgwpGYtqMVfU2ZkOfzKENV1dzKlQshSNSNtHGh+qDKcS2jZiP8E8PklUuFN984lJlS3pmm1D2jFaX7dOM0mVB53Bzb5NA9o0tP4LkxuaKKs/PumU1G9eO6kiVfWqZBmqAACAzmHWfw2tsf7LLaonqQI/TTeZVOn0dVIl53VDoyX1Uu31X6FKqtQYACH0vLu8ugkvfOELN9zdfffdd6/5OQ888ICPRwXYTEn9QDKmgQaSCOPOXvmZNEOVbpf2Yf1XIhbVNduH9MPz83rkwrz2bVr/CnB0JrP6a/tIqmaPxnoObRnS5fmcjl9ZXHelE8LN9Km8oM6UilRJqjxxZVFLuaIG11hHsZIpqa/1c2LK6v1KqsyTVAEAAB1kMWc/dxle4/lWyrmozlyECfhipqpTpR61UhqdouhRUsWyVnfRhCqpYtZ/dfgQrId1VKcK0E6TTp9KIymV6o+fSRdY39TlTFF9ysOkilQpq3+UXpWuVCmpry+dsBbTYUGvSmeyLKuqT6X+ocrWkZS2j6RUtupPlFRK6sc2/LjqpEo9ZfXlsqWTDSRVWP8FAAA6yWJug04Viurht3K5av1Xo0mVDh+qmKL6VpIqsqRidvWfhyqpwvqvTsdQBVjHlNun0th0fGzAPoFUKlucROpyfhTVS5WhCmX13en8jFNSP97KUMV+AnbiKle1dKLHLi/o8nxOqURUT98/0dDn3uSkVR6uo1elXLbc9V9HayRVrtk2rGQsqvlsUWema78QOz+bUa5YVjIW1e4NfpYZqgAAgE40z/ovBGnxsj0UiMSksb31fY5bVN/hJ+lbSqpUvS5ZawVYqJIqDFU6HUMVYB1TTifK5gaTKn3xmBsRnmYFWNcqlsrKl+wn0V52qkjS9Tvtk6aPXGCo0o08SapsNUkVhiqd6N7H7ZTKsw5uajjpdvOeMUnSQ3X0qhy/uqiFbFH9iZie5BTRrycZj+pJO+yP+eH52o895mdv/+aBDdfYMVQBAACdyHSqrFVUX1n/RVIFPjGrv0Z3S7HVP4NrcovqO/wkvSmqjzcxVIklpKjz97XWGrQwJVUSZgiWtpNJ6DgMVYB1NJtUkaRxyuq7nln9JUn9HidVzInNC3NZzfAz1HVMp8ouD9Z/nZ5Kq1DiCVin+frjjfepGI0kVczqr5t2j9bV33NDA70qJ67WXv0lSSPO1Z0MVQAAQCfZcP1Xwqz/4nk4fDLdYJ+KVCk+LxelYgefRzDHXu8waSW3AL5DkipS5/fg9CiGKsA6mu1UkaQJhipdz6z+ikQq8W+vjKQS2jthPxGgV6X7nJ+1d7u2MlTZPpJSfyKmYtmqa1UTwiOdL+q7J+1hRyN9KsZNu8YkSWem0zWHrvefnpUk3bJv49Vfxg07K70qtZikykYl9ZI04hbVF+s6BgAAgDCoJFXWWv9lX1SXLZBUgU9MUmWizj4VqZJ8kDp7BViphfVf0saJnVAlVfolRezbnZ4u6lEMVYB1mPVfm4YafyDfxFCl65mkykAipkgk4vn906vSvc7P2EOQVjpVotGIDjq9KsevsAKsk3z7xJTypbJ2j/fr4OaNBxJrGR1IaP8m+4XCwzWGH5WS+vqGKjdWJVVqldXXm1Rh/RcAAOhE9RXVk1SBT9ykSgNDlXiysvqqk8vqS87rhmaK6qVKr0rYkyqRiJR0XkvleU3fiRiqAOsw678a7VSRWP/VC9JOUsXr1V/G9TudoQq9Kl1lIVtwSy93jKZaui+zAuz4Va5q6ST3Pj4pyU6pNDuQvWn3mCTpYaeEfi1zmYKOOQO3o3vH6rrfa7YPKRGLaC5T0LmZNV6EVKkkVRiqAACA7rOQtZ+7rFVU73aqUFQPv8ycst82klSRKquvOjn50EpRvVRJqqxcqVXMV94XhqSKVFkBxvqvjsRQBVjHlFn/1USnCkmV7meSKr4NVUiqdKWLc/bqr5FUfM3Sy0ZUhipc1dJJWulTMeopq3/IGbjsnRjQ5joTl33xmK51Cu036lVZyBZ0ZcF+sWMSU+sZddd/MVQBAACdwbIsN6kyvEFSJUtRPfwy00SnilRVft7BQ5VWiuql9ZMqJqWiiNQ32tx9e60bhmA9jKEKsI6pJaeonqRK1/qjrx7Tf/jIv2gp1/iuf9OpMpBY/STbCyap8sSVRXb1dpHzztX/u8YHWr4v02XBUKVznJlK6+TkkuLRiJ5zaFPT93OzU1b/0Ln113RVVn+NNXTfN9ZRVm9Wf20Z7tNIjeHg6ABJFQAA0FnS+ZLKzlOstS6EMp0qJFXgi+y8lJ6ybzey/kuqJB86ef2XW1Tf7PqvdYrqTZ9KakSKhuR0uPv94jV9JwrJTxEQLqWy5Q5EKKrvXh//1ml999SM/vXkdMOfa4YqKZ+SKjtGUxrtT6hYtvQEnRld4/ysM1QZa231l1SVVLmyWLP/AuHw9WN2SuWWfeMtJZWevHNUsWhEVxdyujSfXfNj7j8z636tRtywq3ZZvbv6q0ZKRZI7dJnLFPg5BQAAHcGkVGLRiFKJ1afNzPtyJFXgB5NSGdhkDwAakVxn9VUnaTmpss7fQZj6VAy3U4WkSidiqAKsYTadd69MmRhoYqgywFAl7Aqlsq46vTlnZxp/wpGuKqr3QyQSYQVYF6oMVZovqTcObB5UJCLNZ4ua4rGmI9zrweovyV47eMTpMnno7OrhR7ls6cEGS+qNG6uGKusNQdyS+i0b96lIlfVfxbLldlEBAACE2UK2UlK/Vgeem1ShqB5+MH0qjaZUpMr6r05OPrhJlSYvQnPXf604z2OSKmHpU5G6I1nUwxiqAGswJyjHBxKKxxr/32RiiKFK2F1dyMmcLzw73fgvsEzefqLtV6eKRFl9N7rgDFV2ejBUSSVi2j1u389x0kyhly+W9S9POCX1R1obqkjSzaasfo1elROTi5rPFpVKRN2OlHpdu31Y8WhEM+mCOwRcqZJUqT1UGUjGFI/aJyPms6wAAwAA4WeSKkNr9KlIUp+TVMkWSiRx4b1pJ6nSaEm9VNXR0cEn6Us+FdWHMalijrWTh2A9jKEKsIbJRdOn0tyDOEX14WcKwyXpTFNDFX+L6iXK6ruRl0MVqbqsnrhw2N1/ZkZL+ZI2DSb15J0NxvjXcNMeO1Hy8LnVSZX7T8/aH7N7TIkGLwzoi8d0zTZ7ELPeCrBG1n9FIhE3rUKvCgAA6AQLzoUgw6m1hyopJ6lStuw0LuCpZkvqpUryoaPXfznn0bwuqnc7VUJSUi+x/qvDMVQB1jC16PSpDDZXjGWK6jOFknvyHeFyqWqocnZ67auxN2LWf/X7tP5LqiRVHr0wzxVQXaJSVO/NUOXgZjNU4cqWsPu6s/rr+Uc2KxpdvUaiUdVJlZWPD/c3ufrL2KisvlS2dGrSfpFWT1JFqqwAm0szVAEAAOG36Kz/Wm+o0lfVs8IKMHjOJFVaWv/VwSfpWy6qX2eoYpIqoVz/1cHfrx7GUAVYw5STVNncZFJluC+uRMw+aTadJq0SRhfnKr9gz06nGx5aZJ1h2YCPSZVDW4aUjEW1kCvq3Ezjgx+ES7FUdkvFvehUkaRDW+0nYQxVwu/xSwuSpKftn/Dk/q7dPqxkPKr5bFGnppZfifaAKanfO9bUfd+w2wxVVqfkzs2klS+V1ReP1p24GiGpAgAAOshCjfVfyaokcLbARZTw2IwX6786+CR9q0X166V13KTKWHP364duSBb1MIYqwBpMp8qmoeYm45FIROOmrH6RoUoYVSdVFnLFhk/2mcJlP5MqyXhUR7bZV4L/G70qHe/SfFZlS0rEItrS5MB2pQOb7Sdhp6d4EhZ2M86AfXOTv1dWSsSi7orA6l6V+WxBj1+xBzhHW0yqrFVWb0rqD2weVKzOxA1DFQAA0ElMUmUotXZRdjQacQcrJFXgqVJBmjtn324qqbJOn0gn8SqpsrJXJtRJFS6S7EQMVYA1TLrrv5o/8TlhelVIqoTSxfnssn9vtFclU/C/U0WiV6WbXJi1f+Z2jPZ7sv5Jkjucob8p/GadgcLYgDdDFUm62UmUPHS2sqbrobOzsixpz0S/tgw39zvsSU5Z/fRSXhfmlj9WNlJSb9CpAgAAOkmtonqpsgIsR1IFXpo7K1llKZ6ShrY1/vnd0NHRalJlvcFSmJMqnfz96mEMVYA1TLlF9c2f/HKHKks5T44J3rq04kRho70qmTas/5IqvSqPkFTpeJWS+pRn92lO0M9lCiqWuEouzGadPpFxD4cqN1X1qhimpL7ZPhVJSiViOrJOWX0jJfXGaL99QmLeueoTAAAgzGoV1UtSn1NWT1IFnlq8Yr8d3i5Fmzhlm+yGpIpzDs3zThXndU0okyoMVToRQxVgDWb9VytrWipDFa7MDSMzVNm/yX7S0XRSxcf1X1IlqfIoSZWOd94ZquwaG/DsPscGKisJSAGEV7lsadZJLY4PrL1Gohk373HWdF2Yc4dqD5xtraTeuHGX/dizeqhiP+E/2ERSZZ6fUQAA0AFMUmV4o6RK3D6dRqcKPGWGKoNbmvv8RDd0qvhcVB+qpEoXJIt6GEMVYA2VpErz6782kVQJrXLZ0mVn/dfTndLoszONDVXcTpXk+k+0vXCdk1Q5P5vRXJoTkp2sMlTxLqmSiEXdK+hmWDUYWgvZospONcmoh0OVg5uHNNQXV7ZQ1rEriyqXraqS+laHKqasfvlQ5QTrvwAAQJdbcDtV1n+tl0rQqQIfLF213w5ube7zuyH5UGx1/VeNovowJVW6YQjWwxiqAGuYcjtVmk+qjJNUCa3JpZyKZUvRiPTUffaJx7MhTaqMpBLaM2FfaUGvSmc7P+MMVcb7Pb1fk4qbYegWWmbgNZCMuasivBCNRtzhx0NnZ3VicklzmYJSiaietGO4pft+8hpl9XPpgts5drCh9V8MVQAAQOeoq1OF9V/wgztU2dzc5yfXGSh0kpLzmqEnkipdMATrYQxVgBWyhZIWnCdRJFW6k1n9tXU4pf2b7V9iDQ9V2tSpIlFW3y0qnSreDlVMr8oMZfWhNeOu/vKuT8W4yVkB9tC5Od1/xl79ddOuMSVirT3Fu37HiGLRiCYX87rkJPuOT9ople0jKQ1ucJJhpZEUQxUAANA5Fp2kyoadKgnWf8EHZqgy1GRSxU0+dPJQxaui+qpBRakg5e3XMupvLdHvKdZ/dTSGKsAK086JyUQsopENnkTVUkmqcKIzbC46Q5XtoyntnbB/4Z6fzahk9vPUIZ23n2infE6qSNL1O+yTppTVdy7Lsnwbqkw466RY/xVepqR+zMPVX8bNVWX1DzhDlaP7xlq+31QipiNb7Sf5PzhnrwA7fsVZ/bW1/pSKRFIFAAB0Fnf9V9/6z91MpwpJFXiq1U4VN/mw6M3xBMEtqm92qLJGUiVbtdI4Ndrc/frBTRYxVOlEDFWAFSqrv/oUiUSavp8JhiqhZZIqO0ZT2jaSUiIWUaFkuVdj1yNbsJ88tyOpcp2zxoekSueayxS05KSbdnk8VDHpB9Z/hddsxsekym77RcFjlxb07RPTklrvUzFuqFoBJkknJp2S+s3196lI0ghF9QAAoIO4RfUbdqo4679IqsBLS5P221aL6jt6/ZdzDi3u4fov06fSNyJF/T+HU7cknSqdjKEKsMLkkimpb+3kF0OV8KpOqsSiEe0et3+RnZmq/4mHSar0t2P9l1NW/8SVBeW5EqojmZL6TYNJz9NNrP8Kv5kl/5Iqu8b6tWkwqWLZ0kln6HF075gn9236Wn7opOTcpEoDfSoSSRUAANBZFrL2c5aNiupJqsAXS14lVTp4qOImVZodqlQNlpxuyFD2qUiV9V/FrFQqBnssaBhDFWAFN6nSQp+KVBmqzGYKDa2Vgv8uzdknuHeMpiRJu53i8LMz9T/xaFdRvWSfNB1JxVUoWTp2ZcH3rwfv+VVSL0kTg6z/CrtZ53vjx1AlEom4aRXJfjzbOpzy5L5NUuUHK5Iqh7Y2llQZdf67c8Uye8cBAECoWZZVSarUUVTPcxt4yi2qb3GoUliqDBQ6jUmqNDtUMekPq1y5L5NU6Q/R6i+p8v2SWAHWgRiqACtMLdpT8c2DrSVVzJoXy6qcUEM4mKTKthH7xKPpVam3rL5cttz1X+1IqkQiETetQq9KZ3L7VEa9H6qMsf4r9Mz3xo/1X5J0k9OrInm3+kuyy+qjEenqQk7nZzM6PeWs/9rS2FBlKBlX1NmmyQowAAAQZplCSeaayI2SKqkESZWukV+Sjn9VKgf8vSzmK90frRbVW2U7/dCJih4V1UuVNWhhTarEklLUeZxhBVjHYagCrDC1ZJIqrZ38SsSibtE9V5CHi+lO2eGc4N7T4FAlW6xcjdSOThWpqqyeXpWOdMEZ5PmTVGH9V9jNuEkVf4YqN++pXHF1i0ervyR7aHzYSaV8/gcXVShZ6k/EtGOksSRMNBrRcIoVYAAAIPxMSX0sGtlwK4FJqjBU6XCWJX3y/yf95Sulxz4X7LGYlEok1vzJ/+rkQ6euACs5rxeaLaqPJaoGFc7fQWbGfts/1tKheS4SkRJdsLKtRzFUAVaYXDSdKq2t/6q+D7NSDMGzLGtZUb1USaqcqXOoks5XhiqpeJuGKiRVfJUr+hvbN+u/dnpcUi9VVkoxvA2vWTep4v36L2lFUmWfd0kVqbIC7DMPnpckHdg8qKiJnTSAXhUAANAJzFBlqC+uSGT95zxupwrrvzrbsXukE1+zb199LNBDWbb6K9rk6dpoTIo7F0B16jqpkkmqtHBBmtur4pTVhzWpIlX14CwGexxoGEMVYAVTLL+pxfVfUuUEGic7w2M2XXCvJto6Yg+99jhF9WedE9+1ZJyhSioRberkYjOu32EPVR69OC+rU3ejhtTffOeMnnzHF/WVRy/79jVMUf2uMW+6LqqNs/4r9GYz9u8Av9Z/bR7q0xufs1+33bxTT97p7Z5gt6z+vD3QbbRPxTBDlfksP6cAACC8TJ/K0AZ9KpKUSpBU6XilonTPOyr/np4K7lik1vtUDDNQ6MTkg2VVFdW3cKFzwrmY0az/cjtVxpq/T7+4Q5UOHYL1sI1/SwA9yKRKNnuQVJkYdJIqrOUJDdOnsnko6Ua2TVLl6kJOmXypZk+KKakfSLbvIfTw1iElYhHNZ4s6P5vR7vGB2p+Eunzl0csqli3982NX9OPXbfPla1SGKt5/38z6r9l0XuWy1bZBH+o3s2QPEvwoqjfe9VNP9uV+zVDFOLRlcJ2P3BhJFQAA0AkWnaTK8AZ9KlJVUsXnxDt8dP//lCar0ilLk8Edi1QZqgy1OFRJDkqZ6c48SV8uSnIuIm0pqWKGKp2UVOnA71ePI6kCrDDlrv9q/YriiUH7JNI0679C49K8/Ut1+2glMTA6kHCfNJ+dqX01h1n/tdGOXa8l41Ed2TosiRVgXjsxaT95eeKKP3HbXLGkqwv248pOH5Iq5kR92aqsK0C4zKb9Tar46fqdI6qe0zVaUm+4QxUSVQAAIMQWc/ZzlVpJlT6nqD5bIKnSkbLz0tc+aN/e9TT7rRlqBGXxiv3Wq6RKJ67/MikVyS5xb5bpKemkpEonfr96HEMVoIplWZp0i+q9S6pMs/4rNExSZfvI8m6LvQ2U1Zv1X7USLV5ze1Uoq/dMvlh2u3SeuOLPk5iLs/bPXCoRdVMlXuqLxzTo/CzyWBM++WJZS85jhp9JFb8MJOM6VDVIaTapMuImVRj8AQCA8Jo3nSo1kypm/RdJlY5034ftIcrEIen5v2a/Lx2SpEqrQ5VkBxefl6pez3q5/is7Z78lqQIPMVQBqizmiso7O1G96FQx9zHN+q/QWFlSb5helXrK6jMF+4l2O5MqUqVXhaSKd85Mp1Uq2/HiycWcL1fRX5itlNRvVHbZijG3V4XHmrAxKZVoRBpJdd5QRVq+AuzA5maHKvaJCdZ/AQCAen324Qt6xvu/rO+emm7b16ys/9r4eVsqYYrqSap0nLlz0rf+2L79kvdIw9vt20td0qnSyckHk1SJRKVYC+vWV67/6oSkCkOVjsNQBahi+lSG+uJu8VwrxhmqhI6bVFkxVNm7ySRVapfVZ/L2E2eSKp3vxNXlK7+euLrg+deo9Kn01/jI5o07qwZneKwJnRlnUDfan+jYvpsbnKHKrrH+pruk6FQBAACN+uqjV3RlIad7/u1S275mvUX1laQKQ5WO89X3ScWstO+50pNeIQ1utt+fnrSL0oPidqpsbe1+3KL6DjxJb5IqraRUpKoVaCapMmu/TY23dr9+cIcq/qwjh38YqgBVppbsqbhXK3pIqoTPJXf918qkin3Cu56kSjofTFLlOiepcm4mw4lJjxy/uvyJph+9Km0ZqrhJFX4uwmamg/tUjBdft03DqbhefsP2pu/DDFXms/yMAgCA+iw5r7tOTbVvjZEZqtRbVJ8tsP6ro1x4UHroE/btl75PikSkAWeoUspLOe8vsqubZ0kVM1Tp4PVfrZTUSx2WVHFWLXfi96vHtZClArrP5KLpU/Hm5JdJqnD1eHhcml9n/ZfTqXKujqJ688R5oM1JldH+hHaN9ev8bEaPXpzXsw5uauvX70YmqRKLRlQqW74MVarXf/nFnLCfZf1X6Mw6g65O7FMx9m4a0A/edWtL90FSBQAANCrt9NKdaeNQZSFbX1LFbLYgqdJBLEu657/bt298jbTrFvt2csBONhTSdlolNRLM8S2aocrm1u6nG9Z/tZpUSVYV1ZeKUt4ZloWxU6WTk0U9jqQKUMWs/9o02HpJvX0/9onOqaW8rCBjpHBdWmf9lxmqnJlO1/xepQMqqpeqVoDRq+KJE5P2E5dnHpiQJB3r0KTKBKm40JrtgqSKF9ykCkMVAABQJ/O66/T0ksrl9ryeXnBStbXXfzmdKhTVd47HvyCd+oZ9wv7H37H8z0xaJahelXLZHuhI0mCr6786uajeGarEW13/VZVUMSX1kpQaXfvjg8T6r47FUAWoMrVoP4Bv9jipkiuW3SeECM5CtuDGuVcOVXaN9SsSsZ+41zoxnXGSKu1e/yVVldXTq+IJk1R56fXbJPmz/uvCrD3I8zOpYlIQrP8KH7dTpYOTKl4gqQIAABplXkNnC2VdWci15WvWvf4rYdZ/kVTpCKWCdI8zSHnWL0pje5f/+aCzBcIMNtotOyuVi86xtJpU6eDkQ9F0qni0/iu/VOlTSQ5LsRAubHLXf3Xg96vHMVQBqkwtebv+azAZU9K5goUryINnUiqj/YlVZcupREzbhu1BS61elUw+mPVfUiWp8ihDlZbNLOXdE94vebLdFXF+NuN+f72QK5Z01vl52rtpwLP7XWmCVYOhRVLFNpJiqAIAABpjuiwl6fRUe044Lmbr7VQx67+4eLIj3P8/palj0sAm6fm3r/5zN6kS0FDF9KmkRj1IaXTw+i+TVGl5qGKK6jPh7lORlq8qQ0dhqAJUmXSSKl6t/4pEIpTVh8jFubX7VIy9zgqwszOZDe/HXf8VYFLl2OVF5dnf25ITk3YqZedoSrvG+jUxmJRlScevepdWeeLKooplSyOpuHau83PnhTG3qJ7HmbCpFNWTVJHsx89CiccuAABQW/W2h9Nt6lUxSZWhvo2fu6USZv0Xz2tCLzsv/fMH7dsvfPvaK6BMOiSopMriFec4Wiypl6rWSXXgSfqiD0X12Rn7dhj7VKTOThb1OIYqQJUpj4vqpcrVydOc7Azcen0qhulVOVsrqWLWfyXbHx3dPd6v4VRc+VLZ05P/vej4FftJy8Etdtz2sPPWy7/XRy/ahXjX7RhRJBLx7H5XMifsZ1n/FTozblF9jydV+isnJuhVAQAA9UjnKkmVU21KqrhF9fUmVVj/FX7f/H17WLLpiPTUN679MQPO+q+gkyqt9qlIlZP0nZh8KJn1X62mdar+DkKfVDHrvzi/02kYqgBVppZMp4o3SRWpMqCZXmSoErRaSZU9E/bVDDWHKm5Spf0PoZFIpNKrQll9S447SZVDW+wreQ5ttZ/MeNmrYta0Xed8z/zC8Da85pyhSq+v/4pFIxp2Cl9ZAQYAAGqxLEvpQvuTKo0W1WeLJVmW5ftxoUmzZ6Vv/4l9+yXvkWLrJJDcpEpARfXuUKXFPhWpqqi+A0/Se1ZUX7X+y3SqhLGkXqpKFpFU6TQMVYAqfiZVWMsTvEvz9lqvbSMbr/+q2alSMJ0qwZScmV4Vyupbc+LqiqSKj0OV6/0eqjhrBmfTeV7UhQzrvypGKKsHAAB1yhbKqn5ae3ra/xOOlmU1UFQfcz5HKpR4/h1aX32vVMxK+54nXfvy9T8uLJ0qQx4mVTp5/ZdXRfUdkVTp4HVtPY6hCuAolS33Km+vOlWkSoH0FJ0qgaudVDGdKhv/MjOFiakAiuolkVTxyAlnzddBJ6lihirHPBqqWJbVtqTKhDO8LZQqLwQRDmb91yhDFbdXhaEKAACopbqkXpJOT6Z9v3goUyip7HyJ2kX1ldNplNWH1IUHpIf/1r596/ukjdYxd2OnSkeu//I6qZKuSqqMtXaffunkZFGPY6gCOGbSeVmW/XvWyyuK3aJ61n8FrtKp0r/mn5ukyoXZrIobFClnnL25AwEU1UvLkyqkEppTLJXdRNLKpMqpySVPirQvz+c0ky4oFo3oyLahlu9vI/3JmPvCjl6V8LAsS7NuUqW3139JDFUAAED9TEl9ImafCF/IFTXt84WKi06fSjQi9dd4rVc9VMnSqxI+liV98b/bt296rbTz6MYfb4YZS0Gt/5pcfhytSHTwOinPkyqZDkqqdOD3q8cxVAEcZvXX+EBS8Zh3/2uYtTx0HQTv0vzGSZUtQ31KxqMqlS031bKWjHPV1EBASZUjW4eViEU0lynowgbHifWdncmoULKUSkS1w1kHt3M0pYFkTMWy5cnOZpNSObh5UKk2DODcXhVScaGxmCuq6FzuyFBFGum3r/ikqB4AANRihiojqYT7+u10jTXNrVpwEt9DfXFFNko1yO66TDqDFZIqIfTY56XT35TiKenfvaP2x5ui+qCSKm6nihdJFbP+qwNP0pukSstDlQ5KqpihSrlQGSqhIzBUARxTi/aDt0mWeMVNqnCiM1CZfMm9gn/7OkOVaDSiPeP2FQ0b9aqYTpWg1n8l41Ed3josiRVgzTrurPg6sHlI0aj9gikSiXjaq/JIm1Z/GWaAS39TeJjHnL54VP0BPV6ECUkVAABQL7P+qz8Z075N9gnS01P+niReyJo+lfo2V6TcoQpJlVApFaQvOYOUZ/3f0tie2p9j1n8V0sF0Wyx5uP6reqDQaYpm/VeL5+WSVUX1blJlvLX79IsZqkhSoQMHYT2MoQrgmFzyvqReqjrRyVAlUCalMpiMabhv/f24bq/KRkOVvCmqD+4kKb0qrTkxaQ9NDm0ZXPb+w84qsONXWx+qtKtPxTBrC1n/FR4zrP5axgxV5rP0/gAAgI2ZpMpgMq59E/Zz9lOT/p4kNuu/hjZ4vVjNlNXnWP8VLg/+jTT1hF0+/7y31vc5ySEp5vR4BJFWMeu/PCmqd1ZPF9JSucN+Nktm/ZdXnSqZ8CdVYolKMqcT00U9jKEK4HCTKkPeldRLlaQKRfXBujiXkWSnVDaKcptelQ2TKs4T/Fp7dv107XYnUeHByf9edOKq/WTF9KkYhzxMqlSGKsMt31c9xknFhY4ZcI1RUi+pKqnC4A8AANRghir9yZj2ba79Gs0Lizn7OUqtknrD9KpkWf8VLv/2f+y3z3mzlKrzArdIpJJWWWrzUCWfrpSUm2NohUlpSFIx0/r9NeL0v0hfea+dFmqGGaq0XFTvdKrkl6TMnH07rJ0qEr0qHYqhCuAwnSqbPV7/ZU50zmUKG5afw1+mpH7HOiX1xp5xJ6kys/aTD8uylC5UnuAHZd8m+5fuGZ8j8N3KDFVWJVU8GqpkCyWdnLS/xvVtT6owVAkLkirLsf4LAADUK13VY7nfee1zqk3rv4bqHKqkSKqET25BOvVN+/aTbmvsc91elTaX1Zs+lVif1OfBa8d41TmPdp+kv+e/S9+4UzrxteY+3+uieqtU+fsNa1JFqqSL8lw020kYqgCOqSV/kirjA0mZYMQMV+cGxhTPbxtZu0/F2FMjqZIrlmXZvdOBJlVMosbvssZuZdZ/Hdy8PKlSPVQpOwXjzXjs0oLKlp1U2zLs7WPKeiZMUT1DldAgqbLcCEMVAABQp7S7cjle1anid1KlwfVfFNWHz/Gv2oXfE4ekzYcb+9ygkirVJfUbbNWoWzRaWX/V7qHK3Hn77eKV5j7fFNW3nFRZI63TEUkVzu90EoYqgGNy0Z9OlVg0ojHnRBJreYJTSarUGqrYVzScW2dYYVZ/SeEYqsymC5ygbNBcuuD+/35gRVJl38SAErGIMoWSLsw1H5Wu7lPZaN2cl8YGTFE9Pw9hYZIqYyRVJDFUAQAA9VvKVZIqJqU/vZTXfNa/5xGVovoG13+RVAmPx79ov7325Y1/7oAzVGl3p4oZqgx5UFJvmJP07SyrL5cr/y2Z6ebuwxTVt5pUiSWlyIpT3qnR1u7TT0ENwdAShiqAw+1UGfT+qnK6DoJniuq31xyq2L/Mppby7hP5amb1VzIWVTwW3EPoYF9cm51U1Rmfr9jqNsedlMr2kdSqq9Disai7XqCVFWDt7lORpPFB1n+FjUmqjJNUkcT6LwAAUD9zMdtgX0xDfXFtdi5+9PO1T6NJFXf9F0mVcCiXK0OVa25t/PODSqqYVMegh0MV9yR9G88VZGbsdVvmdjNKHq3/ikSkRNUFlMkhuxA+rNykCuu/OglDFcBhiuQ3e5xUkSpl9QxVglNvUmUklXBX9ZydWf0EJJMPvk/FcGPw01zN0IhKSf3gmn9+ZFvrvSqPXlyQZCdV2sX0dkwvccI6LOhUWc4MVfy8whQAAHSHJfO6K2EPOPa1oVelklSp7+RrZf0XSZVQOP99O2XSNyrtfXbjn+92qgS1/murd/cZxEn6xcuV2+kWkyqtrv+SKr0qUrj7VKSqThXO7XQShiqAY8pd/+VDUoWug8CZTpVaSRWpslprraug3KFKgKu/jH0T7dkt3G1OXHX6VNYZqhzeYj+hOX61uSeglmXp0UuV9V/tYh5nSKqEB50qy5mhykK2qFILnUUAAKD7ZZyi+sE++3VXO177NN6pYorqSaqEwuNfsN8e/vHmUgluUqXdRfWTy7++F0xSpZ3rv5aqelSCTqpIy4cqYe5TkYJZ14aWMVQBJGULJfcJlNedKtX3Ob3Iyc4g5ItlTTrr3XaM9tf4aGnPuP0E5OzM6k6NTMEUJgY/VNm7af3hD9bnJlVWlNQbh7a2llQ5N5PRQraoRCyiQ1vW/hp+mCARFzqzJFWWMUMVSVogrQIAADaQXrEhwCRVTvuYVFl0np8M1dupkiCpEiru6q+XNff5plPFJEfaxQwjhvxIqrTxXEF1OX2znSpmqOJJUqWqrD70SRWzro31X52EoQqgyuqvZCyq4TqvSmnEuFsgzcnOIFx2+lSS8Whd3QamV+XsGmX1aeeKKdZ/da4TkzWSKs5Q5diVRVlW41fTmz6Vw1uHlYy379esSUPkimU3UYVgzZBUWSYRi7oDaXpVAADARsxQZTBpvz7fv9l+7XPKxwvK3PVf9XaqmKQKQ5XgzZ6VLv/ALic/8pLm7mMw4KJ6LztV3ORDG88VLHqQVPGqqF7qsKQK6786EUMVQFUl9UNJRSIRz+/fXEE+xRXkgTAl9TtGU3V9f/dM2L981xqqZAvhWf+1d8J+okRSpX6lsqVTk/bf13opkkNbhhSJ2Kubmvl/ttKn0r6SesleUxCP2j/fDHDDwXwfxkiquEZSlNUDAIDaVl7Mttdd/+VjUsWs/2o0qcL6r+Adc1Iqe54pDUw0dx8DAa3/WjRDFR/Wf7XzJH31+q90i+u/PE+qjLZ+f35yk0UMVToJQxVA1X0q/pz4ctd/LeV8uX9szPSpbBup3aciVXWqrJlUCV9R/cX5rHJFnsjX49xMWvlSWX3xqHaOrb0KLpWIafe4/WfNrAAzSZXr29inIkmRSETjrAALjWKp7F7tWE9CrleYFWAMVQAEYSlX1B999ZivJ2UBeGNpZVLFWf91eT7nWyq72aL6LEmV4D3m9Klcc2vz9zHoFNXnFyqJiXbwpajeDFWCWv/ValLFg6FKspPWfwWwrg0tY6gCSG7fxqZB70vqpaqi+iVOIgXh0pzdjbKjjpJ6qbpTJb1q/VM6REX1mwaTGkzGZFnS2enV/S9YzfSpHNg8qFh0/dSSKatvaqgSQEm9YU7em4J0BGe2amhQ3SXS68zfxXymGPCRAOhFH//Wad15z+P6o68+EfShAKjBDE7M6tCxgYRGnATJWhe/eaHRovpUgqL6UMgvSSfvtW9f8/Lm7yc1JkWd7/1Sm1aAlYpS2knGeLr+y9nKENT6r8JSc4Mpt6jeg9dPHbn+i06VTsJQBVBlLZdvSRVnWENSJRiX5uy/9+11DlV2jvUrGpGyhbKuLi7/nmVDVFQfiUS017li6wy9KnU5fnXjPhXjcJNl9Yu5ok4769iCGao4A1zWfwXOlNSPpOKKx3i6ZYyQVAEQoH85bp8k4zEICL+lFeu/IpGI9m+2n8Of8iFtZlmWO1QZrnf9V5yi+lA48XWplJPG9klbrm3+fiIRacBJq7SrVyUzLcmSVPW1vZAIOKkiNZdWMYOYXiuqD2JdG1rGq3xAlU6VzUM+JVUG7ZNIM0uFpoqv0ZpL805Spc71X8l4VDtGTa/K8gRImNZ/SdI+d7cwMdF6nJi0n6Qc3Lx2n4pxZKvdh2KGMPV6zEmpbBvpc7uU2skMVWYZqgTOpIXGA/g5CDPWfwEISqFU1vdP2yd4WNUDhF9mxfovqWpNsw+vfTKFkkpl+7V6vUmVPqeoPktSJViPf95+e83L7MFIK9xelTYNVcwgYmBCitX3c1eXZMCdKpKUnm78PtykihdDlU5KqtCp0okYqgCq6lTx6eSXSarkS2X36he0j+lU2T66dofGWtYrq8+4RfUePuFpgelV8SsC321O1JlUOdRkUuURt6S+/SkVqXICf4ZVg4GbcYYqlNQvx1AFQFB+cH7OvTiGVT1A+C3llidVpEqvih9JlUWnTyUaqX8rgVtUz6A2OOWy9Pg99u1rX9b6/ZlelXSbyur96FORpITzerdd67/KpcogKmlfoNhUUsUtqvfgNVQnJVWCWNeGljFUASRNuuu//Emq9CdjSjlPuDjZ2X6XnKFKvZ0qUlWvysqhiptUCcfD595N/l2t1Y1Mp8rBLRsnVcz6r4tzWS1k6/9/1pTUBzZUcTpVZkiqBM58D8boU1lmpN8eSDNUAdBu3z5ROUHGCVAg/MzFbIN9lQGHuaDMj5T+QlWfSqTOtEPKSarwmBKgSw9Ji5fsk9L7ntv6/bU7qeIOVTZ7e7/tLj5PT0uWc8HC5sP220wTSRUvi+qrhyokVeCDps4KHj9+XL/8y7+sF7/4xXrxi1+st7zlLTp+/LjXxwa0jVn/5VenilRJq0zRq9JWxVJZVxbsv/NGhiputHydocpAMiRJlQn7l+9pkio1LWQL7s9CraTKaH9CW4bt/2ePX63/iU3wQxUnqcJQJXBmBZsZdMFWKapnqAKgvb5zonJyhxOgQLjli2UVSvYqroGqDQH7NpnXPv4lVYZT9T93qyRVSL8F5rEv2G8P/TtvejjMcKNdnSpmqDLkcVLFrP8qtOk8gVn91T9RSd0EnlSp2lQS+qQKnSqdqOGhyhe/+EVdf/31+td//VfddNNNuummm/Sd73xHT37yk/WlL33Jj2MEfGfWf20e9CepIsntV+BkZ3tNLuZVKluKRyMNJZH2OEOVszPLn4Sk3fVfIelUqVr/VS7T17MRk1LZMtynkTpeLB3e0tgKsHLZ0mOX7PVf1+8YbvIoW2PWf00v8TgTNNZ/rc0dqjSQAAOAVhVLZX3vVPVQhROgQJiZC9mkleu/7Nc+52cyyns8HF2sSqrUyxTVZwsMagPzuDNUucaD1V9SgEmVLd7er1n/lW9snXXTFi/bb4e22f0wUmtF9T2XVHE2aTBU6SgNX2r9tre9TW9961v1O7/zO6ve/1u/9Vt6yUte4tnBAe1gWZabHvEzqWJOdpoBDtrj4pxdNL91uE+xaP2lde5QZUVRfSZkRfU7RlOKRyPKF8u6vJDVjgZ6Y3rNiUmnT2XzxikV4/DWIX3rxFTdQ5XT02ml8yX1xaPuvud2M6kIU5KO4FSSKgxVqtGpAiAIP7wwr6Wqk7Q5ToACoZYu2AOORCyiZLxyLfCW4T71J2LKFEo6N5OuudK3EWbl71CqgaFKwqz/YlAbiPmL0sUHJUWkIy/15j7b3amy6NNQxU0+tCmpYv47hrZI/eP27UaL6sulygqxWK8lVaqGYJYl1bmCEMFqOKny6KOP6ud+7udWvf9nf/Zn9cgjj3hyUEA7zWeLbrR4wqeieknaxBXkgbjkltTXv/pLqhTVX5xbfhVUxnmCX295od/isah2jdvH6sdu4W5Sb5+KcbjBsnqz+uva7cOKx4Lp3BknERcaZrA1Psj6r2oMVQAEwfSpmOd3nAAFwm0pt/bK5Ugk4luvykK2+aQKg9qAHPui/Xb30+yT+V7olqSKOUnf7vVfQ9sqQ5VGkyrFqlX5XhbVJwa8uT8/me+XVV7+94BQa/isz5YtW/Tggw+uev+DDz6orVs93gEItIHpUxnuiyvl40onc7XyNCc72+rSvCmpbyzBsWWoT6lEVGVLujBbSauknasc/fxZaZTb/8JQZUNmqHKoRp+KccQZqhy/2thQ5brtwfSpSFWdKgxvA+cW1ZNUWYahCoAgmKHKC6+xX69yAhQIt0qP5erXXJWhirdrcsz6r+FGkipOUX2WQW0wHneGKtfc6t19tr1TxRlG+Lb+q03rpMz6r8GtVUOVBpMqpaphgifrv5xzQGFPqUjLV5WxAqxjNLz+6+d//uf1C7/wCzpx4oSe85znSJLuu+8+/e7v/q5uv/12zw8Q8NuUc/LRz9Vf1fc/zfqvtmo2qRKJRLRnfEDHrizq7Exa+52VURs9wQ/Kvk0D+sYxfwobu4kZjhxqMKlyempJuWLJfdG0nkpJfTB9KlJl/ddSvlTXMcM/Jqky1k9SpdpIVVF9uWwp2sBaRgBoht2nYl8t+2PXbNFffvs0RfVAyC3l198OYNbsnvL4grJKUT1JlY5QyEjH/9m+7VWfihRAUsX5On4V1bdtqLLG+q/MbGP3Uaq66CrmwWuoAWeV2/C21u/Lb9GYFO+Xihl7BZhZQ4dQa3io8o53vEPDw8O666679Pa3v12StHPnTr3rXe/SW97yFs8PEPCbSao0UmLeDPcKcpIqbXVxziRVGhuqSHYC5NiVRZ2Zrjxhz4SsqF6S9k3YLyxY/7W+ctnSyUmz/qu+pMqW4T4Np+JayBZ1cnJJT6qRQHn0ol1Sf92O4JIqI6mEohGpbNkn9beNhOfntNfM0KmyJpNUKVvSYr6okRRDJwD++rcL81rMFTWSiuvmPaOSpHypzGAXCLHKhWyrT1nt22Re+/iTVGlk/VfK7VRhqNJ2J79hn4Ae2S1tu8G7+zVJleysfZLfi5P767EsadEkVTZ7e98mqVLK2V0lUZ9fF65VVN9op0p1Sb0XnSJ7nim99P3S3me1fl/tkBx0hipcLNspGl7/FYlE9Na3vlXnzp3T3Nyc5ubmdO7cOf3Kr/yKIhTpoANNOsmRTT72qUiVvpYp1vK0VbNJFWntsvqwFdVL0l4nAl89/MFy52czyhXLSsai2j0+UPsTZP++q7dXZS5d0HlnTdyTAhyqRKMRd90UA9zgWJalGZNUGWBoUC2ViLmFs/OsAEMPsywr6EPoGd85aa/+esaBiWUnaDkJCoSXSaqs9ZrLXf/l8WufBXeoUv9zN5NUyRZY/9V2j3/BfnvNrd6WevePS3Lur9GhQKNyC5WVV351qkjtOUnvdsNsbb5TpeS8fo17dMFzNCo95812504naHcPDlrWUpPu8PCwhoeDW3MCeGHaXf/lb1LFrP+i66C9Ls7bJ7qbSapUhipVSZV8CJMqPpU1dpMTTkpl36YBxRq4KvXwlvqGKo9esld/7Rrrd6/ED4pZATbNY01gMoWS8s7JunGfB/adiF4V9LpMvqR/d9fX9cufeCDoQ+kJ3z5hnxR71sFN7glQibJ6IMxMj+XgBkOVs9NplcreDajdovpG1n8lnPVfxTLD8nayrKo+FQ9Xf0l2osOsjfK7V8UMIhKDy4cgXoj3SRHnd147TtKbxM3QVqnfSao02qniJlV69PWT+RnI19fpiuDV9dvi6NGjdadQ7r///pYOCGg3d/2Xzye+zAoYkirtUy5bujxnf3+3N1hUL1UK4M/OrF7/tVYUPSjmOOcyBc2lCxrlyvhVTjh9KvWu/jLqTapU+lSCS6kY9mPNktvpgfYzKZVELLLmyYBeN9qf0NWFHEMV9KzjVxd1cnJJZ6bT+tBrblYi1tJ1bthAqWzpuyftkzrPPLBJiVhUsWhEpbJFUgUIsXTOdKqsfs21Y7RfyVhU+VJZF2Yz7oVwrVrM2s9LGulUSVVdaJcvlekzbJfLP5Tmz9nl3gd+zPv7H9xsD1T87lVZquoh8VokYg9r8gv+J1XKpcoAamhrpXS9mLW7bxJ1nospMVSRxPqvDlLXM/if+Zmf0U//9E/rp3/6p3Xrrbfq+PHj6uvr0wtf+EK98IUvVCqV0vHjx3Xrrbf6fbyA5ybbVVTvDG0WskX3Cmb4azqdV75UViQibR1uPIm0Z8L+5W/WauWLZRWdq6HCtP5rIBnXFue/j7L6tZ24avpU6iupNxodqlwfYEm9YZIRrP8Kzqzzdz82kGQ16hpGq8rqgV5krsAula1laVh475EL81rIFTXcF9f1O+0LHyiWBsIv7V7Itvo1Vywa0e4Vr9O8YDpVhhvoVFmefuMxpW0ec1Z/HXyhlGh8I0VNpqy+XUkVr1d/Ge0qq09PSVZZUsT+u+sblqLO/0eNrFArmvVfDFXQGer6bfHOd77Tvf2mN71Jb3nLW/Te97531cecPXvW26MD2qBdRfWj/dUF0nltHfHhlz+WMX0qm4f6mroKdI/TvTGbLmg+W1B1ojtM678kad/EgK4u5HR6Kq2bdo8FfTihc9xJqhxqcqhyYnJJpbK17uqwMJTUG2b9F6sGg2NSQuOkxtY04lwBSlIFvWrJOXEnSaemlhoe+KN+pk/l6Qcm3N/hffGo0vkS67+AEEvn1h+qSNL+TYM6cXVJp6aW9NzD3hR8N7P+KxmLKhKxt1FlCyWNpHju1xZun4rHq7+MQWf919KUP/dvuCX1W/25/3Z1dJiS+oFNUsz5/6d/3B4aZWak0V313U+pqqi+FyWd54MMVTpGw2cZP/3pT+v1r3/9qve/7nWv0//6X//Lk4MC2mnKKarf7PP6r2g0wgqwNrvoDFWa6VORpMG+uJswOjuddvtU4tGIW7QcFpTVb6ySVGls/dfu8QH1xaPKF8s6N7P2322xVNZjl8M0VDFJFU5YB8WkhMb6e/QqqxroVEGvW6waqpyc5Pe2n759wj4h9qyDE+77zHqeLEkVILRMom9gndSIH52Si25Rff1DlUgkQvqt3RavSOe/b98+8lJ/vkbbkirO/Q96MxhcJdGm5EN1n4rRTK9KrydVEm1KFsEzDZ8V7O/v13333bfq/ffdd59SKa68R+eZalNRvVS1loehSltcmreHKttbSAVVyuozbp9K2FIqkrRvwn7CdHqKX8ArLeWK7s/Coc2NXQ0ci0bcK4iPXV57BdjJySXli2UNJmNuv02QeJwJnhlojZFUWRNDFfS6dL56qEIZqV9KZUv/erJSUm9UiqVJqgBhlSk4nSrrvO7av8n71z4mqdJIp4pUGdSy/qtNjt0jyZJ2PEUa2eHP1zBDDt87VdYYRnipXeu/3G6Y6qHKuP02M1P//ZSc1689m1Rh/Venabhp+Vd/9Vf1i7/4i7r//vv1jGc8Q5L0ne98Rx/96Ef1jne8w/MDBPxULJXdK4r97lSRpIlBkirtdGkuI6n5pIpkD1UePDurs9Npt2MlTH0qhh9Xa3WLk5P2k5JNg0mNNnGS+/DWIT16cV5PXF3Ui7Vt1Z8/4vSpXLt9WNF11oO1k7v+i06VwMw6j/EmNYTlKp0qxRofCXSnxVzlZP4pkiq+efTivOazRQ31xXV9VZI0xQlQIPSWchsnVfZ6/NrHsqxKp0qDK7xMUiVbYFDbFmb117Uv9+9rdEunikk+tGv9V/UaswEnqdJIp4pZ/xXv9aEKF9x0ioaHKm9729t08OBB/cEf/IH+6q/+SpJ03XXX6WMf+5he85rXeH6AgJ9m0nZPRiTSnpNfmyiQbiuz/mv7aH/T97HXGaScnUkrkx+TFM6hCuu/1mf6VBpd/WUc3rJxWX2Y+lQk1n+FgZtUGSSpspYRkirocell67+4GtEvZvXX0/ePK17VrUdSBQg/d/3XBp0qkt1LZVmWIpHWLmzKFsoqle0CzUbWf0nVjykMan1XzEnH/9m+fc2t/n0dt1PF56HKohmq+LT+q13JhzXXfzWRVDHrv2I9emGa6VTxewgGzzQ8VJGk17zmNQxQ0BWmluxJ+MRAct0Cai+ZtTymxwX+utRip4pUKas/M50O+fov+zgvzWeVLZSUCuExBsXtU2lw9ZdhyurXH6rYSZXQDFUY3gZuNkNSZSOs/0KvW6xa/3VhLsPvbZ98x1n99cyq1V9S9VXlnAAFwsqsSVxvqLJrrF+xaETZQllXFnLa1sK6Z0layNnPSSKR9b/meirpNwa1vjv1Tfsq/qHt0vab/fs6A+1a/2WGKp1eVL/RUKWJpErPDlXoVOk04WpaBtrMDDfasfpLqiRVpln/1RaX3KRK80+y97qdKmn3iqkwJlUmBpMa6ovLsrRuoXqvMkmVQ1ubTKo4Q5XjVxZlWdaqPw/dUMWs/+JxJjCzTlJlnE6VNZFUQa9bqkqqWBYpUz+U1+lTkar7DzgBCoRVJamy9nXAyXhUO8fs13herABbzFZK6htNvZBUaaPHv2i/veZWKerj6czBdq3/coYRfq//8r1Txfx3tJpUMeu/enWowvqvTtPwo1CpVNKdd96pZzzjGdq+fbsmJiaW/QN0kslF+0F702B7djaaq5anuYLcd5Zlueu/Wu1UkaSzM5maV0wFKRKJuAMgTs4s12pSZf/mAUUj0kKuqCsLuWV/NrWY05WFnCIR6Unbh1s+Vi+Yx5n5bFHFEi/ugmBSQqP9PfqCoIZKpwpDFfSmdG75yXxWgHnvR5cWNJcpaDAZ0w07l1/0kDInQEmqAKFVz+uu6hVgrXJL6htc/SVVDWrpVPGXZUmPf96+fc3L/P1abqfKtFT26ftazEvZOfu2b0X17Vr/tVFR/Wz999PzRfXO+QqSKh2j4aHKu9/9bn3oQx/Sa1/7Ws3Nzen222/Xq171KkWjUb3rXe/y4RAB/7Q9qeJ8nWnWf/luPlN013W1EgffMZpSLBpRvlh2r4IK4/ovibL6tZTLlnuyqtlOlb54zH3RtnIFmOlT2TcxoMEmXoT5wZywlqRZTloHgqTKxlj/hV63WJVUkaRTDFU8Z/pUnrZ/YlmfilSdVGGoAoRVrU4Vqfq1T+uPoeZxeSjV+PP5FEmV9rj6I2n2jH3C/eAL/P1apmRdVmNJi0aYFEwkJqXG/PkabVv/5RTVVw9VmimqL1JUL0nKcz6nUzQ8VPnrv/5r/dmf/Zl+7dd+TfF4XP/pP/0n/fmf/7nuuOMOffvb3/bjGAHfmE6VzUPtTarQdeC/i/MZSfZJzVb2lMdjlWj545ftE+j968TQg2aSKgxVKi7NZ5UplBSPRtzUUTMOOSvAjjk/A0bYVn9J9s+sOWk9y2NNIMxjvOm3wXJuUiVbWHOlHtDtlpwrsM0JQZIq3vvOSXuo8syDqzcpmE4V1n8B4VVr/ZdUSap48drHTaqkGr8gppJUYajiq8e/YL89+ILKyWe/xBKVQYdfvSqLVau//Fpl5q7/8vH8QKkope3fuRraVnl/M+u/Ss4FV73aqdKudW3wTMP/5166dEk33nijJGloaEhzc3Zc7Sd/8if1uc99ztujA3zmJlXadOJrwhTV03Xgu0qfSn/L92WGFY9dsk+oD4Q0qbJ3E+u/VjKrv/ZuGlAi1vyTVbes/urKpEr4hipSJSExvUQSoN1KZctNYIyRVFmTGaoUSpabKAR6yZKz/uuGnaOSGKp4rVy23JL6lX0qUqX/gKJ6ILzqWf/l5QVlblKlqfVfzmMKg1p/PeYMVa65tT1fz+9eFTOs8atPRWpPR0d6UpIlRaLSQNXv3H7nooZmiup7Nqli1n/RqdIpGj7DtHv3bl28eFGSdOjQId1zzz2SpO9+97vq6+vRH3x0rEl3/Vd7fnbN+q+ZpTxX5/rskgd9KsaecfsJ+ymz/iuEnSqStG/CXK3FyRnjxKRTUr+luT4V47Dz+SvXfz0S0qHKGKm4wMxnCjIP72N0qqxpIBlTPGqXwLICDL3IFNU/eZf9u8OLPgBUPH5lQbPpggaSMd24a3TVn1NUD4RbqWy5Q88NO1U2VzpVWn1tvZi1n480s/7LTb8xqPXP0pR07l/t2373qRimV8WvpIopdx/ycahikg9+rv8yiZuBTVK06v/X6qRKvf9/mvVfvZpUaVcHDjzT8FDlla98pb7yla9Ikn75l39Z73jHO3TkyBG9/vWv18/+7M96foCAn8z6r3Z1qpj1X8WypflsscZHoxUX3aSKB0MV5yqoUtl+MhDaoYqTVDk7k1G5zNBOko47Q5Bm+1QMN6lypfIEJ18s67iTXLluRzhK6g2TipshFdd2psdmqC+uZNynKH+Hi0Qi9Kqgp5m1Nk92kiqX53PuoAWt+/Zxew3JU/eNr5lS7aOoHgi16hTrRp2FJqmykC26fXbNaqWo3qyaZlDro+NfkayytO0GaXR3e76m70kVp9y9LUkVH4cq7nBo2/L3m06VUr7+IYEpqu/ZpEqbOnDgmYZ/Y/zO7/yOe/u1r32t9u7dq29961s6cuSIbrvtNk8PDvCbWf+1uU1DlVQipsFkTEv5kqaX8ssKpeEtN6nSQkm9sbKLI6xF9TtGU4pHI8oXy7o0n9XOsdZXn3W6E85KlUObW0uqmE6VycWc5tIFjQ4kdOzKggolSyOpuHaF7O/arJ2aafEFJhpn0kE8vm9spD+hqaW85vgZRQ8ya2Z2jaU0MZjU9FJep6aW3CELWvPtE+uv/pIoqgfCzqz+ikQqKZC1pBIxbR9J6dJ8VqemllrqsvNi/RePKT56wr6wW0de0r6vaVZZLU35c//VnSp+cU/S+5h8WO+/IzFgJ05KeTut0lfH6/GeT6qY9V9LUrnsX9cOPNPyd+jZz362br/9dgYq6EhTi05SZbB9k3DzZG+aK8h9dXHeu6TK3hVDlY1i6EGKx6LaPW6f3Kes3mY6VVpNqgz1xd1Vck9ctbt1Hr1ov33SjhFFIpGW7t9rE04qjqL69pt1S+oZqmxkhKQKepRlWW4qZbAvrv1OyvTUJL+3vVAuW/rXU2aosrqkXqKoHgi7tNM7NZiM13yObZL6rb72Wci1UFTvXHCXpSfOH+WydPyr9u1DP96+r9sNnSrtKD5fXCepEok03qtikio9O1Qx550sqZjx92vNnpE+/tPSZ9/q79fpcnWN4f/hH/6h7jv8qZ/6qaYPBminTL6kJWf9QrvWf0nSpsGkzs1kGKr47NKc/UtohwdF9XvGl99HKqRJFUnau2lQp6bSOjO9pGcfWvsKzV6RyZd0ftb+OTjYYqeKZK8AuziX1bHLi3rqvgm3pP76kPWpSAxvgzSzZA8JzLpHrM0keViFiV6TL5VVdFZ0DiTj2r95UPefmaVXxSPHrixqeimv/kRMN+4aW/Nj3FJp1n8BoWRWJNazcnn/pkF95+R0y4+hi87zkWY6VVIkVfx1+Yf2iqnEoLTnme37uu3qVPE1qWKGKm3oVFmrG6Z/XFq8ZCdV6lHs8aL6eL+kiCTLHoQlW7swdEOzZ6UTX7OHK2haXb8xfuZnfmbZv0cikVVFYOYKglKJ6Tw6g+lTScajTcV8mzVO10FbVDpVWv+FPDGYdNe2SeFNqkjSvglvrtbqBied1V9jAwm3Y6QVh7cO6RvHJt2y+kfdkvpw9alIlRP6rP9qP7P+a4yhyoboVEGvWspVdQUkYzqwyX7BbH5noTXfOVnpU1mv16qP/gMg1Mz6r8E6XnPtdZIqZ1p87WPWfzXTqeI+pjCo9YdJqRx4vhRv4/PrdnWqDG315/6lyjopP9d/ucOhNf47TK9KmqRKXaJRe5CSX/S/rH7xsv12aLu/X6fL1bX+q1wuu//cc889espTnqLPf/7zmp2d1ezsrD7/+c/rlltu0Re+8AW/jxfwjNunMphs6+oec3J3iqGKb5ZyRbdscLsHSZVIJLKsVyWsnSpSVQR+mqHKiUl7+HHIg5SKVFVWf3VRlmVVDVVCmFRxO1V4nGk3U5RqvgdY22i/fdKCoQp6jVn9lUpEFY9FdWALQxUvffuEPVRZb/WXxFXlQNhVkiq1Bxz7ncF0q0mVhaz9fKSZpIqbfmNQ64/jTp/KoX/X3q/re6eKKarf7M/9S1Xrv9qRVNm2+s/6x+239SZVer2oXqqkU9o2VPFxqNcDGv6N8au/+qv6yEc+ouc973nu+2699VYNDAzoF37hF/Too496eoCAX0xSZdNQex+wN5mkCic7fXPJ6VMZ7ot7lkLaMzGgH12yOzTqiaIHxfS/tHq1Vjc4fsXpU9nsTWz2sDOceeLKoi7P5zSTLigaka7ZFr6kytgAjzNBmc2QVKmHu/6LoQp6zJJ7Bbb9/MQ9IchQpWWWZek7Tkn9M9cpqZe4qhwIu0aSKp51qmQ9KKrnMcV7+SXpzLft2+3sU5H8TaqUy5X7XSvh4RWz/qtckIp5f5I+tdZ/SfV3qrhF9T08VGlHD44kLVyy3w6TVGlFw0X1x48f19jY2Kr3j46O6tSpUx4cEtAek05SpZ19KlJl/ZdJysB7l+a8K6k39oxXkioDdVw1FZR9zsmZ0+xmd5MqXvSpSJWkyvnZjO4/M+Pedxg7dkwibpb1X203Q1KlLiMp1n+hN1WX1EvSfmfwP7WU13yW/x9a8cSVRU0t5ZVKRHXT7tF1P46ieiDcGulUMUOVqaW8mzZphrv+q5mkCisF/XPqPju9MLZX2nSovV/bdKqkp6QV9Qcty85KZadX0NekStXFhX6tAFuqJ6kyW999uUmVHr44zaxsyy/6+3XcpMoa3zfUreGhytOf/nTdfvvtunz5svu+y5cv6zd+4zf0jGc8w9ODA/xkhhqbBoNJqkw7SRl476IPQ5W9E5U1YmFe/2WSKvPZomZ7PKVw4qqTVNniTVJl01CfxgcSsizpcz+4KCmcq7+kygn92XRe5bLHLwKwoVm3U4WhykboVEGvWswt72cb6otry7D9XJS0Smu+fdK+Evap+8bVF1//uRpF9UC4NdJjOZxKuK+vW0mrtDRU4THFP9Wrv9q4sl1SZdhRLtpDEC+ZPpXUqL+rruJJKeq8JvFjBVipYA+dJG86VdykSi8PVZxzFwWfN4+QVPFEw0OVj370o7p48aL27t2rw4cP6/Dhw9q7d6/Onz+vv/iLv/DjGAFfTC3aD9ib251UcVbCTHMFuW8uzWUkSTu8TKpUd6qEeP1XfzKmrc7JmV4uq7csSyeumk4Vb4YqUiWt8pVH7QsLwlhSL1VWT5UtceVzm80s2X/frP/aGOu/0KvSudUrZg5splfFC6ZP5ZkH1l/9JckduHBVORBOmRVrEmtpdQWYZVladNd/NX5RDI8pPjIl9e1e/SXZw46k81rP614VM1QZXGNlltfMCjA/TtIvOSvMItHKAKVas50qDFXa0KmyQcIIdWt4DH/48GE9/PDD+tKXvqQf/ehHkqTrrrtOL37xi9ta9g20yhTFt3v9l/l6JFX8U0mqtF5Sb+ztkKGKZL+wuLKQ0+nptG7eMxb04QTiykJOS/mSYtGI9k54O1T57qkZ90q0sCZVkvGohvriWswVNb2U5wR/G5mkyjh/5xsiqYJetbhi/ZckHdg0qH89Oc1QpQXVfSrP2qBPRZJSCYrqgTBbytW//kuyu6nuPzOr09PNPYZmC2UVnWR3M0X1PKb4ZPasNPm4FIlJB34smGMY3CTlF5z+k8Pe3a85oe1nn4qRGJSyc/6skzKrvwa3SNE1/n/tdwYtjXaq9HRRvelU8Xv9l5NUYajSkqaKASKRiF760pfqpS99qdfHA7TNpJNUaff6L3OizVzNDO+ZThUvkyq7xwcUi0ZUtqymYuHttHdiUN89NaMzPdyrctxJqeydGFAy3nAoc12HVvSzXB/SoYpkr59azBXdjg+0B50q9RlhqIIeZboCBvsqJx9Mrwrrv5p3/OqSJhdz6otHdfOe9ftUpOqryjkBCoRRpmAeJ+t7zbXXJFUmm7sSfyFnPxeJRKSBJtY885jiE7P6a/fTpP6xYI5hYLM0c6qSyPCKuT8/+1QM9yS9D0mVWsOhppMqvTxUMZ0qPj4nLOYra9tY/9WSps4MLi0t6etf/7rOnDmjfH75zv63vOUtnhwY4LepgIrqzRBnMVdUrljacOczmuMmVUa8G6r0J2P6vX9/k9KFkluwHFatRuC7wXHTp7LZu5SKJB3ZVln3NTGYdFethdHEYFLnZjI9363TTtlCyT0RQDpoYyRV0KvcpEqyev2X/XubpErzzOqvW/Zu3KciSX3mqvICq3qqLWQLuvOLj+mVt+zWU3o06YxwSDvrv+rtsdy/yRlMN3lBWWX1V1zRaOPbV8xjSpbHFG8FufrLMEOPtNdDFbN6qQ1JFT87OhZr/Hc0O1Tp6aJ6s/7Lx3M55ucvGq+kidCUhocqDzzwgH7iJ35C6XRaS0tLmpiY0OTkpAYGBrR161aGKugYU0umU6W9J0VH+uOKRSMqlS3NLBW0fZShitcuzXtfVC9J//6puz29P7+YVWWnp3t3qGL6VLwqqTdMp4pk96mEee2lOak/vcRQpV3MgCAWjWgk5Im2oJmkSq5YVrZQUqqJK0OBTrS01vqvzfbvlpOTS7IsK9S/W8LqO05J/TMP1j454JZKc1X5Mnffd0r/81undXYmo4++8elBHw56WDq3OtG3EXNB2ZkmX/u4JfV1JmNWSpFU8V6pKJ34mn370L8L7jjMUMXzpEobO1USPnZ0LNo9o+sOVUzPSmZGsiw7DrYRt6g+vBcu+s4dqvi4/sv9vm2Tot5t9ehFDf/tvfWtb9Vtt92mmZkZ9ff369vf/rZOnz6tpz71qbrzzjv9OEbAc5ZlBZZUiUQi7gqwKXpVPJctlNyTyF6u/+okJgJ/poeTKidMUmXFuq5W7RxNacDZ73zd9vCu/pKkCWf91Gwb13999UeX9fMf/56uLvTmY9uMkwoa7U9wUrSG4b64+7qKsnr0krXWf5kTgvNZVjY2w7IsN6lSq09FkjvEzRfLsizL12PrJF961D7JYtboAkExj5P9dRbVm6TKxblsU2kRN6nS5AUxXZt+yy1IM6eD+doXHrB7QFJj0q5bgjkGyV7/JVVWJXll0QxV2rn+y4ehSq3hkEmqlIv2z1MtJFX8HYIZCzWGYahbw0OVBx98UL/2a7+maDSqWCymXC6nPXv26Pd+7/f027/9234cI+C5+UzRLaObGGz/A/amQXpV/HJl3j6Zm0pE3fUyvWafk1S5NN/cC4tucGLSSap4vP4rEom4K8Bu2LXxzvaguUmVNq7/+n+/dlxfeuSy/vmxK237mmFiHtPH6FOpKRqNuKsU57ON/S60LIsToehYaxXVpxIx7XQuBGEFWONOTi7p6kJOyXi0rrVVfVVda1xZbrs0l9XD5+YkVXongaAs5c2axPqSKmMDCbfzspm0ynzV+q9mdG367a/+vfT/3CLNnW//1zZ9KgdfuHYBerv4nlRpR1G9M1Txdf3XOmXniX4p3m/frqes3k2q9PBQJdmGoYpbUk+fSqsaHqokEglFnXjQ1q1bdebMGUnS6Oiozp496+3RAT6ZdBIiw6l4IJ0m44P2iSSSKt67OJeRJO0Y7e/ZK8UnBpPui4JzM72XVskWSjo3Y/8cHNrqbVJFkt552/V684sO6xU37fD8vr1kBsbt7FQxJwPNepteY/6ux+lTqUuzvSrv/9yjOvreL7mP90AnMY+PK0/embJ6hiqN+/YJ+0TN0T1jda0SrH7uz1DF9pUfXXZvTy3lVS4zuEZwMk5SZaDOoUokEqn0qjTxGGqG3UNN9maax5SuSr+Vy3ZapFyULv2g/V//CWeoEuTqL6mSVDFDEK+0c/2Xn8XntdZ/SfX3qpTLUtl5TcD6L3+GYIZJqgyvMwxD3RoexR89elTf/e53deTIEb3gBS/QHXfcocnJSf3lX/6lbrjhBj+OEfCcWf3V7j4Vw5TV03XgPbdPxcOS+k4TiUS0d2JAj1yc1+mptA5vHa79SSH3w/NzmlzMaTgV12BfXIPJuHs7EVt+fcDpqbQsSxpJxd1UmJdu2TuuW/aOe36/Xht30hLtepyZzxY06Ty2mrUNvcas7RknqVKXZoYqc5mCPv6t08qXynro7Kx2jPb7dXiAL5bck4XLX4Yd2Dyofzk+1dQJwV73nZP1r/6SpEQsokjEXu+eK5SkHk02V/vyI5WhSqlsaTZTCCTND0jrP05uZN+mAf3g/FxTSZVFJzE73OT6r1RiefqtK3rilq5UVjHNnmnv187MSue/Z98OeqjiW1G9M1RpS1G9j0mVev47BiakhQtSukZSpVT1mrWX13+5QzA/O1VIqnil4d8aH/jAB7SwYO/Ce//736/Xv/71+sVf/EUdOXJEf/EXf+H5AQJ+mHJi7X6ccK2HSarMMFTx3EVnD3Sv9qkY+zZVhiqd7tGL8/rJ/+eb6/55Mh7VUF9cQ332kKVUtq86PbhlqGfTSlJl/Ve79vNXnwjM9OxQxX5MHyOpUpdmhipf+OFF5Uv2/+PZAleYo/NUkirLT7odMEmVKYYqjajuU6mnpF6yLz7pi0eVLZRJqsj+mbzvuP13GI1IZcteAcZQBUHJOOu/6k2qSJVuqlNNPIa2WlS/Mv3WFUOVuXOV27Nt7lU5+XXJKkubr5HG9rT3a6804AzrlzzsVMmnKyfM29GpkvCxU8Ws/9pojVm9SZVS1RaXnk6q+Pj9Msz3jaRKyxr+rfG0pz3Nvb1161Z94Qtf8PSAgHaYXAqmpN6YcJIqUwxVPGfKNbf3+FDFLatv4mqtsDntvDjqT8S0ZbhPS7miFnNF90RIvljWdDG/KpFx0+5wd574rd3rv6pX1phd2J0kWyjpT/75Cb3k+u26scmfHTMcIKlSn5F++2noXAODv79/8IJ7O1fszeEdOpsZqqy8AruV1TVhd3pqSYu5op680/vfy6en0ro8n1MyFm0oRZpKxJyhCo8j3zg2qXyxrH2bBhSPRnT86pImF3K6ZlvnJ53RmZbcovpGhir2Y2gzF5QtrLOWsV5dmX6bq1rt3+6kirv668fb+3XXUp1UsSzJiwv2TLoj1if1jbR+f7X41dFRKlR6UrxY/1Wqej1Ap4rPRfUmqcJQpVUN/9Y4efKkisWijhw5suz9x44dUyKR0P79+706NsA3blIlsPVf5gpyhipeMzv2e32osm/CvLDo/JMzSzn7hdXTD0zo4z/7DPf9hVLZHbAs5UpazBW0mCtpKVdUqWzpBde2YUdtiI2567/ak1Q5cbWzkypf/LdL+sOvPqFvn5zWp/7rs5u6D5M+JKlSn0pSpb4h3OX5rL51onKlIFeYoxO5BcwbdKpYltU1Scty2dJr//Tbmknnde9vvkjbPF7Pev8Z+yTNTbtHG7o63C2WJvGmLz9qr/568XXb9MPzczp+dUlXKatHgMzzyMEG1n/tb2WoYorqm1z/FYlElIrHlCmUuue5yWxAQxXLko7/s337cAiGKqZTpZSXcgtSyoMhiCm9H9zizZCmFr86OsxwKBKT+jdIitY7VDEl9dGEFG24/rt7tGX9l+nCYf1Xqxr+SX3jG9+of/mXf1n1/u985zt64xvf6MUxAb5zO1UCW/+VXHYc8I6bVOnhThWpEoE/3QVJlbQ5AbXiarVELKqxgaR2jw/o2u3Deuq+Cb3gmi36iRt36Labd2qkybLJblGdVGlHaebypErnDVXOOv+vPHpxvum/L7NqbYykSl1GGlz/9Y8PXVD1tybHyVB0IHOhwMorovdODCgasTupri50zwntY1cWdWk+q1yxrPtP1zih0oSHz81Jkm7aPdbQ55l1PV1zArRJpbKlr/7IXgPy4uu2afOwfcHZJK9REBDLstzhcyPrv/Y7r33OzaSVb/D/68Vsa0kVSepzelW6Jv22bP1XG4cqU09Ic2fspMK+57Tv664nOVBZn+VVr8qSs3ppqE0XAPq1/sucmB/csvEQZMAZuNTsVHGe+8R7ePWXVJVU8ek8Trlc+d6x/qtlDQ9VHnjgAT33uc9d9f5nPetZevDBB704JsB3U0skVbpVpVOlt8uL9044LyymMyqV/T+h7qdmyiohjTtpiWLZctca+Kl6h3WmA9d/XXAeOxayRfd2o8yqtXGSKnUxSZX5bH1DFbP6yxTCZgtdcuICPaWy/mv5ycJkPKrd4/bv7pNdtALs+1WDlIfPz3l+/w+fm5Uk3bynsdViJqmS6/HHkfvPzGh6Ka/R/oSetn9cW4bMUKV7BnvoLLli2b2AYqCBIceW4T71J2IqW9L52UxDX9N0qrRyQVbXpd+q139lpqWcj1fNVzv+Vfvt3mdXTi4HzaRVvOpVMQmPwTYNVfxaJ7VYR0m91EBSxTk3Fuvxi9P87MCR7O9D2XmtvlEXDurS8FAlEom4RfXV5ubmVCr19pNSdA5z9VVQnSrmhNvKDgi0plAqu+sKen39186xfiViEeVLZV2ab+4EcVikc2ZVSheUPrZRKhFzTz7P+rwC7P9j773DJMvL8u/7VO5cnad7ctiZ3dkwG1k2khaQsCAqKLyKoiIiArLKT0CCL+Ku+P7khwFF9gX1VVQUUcICStzEBnZn2dkwYWcnz3SO1ZWrznn/OOf5nuruqq5zTp1cz+e6uKaZ7XBmquaE537u+1YUBSdr4r9yAXSqXKh5AD8ysWzpe+hF9W3+MGAQM0X1z8+s4KnzS4hGJLx8v2pVb/cNcyZ4VKp6MXq9jWiKALNStOxXKJ4L0AUQu6hUZTxzQT1fX77ZpKgitsrb+zzy3WfVbdWX7BtGPBrBkPZsNBsitxQTLGrvITtMRPpJkqQ79U2eQ1dajP8Cat1vwbsHrkutqFLv/zsF9an4IfqL6NLK6u1yqhgpd7cTGtLbHv9FjptmoormVMkbdKq0c0k9oMd/VfKA7MD5ZEXrU+kYAGK8CNgqpkWVW2+9FXfdddcqAaVareKuu+7CzTffbOvBMYxTiE6VLo+cKt3kVClDDriLwE/MZIpQFLUscNCjaDe/EI1IYuM16L0q7FSxzkCnO6642ZXSKjdMEOO/JhZ18fHI5PrlESMs5qiovr3PP0YxI6p8TXOp3HLREMbTqmgemsEF0zZQ9BewvlMFAHZqA8ETIXKq1EZ+HTq3ZOt977GpFRQrMnqSMdGnYJRU2AagFvmO1qdCYvUQO1UYjyE3XyoeQTRirm9CF1XMDY9bLaoHdBdtaKJJKf4rpqU/uBEBVikCp+5XP979Uud/nlGEU8Wu+C/qVBmy5/s1w6k4KRH/ZbNTpd0H/bUOLSfcKlRS38N9KnZg+qrxyU9+Erfeeiv27duHW265BQBw//33Y3l5Gd///vdtP0CGcYK5rLdOFdpirsoKlgtlLjW2CYr+Gu1NIWLyJjyMbBvoxMnZLM7M5XDjbq+PxjqNOlWY5qQ7E7iwVMC8w6LK2qiaQMZ/1TpVLIgqiqJgMc+iihkoZmO5iaiiKAq++pPzAIDXXzmOk7PqQ2G7b5gzwYN6AuJRCYnY+t22neRUCYmospAtCYEoEY0gU6jg1FwWu4a7bfn+T51fBABctrnP9H0fO1VUB+CJmSziUQm37lWHe7qowm56xhvyZevLVNsHrbn9MloMqR1OlUIYhNriij4A33odcPI+d0SVs4+oboquEWD0Mud/nlFI/LCtU8Wj+K+yR/FfZjtV2t2pEksCUhRQquq/h1Svvd9flNRzn4odmHaq7N+/H4cOHcKb3vQmTE9PI5PJ4K1vfSuOHDmCyy7z0YmPYRpQrspim9grN0MyFkWPtgkzxxFgtjEp+lTaO/qLCEtZPcUAmMlVZlRqy+qdhAaAvdrDaO02dhBYLpRXOW2sxH9lihXRX8TxX8Yw6lQ5dG4Jp+ZySMUjeMX+TTW55cF6nzFMVsRZ1r+eifiv2WBft4knzqpDuV3DXbh0szoUeMrGXhVRUm+yTwWoieoJy1a5Bb6nuVReuGsQPZrIrRfVs1OF8YZGvVNGoGefMyadKtSp0tNKUX0sRE4Vcqmk+nRxY/G08z+Xor92vxSQfLQg2anFf9nmVDEYm2UXThfV29WpUiWnSpuLKpKkR4CxU8X3WLpqjI+P484777T7WBjGcYqVKv7oG88CUDfmvHSIDHQnkClWsJAtAS4tKYSdiSV103xTm5fUE1RWb/bBwm/QgJ6dKuah4f68w50qtIl86XgfHjoxJ7YMgwJFf8UiEiqyghOzWRQrVTF0MwL11qTiEaRMZIC3M0ZFFSqof/n+TehKxvTBRRtvmDPBhAZ3XQ02sHfWdKrIshJ41y2V1F+zrR9dyRieOLOIJ88u4fVXbrbl+wtRZXPa9NcKcTYMW+UW+e6z6mDv5fv1bVXqVJlbKUFRFEh+GmwybUFexP6av5faYcGpoiiK6FTpaaGonu79QnFvQv0pfVuB9Db1YzecKlRS76c+FaDGqWJXUX1I4r/IcdPM8UCiSmERkGUg0mC3XxTVs+MfiU6guASUVuz/3isui3ohx7RTBVDjvn7xF38RN954I86fV+MY/vEf/xEPPPCArQfHMHZyZi6Hn/ubh/BPD6s3BO9/5T7TOa12QvEw7FSxD3aqrIYs8Kfngx0jQvFf7FQxj1tOlZOz6g3fpePqJnIuYPFfFzRB9qLRHvSmYqjKCo5Pm7uJpd4ajv4yDokquVIV5Wr9IURVVvD1Q6qo8voD4wCAZJw3zO3i+ZkVPHLCpiEB0xRyXnYl6w8LN6c7EItIKFZkTCwX6n5OkDh4ehEAcPX2flyxRXWT2FVWX6xUcWRSdRXS9zZDqLbKLTCfLeGx02oUy8suqRVV1A3hUlXGcj5Y13ImHLTSpUgLZWfn88I93IxiRUZF+9zW4r9o4SMEQq0XosrKNDB5SP1410uc/VlmsbtTxe2i+tr4L8XGPl/x52iyIUyiiiKrQkEjKP6r3Z0qQI0Q5sAch4rqu9mpYgemRZX/+I//wCtf+Up0dHTg4MGDKBbVN/7S0hK7Vxjf8u2nJ/Gav7wfT51fQn9nHH//tuvw9lt3eXpMFD22wKKKbdAAYrSXRRVgdVmjYucNlMuIhyve/jdN2qWieupUoXiXQlk2/DDrB6hPZXM6hYvH1D/DUZO9KvR3zB1Zxunt0DdCG/WqPPT8HGYyRaQ747h1r/rQlgrT4MIj8qUq7vrWYbzi/9yHn//cwzg+bb5HiDHPSpP4r1g0gm3atTvovSqVqownNQHl6m26qPL0hSVUGoioZjg6mUG5qqC/M44t/eYdyvpWeXueR35wZBqyAuwf68XmtP73l4rrEcUzHAHGeIBYprLgVBlPdyAelVCqyiLBoBkZzaUiSa09a1BPUyEMQi3Ff/VtUYUVAFg86+zPfP4H6q+brgC6fRbjYWenilzVHS9udapQ/JciAxUbz+tG479iSSCuiQQbRYAJpwrHKDvmLgKAjPa69XCnih2YFlU+8YlP4LOf/SzuvvtuxOP6m/2mm27CwYMHbT04hmmVUkXGH33jWfzmPz2OTKGCa7b345733IIX7/Pe6tbfxU4VuzmrdYdYebgOI1v71RuoTKEieoSCSI6ylRts9jKN6dfivxYcjP+SZQWntIi5S8f1beEgRYBR/NdYXwcu2dQDwHxZPf0b6+c+FcNEI5IY3jWKAKOC+ldfPiaKvZNhitjwgPufm8ErP30f/vbeE0L8vO+YTduXzIbQsLBR/BcA7NRcpicDLqocmcwgV6qiJxnDRSPd2DXUje5kDIWyjOMzrcdZUPTX5VvSliKq2j1G8DvPqkOV2/avH6pwrwrjJbkW4r+iEQlbNbcKxQ82Q5TUJ2ItRS6mYiESaklA6duiO1Vys85szRN+jf4CapwqNjh7c3MAFACS3tXiNDSgB+x7DStFNc4LMFZ4LsrqN/h3yUX1OqJTxYn4L3aq2IlpUeXo0aO49dZb1/1+X18fFhcX7TgmhrGF84t5vOlvH8LnHzgJAPiNW3fhX3/jhRhP+2PgTk6VeRZVbEFRFDGAoEzydqcjEcWI9mAc5LJ6EZdiIQag3aH4LyedKheW8ihVZMSjEnYNdYleyVwxOLEh5FQZT3dg3ybVqWJWVOH4L2v0btCrUihX8e2n1Rt/iv4CwEX1FplbKeKOL/0Ev/T5R3FmPoexvhReean6IPwwR4C5wkpx4/gvQC+rD7qo8sQZdXBy5bY0IhEJkYiEyzQ346GzrZfVU4zYFZvNR38B7S3OFspV3PecmoX/8kvqiCparwqLKowX5FqI/wKAl2rLkx/+z6cNuY7JQdhK9BegO1VCESlITpX0VqAjDSS186xTbhVZ1kWV3T4UVbo08cMOpwr1kHQOAFGXnm0jUV2oKNt0b0F/jkgMSKWbf36H9jkbOlU4/ktA7iJH4r+02DYuqrcF06LKpk2bcPz48XW//8ADD2DXLm/jlBiG+P6RKbzmL+7HT84uojcVw91vvRYfevUliEct1Qg5Qj/Hf9nKYq4s7NuUp8vURoAFdziTpc1edqqYhqKonBRvafC3fbALsWhERCfQQ3EQoE6V8XQKF49pTpWJZVPfg5wqaXaqmGIjUeUHR6aRKVYw3pfCdTsGxO+3+4a5WRRFwX88fg63fepefOWJ85Ak4Fdu3IHv3PEivPPFewAAj5ychxygyL6gkm0S/wXookrQ479ESf32fvF7V2xJA4CIBWsF3aliUVRpY3H2oRNzyJWq2NSbEkJXLdSrMpthUYVxH+FQt+BUAYD3/9Q+XL9zAJliBW/7u0cx3aSfSi+pb1FU0ZwqhTA4VWo7VQDne1Wmngay02pE1NbrnfkZrUBOlXKu9Tgmt/tUCLvjpGr/HI2K52vp0O7j8/ONP6fKRfUCpzpViiu6+4WL6m3B9IT57W9/O9773vfikUcegSRJuHDhAr74xS/i937v9/DOd77T9AF85jOfwY4dO5BKpXD99dfj0Ucf3fDzP/3pT2Pfvn3o6OjA1q1b8b73vQ+FQvCLHBl7qFRl/Mm3juBX//4xLObKOLClD/e85xa8vI613WsGLMZ/KYoSDluxzZzURIOxvpTIyWaAbQPqBfnMXICdKsXWNtbamYFOKqp3Lv5rrUOsUxsWBkpU0eK/xtMd2DuqiirTmaIpMWqRnSqW6OtoHP/11Z+oBfW3Xzm+KpIj1cYb5mY5NZvFL37+Efzuvz+JhVwZF2/qwX/+1k34w9ddiu5kDJeN96IrEcVSvozDk+aERMY8NCzcyHm5i5wqAV6GAICDZxYBqH0qBPWqPHW+NadKvlTFc9PqUOCAJtSYRZxHwrBVbpLviuivkbrRaUJUWeHFL8Z9cuXW7vuTsSj+9peuwa7hLlxYKuDX/uExEb1Yjww5VTYQu4393JA4VaoVYFm9/1ovqpx25meSS2XnLUDMh/fRyR590N+qW4XK7qmnxS1qy+rtgJwqRvtvqKx+I6cKiSrsVNHjv+x6vQjqwYl3qe9rpmVMiyof+MAH8Ja3vAUve9nLsLKygltvvRW//uu/jne84x1497vfbep7felLX8Idd9yBj33sYzh48CAOHDiAV77ylZienq77+f/8z/+MD3zgA/jYxz6Gw4cP4/Of/zy+9KUv4UMf+pDZPwYTQiaXCnjL3Y/gs/c+D0Ddwvy337xB5Kr6jUGLsTwf/q+ncfkf/g+Xyq6BnBjkzGBUhFMloPFf5aqMklZoy/Ff5iHXxEKuBEVxZgv9xIz6b48GgbRZuNEDrJ+QZQWTS9SpkkJ3MibcbkdMDJkX2KliiT7NqbJcWP1+WcqX8f0j6v3g6w9sXvXfklxU35RyVcZf//A4Xvnp+/Dg8TkkYxH8/k9djK+/+2ZcuTUtPi8WjeC6ner24MMnNtgeZGxBj/9q7lQ5O5+zpdDdC2YyRZyZz0GS1PgvggSQwxPLLf37fXZiCVVZwXBPEqO91oYv7XoeURQF3z2siSp1or+AWlGFnSqM++Rb6FQh0p0J/N2vXIeBrgSeOr+E9/zLT0SH2FrIqdKdau3+LTSRgpkJQKkCkbjeleG0U+X576m/7n6pM9+/VSSpplelVVFFm3W67RKwO05KlNQbXF4WnSob3GtW2KkicMqpktH6VLik3jZMiSrVahX3338/3vWud2F+fh5PP/00Hn74YczMzOCP/uiPTP/wT33qU3j729+Ot73tbdi/fz8++9nPorOzE1/4whfqfv6PfvQj3HTTTXjLW96CHTt24BWveAXe/OY3N3W3MOHnR8/P4jV/cT8ePTWP7mQMn3nL1fjD110qbLh+RBTVm9gCe+zUPL74yBmUKjIOnl506MiCyalZVTTgPpXVkKgSVKdKrduho4WHq3aFzjPFiuxYcfwpTdDcIUSVYDlVZrNFlKoyIhIw2psCAOzTyuqNZHETJJCn2aliCiGqrHGq/PfTkyhVZVw00o1LxlZvUomIjaBvgzrEE2cWcPtfPoA//fZRFCsybt4zhP95361454t3141BvWGXmhXOvSrOkxUb0Y2vZ2O9KSRjEZSrCs5rfU9B46DWp7J3pAe9NYPKLf0d6O+Mo1xVcGTC+nIQRX9dsbnPUkk90L4xgk+fX8bUchFdiShu2F2/JHmohztVGO+g82Rni7G/2we7cPdbr0UiFsF3D0/hE/c8W/fzqKi+xy6nStCFWupT6R3XY51IVFlyoFOllAXOPKx+7Mc+FUL0qrR4r0QOjy6DDg+7SJCo4kD8lxEMOVW4U0WQsFkEI4QYxn0qdmFKVIlGo3jFK16BhYUFJBIJ7N+/Hy94wQvQ3d1t+geXSiU8/vjjuO222/SDiURw22234aGHHqr7NTfeeCMef/xxIaKcOHEC3/zmN/HqV7+64c8pFotYXl5e9T8mXFSqMt71xYOYy5awf6wX33j3zXjNFWNeH1ZTzDpVZFnBH31DvxlczLMlv5ZTc3qvA6NDG/en54MZI0Juh0Q0gkTMP51IQaErEUVCG6IuOBQBti7+KxGsTpUJLfprpCclBs6XbKJeFeNDP4pY62eniin6GnSqfPXJ8wCAn75q87qhqV4GG4z3mJt86cdn8DN/8yMcmcygvzOOT73pAP7x116w4bXxhZqo8siJuYabvIw9UEfYRrE2kYgkFiKCWlZPosrV29Orfl+SJFyuuVUOtdCr8hSJKhajvwBdnG03UeU7mkvl1r3DDZfPyKkyw/FfjAeI+C8b4pyv2d6P//OmKwEAf/fgKfz9gyfXfc6KzfFfgV/4ECX12/Tfc9KpcupBNfYpvQ0Y3G3/97cL25wqJKq4Hf9lc5wUiSqG478MdKpQUT07VWqcKiv2fl8hqnCfil2YnlBddtllOHHiRMs/eHZ2FtVqFaOjq21Ho6OjmJycrPs1b3nLW/Dxj38cN998M+LxOHbv3o0Xv/jFG8Z/3XXXXejr6xP/27p1a8vHzviLJ88tYSFXRrozjq/81o1iW9rv0AZ5rlQ1VJL51SfP48lzega1kx0JQeSU5sTYwfFfq6BB2tRyMZBlrFktKoVdKtaQJEmPAHOgrL5UkXFWi5YLavzXhUW9pJ7Yt0kt7j0yxU4Vp6Et9qWaa9r0cgE/el7dBHzdgfF1X8OdKo353H0noCjAa68Yw/d+98X4mau3NN3kv3S8F93JGJYLFRye4OUjJ8kaHN7tDHhZ/ROam/qqmj4V4oDWq3LonPVeFSq6v8JiST2gi7NBvDdqBdGn0iD6C+CiesZbRFF9iyIH8ZorxvD7P3UxAODj33hW/BsgRKdKi0X1+r1JwM8pS5pw0rdF/720NkNzQlSpjf6y6Dx0BRJBWu1UWSFRxav4L5ucKiLGzGCMlJlOFRZVdBHMrteLEPFf7FSxC9Oiyic+8Qn83u/9Hr7xjW9gYmLCVRfID3/4Q9x5553467/+axw8eBBf+cpXcM8992wYPfbBD34QS0tL4n9nzzpgWWQ85cHj6oXtxt2DgSoo70nGEI+qNw7NyupzpQo++a2jAPQHncU6pb7tzGl2qtSlvzMu7OxnA9irQoP5LhZVLDNgsb/JCGfmc5AV9fUZ7lHPTUFzqlygPpV0h/i9i7W4qWOTGcOb++xUsUZf53qnyteevABFAa7elq7bi1Yb2+NUV1AQWciW8LzWcfTx118m/u03IxaN4AWiV4UjwJwkW2reqQLocYqnAhjdWarIQvS4Zvt6UeUK4VSxJqpkCmWc0MSmyza3IKq0oVPl3EIOz04sIyIBL7m48UBvuKZThc+xjNvkbOhUWctvvmgX3vyCrZAV4N3/8gSePq+ff6hTpadFUSU0kYLkVOmrWUYmp0p2xv4hL5XU+zn6C3DAqeJV/JddThWTfw5DnSoc/yVwqlPFbBcO0xTTosqrX/1qPPnkk3jd616HLVu2oL+/H/39/Uin0+jvX3/j3IihoSFEo1FMTa3eFJiamsKmTfVVs4985CP4pV/6Jfz6r/86Lr/8crzhDW/AnXfeibvuuguyXP/ilUwm0dvbu+p/TLh4QBNVbtrjsoWyRSRJQr+20dxsg/xz953A5HIBm9MdePstOwGsj0ppZxZzJTHQ5KL61UiShG1UVh/A4Qw5VezaVmtH9LJ6+88ZFE2zY6hLbMPrnSrBcqpsrhFVdgx2IRmLIF+u4owBMbJclUV8RD87VUxRL/7ra09eAKBGf9UjWRMFGPjhhY08cVbd/ts13GVYUCFeuIvL6t3AaFfATm1B5EQAnSpqCb2MdGdcOBhrIXfJc9MZS9eJZy4sQ1GA8b6UEPOtIGIEg75VboLvHVY3i6/dPrDhOYI6VYoV/drmBflSFRNLwewVYqxDokrXBjGJZpEkCR9//WW45aIh5MtV/Orf/1jc/9kW/xWnvreAn1MWtSXkWqdKKg0ktTmanb0qi2eB2WOAFAV23mrf93UC0alik6jielG9dj22Lf7L5HCenSrmEM4im+O/2KliO6ZFlR/84Afif9///vfF/+j/GyWRSOCaa67B9773PfF7sizje9/7Hm644Ya6X5PL5RCJrD7kaFS9ePEWTXuSLVbwhJbbfHPARBVA3yDfyKkysZTHZ+99HgDwwVdfLIqUlzj+S0CbnKO9yQ1zytsVEppOs1OlLTEq3lrh1Jo+FSB4ThUa2Iz16fFf0YiEvaNUVt/chUuiriQBvR3sVDED/X0ta0WxJ2ZWcOjcEqIRCa++vH4/Wm0PAIsqOo+fVu+HrqkTudQM0atykntVnMRo/NeOAMd/0fvw6m39daPnRntTGO1NQlbU0nSz2NGnAtRslQe9/8AE39X6VG7bv/EwrzMRE9fyWQ97VX7tH36MWz75A5xbCN79K2Mduve3O/o3Ho3gM//X1dg32oPpTBG/+vc/RqZQRoadKqsRnSo1ThVJcqZXhaK/tlwLdKTt+75OYIdTRVE87FQh54Pd8V9Gi+oNdKqQqMJOlZr4L7udKiZj25immBJVyuUyPv7xj2N8fBwvetGL6v7PDHfccQfuvvtu/MM//AMOHz6Md77znchms3jb294GAHjrW9+KD37wg+Lzb7/9dvzN3/wN/vVf/xUnT57Ed77zHXzkIx/B7bffLsQVpr149NQ8ylUFW/o7RCF3kBjsbj7s/H++fRSFsoxrt/fjNZePiagULqrX4eivjdk2oP69nJkL3nAmKyIAWCyzSr+D8V+0Rb2rjqiSD4iocl4rqh+vcaoAwD6trP6wgbL6Re3vtjcVRzTi4zxoH7LWqfLVn6gulZv3DIm4y7XEoxLor7mdtsybIUSVOpFLzdg/1oueZAwZ7lVxlKzBDWw6p55byKEUsAGdKKnflm74OVe0UFZP0WKXt9CnArRf/NdyoSzi/V6+v/mG6lBNBJhXPHVuCRVZWRXVxIQfJ+K/iN5UHF9423UY7kniyGQGv/XFg+L+uDvZ2lKM6FQJslCrKLoTpW9NF7EQVU7b9/OCEv0F6DFXrYgqxQxQKaz+fm5B8V9lG0SVcgEoaOdlo38OcqoUlgC5wb07F9XrkAhmx+tVy4rmVGFRxTZMTani8TgOHTpk2w//+Z//eczMzOCjH/0oJicnceWVV+Lb3/62KK8/c+bMKmfKhz/8YUiShA9/+MM4f/48hoeHcfvtt+OP//iPbTsmJlg8+Jx6Ubt5z1DTIlY/QhvkjZwqT55dxFeeOA8A+Mhr96ul09oAiovqdU7Nckn9RgTaqaJt9XY1iUphGtPvYFH9yVnVkrxzWBdVOrRhYTYg8V8TVFTft1pUuXgTOVWaiyoL3KdimVpRRVGUmuiv9QX1hCRJSMaiyJerwR5e2Ei5KuPJs+oDrhVRhXpVvndkGg+fmGupq4JpTNbgNW24J4muRBTZUhVnF3LYPdztxuHZwhNnFgGoTpVGHNjSh+88O2WpV+Wp8+RUaVVUaa+i+vuOzaBcVbB7uGuVu7QRQ90JnJnPeVZWny1WRIF4EONrGevkHF6o2pzuwBd++Tq86W8fwv3P6QPyVovqdadKgM8phUU9bqh3TQSrEFVsiv+qVoATP1Q/3v1Se76nk9hRVE8ulXiXPjR3C4r/siNOiv4ckbguljSj9vPyi3qcWi3sVNFxolOlUgJyWncix3/Zhun4r1/8xV/E5z//edsO4Ld/+7dx+vRpFItFPPLII7j++uvFf/vhD3+Iv//7vxf/PxaL4WMf+xiOHz+OfD6PM2fO4DOf+QzS6bRtx8MEi6D2qRCDXY2dKoqi4I++8SwA4Geu2owDW9MAgLQmxHD8lw45VXYYeEhsR7ZrLq4zAXwoZadK64j4Lyc7VWpcYl0Biv8qVWTMaFu44+nUqv928SY1O/qIgfgv2nJMc5+KaUhUyRQq+MnZRZyczSIVjzTdpG7HPoSNODKRQb5cRW8qZnkATxFgDz3PZfVOIMuK3hXQJP5LkiThvj05ExyX6eRSAecX84hIEPet9bDqVFnKlcWA/YrNjb+/EcRWeZs4Vb77LEV/GdtO9dqpMrVcEB8b6TZjwgPFfznhVCEu39KHv3jzVajdybQr/qsQ5GUPiv7qHNKdDYTd8V9TT6muhVQfsPlqe76nk4j4rxbukUSfissuFaCmqN6G82lt9JfRxeZoTO/ladSrwk4VnYSNIhhBr1skpsexMS1j+spRqVTwhS98Ad/97ndxzTXXoKtr9RDzU5/6lG0HxzAbMZMp4oi2QXzj7jpKdwDo36BT5Z6nJvDY6QWk4hG8/6f2id8np0qmWEG5KiMeNa2Nho6Tc+sHu4wOFdWfXcihKiuBiifKl9ip0iq6qGKvUyVbrGBqWb35rdupUvT/sHtquQBFUR+E15b2XjymOlVOz+eQK1U2FPYo/oudKubpTel/Z//0sPqgftslo007J0IxvLCRx06rGdVXb+9HxOI5nkSVR0/OB+5aEQRyNY4IIwXMO4e78OzEMk4FKLqTor8u3tS7oXB0ueaEOjWXw1KuLKJtm3Ho/CIA1YFr9GsaEYqtcoOUqzK+f0Qdprz8EoOiSo8qqsx41KkyyaJKW1KuyihX1V4vO4vq6/Hy/aP46Gv34//+urrE2NdiJ14ohNp6JfUExYHZJapMPq3+OnYAiATgOY+cFaWMOvy34qYQfSpeiCo2xkmtmOxTITrSQHG5ca8KF9XrOOFUWVGXK9A9CkR4hmgXpq9UTz/9NK6+WlWSjx07ZvsBMYxRfvS86lLZP9aLwQa5636HnCrz2dVbYIVyFXd98wgA4DdftBtjNbE0tSXIy/lyYP/sdkJbi9s5/qsuY30diEcllKsKJpby2NIfnL8ndqq0zoBDnSo06BvoSqxyaNBrlQtApMp5iv5Kd6yLkBzqTmKoO4nZlSKOTa3gyg22rhdF/Bc/BJglEYugI65GeX39kBb9deXmJl8VkuGFjVCfyrUWor+I/eO96EmpvSrPXlhuubOCWQ1Ff0UkIBVv/jC7k5wqASqrP0gl9dvTG35ef1cC2wY6cWY+h6fOL+Hmi4w5ziku7HIb4ul0t5sMRVECGSNslMdOLWC5UMFAVwJXbRDLVovXTpXpZf3nsqjSPtS6nO0uqq/H227aCQnAhaXCqn5AK4RCqK1XUk/Y7VSZVsUsjFxqz/dzmlRa3fCXK2qvSl/ze9V1CFHFpBhhB3Ebh/Qkqpj9c3QMqO+fZk4Vjv/SRZVqCaiWgagNi3sZElU8eP+FGNNTqh/84AdOHAfDmOZBLfrL6IOYHxnoUi8YC9nVsTyff+Akzi/msak3hd+4ddeq/xaNSGLoscSiCpbyZcxrTh8uqq9PNCJha38nTsxmcWYuFyhRhTpVnIwACDtp0alib/wXDfrWZrPrRfX+71SZWFJFlbG+VN3/fvGmHjxwvIijk8sbiioUrdbq5nS70tcRR75cRakio68jjlv3Nt/gC8Xwwkb0YbZ1USUakXD9zgF897Daq8Kiir2siD6VmKEBPkWaBklUeVxzqhjp9bliSx/OzOfw5LlFw/fyT52zp08F0IvqFQUoVWXx/8PId7Tor5dePGLYgTbcrS4JeNWpUutUOb+QR6UqI8bu/NBD0V/xqIREzJ3X+1du2mnL90mGoai+UUk9oIsq2WmgnAfiHes/xwxTz6i/ju5v7fu4hSQBnYPqtn/OoqiyQqKKB/MrEf9lo6hiNsaMelVyjZwqFP/V3vMtALoIBqivWUe69e8pSuq5T8VObLlSKYqCb33rW/i5n/s5O74dwzRFURQ88Fyw+1QAoL9LHcDN1ThVpjMF/PUPjgMA/tdP7au7oU9D0sU896pQT8hwT7JpXEw7s1XrVbn32IzHR2IOdqq0jlPxX5Tzv1ZUoc3CbADivy4sqkOb8XT9B0Mqqz88sXFZvR7/xU4VK9RGbrz68jFDgxQagAZ6eGETFxbzuLBUQDQi4YDWVWEV0atygntV7IYiEY1G2uwcUq/bpwIiqhTKVTxzXu2g2qikniBhxEyvCn3uFS2+zwFdmAXC7XhTFAXfOawOUm4zGP0FeO9Uqe1UqcgKJpYKG3w2ExbIqdIRD57ISeeUUlWGLCseH41FljaI/+roBxLqfbEtZfVBc6oANb0qFsvqvYz/imuiih3xX6JTxfg1BQDQqfV4NHSqUFE9P08hlgAi2vORXRFg5FTpMfm6MRvSkqhy8uRJfOQjH8G2bdvwhje8AYUC3+ww7nBqLocLSwUkohFct8P6VqbXDJJTpaZA+lP/cwzZUhUHtvQ1jEBJd3BZPaH3qQTHfeEFr71iDADwt/edwOcfOOnx0Rgnx50qLUPdTblSFQUbI7kaOVUoRz8fgPivCxT/1cCpsk8TVY5ObiyqLHCnSkvUiio/feW4oa9hp4oO9VhcMtbTtAC9GSSq/PjkPCrV8A6avUB3qhi7nu0c6gagxtLYee52imcuLKFUlTHUrUZ7NYOEEXKfNGMmU8SFpQIkCbh0vLeVQwWwRlQJsTj73PQKzs7nkYhFcIsJdz91qsx61KlSK6oAHAHWLgjxOYCLcqkaIagU1OsnxX/Vc6pIku5WWWoxAmxlRhMYJGDk4ta+l5tQr0rO4uJJ1mIXiR0k1HsKb+O/tLldI1FFdKqwUwWA/b0q7FRxBNOiSrFYxBe/+EW89KUvxb59+3DnnXfijjvuwPT0NL7xjW84cYwMs44HtOivq7enA73BTk6VhVwJVVnBMxeW8KXH1M2Pj7x2f8OyWd2p4s2Djp84rQ12OfprY9547Va892UXAQD+6BvP4h8fPu3xERmD3A5B/nfuNb2pmIj7WLRRiCVBc51TJU5OFf/Hf12o6VSpxyVj6uDuyOQyFKXx1iEJ42l2qliCusLG+lK4bseAoa/hThUd6lO5xmBXwkZcMtaL3lQMmWIFz04st/z9GB1aEjDqqu3vjKM3pX4udcf5mYOnFwEAV23rNxRvdtnmPkiSKhrNGIiYevq8Kr7sGupCT6p1AVuSpLYQZyn66+Y9Q6YG1d47VdSfS/cvLKq0B3SedKNPxW5qhdogCOF12aioHrCvV2Vai/7q36EPjoNAy04V7eu8jP/ytKienCpNiurZqaJCQljZLlFFe93YqWIrhkWVxx9/HL/1W7+FTZs24dOf/jR++qd/GmfPnkUkEsErX/lK9Pa2vjHEMEZ5UIv+ujnA0V+AHhWjKGp8zB9941koiuoquHaDwRJt9do5IA0qp7RBAztVmvM7t12Ed754NwDgI//1NP7txzZYtx1GOFUC+HDlFyRJEg4KOyPAmjpVSv5/oKQ4kbEGosqekW5EJFU02Wjox/FfrbGpTx3eve7K8YbLBGsRw9AQb5gbxY4+FSIakfCCneom5sMcAWYrK6IjzNhgW5IkcX49Obvi2HHZBTmmjER/Aaq4tGdYHRgYiQA7JPpU0paOrx66qBLe88h3D6uiipnoLwAY6tZdrjkPOtImteszuZKCICwyrUPxX0ZjEv1ELCKBbmECeU6pFPVNdhJP1mKXqDKlRX+NBij6C9DFkJxFUcWqw8MO4jZ2qlh13DRzqlS4U2UVdjtVMuRUYVHFTgyLKtdffz2SySQefvhh/PjHP8Z73vMejI7yi8G4T1VW8KPng9+nAgDxaERsIX7psbN4+MQ8ErEIPvCqjW2wLKronKb4r6EAbbl4hCRJ+F+v3Idf1QoZf/8rh/DVn5z3+Kg2RjhVAhgD4CfSNveqLGRL4vyzY7B+UX2uXN3Q3eEHzmtOlc3p+vFfqXhUDDUPbxABpjtVOP7LCr/14j340Ksvxu+8bK/hr0nG1VvYgscb5oVyFe/91yfwn0+c8+Tn50tVPHNBdZQYKQc3wgt3qUsdDz3PooqdZC3E2uhl9f4eKCuKojumTLwPL9d6VZ40EAGm96m0XlJPULF0YLfKmzCTKeInZxcBAC+7xNzwqzsZE6LTbMZdZ7wsK5jOqKIKuRfPslOlLRCdKgFcppIkSXfRBnHhY1l7Joyl1EL2eqS1WDC7nCojASmpJ4LcqUID+nIOkFt8f1oVh6hTpWFRPcV/8ZIaAN1dZFv8l9apwvFftmJYVHnZy16Gz3/+8/j4xz+Ob3/7274flDDh5enzS1guVNCTiuHyzfY9WHnFoGav//R3nwMA/PrNO7Glf2PXBQ3ulrioHqdEpwqLKkaQJAkfee0l+MUXboOiAHf825P45lMTXh9WQ6iXg50qrSGcKll7zhknNJfKWF9q3YMv/f+qrPh6Uy9TKCNTULdvx/rqO1UA4OJNWgRYgygkRVFEvxX11zDmGE934Ddu3W1qiOKXovqDpxfw1Z9cwF9+77gnP//QuUVUZAWjvUlsbuC4MovoVTm1wL0qNqLHfxl/n5Oo6/ey+vOLeUxniohFJFOixwHRq7K44ecpioJD58mpYt+9fyoebqfK0ckMFAXYPdyF0d76ywONkCRJRIDNuBwBtpAroVxVZw3XaiIdx3+1B9kSOfqCed8f6EhB0aeyRe1PqYftTpWAiSqtdKpUSkBhUf3Yk06VmllJJW/9+5QLQFF7JnLKqcLxXyqiB8cGt7Is66IKx3/ZimFR5b//+7/xzDPPYN++fXjnO9+JsbExvPe97wUAQ7m5DGMX1Kdyw65BxKKma4F8x4A2hCtVZAx1J/FbL9nT9GtEUX2biyqZQlkUaG7j+C/DSJKEj7/uMrzxmi2oygre8y9PiMxtv5E1GZfC1KffZqfKqQbRXwDQWVPU6ecIMIr+6uuIb7g5fnGTsvpcqSoKSdMd7FRxC78MLjLaOWrexmg9Mzx+RncH2HU/vn+sF30dcawUK8IFw7SOiP8y4VQR8V9z/hZVDp5ZBADsH+9dVdbcDBJIDp1b2nBhb2q5iJlMEdGIhP1jNjpVfCLOOsVcVh1QmRVUCL2s3l1RZVIrqR/qTmD3iDpUOu3zfwOMPeQDHP8F6OeUQhDPKRuV1BN2iCqyDMwcUT8eCVj8VytOFYoMk6JAKm3bIRkmVrN4U2pBpKbor2gCSJm8Hm/UqaIoQJXjv1Yh4r9sWCrILwCyFuXpRfxciDE1kd66dSs++tGP4uTJk/jHf/xHzMzMIBaL4fWvfz0+9KEP4eDBg04dJ8MIHtRElZsvCnb0F1Gbwf/+V+41VGDaR0X1Hg1x/ALlKw92JdBrQ2lpOxGJSPiTn70Cr79yHBVZwbu+eBA/PDrt9WGtg2IAgrqx5heEqJK155zRqE8FAGLRCBLawDvrQQ67Uaikfqxv42HTPk1UaRT/RUJVIhrh96mL+KWongZAS/kyZNl9F7foU7GhpJ6IRCS8YKcWAca9KrZBSwJGi+oB3YV70udOFavvw0vGehGLSJjLlkQcYz2e1JwsF4102xoL5Bdx1imoC4xc8WYZ1npV3BZVppd1MWir5t5fLlSEK5QJL9kAF9UDte63AJ5TmpXUA0B6u/rrypTqWLDCwkk1giqaBAZ2WfseXtFKp0pt9FfEg8XgSKSmV6UF54MoqR9t7GhqhHCqLK7/b9Wa8zs7VVTs7FShvqSOAf77tRnL/5pf/vKX45//+Z9x4cIFvPvd78a3vvUtXHfddXYeG8OsI1+q4rFT6oNb0PtUCCqC3D/Wi5+7ZoPNkBpoG3qxzZ0qJKpwn4o1ohEJf/bGA3jVZZtQqsp4xz8+jh8dt5gR6wCKougxACbiUpj1UCzVgk0DiY1EFUAXwfzsVLmwqD4MNotMumRMjf96fnoF5TpRSIs1fSrs3HUPGoZ63YVAwq+iAMsFd6/JVnssjEARYFxWbx9ZC0sCdH8zkykKp4sfESX1Jt+HqXhUCNeHNuhVeeqc/dFfQPiL6ue0RYpBi9GUFP/ldqcKOVVGe9WI0WHNMXN63t/iItM6ulMlmPf9wv0WxHPKkiaqNCqpB9ShOEUSLVnskpvWor+G9wHRgDmSWnGqrHjYp0KQqFJuwfkg+lQs/DmoU6W4vFpEAfQ+FYCdKoQQVWyI/6KS+h7uU7GbliXS/v5+vPvd78YTTzyBH//4x3YcE8M05LHT8yhVZYz1pbArJIP0X3jBNrxo7zD+9xsPIBoxNpCj0ul239iiPpXtHP1lmVg0gj//hatw2yUjKFZk/No/PIYfn2pQHucyhbIMSgMJagyAX+i32d1GnSq7huufh+n1yvlYVJlY0pwqDUrqic3pDnQloihV5brb4uRUqXUdMs7jl2ForsaNZZdoaZSTs1ks5MpIxCK4dNzeYTOV1f/45Dz3qtiEFadKX0dcDMT92quSL1XxrBYTZ0Xcu0LrVdlIVKE+lcu1z7ULParHv9eqVpjTHCYkSphFiCouO1WmakQVANg+oN7nc69K+NGL6oN535+M+2PhwxJLBpwqklQTAXba2s8RfSoBi/4CdKdKYXG9KNAMcqp0eyiq2BEnJcrOLURIpfoAaPOutW6VWlElxqIKACBup1OFXjfuU7EbW31nV199tZ3fjmHWQX0qN+0ZCs1G8JVb0/iHX30B9o/3Gv4aKqpvd6cKDRi4pL41ErEIPvN/XY0X7R1GvlzF2/7ux3jiTIMCORepjY7qMJHRzqyHnCp29D4oitL03x7FNvg5/ouiZsabOFUiEUlsUh+pEwG2UONUYdwjGfdHF0Lt4MSuziKjkEvlwJY+EblnF5dsUntVsqUqnuZeFVvIFrUNbBOiCqC7VU75tFPi0LlFVGQFo71JjDeJU6zHAdGrslj3vyuKIorsr9hsr3gY9qJ66h207lTxJv5LF1XUwdo2FlVcJ1us1HXnOg0tKgTXqRLgc4qRThWg9V6V6WfUX0cCVlIPaPFV2gwqZ3IJMduCw8MuSFQpt3A/IcQhC6JKJKr3sKztVaGSeimqfh5T83rZcO0TJfXsVLGb4Ld8M22F6FMJSfSXVfo69K1zLzLc/QLFf7FTpXWSsSj+9peuwQ27BrFSrOCtX3gUT59vvDXqBrmiHpUSMejiYuqjF9W3LsROLReRL1cRjUjYOlD/315XAOK/JrT4r/G+jUUVANi3SRW9j0ysHy4vsVPFE/zShVDrxnLbPWo1cskIkYiE66lX5XmOALMDcqqY7V4SvSoz/hRVqKT+6m39lhaeyKny1Lmluve05xbyWMiVEY9KuHisp5VDXUego3oMQE4Vq50qXhXVT2mdKps0pwrda5yZY1HFDbLFCm750x/gjZ99yPWfrTtVgjlU1fve/Hv/WxdFqRFVNnCqALroYlVUEU6VAIoqkageYWW2VyXro/ivVpwPIv7LYtm56FVZs8ApSur5eUpga/xXCw4jZkNYVGECw3y2hGe0bckb9wx6fDTeQqKKrAArPt4Edxra2mzU68CYIxWP4vO/ci2u29GPTKGCX/z8I5i3qdjcCqJPJaARAH6C4r/sKKo/Mave2G0b6EQ8Wv82gh6G/Rz/dWHJmFMFAC7RBnlH2aniG8ipUvDYqVL7HvfKqXKNjSX1tXCvir3QNc1M/BcA7BxShyAnDTpVFEXBfz1xHm+5+2FXXrtWe30uGu1GMhZBplip68ahWLCLN/UKEcQuKKqnGMSoHgOQU4UcJ2bR479c7lRZWhP/NchOFTc5NZfFfLaEJ88tuh7/aNXR5xfEwofH9yamyc4ClQIACejdvPHntuJUKeeB+efVj0cCGP8FWO9V8UOnSoJEFTvivyzGSJGostbpU9GuM1yirkP9RXYW1XezU8VuTIkqiqLgzJkzKBQKTh0PwzTkoefnoCjAvtEejPSYjxcIE6l4VEQWtGuvSrZYwXRG3WjYPsCiil10JmL4wq9ch60DHVjMlfHoSe/6VUQEAJfUt4xeVN/6YKRZST2gC2E5n4q+sqxgQhvajBmIq9k3ulH8l/p3mmaniqv4xamSXyWquHc9XsqVcWxKFTidcKoAuqjy2Kl5T2JgwgY5VcwOC3cOqQ/VRjpVjk1l8Aufexi/86Wf4EfPz+GfHraYeW8QRVFEXOhVFsW9eDSCS7UI3Hq9KofOLwIALre5pB4IeFRPExRFEQ6TIatOFVFU765TZTqzWlTh+C93Wciq1zJFgevLVfmyNUefXwhsTxP1qfRsaj7UbkVUmTkKKLI6WA9qDBH1qgTRqUJDelvivyz+Ocjp09Cpwn0qgoQNziKCnCo93KliN6ZFlT179uDs2bNOHQ/DNKS2T4UB0h1aWX2b9qpQ9Fd/Zxx9vCFuKz2pOPaNqgMOtyMfaqENcHaqtA5FU2UKrWdkUwTNRl1GnT53qsxlSyhVZEgSsMmAqHKxFv91fjGP5cLqc+6iNkjv5/OQq/hlGJqrGZwsuuhUOXhWfRjdOdRleWDajIs39SDdqfWqeBwHGQbEBrbJa9oOcqpsIKqsFCv443uexav//H48UrMM4XQPy5n5HOayJSSiEVy22Xg34FooAuzJOr0qh86q770Djogq1M3kz2tVK2RLVXF+HLToVBnWzi2ZYsW1IXGpIgtnzNpOlQuLeZRCKID5jdr+vRmXnwOyxWDf+yeD2tNkpKSeaEVUmdaiv0YuVUvvg0inlpiSNekEpU4VL+OX4jY6VVqO/2rkVGFRRZCws6ienSpOYUpUiUQiuOiiizA3xzEAjPuIPpWL2jv6ixBl9W3qVDmtDQq2c0m9Iwz3eFNOWku2plOFaY2+jrh4dmn1nCFi94aDK6pMaNFfIz3JhhFmtfR1xkUB89oIsAXuVPEEPbfc28FFvsaN5eb1+KAWuXS1Q9FfwJpeFY4AaxndqWKtU2UhV17nTlYUBV9/8gJe9mc/xN33n0RFVvCK/aP4u7ddBwA4NZuDojjXvUfRX5dtbi2a6wpRVr9avJNlRQh6l29OW/7+jQhzUT25SzoTUcsD6t6OGBLaNdKt+0FyqSSiEQxoLtvhniRS8QhkRRVWGGepjYqdczn6LV8K9r1/YHuajJbUA0B6u/rryqReLm6UKa2kPoh9KoRlp8rs6q/3AjucDxRjZjn+q5FTRTvXcKeKjq3xX5qoF1SHmI8x3anyJ3/yJ3j/+9+Pp59+2onjYZi6nJnL4cx8DrGIhBfsZFEFqCmrz3vXeeElJ7lPxVH0HG0vnSrBjgDwE9GIpJ8zWtymP6FtS+8KcPwXDWWM9KkQ+zbVjwDjThVv8Ev8l1edKq32WBhF71XxLgoyDCiKYrlTpSsZw4hWGF7bq3J8egW/9PlH8e5/eQJTy0VsH+zE3/3KdfjcW6/FjbsHIUmqg8XJTfODZ+wR98ip8syFpVUdDqfmssgUK0jGIrhotLuln1GPwA5ADTCXpZJ66wMqSZLE17vVq0Il9SO9SUjaNogkScKtcpojwBynNvLL7eeAbMDv/eneJHjxXwZL6gE1vinetfrrjCKcKgEWVax0qmQm9aG2VTHCDuh1sxr/VcoBJe05yGr8V6NOFYr/YqeKjl1OleKKXnbPRfW2Y1pUeetb34pHH30UBw4cQEdHBwYGBlb9j2Gc4MHn1YvWlVvTph9Gw0rbO1Vm1YcqKq9k7EXP0fayqN5aVApTH3JStJKPXanKOKNF723cqeJvp8qFRXUTdrzPuKhy8ZgabXNkYnnV75NIRb01jDvoueUeO1VWxX+5cz2uVGX85OwiAOdFlRt2c6+KHRTKMmTNMNJp4T6WzrenZrPIlSr45LeP4FV/fh8eOD6LRCyC37ntIvz379yKl1ysPiwnY1Fs1kTjU7PODaEfP70IoPX34a6hLvQkYyiUZTw3vSJ+n5wr+8d7DbkKzeIXcdYJSAQZ7GptQOV2r8rU8uo+FWKb1p/IvSrO46Wokg949G9g478oysuIU0WSaiLATPZ2TWmiymhAS+oB3WlC3SJG+M5HAaUKbLkO6Blz5riMIIb0Fs+jFGEWSwFJi5GfjTpVKuxUWUfcpk4VimyLdwHJnta+F7MO01erT3/60w4cBsNsDPeprIe2ztu1U4UiiDbqdWCs4wunihaV0slF9bbQ3xnHSbRWpn1uIY+KrCAZi2BTb+MuEiGqFP05qNKdKs37VIiLGzhVuFPFG/TBhZ+K6t0RoY9MZpArVdGTjOGiEfu392vZO9KD/s44FnJlHDq35LiIE1ZWirprrzNu/pq2c6gLj5ycx38cPIc//fYRXFhSB88vvXgEf3j7pdhWZ8Fk51AXzi3kcWo2ixfstH/xbaVYwdFJVWS+usX3RSQi4bLNfXjoxBwOnVvEJWOri+sPaE4WuxHnEY/FWSdotaSeGOp2Nw6WRJW19xjkVDnLoorj1HaquOVQIoLuVEkJ95s/738bQo6TtAFRhT5v5rC5XpXcvN7rMHKJuePzE9SpkjMYi3rmYeDQlwBIwKv+1NsuGYr/supUoeivrhHrfw7RqdKoqJ5FFYFd8V8Z7d8dl9Q7gmlR5Zd/+ZedOA6GaYgsK/iR6FNhUYVIa1vnbhbj+gkqqmenijO4/RBdD3aq2Eu/DeeM2ti9SKTxzbSI//Jp/MGENpAcM+NU0crqj05moCgKJElCVVZEcX1fBz8EuIkYXHg8DK11Y7nlVKHIpau292/479AO1F6VQXz7mUk8fGKORRWL1MZZWnnNdmhOlfufU++HN6c78IevuxS3XTIiIpLWfc1gF+5/bnZVZJidHDq7CFlRj2Wtq8AKV2xRRZUnzy3h59VKGDx1fhEAcPlm+0vqgRrHW9AGoAagLoyhFuK/1K93d8lmUhNVRnpXi0HbBtTr9WmH3s9B44dHp/HAc7P4/VddbLuLq7ZTxS2HEqA+85P7NKiiSmCFWjNF9YC1snrqU0lvC/a2fJeJ+C+5Cnzz99SPr/4lYPPVzh2XEeItxkmR48Fq9BdQ06mytqie47/WkaiJa1MU60KWeN24T8UJLE2qqtUq/uu//guHDx8GAFx66aV43eteh2g0mBc/xt88O7GMhVwZXYkortya9vpwfEM7O1Xypap46OJOFWcY0vLb3S6orIWdKvZC8VTzrYgqM8a6jHSnij87Vc5b6FTZNdyFeFTCSrGCcwt5bB3oxFK+DOqA5k4Vd/FLxMZqUcWd86XoU3GwpL6WF+4aEKLKu16yx5WfGTZWREm9tSWB/ZpzIxGN4B0v2oXfevEedDQZOu6oiQxzAnoftupSIahX5SnNnVKVFTx9fln7b86IKqmgDkANMLfSeqcKoN8PuuVYmNY6VdY6VbYPUvwXF9UDwJ9++yienVjGi/YN45aLWhhw1qE2/svJTqa11MZpBjb+Swi1Lp1TKiXg/OOqc8SoILKWUk53XRiJ/wKsiSqiTyXA0V+A3qlipKj+8b8DJp8CUn3Ayz7m7HEZQRTVtxj/1UovjHCqLK7+fS6qXw+JKnJF/fuxKjgJUYX7VJzA9NXq+PHjePWrX43z589j3759AIC77roLW7duxT333IPdu3fbfpBMe/Og5lK5ftegI3nKQaWdO1VOz6sDgr6OuHDsMPZCm4mZYgWFchUpC3ElrcJOFXvpt+GccXLWoKiSpKJ6f27/TiyZj/+KRyPYPdyNI5MZHJ3MYOtAp4h76knG+PrkMn4pg82XdOEwW6qiVJGRiDn7XnCrpJ64Ybc6QHjs1ALKVZnf6xagc6HVXsCb9wzh7rdei32jPXWjvuqxSztPn3RIVNFL6tO2fD8STo5MLqNYqeLUbA75chVdiSh2DTsTcxfmovpZ4VSxp1PFreH65FL9TpWtNfFf5BZtZ2ipjkQoO6mNsnRzuYqivyRJFzyDhi7UunRv8h+/Bhz+GnDbHwI3v8/a96Dor0SPOvw3ghBVzhr/OeRUGQ1wST2gO1Vy86oTJdLgGTk3D3z/E+rHL/mw/nVeIpwPFkUVEf/VgpDb2aConp0q60nUPG+Xstb/bkT8FztVnMD01eo973kPdu/ejbNnz+LgwYM4ePAgzpw5g507d+I973mPE8fItDncp1KftBY1s9iGThUqXd3B0V+O0ZuKIaENzryKAMsFPFfZbwinSgtF9YZFFU2E82P8V6kiY1qLszAT/wXU9qqo29PkTEh3sUvFbWqHoQrZhVxGUZR173Gn3SpTywWcW8gjIgEHtjqzvb+Wi0a6MdCVQL5cxaFzi678zLBBThWr17NIRMLL948aFlSAGqfKXBaybO+/EVlW8MTZRQDA1TY5prb0d2CgK4FyVcHhiYx4r126uQ9Rh2Luwl1UT04VmzpV3Cqqz9QXVbb0d0CS1H9LrdzHhAUSIOz+u1AUxbOielFSH48GVjRzXajddoP668n7rX+P2ugvo3/vLTlVAi6qUKcKlPW9ILV8/4/U/z5yKXDtr7pyaE2xLf7LBqdKOasLKQBQ1WZa7FTRiUSBmHYtLK1Y/z52vG5MQ0yLKvfeey/+9E//FAMDeuHh4OAg/uRP/gT33nuvrQfHMIVyFT8+parYN7Oosgpyqiy1o1OFSuo5+ssxJEmq6VXx5uGVNnutxqUwq7GlU8WoqOLj+K+p5QIUBUjEIhjsMnfjfrEWwUNl9QtZKqnnBwC3qd1iLVW92TJXBR31YxKhnV50OKi5VPZt6kVPyh0xT+1VUe/7Hz4x3+SzmXpkW4z/ssKW/g5EIxIKZVkMqu3ixGwWi7kyUvEI9o/32vI9JUkS3SmHzi3iqfNqDNgVDvWpAHqMYCGM8V/aYHzI5HVuLcMud6pMCafKajEoFY+KSLAzXFaPXFG9R57N2vu6rBQrKFd1EXYuW7JdlG1EVvszdQb4vt91F+3OW9RfzzysD6XNYrakHgDS29VfMxOrB+ONkGVgWq0OwGjA47+icSCVVj9u1Kty4SfAY3+nfvzqPwWiPnlPi/gvi6KKiP9qIUYq2QdI2j18rShVZadKXcitUsxY/x7sVHEU06JKMplEJrP+BV1ZWUEiwUMFxl4OnllAoSxjqDuJvaPOWP+DCnWqLObbb1vrlCaqUL4y4wwiR9vFkspa2KliLxT/ZXWrsVCu4oIWmxXk+K8LWp/KWF/KdGH0PuFUUe+DaIDOMYTuQ9uggHfRPbXv70196rBvweENaj36K+3oz1nLC3epm5kPn5hz9eeGBRqAWo3/skI8GsHWftWNZ3cEGEV/XbE5bWsc3IEtJKos4UmtW+Vyh/pUACAltsr9d61qFRJB6F7OKm52qmQKZRH9utapAugRYO0uqpQqslgmmLf5daFlEYqxrMqKa6kI+XLw7/t195tL9yUjl6rF3+UscP6gte9htqQeUN0a8U4Aii7KbPgzzqib9pE4MBiCbrauDXpVFAX41v8CoACX/Syw42ZXD21D4j6I/4pEdFGqVlQhcY6dKqvp36H+SqKkFVZs6MJhGmL6Lvi1r30tfuM3fgOPPPIIFEWBoih4+OGH8Zu/+Zt43ete58QxMm0M9ancvGcwsDZgpxCiShs6VTj+yx2GXN5OXIvYWONOFVvQnSrWzhmn53JQFDUabqDJ5qtwqpT851SZ0LZgx01GfwHAJZvUjeyTs1kUylU9/quD47/cJh6VREqFV70qVKqbiEVEGfSCw9fkx8+426dC3LBbFVUeO7WAUgj7J5ym1fgvq+hl9fYOoQ/aXFJPUFn9wdMLODyhxiwe0H7PCcipErZOlXJVFtd6s47MtdC94FK+7Pi//SmtH6QnGavr6tpOospce4sqtfdWczYL+fPafc1wd1KkIrj1HBCG+37qoHTtnBKJADtuUj8+dZ+170GiiNGSekCNCTMTATalRX8N71OdHkGHyurrOVUOfQk4+4gqOr38j9w9rmYkfBD/BQCdWupRba8KF9XXZ/O16q/nfmz9e6xoThUWVRzBtKjyF3/xF9i9ezduuOEGpFIppFIp3HTTTdizZw/+/M//3IljZNqYB46rG5Hcp7IeutEtVmTPi3rd5jQ7VVyBHsS97lTpCvDGmp+gTpUFi/FfJ2fVLNedw91NRW5dVPHfuek8OVVMlNQTo71J9HXEUZUVHJ9eEX+X5AJi3EOSJH0j1KPonnyNmy4tFh2c2+YulKt4WotEumbbQJPPthfuVWkNiv9y06kC6K5COn/bxU+0PpWrbCqpJ6is/sRsFqWKjJ5UDNsdXKAR/Qchi/8ix1xEaj2eMt0RF502czZHTa1lalmL/uqrf33exk4VALpIC9gvqtB7p78rri9XueRYp3vGUDhV3Hw233Gr+qvVXhUqmzcjqtR+vhFRZVorqQ96nwrRyKlSWAa+81H141vfD/Rtdve4mkHxX1adKlnNqdJK/Beg96rUc6pw/NdqtpCo8pi1r6+UgJzmMuf4L0cwLaqk02l89atfxdGjR/HlL38ZX/7yl3H06FH853/+J/r63CnMZNqDpVwZT2kP7iyqrKc7GRMPOUttVFavRhCpD13NIoiY1nAz8qEeYchW9hPCqZIvo2ohH/sE9akYGHDRlmGxIlv6WU4yoUWYbU6bd6pIkiTK6o9OZoQrgeO/vMH1jdA15GpKdWv/fTnF0+eXUK4qGOpOYuuA+fdvK0iShBfuol4VjgAzS9ajjjBdVLFvCF2uynh+RhVp9o/Z06dCjPSmRG8GoIosTjrVw1pUP6Mtwwx0JU3HXK4lEpH0JZuMs/eDJKpsqhP9BQDbtPuP020uqtQurMzbLHRRRGx/Z0J/3R2OtSTCEPub9OK+hHpVzj5irN9kLRT/ZaZTBbDmVBkNiahCZfXZNfdD9/2p6uYY2A3c8C73j6sZFP9VKQCyyeteKauXpbcsqmiLQXl2qjSFRJXJQ9b+fVMPTiSm/70ztmI5BPeiiy7C7bffjttvvx179oQgF5HxHQ+dmIOsALuGuzBuYfgVdiRJqtmMbR9RhbbTelIx3g53GNpQm2GnSiggd5uiAMsWBr+nREl9836r2gdiv0WAXVhUhzZjFuK/AAhR5cjksnAl8LnIG7weiNJgqyMRFcKaVSeYEWr7VLyIRNV7Vbis3iyiqN7t+C/N0UtddHZwajaLclVBVyJqSZxuxhU1HSqXb07b/v1rIadK2Irq57RlmKFue4ZTbsXBTmqiykhv/U1lcqqcbXNRZZVTxebFJxJVBrsSrncrhsGpkop7cF8yfLHacVEpmN9ml6vA8gX1YzOdKoAuqpAosxHTmqgyEvCSeqKeU2XmKPDw36gf/9Sf+NNxkahZjDMbAUa9HLEOINFi1zE7VYzTv1MV8aolYPJp819fG9kWsa8Dj9ExtC51xx13GP6Gn/rUpywfDMPUovepsEulEX2dccxlS47GjfgNGuzuGOzinh2HoYdxr4rqabOXnSr2EI9G0JOMIVOsYD5XEnFgRqGi453DzR1iyVgEEQmQFSBfqqIn5R/RgYrqxy3EfwHAxdpm9pHJDCpV1YVj9u+SsQevB6L5kp7/TsLaYta5JYfHNFHl2u3ebJrdoIkqj52eR7kq21pQHnaytCTgkVPlzFwOVVkRDudWODqVAQDs3dTTsguiHge2pvE/z6pDgAMOltQDqwegiqKE5r6SYrpIDGmVoZ4kMOH8ks201qnS0KmiiSqTywUUylXhVmw3ckV9YJ8rVW39u6BOlf6uBBTNaOxWDLDuVAnufb8nkYKSpJahP/OfwKn79Y4VI6xMAXIZkKJAt8loIKNOlUoRmH1O/Tg0TpU1nSqKAnzr9wG5Auz9KWDvK7w7to2IpQApAiiyGgGWMuE2rY3+avVaSaLKqk4VLqqviyQBm68BnvsftVdlyzXmvj5DokqL7iKmIYauWE888YShbxaWG1HGHzz4vHqR4uivxginShvFf53WyimdzNhmVIY9LKqvVGVRiMpOFfvo70ogU6xYEmJJVNllIHZPkiR0JmJYKVaEOOYXdFGlVadKRkRjcPyXN/jGqRKPCieYU04VRVEcKwc3yp6RbnQn1X/Xp2azuGi0x5PjcIsnzizgqfNL+KUXbm/5GYecKm4vCYynO5CIRlCqyriwmMfWgdbvnY5OqqLKPode/8s31zhVHBZVaAAqK0BFVhCPhuNZlmK6Bm1zqrjTsTepxfuONhBVBroS6EpEkS1VcW4hjz0jLW5LB5Rapwqg9qrY5RqjTpWBzoSYm7onqgTfqUL3JQW370t23KKKKifvB178AeNfRyX1vZuBqMnrU3q7+mszUWX2GKBUgWSf+nPCwFqnypFvACd+oAoCr7zTu+NqhiSpEWCljAWnio3DeSqqr3WqVLV5FjtV1rP5WlVUOW+hV0WU1HOfilMYOnP+4Ac/cPo4GGYVFxbzODGTRUTS4yaY9fRpospSG8V/UYQF96k4j5edKrmagscgb6z5jf7OOM7MAwsmt+mX8mXxPthh8N9eRyKKlWLFV/FfK8UKlgvq8Yw1KMJtxl5tkDiTKYpBKcd/eYP3nSrq618b/+XUksPpuRzmsiUkohFcttneHgujSJKEi0a78cSZRRybWgm9qPLBrzyFI5MZXL65D1dta03Ioo6w7qS7w8JoRMK2wU4cn17BydmsvaLKJmde/6u2pTHam8RIT8qReLFaknHdbVWshMd9Nas5VQa77BlOiSUbpztVMhuLKpIkYdtgFw5PLOPsfK5tRZW191VzK0Xb/q2ITpWuBGKaE82t54B8CEQVui8pVxXb3IGG2KmV1Z97FCjngbjB9wMJImajvwDdqbJ8QS3DjjUQcWv7VMKyhF3bqVLOA9/+kPr/b3wPMLjbu+MyQqLToqiixX912SCqiPivGqcKxX9FWVRZRytl9eRU6Rm173iYVYTjzpEJHRT9dcWWtBAOmPXoQ5w2iv/SRJXtgyyqOA3FRizly8I14hYUbRCLSEjE+FJlFxRTNW9ym55i94Z7kug2uGlNDqO8j5wqE5pLpScVsxxJ1pWMCaccbVWmO9ip4gXCqeJR/FehrA+ARFG9Q04V6lO5fEuf2K73gr0j6iCdIqDCzLQWfUnb860g4r88WBKwu1eFXnunnCo9qTh+8Hsvxr//5g2OpyAkakSUYtk/16pWEZ0qPcHqVJkSTpXGQ7VtA+qw+Ewb96qsdQDP2VgkT27Lga4EBrXXfc4lp0o2FPFf+jnF1WenwT3qJnq1BJx91PjXkVPFbEk9oLo1Yh0AFGD5XOPPm35G/XUkJNFfwGqnygOfBpbOAL1bgFuM1yZ4RlxbriibPIeSqGKHU0WIKov674miep79rWOzFvm1cFIV8szAThXHsXTFeuyxx/Bv//ZvOHPmDEql1Rfxr3zlK7YcGNPecJ+KMYRTpY3iv07NqjcAOzj+y3HSHXFEIxKqsoL5bAmbLG72W0F/sArutpofsTr4teIQ69Aeiv0U/3VBG9i0utG5b7RHRBECQLqLHwC8IOlFIWwNq4vqKf7Lmevx42eopN6b6C9ir+ZOODYZblFFURRxb2XHwFIU1XvQEbZzSL1fogjHVsiVKmKY7ZRTBXBvqBqJSCIereCR480JSPwYssmpQuKMk6KKLCtCyNzofpOWqmqvwe1Gdm38l41OEjrf9XcmROeQW06VMMV/AeriRYdbfxZJAnbeAjz172qvyq4XGfs6ElWsOFUkSRVjZo+pjpeBXfU/r9apEhZqO1Ue/LT68Sv+CEgEYOmTSubNOlWyDogquTpOFY7/Wk9HGhi8CJh7To0A2/tK419LYhg7VRzD9Prvv/7rv+LGG2/E4cOH8Z//+Z8ol8t45pln8P3vfx99fc7m3jLtAw0POPprY2iIs9gm8V/FShUXltRNc3aqOE8kIonOCLd7Vcip4sUAKsyQqDJvMv7rxIzxPhVCd6r4J/6L+lSsRn8RVFYPqG6qHn6feoInhbA11A6A9OtxCQq1+9qI6FNpMYaqVcidcCzkTpWVYgVVWX0dF2wRVby7plFk4ykbRJXnplagKGrHxqBNJeheI8TZEDpV7OtUcd6pMpctoSIrkCT959WDIuza2amSWyOqzGfte13ofDfYnRCvw8xK0ZHr2lro3t/t7ik7iUUjIvLL9WjSHbeov5683/jXLJ1Vf7UiqgA1ZfVnG3/OtCaqjFxq7Wf4EXKqKFWgUlD/7i99g7fHZJSED5wqdTtVyKnC7v+6WI0Ay5BThUUVpzAtqtx55534P//n/+DrX/86EokE/vzP/xxHjhzBm970Jmzbts2JY2TajKV8GWfn1cGXV7nhQaHdiurPzuehKEB3MiZKMxlnqX2gchN2qjhDf83g1wy04WzOqaK+djRM9AMTLZbUExfXbGinO+OOR9Qw9fG6qD4v4r9iQrAsVxUhttjFcqEsIpeu3p629XubZe8mdcPx1FxWxJ+FkdplFVucKto1ze1OFQDYKeK/Wh9Ci+gvB10qbiPE2TA6VWwSvnRRxTnHwtRyQfysjbpttglRxZ44uyCyUnQm/qsqK+KZsr8zgWGtW7FUkZEpOr8gQ32KnfFg3/unvLo3oV6V848bdyEIp4rFOZ4QVRqU1ecXgOXz6scjl1j7GX4klgQS2nVQigKv+tPg9MVQ/JcvOlVqRBV2qmwMiSpmy+pXtE4Vjv9yDNOiyvPPP4/XvOY1AIBEIoFsNgtJkvC+970Pn/vc52w/QKb9ODyxDECNZ6HOEKY+9PfTLkX1tGW5fbCTh5guIcrqMy47VUreRaWEGXpAvvfYDM6a2PIkUcVoST2gC2I5Hw1ezy+qQxt7RRW+TnmFb4rq41F0JqKin2HB5l6Vn5xZhKKow8SRHvdiGOsx3J1Ef2ccsgIcn17x9FicpDZWdd7G+C8vugJ2Dqvn7TPzOZSrrf1bodi3vQ71qXiBLs6GQ1RRFMUxp8pCroRKi++hRpCosqlBST2xvcap4oZ7wo/UXnsA++K/lvJl0F9pujOOVDwqevTceA7IiZjEYIsqSa/uTfp3AH1bAbkMnHnY2Ncs2uVUaSCqTB9Wf+3dokYYhYnuYfXXF/xGsKLNKKLM0/gvzalSyQNldeENVS6q35DNJKo8DsgGzy2yrIsqHP/lGKZFlf7+fmQy6g315s2b8fTTTwMAFhcXkcu1rw2XsY9nL6iiyiVj7FJpRh9tnbdJUT31Ouzg6C/XIEeQW3nKBLkb2KliL6+6bAw7h7owsVTAm+9+GOcWml+3FUURgqa5+C/1QdxP8V8TS+RUaW0wvX2wS2SNk/uHcR8ahnrlmKjtVJEkybFITiqp97pPBQAkSRID9TBHgNWKKq2KZMVKFeWqOqn0YlFgtCeFVDyCqqzg3EK+pe/ldEm9F4Qt/itTrKCkCR92OVUGuhKISICi2CMy1mNyuXlJPaAuRUQkoFCWXXdR+4UVTXwg145drwl9n95UTLiFBl18DtCvqcFeqPLs3kSS9AiwUwYiwApLQHFJ/dgpUWVKK6kPkuhglBd9ADjwZuAlH/T6SMxBooqX8V/JHiCi/Tsnt0pVu++K8bJaXUYvBWIp9d/t3HFjX5NfAGTtOdwOhxFTF9Oiyq233orvfOc7AIA3vvGNeO9734u3v/3tePOb34yXvexlth8g0348qzlVLh1nUaUZVFTfLp0qVEq5nUvqXcONHO16CKdKwB+s/EZfZxz/8vYXYudQF84t5PELn2surMyulJApViBJwDYT//b8GP+ld6q05lSJRvTBcl8H3/x7hdcb5vk1pbp6Wb29w6eDWs/c1T4QVQA9+uloiEWVVfFfLQ4TczXnwC4PFgUiEUkso7Taq3J0MrzxX2EpqidHQXcyJtx8rRKNSBjQOvacEjKmltXvO9rEqZKIRcQ1/EybltWT+ED9MnM2vSYkqtBrDejPAXb9jI3Q7/2DvVDlqYt2p4leFYr+6ugHkt3Wfl56u/prQ6cK9amEUFQ58PPAGz4LpALWKy3iv0ycP4srughjx3BektaX1VfYqbIh0TgwdqX6sdEIsBWtT6VjgMUqBzEsqpAj5a/+6q/wC7/wCwCAP/iDP8Add9yBqakp/OzP/iw+//nPO3OUTFvxjOZU2c+iSlOoU6Vt4r/mzEcQMa2hO1Vc7lQJQVmlX9nUl8K/vP2F2DHYaUhYoeivLf0dYvhkBNrIzvtk+1dRFFxYUjdhN7cY/wXom9rsVPEOzyI2NMRWbZxEFfV8uWDjNbkqK3jizCIA4BqPS+qJi7T3/nNT4Y3/qnUAtyqS0VZ5MhZBbIOuCCchUeVkC6LKQraEaW1gf1GInCqpkDlV5rL2Rn8RTveqTC2RU6W5k5SWq9q1rD67xqliV6dKfVHFveeAWvdnkBELH2UP7k3IqXLhCaDYZPFB9KlYdKkAulMlcwGo1HkfTmmiymiISuqDjoj/MnEPR9Ff8S7rAtxa1vaqcFF9c8yW1VNJfQ/3qTiJ4Tv7K664Atdffz3+4z/+Az096o10JBLBBz7wAXzta1/Dn/3Zn6G/3x8Pe0xwKVVkHJ9WbwD2c/xXU2iAkylWHMs49hMc/+U+XjlVaBAf9G01v7KpL4V/+Q1dWHnz3Q/j/GL9WJiTs+pNt9l/dzRozvkk/msuW0KpIkOSjA1tmvHqy8fQk4zh1r3DNhwdYwVRBuvRMLS2qB7QBbYlG50qx6YyWClW0JWI+sYdQIIiuRbCSG3811y21FJ3Aw0Kuz1cEqBlFLqPsgI5k7YOdHj6Z7Ebrx1vdkOOgsEuh0QVh7o1pjLGOlWA2rL6NhVVSiSqqAsidsV/kYBcz6ky42L8lxfdU3biaTRpeqvaraJUgdMPbfy5S9SnYrGkHgC6htVIIkXWC+kJRdE7VcLoVAkq5FQxE/8lor9sfOahXpX8GqcKOyoaY7asXpTUc5+KkxgWVe69915ceuml+N3f/V2MjY3hl3/5l3H//QZshQxjguemMyhXFfSmYtjS3/omcdjpTek3ncsFfwwunaJUkXFeywLfwfFfrqE/RLvdqaKVcLKo4hhjfR34l994IbYPduLsfB6/8LmH6gorJyz0qQA1RfU+if+a0Erqh7uTSMRa3xZ/ycUjePJjr8DtB8Zb/l6MNcipUvBiGxTr47/6HXCqUJ/KVdv6EY1Itn3fVtg7qm4pnl/MI1MIp1O21gFcqshi2GcFcqp0eli+TOfvVpwqIvorRC4VQI//CouoQsNvu/pUCKcdC5OaU2WkSacKoMdetW38V3F1/FeuVBXXo1YgcYauZYB7y1WKooQm/svzc4roVblv489rtaQeUGOc+raqH5NIQyydUztbIjFgaK/1n8HYi3CqWBBV7OzlWOdU4fivplBZ/dQzxl4/UVLPThUnMTxVuOWWW/CFL3wBExMT+Mu//EucOnUKL3rRi7B371588pOfxOTkpJPHybQJtdFfkuSP4YGfiUUj6NGElUWbM9z9xrmFHGRFHV4N9/DF1i2861Qhp0qwt9X8zlhfB/61Rlh58+fWO1Yog3+nWVFF22RuZRhpJ/TnGrMh+ouI+GTI3a7oG+ZeFdWvFn/1+C/7rseHtZ65A1v9k9md7kyIMunnpsMZAba2q66VTXBaEvDyerbDDlFlKnx9KoD35xG7EU4V20UVZ+8HKVpuUx/HfzWDhNrR3hQSWqTgXLb112WhXvxXj7MOJaJYkSFrhsCgL1Ql4x6fU3beqv7arFeF4r/SW1v7eY3K6qlPZfAidh/4CVFUb+J+QDgebBRVOjWniuhU0e6z+L3SmL4tqutErgATTzb//IwDrxuzDtOrml1dXXjb296Ge++9F8eOHcMb3/hGfOYzn8G2bdvwute9zoljZNqIZy9QSb1/hgd+h4pxF/Ph3BYlKLJi+2AXC24uMtSj3tjM50quRsxlfbDZ2y6M9XXgX97+Qmwb6MSZ+Rze/LmHRaE7oA/hdg6by9Dt1FwEWZ/Ef00sqX+mzenWo78Yf+B1bE+jovq1A/lWoEEjFTP7hb2aW+FYSCPAlvL2iSokvnkb/6UOoS8s5i0P+sipsjdkTpWUx443u5kTThWb4796nOtUKVaq4t/YaI/x+K/TAU/t/AAAs1RJREFUbSqq1EYKkgBiRwTYvLYQ0F8rqmgf29Xb0ojaBZzgx395fE4hp8rkISC/2PjzlmxwqgCNRZWpZ9RfRzn6y1eIonoTokp2Rv3VzuE8O1XMI0nAluvUj41EgFFRfTc7VZykpfyLPXv24EMf+hA+/OEPo6enB/fcc49dx8W0Kc9qG5ncp2KcvjYpqz81qz44cfSXuwx0JiBJaizuvItuKHaquMt4WnWskLDyC5qwUpUVnNLiNczGf3VpgpgdkRR2QEKR34bTjHU8L6ovry6q7xeiin3nyhlNVBnxmUNT9KpMhVNUqS2qB1obWK5oUT2dHooqw91JdCWikBXgrIVBtKIoQkC7eFO47tHD5lQhJ4n98V/OOVWml9XvmYhFhDi9EdsH1PuRmUzRN/cYbqEoilhW6UxGMaiJZ3M2iF2iqL6zjlPFYcc6ic/JWMQ3UZdW8dyp0jsGDO5Re05O/6jx54mi+hY6VYDmThXuU/EXCRJVTNwLLJxSf7Wzm6Mjrf6anwfkqvp+BYCYv+53fcfma9RfjZTVk1OlhztVnMSyqHLffffhV37lV7Bp0ya8//3vx8/8zM/gwQcftPPYmDZDlhUcron/YoyR7lBvfNcOAMLG6RqnCuMesWhEPFzZ8cBmFPHAGPAIgCCxVlh5890P4+CZBZQqMhLRCMZNxmZ1JPwV/3VBy2s3++dg/IunZbDQ39vr47/sW3IgUcVvsZd7tQioY2EVVbTXMKYN91rZ0ibnZbeHzktJkkQE2IkZ8xFgE0sFZIoVxCKS6ShIvyMGoCFzqgza7VTRvt+MAzFQU8vq9Xm0N2nIjd7XGRe9kmcX2sutki9XoWgxWV0J3alih5OkbvxXtzvxX2KZykPx2S5SXneqADW9Kg0iwKplIDOhfuyYU0UTVUYvbe37M/aS0JIHjMZ/TT4FPPVl9eNtN9h3HKKoflEvqQeAKMd/bYgoq3+8+eeyU8UVTIkqFy5cwJ133om9e/fixS9+MY4fP46/+Iu/wIULF3D33XfjhS98oVPHybQB5xbyyBQrSEQj2DNiLmamnelzIG7Ej9C2PDtV3MeLXhUq4QzDw1WQGE+r5fVbBzpwei6HX/7CowCAbYOdpjcHRVG9T+K/yKkybiCvnQkGXpbBVmUFJe3nUlQJlfva5VRRFMW3ogo5VY5NhbNTZVmL/6KYoYVWRJWS950qgN6LRXGqZqDor13DXUjEWgo68B2el0rbzGzWaaeK/Qs2k5qosqnX+PV5m/Y8cLrNyuqpT0WSVJfkIIkqNtyj143/0sS0bKnqqCtILCnEg79M5QuhdqcmqjTqVVm+oDoDogmga7i1n5Xerv5aK6pUy8DsMfVjdqr4i7gJp4osA994H6BUgUteB+x6kX3HQfFfuXk9+gtgUaUZ41cBkNT4vkyTXvOVafVXLqp3FMN3xa961auwfft2/OVf/iXe8IY34PDhw3jggQfwtre9DV1d4dpYYrzh2YklAMDeTd2IR8P1wOYkaYr/apNOlR0h25AMAtSr4qaowk4V79ic7sC//sYN2DrQIR5yrWwm66KKP5wqE4vsVAkbXkZs5Mu1+e+rO1Xscqos5ysoaV1WfhNVaPllJlO0Jcvfb1BPHZ377HCqeL0ksFOU1ZsfQusl9eFzknvteLMbchTY3alC56D5bBFVahS3iSkt/mvUhKhCEWDtVlZPS0ed8SgiEQmD3fS62OFUUc97tU6V7mRM/Btx8jkgJ86Twb/vF+cULyMFyaky9ZReBF6LiP7aAkRanLtQ0f3yeVVMAYDZ5wC5DCR6dCcL4w8SJjpVHv874NyP1dfxVZ+09zioqD6/oJfUA0C0eQRkW5Ps0YXKjSLAiitASVt84qJ6RzF8Bo3H4/jyl7+Mc+fO4ZOf/CT27dvn5HExbcgzF7hPxQpOFOP6jXJVxrkFdct8B8d/uY5u/fegU4WdKp6wOa2W128dUAWIfRaKiTt9FP9VrsqYyqiiyhgX1YcGEbHhwTYoObAkSR+g0PV4uVC2Zeg4rb1n+zriYpveL3QlY+L8ELYIsFJFXicot+RUEc5Lb19Dun86NWvdqbJvNHxO8pTH3Ux2UqrIWC6o56bBLnuFWBq0ywqwYHPHnh7/Zfz6vFVzkVnpCAoywvmm3R/bFf9VrFSFC6a2U0WSJPEcMOOkqCLiNIN/3y/OKV46VbpHgOGL1Y9PPbD+v9tVUg8AXSNqubgiqw4YoKZP5RL1RonxD3FtltIs/iszBXz3/1Y/fumHgd5xe49DFNXPry6p5/dLc7ZovSobldWvaH0q8S5ViGEcw7Co8rWvfQ2vf/3rEY3666GOCQ/PaqLKpeN9Hh9JsKBOlTA7Vc4vqIXZqXjEd2W97YAn8V/aQ2MYYgCCypb+Tnz5N2/Eh19zCX715p2mv76rJv5LUezdajXL1HIBigIkohEM2TxoYryDnCpebINSDEpnPCo6AOh6rCh6fFQr+DX6i9AjwMIlqtD9lCQB20PkVNlhQ/xXmJ0qYSiqJ7dCLCKhr8Pebd94NIJ+TTi2+35wykr81wDFf5l/PweZ7Jp4XLviv8ilEo1I6EmtPleR68nJbkU9JjH49/2+Oads1KsiRBUbXCSRiO5WoQiwqWfUX0c5+st3JDRRpVn8139/CCguAWNXAi94u/3H0VHHqcIl9cbYrPWqbORUoWgwLql3HM5YYnzDsxNcUm8FvVMlfPEbBA0Atg90IWKy14FpHTc21NbCnSr+YLQ3hV+/ZdeqKAijUHm3rHi/AXxBi/7a1Jfic0iIEIMLT5wq67dqE7EIurVzlh2b3NOaqOLXZYK9mqhCA/ewsJRXX7veVBxD2rmvldfTb50qE0sFU90IlaqM4zNqhIQV16Lf0QegwXeqkNgx0JVw5FrnlHN5ckm9Ro/0Gj/Xbdc6Vdot/kt3qqj3WHbFf9HX93euf++4sVwlFhVCIaqof4aCl04VYONeldr4LztYW1YvnCpcUu87KP5LLq+O3arl+PeAp78MSBHg9j8HIg78uySnSrWkCisA96kYhcrqLzwByA3u58ipwiX1jsOiCuML5rMlTGg31BdvCt8Dm5PQJtpiiJ0qFFWxY4hL6r1gsJs6VdwR7hRFCdXGWrvSWTNA9DoCbGJJK6nn6K9Q4WXBdK7BAIiuyXb0qvjeqbIpnE4VilNNd8aFoNzKwHLtZrlX9HfGxfvTjFvl1FwOpYqMzkQUW/rD10mV9ENUj03Q0HvQ5pJ6gobrc1l7h+skIFtxqpxdyEO2uePFz5Dzje6x7Ir/IuF4oGu9w0kX05wTVbIhiv/yjVNl+83qrzOHgZWZ1f9t0cb4L2C9qDKliSrsVPEf8Zoo9XoRYOU8cM/vqh+/4B3A+JXOHEeiSxdRVjRXBTtVjDF8MZDoVjtTZo7U/xwhqnCfitOwqML4Aor+2jHYiZ4Ul1OZQRTVh7hT5dScuoXGfSreMOzCw1QtxYoMej7uZKdKYIlGJPFgSXFuXnF+URNV+sI3EGxnUl4W1dMAaE1EYb82kCK3QyuQO3DYoQFpq9Q6VbyO+LMTiv/q64iLpYLWRBV/LAlIkqRHgJnoVSHR7KLRnlA6/XwzALUBimeyu6SeGNIE3hkb7wcVRRFOFTOdKmN9KcQiEkoVvTOtHSAnN7ki7YrmqnWqrGWoh5arnHSq+OM8aQe+6WnqGgRGL1M/XhsBRk4Viu1qlVpRpbAMLGniygiLKr4jlgAi2vN1vQiw+/8MWDgJ9IwDL/0D545DknS3CkVVsVPFGJEoMH6V+nGjCDAR/8VOFadhUYXxBc9OLAHg6C8rpLWb3zA7VSgveTuLKp7gdqcKDaAA7lQJOp2iV8Vjp4oW/zWeZlElTNQ6Vdwe6ovepzUDIBpIUT59K0wvm4/EcZNdw12IRiQsFypi0zwMkFOlryMuXs+lfBnlqrUB2YpPOlUAYKcWmXTShFPliBbvdnEIo78An5RK2wTdpw055lSx37mcKVaQL6v3CGZElVg0gs2ac+rMXPtEgK0Ip4r6viWnSr5cbWmBRXeqrB9qDnbRc4BzjnU9UjP49/2+ihSs16uiKDWdKnaJKtvVXxfPANOH1Y97xoDOAXu+P2Mv1KtSXnPunDkKPPBp9eNXfdL5gnPqVSFXBTtVjEMRYI3K6oVThTtVnIZFFcYXPMMl9ZZJd9JWbDlUm6K1nBZOFY7/8gLaUJvLllyJWMjVbIBHQ7gV205QPIXXosoFzakyxvFfoYKK6hUFKFkceFuFhoBr479o0cGOThXhVPFp/FcyFhU9HWHqVaEllXRnAunOBCTtMmT1NaXznx9EFUtOFe213RvSeN5QOVU0t8GghR40IzixZDOluVR6UzHTA3VRVt9GvSq5NR1N3ckYElH1PdyKW4W+tr/Oe4ccSk4uV4nzZBjiv7R7k0LZB+eUer0q+QV9mN672Z6fQ06VpTPAtFZSzy4V/0IRYKWaewFFAb5xh9q1svengEtud/44hFNlQv01yok1hmlWVs9OFddgUYXxBRT/tX+MnSpmoXzsqqyI7aUwUanKooSShgGMu9CGWlVWXHFErS3hZIKL7lTx9tx0YYmdKmGEhqGA+xuhjUp1KZJz0c5OlW7/ioF7R7sBhKtXheK/0h1xRCOSeE2tuo9E/JcPrmkkgp00Iaoc1V7bMJbUA952M9mNcKo4JMQOOyCqTGqOvE195s9zoleljUSVlTUdTZIk2RJTKJwq9eK/up2P/2rk/gwiKT+dU7bfCEAC5p4DlrXBNfWedI0AcZvuL8jxsnQemDikfsx9Kv6FyuprRZWf/DNw+gEg3gm8+v+B2ChxEnIyZTRXRdSfS0S+hJwq04eBYp178JVp9Vd2qjgOiyqM5+RLVTw/swKA47+skIpHRa68HUMcv3FhsYCKrCARi5gqsGTsIxGLCPHOjQgwKvXtDMG2WrsjRJWiP5wq3KkSLhLRiHjmczu6J9egVLdfc48u2tCpQpFafo3/Alb3qoSFJW24SNc9vQja2vUvu2az3Et0UcXYELpQropS+31hdarEfRTV0yIUz+SYU8WBbo2pZfV7mYn+IkhUOdNGokquzuIRnaNaEVXoa+vFf+limnPxX1nhVAm+qCLOKX5wqnT0A2NXqB+fekD9lfpU7CqpB9TBbTQBKFXg+PfU3xu51L7vz9hLXBNVyLGUnQP+58Pqxy/+gO48cpqOtPprhovqTdOzSRMzFeDCE+v/+4r2d8qiiuOwqMJ4ztGpDGRF3YIZ8WnEhd9Jd+iZ32GDHua3D3SGsiA1KLixpUY02gBngoeI//LwwTJbrIhz4zjHf4UKSZI8i+4R8V/xRvFfrV2Pi5WqWJTwa1E9oLsXwuRU0eO/VosqVpwqlaqMgib4dfso/mt2pYhMofmf57mpFSiK+nfgVPm519A5xBdRPS0y53inijZcz9g3XJ9aNl9ST4j4rzbqVMkW18cJDtrgINqoU4Ve96V8GSWHxEf93t/782Sr+M79JnpV7lN/tbukHgAikRq3iuaEYaeKf0moLmPhVPnOR4D8vCqEvfC33DsO0anCRfWW2HyN+uvaCLBKCcjNqR9z/JfjsKjCeA5Ff10y1gvJDZthCOmzMW7Eb3BJvT8YcmFLjaCtXhZVgo/uVPEu/mtiSXWp9CRj6ElxVm/YoOFFwXWnSoOi+i66Hrd2rqR8+3hUEsN9P0I9G8emVlzp3HIDEmHXOlXmLThVsjV9Up0+iP/qTcWFi8HIILo2+ius9+iiqN4vA9AWcL6oXv2+c9mibT2OJKpYcaNvG2y/+C8RJ1hz7Rm0xaminvfqdar0dcQR0xbbrDr2mkF/Lj+cJ1tFLHv4Rajdeav6K/Wq2F1ST9S6G6QoMLTP3u/P2Eeixqly6gHgJ18EIAG3f9rdXhPqVMnOqr+yU8UcWxr0qmS16K9ITBeuGMdgUYXxnGcuLAHg6K9W6LMxbsRvUETFziEuqfcSUVKZcd6pokcbBH9brd3pEJ0q3j1YXljkPpUw45VTRY//auBUsdi/QUyLPpWkr4fZ2wc6kYhFkC9XcW4h7/Xh2AItqKwXVcy/pnQ9i0clIQB6zQ4TvSpHJ9XFp7BGfwE+HIBaRFEUIcYOOuQqou9briq2ueMnl8ipYn6YRk6VuWwplL2S9cjWuUe2I/5rIdu4UyUSkcTPsNOlVItwf4Zgocp3Qu22G1SRY+Gk6lJxQ1QZ3G1fXwtjPxT/lV8AvvE+9eNrfgXY+gJ3j4M6VaCJ9OxUMceW69Rfzz8G1C46rGgdNd2jqouMcRT+G2Y859kJ9YHt0vE+j48kuNhZjOs32KniD5woJ22E3qkS/Aerdoc6BPIeDquoT2WMo79CiVfDCxFVsjb+S7setzpwFCX1Po9FjUUj2DOsxkgcDUkEmCiq14aLLTlViv5bEtgxaEJUmVI7D8MtqvhsAGqR5XwFFc0tVi/CyQ6SsSh6U+p72a77wamM9U6VnlRc/FnPtEkEmHB0JGrjvyii15rgoSiKEGTIbbkW4Vh32qkSivgvn/U0pXqB8SvVj0/eDyySqGJjpwqwWlQZ4egvX5PQ5ioPfQaYPQZ0DQO3fcz94yCnCsFOFXOMHVDdKCtTeqwfAGRIVBnx5rjaDBZVGE+pygqOTKgP4fvH2KliFYoGCXOnyg4WVTzFzU6VnI9KfZnWoC3+rIcbpBeW2KkSZvQtc6+K6tfEf4lOlda2eXVRxf9i4L5N4epVWVrXqaI+5M9bWFxZof4DH13Pdg2r91OnDIgqxybV13TvaJhFFfUcUpEVVKo+GYJaYEa7P+tJxYTY7ATkXJ6xybEwtWS9UwUAtrZZWT1de2o7mgZbEH4BNaawpL33B7vqDzWddqyHqU+Riup91dMkelXud6ZTBQDS2/WPR7mk3teQqLJ8Xv31lXetFzjcYO3PZKeKOeId+r+18zURYKKknvtU3IBFFcZTTs5mkS9X0RGPYucQD82tQtuUfhdVTsys4NpPfAcv/9S9uOubh/HwiTmUN3iArcoKzs6rW+bbBzn+y0tc7VQhp0oIcpXbna6kH+K/1HPIeJ//h9OMecTwwqui+jXDchJVcqVqS5Fk0xl10Oh3pwqgD9zDIKrIsiL6cPT4L/VXKwPLnHCq+Od6JpwqcxuLKku5Mia1vou9o92OH5dX1AoQvtkst4DTJfXEkI3O5aqsCDFok8Vr9DYhqjQXCcPASp3uERJ+5yzGf1H0VyoeWbcoQAy16IZpRjZEokpKc7/5SqjdqYkqz39f71uwPf6r5vuxU8XfxGvmKrteDFz+c94cx9q+DxZVzLO5Tq8KOVV6Rt0/njbEP2tTTFtC0V8Xj/UgGvFvZrjf0Yvq/d2p8uDzc5hdKWF2pYTnplfwt/edQG8qhlv3DuOlF4/gxftGVkUWXFjMo1SVkYhGeMvcYwZdjP9ip0p4oIEzvaZeQEX1fA4JJyK6x2WnSqOt2p5UDBEJkBU1knO019qAKCjxX4A+cD86GXxRZaVUgZagVCOqaANLC8PEFT/Gf2kddc2cKhTntjndgZ6Ui8W1LpOI6TuGxYqMBov6vocG6oMORX8RdsbBzq0UUZUVRCTrx729TZ0qXXXiv6ycowC9i6VenwrhdAywfk31z7nSKrTsAQClqoxY1Ad7zFtfqMYEZSbU/x/vtN+ZUBv/Ncqiiq8hp0o0CbzmU4BX3X0c/9U6W64FHvv8alFFdKqwU8UNgn/VYgLNsxdUUYWjv1qjLyCdKsuak+aqbWnsHOzCD45OYyFXxjcOTeAbhyYgScBVW9N46cUjeMnFI+Imf+tAB4tuHiM21Fwoqs+G6MGq3emI+8Gpom5aj/WxqBJGvCuqV4fla7d6IxEJfR1xLOTKmqhibfuaiupHAiGqqE6VEzNZlKsy4n4YIFlkSbuPSsUjwsEw0EKkW9aHSwLkVFHfoyXhdl5LO5TUA0A0IiEelVCuKq6fR+xk1jWnin1xsOSEGu5JWh48606VfMvHEwRW6rjfBlssqp/PUZ9KY1Fl0MEY4HJVFvFjYXCqJGrey4WyjA20KvdIdgObrwHOPqL+/76t9g/Se8aAXS9Rv296h73fm7GXnS8CHv4b4KUfBgZ3e3ccnexUaRkqq5/4CVAtA9G4LqqwU8UV/HOHz7Qlz1xYAsAl9a1Cud+LPo//yhTUB4Grtvbjo7fvR1VW8JOzi/jBkWl8/8g0np1YxsEzizh4ZhH/+3+OIaVt+nCfivfUxn8pigLJwY0WP8alMNag1zDvkaiiKIqI/9rMTpVQ4lVRfW6DqJL+zgQWcuWWelWC5FTZnO5AVyKKbKmK03NZ7BkJ7hCeYlRpWQUABrr1gaXZ6x/FWfrpetaVjGGkJ4npTBEnZ7O4alsDUUVzqoRdVAFUx1u5WnHd8WYnFMtEw2+nEPeDNnSqTC1bL6knRKdKkzi7MFCuyihp17rVThX1NcmXq8iVKqaXkua1987ABqIKve5W3TAbUbt4E4aFqlg0glhEQkX2mVC745YaUcXmknpAFVPe+l/2f1/GfrbfAPz+Ke8cKkS8A4ilgIoqsLNTxQIDu4FUH1BYAqaeAcavBDLUqcKiihsEd5WMCTyKouhOlXF2qrRCukPrVPG7U6WgHl9PSr1hjkYkXLO9H7/3yn345ntvwUMffCnufMPluO2SUXTEoyhoD7d72+CB3u/QYK9UlbFccDbKqVEBNBM8OrSH46xH8V/z2ZIYto/28Y16GNGL6r3qVFl/nhKLDm0iqkQiEi7S3CpHJ1c8PprWIMcv3VcBulOlXFXElrhRskX/OVUAiB7DUxsMoinObV+IS+oJ3fEWXFHFtU6VHvtioMip0oqoQp2L5xbyqFJ2X0ipFR9qIwW7ElERY2dF9KAFgP4NLBV2dumshRZvYhFpVRxfkBELH34SaqlXBbC/pJ4JHl4LKkRtr0rU//e8viMSUV1oAHDux+qvHP/lKuG4ajGBZCZTxFy2hIjUHg9sTkIDHL8X1ZNTpbejfjb3WF8H3nL9Nvy/v3wtnvjoy/EPv/oCfOS1+/GOW3e5eZhMHVLxKLq1Bzine1Xq5UUzwaQr4a1TZWJJjxah7g0mXHg1DKXzVG3JNdEv4qKsXZMVRRGiShDivwD9Pu5owMvqhVOlU79P6UhERZSh2XgdirP0U6cKoIsqJ2fr91AoiqKLKm2w2EL/jgsui7N2osd/ueRUseFecFqIKtbPc6O9KSSiEVRk3ZkaVkikjUdXiw+SJIkIMCtl9aJTxYBTxYlnAFq8CUP0F0H3JgU/OVW2Xq/HKznhVGEYK9T2qsQ4/ssSVFZ//nFAljn+y2VYVGE84xnNpbJ7uJs30ltEdKrk/V1UT50q5FTZiFQ8ihftHcav3byzYd434y5u9aqE8eGqXaFzu1edKue1Act4n/UtWMbfiKJ6l0WVjUp1+zpb6zlbzldEvrzTW+d2QY7S5wIuqtB9VN+a5Y8Bi50FWR8W1QPADnKqNCirn1wuYLlQQTQiYddw+CNYw+FUofgvtzpVWn/mmNQWHza14FSJRiRs6VfjPc+GvKyeurzqnU8GRUyh+Xt0cqpsKKr06OdAux1BYSqpJ3QXrY/OKfEOYPuN6sdD+7w9FoYhantVuFPFGtSrcu4xIL8AyJqrumvEu2NqI1hUYTzj2QmO/rILcqoUyrKvt+wyWvxXb6q+U4XxNyJP2WIRplFyRX9u9jLmoQdkr0SVCRJVuE8ltFD3lpvxX4qiiOFWo04VwHr818yKOmjsTcXqOmH8SFicKnr8l82iis+WBKir7mQDUYVcKruGutrC5ZcQoop/76GbQfdmzhfVq99/ZqUIRWltuD6Vab1TBQC2DVJZfbhFlZViYyf3QJf1zhM6r21UVD/QmYAkAbJi/jzYDDpPdvqoe6pVvOp7a8rr/gp4/WeAi1/r9ZEwjEpHWv+YRRVrUPzX3HPAzBH1444Bdv64BIsqjGeIPpUxFlVapTsZQzSi5mL6OQKMujh6DThVGP/hpPW/FnaqhIcu4VTxplPlgrYFO9bHokpYSVJsj4uDi1JVBi3q1nPa9muLDlaL6qe18uaRFgeNbrJ3tBuA6nzw83JHM8hRm+60SVTxefzXqdls3cH4MU0ca5dOu6Qf+w9MQi5ip4vqRcdeRUbGZMfQWqaWWu9UAYBtWln96ZCLKjnhfFt/3RlqIf5rIaue9wY2SAaIRSNiYcDu54DcBh1lQcW3Qm16K3DVL6o9DAzjB2o7Vbio3hpdg0D/TvXjo99Uf+3hPhW34LMp4xnPXFgCAFw63ufxkQQfSZL0CDAfl9VnRFE9O1WCCFn/nY7/yvl0CMWYhwbOWY+cKheEUyU4w2nGHF4U1dd2BHXWcZKkW+xUmdEGVsMBif4C1EFrujMOWQGenwluWT3dQ9kd/9Xts+vZ9sFOSBKQKVbqDmGPtFFJPRD8+K9CuSoEjqEuZ88bqzr2WrwfnMpo8V8tRnSSqBJ+pwotHdVzqlg7RwHAnBYZ1t+18fMZRb9ZccNsBDnUQxX/JXqagnlOYRjXqO1U4aJ662zRelWO3KP+2s19Km7BogrjCSvFCk7NqTe+l4y1xwOb06SFqOLfXpXlPBXVh+emuZ3QIx+cfY+JGIAQbay1KxRRUarItmdwG+ECx3+FHi+GoST8JqIRxKLrb6XJ5bBkVVTRBpXDASmpB9Tljr3aAP5YgCPARKfKmo1tqwPLFZ/G2qTiUYxrDr56vSr0GrZDST0Q/KJ6el/Go5Ir99h29KoUylUhYo722COqhL9ThZaO1p9PBloQPGgBYLCJIOeUY32jOM2gkvKrU4Vh/EZtpwrHVVmHelUWTqq/slPFNVhUYTzhiNansqk35XihYrsginF9Gv9VrsrIaw+r7FQJJm7Ef1WqshiO1suMZoJFbTSSFxFgE1q0CIsq4cWL3HIabNWL/gL0ThXL8V+aqDISIFEFqOlVmQyuU4UiVO3qVNmoWNprdgypg+i1vSpVWcFzU+pryE6VYED3ZYNdSUiS5PjPs+N+kGIOU/FIy0IQdaqcngu3qLIiOprW/32RQ2nOZFF9VVbEQl5zp4pTokrjrpigEoZIQYZxBXaq2MPma1f//24uqXcLFlUYT3hG61O5lEvqbYMGAH7tVMkU9IFqD3eqBBI3RJVczZao3zZ7GfMkYxFodU+ul9VXqjKmljVRpcVoEca/0DDUzQ1ziv/qaFAinxadKu3jVAH0/g2rTpVMoYy7vnkYT55dtPGozGF//Jf6XvFb/BfQuKz+9FwWxYqMVDwiHABhJxnwrXJyJzjdp0LYcT84uaz3qbQqBNH7dClftuwQDAIbibRWz1HL+bLoCOvfoFMFqHWsOyOqNFpUCCLi3iSg5xSGcY0OdqrYwqbLgGjN3183O1XcgkUVxhNEST2LKrZBGe5+fZigPpWOeBTxOnEpjP/R4x6cE1VoWBmNSEjw+yTwSJIkNg/dFlWmMkXIihqHMsSOyNCSjHnhVNk4qoQGU4u5Ut0S8GaQqDLSG6z37b4W47/+/LvP4W/vO4Hf/49Ddh6WKZYaFNXTazpv0n3k5zhLUVY/t1pUOar1qewd7UEk4rzrwQ94cR6xE7ovc+taZ0fHXq2o0iqdiZj4s4e5V4VEWjvjv+ic1pOKNX0+I9FuNmNvDHA+hPFfet9bMM8pDOMaq5wqLKpYJpYENl2h//8e7lRxC55YMZ7w7AQ7VexGFNXn/dmpwn0qwUdsJtr8MFVL7QDKjQgLxnlEWX3R3fgvcqmM9KTaZjDYjiTj7m+Yk6OuWfxXRVaQtSAmTmvlzcPdwXJY7R3tBgCcW8iLmBqjTGcK+KdHTgNQS9KPT3vTy6LHf61+sKdhYliK6gFdVDk5u3oIfXSqvUrqAf08EtROlVmPnCqtdOxN2yiqAMC2ATXmM9yiiv3xX3ROI6fLRgx3W/sZzaDrZJiK6r2IJmWYQMLxX/ZBvSoAO1VchEUVxnXKVVlswe0f6/P4aMIDbVUu+typwn0qwWVIi6LJl6uODcjDmKvc7tDmYd7lYRVtaw65NGRivEFsmLu4DVoQA6D6okoqHkFC21JdMDmEB4Ib/5XuTGBUc9c8Z9Kt8rf3nkCh5jX8+pMTth6bEYqVqrgGrY3/Ek4VE6+nXCOq+XFYuEMTVU7PZVc5qtqtpB4AUgF3qsy57VSxI/5L6zzbZJMjb7sWZxdqUUUU1deJ/9LudQpl2VSHHZ3TmkV/ATUOJYfiv0LpVOH4L4bZGC6qt48tNb0qXFTvGiyqMK7z/MwKSlUZPckYtvRzebBd6E4Vf4oqy1qnSi/3qQSWrkQUKW2b06kIMOFU4T6V0NDpUfzXvLZJaWT7kgkuYsPcTaeKyH+vfz2TJAn9FhcdShVZdLEErageUCOjAHMRYNPLBfzTw6pL5Weu3gwA+PqhC5ai01qBXCqStL77bVA7j2QKFZQMDt5rhWQ/OlW29nciIqnv5+maGKcjk+0nqgjHW0Cjeuay7i4R2CGqTGnvObucKlu1XpUz89kmnxlcNooT7EpExSDfTAQYCf+DBu6VnHKsN4vUDCK08FEI6DmFYVyDnSr2USuqcFG9a7CowrgO9alcMt7LkSw2Qk4Vv3aqLLNTJfBIkuR4WT07VcIHPSTnXI7/0uNQ+AY9zHiRW07xX50NiuoBfet3wWQHB51b41FpnVsiCJCocnRyxfDX/M29z6NYkXH1tjQ+/vrLkIxFcGImK6Ji3WI5r5fUr70/7euIg35r0eBrSgPQiASxkOAnErEItvSrg+gTM+ogulCu4pRWXN9W8V8B3yqn88ZglzvXu2EbHAtTS/bGf20Xokp4nSokPtQTaSVJEsLInAlHHXWq9JsQVeayRVtF75yPHX1WSXkQTcowgSSWBDqH1I870p4eSuDp3wHc+n7gJX8AJNvnHs5r/HeHz4SeZ6ikfoz7VOyE8r/92qmSIadKAIdEjI7I0XaoVyUbwm21dqcz6ZVTxfj2JRNcvCiYNlKqKyI5TbpHKfprqDsZyMUTs2X1U8sFfPGRMwCA9718L7qTMbzsEnW7zu0IMHIV1ROzIhFJCGVGB5YrNf0Hfu0I27GmrP749ApkRX3/Bi1+rhWCX1TvTadKK46FKa07alOfTZ0qg6qocnouh3JVdt3p5gYrws1dX3wYEN1PxsWuBROdKvQ55aoinH12QGJRV4hc6kE/pzCMq7zx74Gf/TxHVtnBSz8MvOh/eX0UbUV41gGYwEBOlf1cUm8rfeRU8Wv8V56cKnzaCTJDDpVUErli47xoJpjQNr+ZjG87oIx5t4ZMjDd4sQ2qx39tIKrQooNJpwrFMAUx+gsA9mqRUUcNiip/88PnUarIuHZ7P27eo24q3n7FOL751CS+/uQF/P5P7XNNkCBRJd1g+WOgK4G5bMlwr0pug/4Dv7BrqAv3HZsR7pRjNSX1fhWCnCAV+KJ6bzpVqGPP7HtcURTRqTLaY1dRvSqqnFvI46I/+BYA1SUWi0QQjUiIRSREoxJikYj6cURCLCrhTdduxbtesseWY3Aa3c1d/9pDTqVZE/FfcyY6VVLxKHpSMWQKFcyuFJE28DVGENfUDdyfQSMZ8HMKw7jKzlu8PgKGsQw7VRhXURQFz1xYAgBcyqKKrdAQwL9F9dSpwk6VICMiH9ipwhhExH+57FSZE9uXwRxOM8bwIrc8b2AA1N+lXusWstacKkF1CVw00g1A/XMsNBEfJpcK+OdHVZfK79y2VwzxX3LxCLoSUZxfzOOJs4uOHm8t5CrqazAopHgco6KKcKr4ePt6h7bdf1ITVY62YZ8KEOytcllWxHvSLVGlKxkT5z8rEWDL+Yr4ux6xqah+pCeJa7f3r/o9WQFKVRn5chWZYgWLuTJmV4qYXC7g/GIep+dy+JsfPm/Lz3eDrDin1BexBk2eo4Bap4qx57PhbvPCTTPCuFClRwoG75zCMAzDGCc8Vy4mEJxfzGO5UEE8KuGikfZ6YHMa2hbKFCqoVGXEov7STPVOFT7tBBm3OlVYVAkPnUmPRBWX41AYb/CiC8HIeSptsVMl6KJKVzKGrQMdODufx7GpDK7fNdjwc//mh8dRqsi4bkc/btqjf14qHsUrLt2E/3ziPL7+5AVcva2/4fewk6V84/gvwPzAstkA1A+sjf8ih1H7iSrBHYAu5cuoymrUlZEIJ7sY6kng7HwesytFbB/sMvW1k8uqSyXdGUfKJneCJEn499+8AdlSFdWqgoosoyorqMhKza8yylX1/+dKVbzpbx/CSrGCTKEciM7HbHHj3kG635kzcY8+ry3jGV1AGepO4sRs1tbngFxZPVdu5P4MGvS+drPvjWEYhnEff01dmdBD0V97RnqQiPHbz056a8SK5YK7MTtGyGiiCneqBBvnRRVyqvh3CMWYg15Lt+O/uFOlPUjG9WGoWxn6evxX4/NUP3WqmI7/UoeNwzZF4niBkV6ViaU8/uXRswCA99W4VIjbD4wBAO45NCEGxk6zpL1WjeK/zDpVsqWNB6B+YKcQVXKQZUV3qrRRST1Qcx4JYFQP3Y/1dcRdfbZqpWOPRJVNNpXUE5IkoTsZQ19nHIPdSYz0pjCe7sDWgU7sHOrCnpEeXDLWi8s29+EFOwfEsxNFkfmdbJPuERJGzBTVm3WqDAnHuo2iShOxKIh4sfDBMAzDuA9PtRlXoZJ6jv6yn1g0gh5tG9LsEMcNlvMU/xWeG+Z2xGlRRWzh+TguhTGHF/FfiqKI3p9Bl+JQGG+gbVBFUctz3YAy0jd0qlCnisWi+qA6VQBg72jzXpW//sHzKFVlvGDnAG7Yvd7NcvOeYfR1xDGdKeLRk/OOHWst9FqlO9vHqbI53YFYREKpIuPIZAYT2nB5b9s5VYIb/+V2ST3Ryv3glCaqjNgsqphlrK8DAMT73s8oiuJo/JeRThX1ZzgQ/xVCl7o4p7BThWEYJtSwqMK4yrMTWkn9GIsqTkBl9WaHOG6QKWpOlQDY65nGDGkP7XY+TNXCTpXw4YWokilWxICdnSrhJlmzme3WRiidpzYsqteuxwsme85mtAHlcIDFQBJVjk2u1P3vFxbz+NKPVZfK79x2Ud1C9EQsglddtgkA8PVDFxw60tU0i/+ioeO8wcWVbAA6VWLRCLZpvSr/8+wkAGC8L9V292pBLqqnBQK3+lSIlkSVJXKqeHue29SnijoTS3lPj8MIxYoMMu01FFVE/Jexc1SpIiOjnaeMRsfZvVwlywryZXJ/+vdcaZZUnJ0qDMMw7QCLKoyrPMtOFUehIc6SD8vqyanCnSrBhrb+7bT916LHpYTnward6fAg/osGCl2JqG157Yw/SdT0h7lVVm9kq5aiokzHfy2r51a7ypu9oNapUi+S7a9/eBylqozrdw7gxt1DDb/P7QfGAQDfemoC5arzr+1irkmnijawnDc4sMwGpHx5p9aH8d/PTAFovz4VQN8qLwXRqZIhUcXdBYJhsWRjQVTRYg5HPXeqkKjif6fKSlG/h+pscF8zYNKpQp1fEcn40puI/7JpuSpfI2SGK/4ruO43hmEYxjgsqjCusZgr4fyiugl0CYsqjkBxI0t+dKpwp0oooO3pTLHiyEZnTnto7PT5EIoxTpcHTpV5bXN3gEvqQ48kSa5nl+cNxH9Rp8qCiRgWRVFC4VTZNdyFaETCUr6M6TUC/Pkal8r7Xr53w+/zwl2DGOpOYiFXxoPHZx07XkKP/6p/3iCnyoJRpwr1H/h8SYDK6g9rbvJ2i/4Cgl1UPyf6w1x2qvTQko2FTpUl9bzgvaiixn8FoVOFekc6E1FEIuvdfcBqF4mRjrH5muivRt9zo59hB3RvKEm6uyMMJAPsfmMYhmGME54rF+N7KPpr60BH28UKuEWfxWJcp1EUBcsFdqqEgd6OmNgMd6JXJQjFvow5vIj/EhnzLg+ZGG8gN5JbA1F6L2/kgqLB/HKhYrhofblQEZvyQe5UScWj2KFFSlHxOfGZHxxHuarghl2DeOGu9V0qtUQjEl5zuRYB9uSEMwdbw3KTThXaAjdaAh2EThVAF1WIdiupB2qK6gMY1UPXuyDFf01nnCmqN0sQnSobxePSOapYkQ3dc+kl9cYXUOwXVbQ/VzxaNwoyqARZqGUYhmGMw6IK4xoi+musz+MjCS/pDn92quTLVTFUYkEt2EiSJCJQnOhVEQ9XPs6gZ8zRKeK/3HSqkKjCTpV2QAwvXIr/yov4r8bDrdoIKaPu0Rlt0NibigU+to4ipI7VlNWfW8jh3x/Tu1SMQBFg//PMpOMbv7SQ0iz+ayFbMrQFTqJKt89FFYr/Ito5/iuIpdI03A5SUT05Q7x2qgSpU4XujzfqaOpMRMX10EgEGPVD9Zu4Vxo26YZpBt0bdoRsmcrtZQ+GYRjGG1hUYVyDRJX9HP3lGDQIWPRZpwr1qUQj0oZxKUwwGHKwV0XEGwR8oMjo6E4VNztVvBkyMd4gYjZcLqrf6HoWj0bQow3TjcZFUVRWkF0qhCirrxFVyKVy4+5BXN/EpUJcva0f430pZIoV3HtsxpFjBdSyZBK/0k2K6iuy7r7diJVic/HND+wc1kWVaETC7uFuD4/GG1Iun0PshK53bneqDFlcsKlUZSHEjPZ5e64LklPFiJNbkiRTYpdwqjSIPKwH3VcVyrI4plYwIhYFERK3OP6LYRgm3LCowrgGxX/tH2NRxSlEUb3PnCrUp9KTioXK2t2uDLVQTtoM2ljze1wKY5wOD+K/5kSkRfCH00xz3N4yF5u1TcTfdJe5SM4ZTVQZ6fF2e9sO9omy+hUAwNn5HP79sXMAmnep1BKJSHit5lb5+pMXbD5KnZVSBZTS1qj7LRWPin4UI1vgQRkWjvWmxABwx2Bn4F1SVqBzSLmqGI7r8wt0vXM9/ksTf1dMduzNrpQgK6qA53VE51ha7VTJFCqriuD9iB4nuPG/TzNl9fTeMeNU6UrGxLXPjuUqo9fToMFF9QzDMO0BiyqMKxTKVRyfVh+sL93MoopTUFG93zpVlmtEFSb42J2nXEvWwAY4EyxoqzLvpqgiMubZqdIOuFlUL8uKGJI0O0+Rs8Goe3QmTE4VLULquakMZFnBZ35wHBVZwc17hnDdjgFT3+v2K1RR5XuHpx1zvC1pr1EqHtlQVOg3MbAMSvxXJCJhu9aB047RX4B+DgEgeo2CAg22B10WVXqSMSS0v7cZE8P1qWXVFTLSk0TUYDm6U3QnY8JR6PeyeqMdTWa6n/ROFXPRzEM99DNafw7IFsO5TEXut6qsoFIN1jmFYRiGMQ6LKowrPDe1goqsoL8z7nkpYZgRRfU+c6pQTAb3qYQD2k60u1NFURR2qoQQGjxnSxVb8reNMG+hfJUJLm5ml+drNrKbxTpRJOdCG4oq2wc6kYhGkCtV8fCJOXz5cdWlYrRLpZbLNvdix2An8uUqvnt42u5DBaALX7Sc0ohBM6KKge4dv7BrSI382jfanotPtaJKkMrq86WqeJ+5HXcpSdKqfg2jTJKo4pPnQepVCYyo0uR8Qu+DOQP36PPaec+sq5eWq2YyrT8H5MvhXKYipwrAbhWGYZgww6IK4wrPTiwBUPtUOP7JOSgH3G/xX8t5dqqECaecKsWKLGI3wvZw1c50agKZorj3YKkX9wZ/OM00x83schJ+JUnfRG2E7lQx16kyEgJRJRaNYPeIOqj//a8cQkVWcMtFQ7jWpEsFUIe3tzscASb6VDo3Xv4gp8pCiJwqAPCOF+3C668cx5uu2+L1oXhCLBoRrokgDUDJKZCI6R1ObmKlV4WcKpt6/XGeI1Hlgs/L6kWnSpP4L134NdGpYtapYuNzQFZ0T4Xrvr9WqOVeFYZhmPDCogrjCs9oJfWXjvd5fCThJq0NcJZ8VlSf0ZwqPexUCQVOdarUdm4EYbOXMUZtTrZbvSq0RT7ITpW2QI//csGpUpP/3mxJpL+TnCrmOlXC4FQBgH2jqqhydl4dVv7Obca7VNZCosq9R2ccWRxZzKuvUaM+FcJMtM6KwQ4EP3DVtn78+S9chbG+Dq8PxTNSASyWJjFjqCvhydKaleE6iSqjPnGqjGvv+aA4VZrdH9MyiSGnCnWqmCiqB+x9DsgHyNFnhkhEQiLq3r0JwzAM4w0sqjCu8JOziwCAyzazqOIk6Zr4L7didoxAnSoc/xUO9LgHe+O/6IExFY94nrPN2Ec0Iomhd9aFIlhFUXRRhTtV2gI3C2FzWlSJkVLddBt3qgB6rwoA3Lp3GNds77f+vUZ7sG+0B6WqjP95ZtKOw1uFHv/VRFTRXtNmQhnHWQaPpIsxgnYx57Erk0SVo5MZw18zuaQes19EFXKqTPhcVKHzSTPnmxnh12pUqp1OFVFUHzKnCuDuwgfDMAzjDSyqMI5TKFfxrOZUuXpb2tuDCTmU316VFbEh6Qd0pwoPFsKA3qnijFOlWV40EzxoqJh3YQN4OV9BRYuR406V9oBiuIouxn8ZGQCJRQeDosp0hgqc/TFsbJV9o7qoYqVLZS23HxgDAHz90ETL32stRuO/Bgz2FdTGWbKoEgzEALQcnAEovQ+HPFoguEp7rvv7H53CH9/zrHjPbwSd5/wiqoyJThV/x3/Rc12n4fiv5sLvfM6qU8W4G6YZuRJ1xYRQVIkHz/3GMAzDmINFFcZxDp1bQkVWMNKTxOZ0+8YKuEEqHhUPhUaHOG5AnSrNYjWYYEAPU4u5MspV+4YP2ZKxB0YmeNBWvxtOlVktR7wnGVtVFMqEFzedKnpUSfP3Vr9BVwMAlCqyKLQPi1Pl+l2DOLClD2+9YTuu3mbdpUK89go1AuzB47NiQ98uSFTpa3KfYrSvoHaxpdOAq4nxHn2rPDgD0BmPnSpvunYr3vPSPQCAu+8/ibf/f48hU9j4+YNitjb5RFQJjlPFaFE9CR4bn6NypSpK2jXTH06V8InPbt6bMAzDMN7AogrjOAfPLAAArt7WzyX1LkBbln4qqyenSi87VUJBuiMu4rns2FIjxLAyzu+TsEED6LwLnSoizoKjv9qGpItOlbyJAVBadKo0vx5T4XQsIjWNoAoK3ckYvvrbN+Pjr7/Mlu+3Y6gLV2zpQ1VW8K2n7Y0AW9SEr3STjW0SyuabvKa5mvLlCMdZBoKUJn4VAuhU8SrqMhKRcMcr9uEv33wVkrEIvn9kGj/7Nz/Cmblcw68RRfV9/hCPx7WFP7+LKlTo3sz5NlgT/7VRFDTdKyVjEdMl8XqnSuvPANk2cKq4cW/CMAzDeAOLKozjHDytiSrb094eSJuQ7jCX4e4G3KkSLiIRSWy12RkBljUYbcAEj05tCOBGUb3ImOfor7bBzdzyXJnEX+NOlSUDTpXpZb1PhYfwjbldc6t8/ckLtn5fw06VbnNOFY7+Cg5BdKqQGDvskVOFuP3AOP7tHTdgpCeJY1MreP1nHsDDJ+bWfV6+VMWytmg14jOnylK+LNwgfoTukZuJD3SOKlbkDe+5yEE50JUwvfRIbpjZjJ1F9eG792enCsMwTPhhUYVxFEVRcPDMIgDYEv3ANKfPx04V7lQJD2T9n7FRVOFOlfBCA+isCwOLOVG86o8tWMZ5Ui4WTOcpptBEp4oRp0rYSuqd4jVXqL0qj56aFzFCdkCLKM1EFRHplt34NQ3z9nVYCeIAdFbEf3m/RHBgaxpf++2bcfnmPizkyvjF//cR/OujZ1Z9DrlUOhNR9PhEcOxJxsS/UzvPKXaTLRlzqnQmYqJnbCM3OTlVzPapALqIlylWWu4LyQpRxR/vBzshoZY7VRiGYcILiyqMo5xbyGN2pYh4VMJlm/u8Ppy2gGJDFvP2xTK1CuUrc6dKeBDWfxu21IisiWElEyy6ku7Ff3ld3Mu4j5uDC3NF9ep7MF+uNj02Eqi93jj3O+PpDly3ox+KAnzjkH1uFaNF9YOaWLtSrGzoaMiyUyVwiKieIDlVxPXOH+eNTX0p/Ns7bsBrrhhDRVbwga88hY9//VlUtP69yWW9pN4vkdCSJAWiV0U/pzS/9tB5am4DR52ISrXg6u3tiCERVf+9tOpYN7OoEDRScfdctAzDMIw3sKjCOAr1qewf7xObpIyz0Jalr+K/8uxUCRvDoqTSPvEuZzAvmgke1D+RdbNTheO/2gY3N8yFqGLgnqY3FRP9U82uyRT/NdLrj+Gon7n9gBYBdmjCtu8pRJWOjc8bPTWv6UZuFaP9B4x/EPFfAepUEU4VHzkzOxJR/NWbr8L7btsLAPjCgyfxa//wGJYLZeFUGfXZeS4IvSqiqN7AOYWcS4acKhbulSRJMvQzjEDnys4Qniut3JuUqzI7WxiGYQIEiyqMo4g+lW1pbw+kjfBnUT13qoSNoR4SVdipwjSH4r/yrsZ/sajSLri5YW4m/12SJMPu0ZkVdZjHTpXmvOqyMUQk4MmzixsWYpvBaPxXJCKJuJyNtsA5/it4JEVRfTAGmlVZEYNxvzkzJUnCe2+7CJ95y9VIxSO499gM3vCZB/HoyXkAqlPFT2zSjmdyKe/xkTRG9DQZiMmi+x96f9SDOlWs9s8NddvzHJAvh7lTxbyL9qHn53Dlx/8H7//3J506LIZhGMZGWFRhHOWJs4sAuE/FTShuZNFAMa4bVKqy2E5np0p4GBIbag50qoRwW63d6dTiKtwsqvdLHArjPCnaBnVhw1yP/zJ2nhK9Kk06OERRvc+GjX5kuCeJG3cPAQC+bkMEWLFSFYO9vibxXwAw0NX8NeX4r+ChF9UHw6mymCtBVtSP/bpE8JorxvDv77gRm3pTeH4miy8+onasbPLZeW7M5/FfVVlBQbu+GTmn0PthbgNRZV47f1npVAFqYoBbfA6gc2UoRRULfW8PHJ9FoSzDJ+l4DMMwTBNYVGEco1Cu4tkLywCAq7ezqOIWfov/os0qAOhhp0poGHIg/ivMD1btDr2mbogqHP/VfpBTpeCGU6Vs7jxldNGBO1XMcfsBtbD+60+2LqqQszciwVB5tj6w3MCpol3PullUCQxBK6qn+6/+zjhiUf8+0l++pQ9f/e2bcGCL3q054jNRZVOfv+O/sjUuXyPXHrpH32jxaUHcK1l7Nhu06TkgH+Ki+lTMvIv2vmMzAIBbLhp25JgYhmEYe/HvHRgTeA6dW0JFVjDSk8R4n79unsOM3+K/qE8lFY8gEeNTTliwy/ZfS85ErA4TLOhhOedC/Bc94A/6LA6FcQ43uxDMxH8B6sATABaaLDrMZDRRpYdFFSO88tJNiEclHJnM4LmpTEvfa0l7bXo74ohEmq8HU3/FRtE62RAPCsNK0sIA1EtoYD4YACF2tDeFL73jBvzs1VuQ7ozjxt2DXh/SKvzuVKHOwWhEEu/TjTAS/9VKpwqgPwfQtcsKiqIgF+b4L1r4MHhvMp0p4MhkBpIE3LRnyMlDYxiGYWyC7/QZx6CS+qu39UNiD6trUMmqb0QV7lMJJc6IKrQBzpemsEEPy04X1cuyUpMT7v9BE2MPnhTVm3WqbNCpoigKprXB1AiLKoZIdyZw60XD+N6RaXzr6UlcNNpj+XstipJ6Y/cp/SL+awNRRThVwjcoDCuimykgRfWzPu1TaUQqHsWfvekAFEXx3XPhWNrfnSq1HU1G/u6oJ2V2I1FFu1caaDH+a6OIsWYUKzKqWoZdKEUVcW9i7N73weOzAIDLxvvYbc0wDBMQeG2ccQxRUr897e2BtBnkVPFL/BeJKtynEi6GevQtOHogahW9UyV8D1btDj0s5x0WVZbyZfF+5AfS9sHVonqTW7X9Bq7Jy4UKSpogxE4V41y/awAA8Nz0Skvfh5wqfQaHiwOaYLvRMJGiTzs5/iswUDeTGzGCdjCbCY5TpRa/CSoAMNarxn8t5MqmSsXdwmxHEzl15zeIKFxo0alC16rZFpwqtfeEYVyoSpkUau9/ThVVbr6IXSoMwzBBgUUVxhEURcHBM4sAuKTebUSnygZbsW6SKagPAr0GN0CZYDDQmYAkAbKycbyAGfROlfA9WLU7bsV/0ZCzJxXjuME2grZBjUZstIJwqsTNOVU2cjVQfEpPKoaUwe/LAFv7OwEA5xZyLX0fcqr0GbxPGRCRbo1fU4rr4aL64BA0pwp1+gzxAkHL9HbExDl90ocRYFmT5xMSfucb9J2sdvW2Fv/VimOdHDjJWARRA9GLQcOMi1ZRFDygiSq3sKjCMAwTGHjiwDjCuYU8ZleKiEclXLa5r/kXMLbRpz3sF8qyL7atlvPkVGFRJUzEohH0a8NCuyLAhFOFRZXQ4VZRPWXMDwVsc5dpDTe7EPT4L2PnqbSBTpXpjDrE4+gvc2zRRJWz861F9ixqw0Wj8V8DogR6o04Vjv8KGkErqqf3H1/vWkeSJNGrcsGHEWDCqWLQIVkb/6Uo693ky4UyyGSethj/RW6YVp4BzHaUBQ297635vcmxqRVMZ4roiEdxzXZeSGUYhgkKLKowjkB9KvvH+3jr0mV6kjGx7eOHXhXhVOH4r9AxZMMDVS00hOrkIVTo0J0qzg69yTXF0V/thYjYcGEYmhfdT0bjv6jnrLlThaO/zLF1QI3smV0pthQtSMsfJIA1gzoINnKqsPMyeAStqH42QEX1QUDvVfGhU6VkLf6rVJHrdtnRvVJP0rqrl8S8hVwZ5aq1a29WiCrhPE/SDMTIvcn9z80AAF6wc0AIvAzDMIz/YVGFcQTRp7It7e2BtCGSJOkRYD7oVdE7VdipEjbsLqsXcSkhfbhqZ4RTpehs/BeVslqNs2CCidgw92X8V3Onii6qpFo8uvairyOObm3IeH7RegSY6fivLr1TrBEU19PN8V+BQRdVguFUmdWcKoMBKar3O5u0XpUJP4oqRXPiQ2dCjzOrFwE232KfCqAuDFBil9UY4JzJJYWgYUaovZ+jvxiGYQIJiyqMI3CfirdQhIWvnCodPFgIG0JUydjUqRLyh6t2RogqDkcSzvOQqS2hLoRCpVo36sROzBbVpzvU9+LiBq4GElU4/ssckiRhS786CG0lAowWUMyKKgu5MmS5/vttxWSxNOM9tFXuh+hcI4hOFXaq2ALFf/nRqZKzECc4ICLA1i8+2SGqRCOS6G6xulxFy1SdIT1PinuTJgsfhXIVj5ycAwDcctGw48fFMAzD2AeLKozt5EtVHJ5YBgBczZmgnkC9KhsNcdyCYjV62akSOux0qlRlRTx08BAqfNADs+OdKtrwYLCLh0ztBDlVFAUoVx0WVUzGlfR36c7RRoIPx39ZZ+tA62X1SyL+y9iAkV7TqqwIN+5aaAhqtAOB8Z7AOVUy1KnCSwR2sEkTVSZ82aliXnyg5ZJ6TpVWS+oJPQbYolOFlhRCGhWu9zRtfO978PQCCmUZIz1J7B3tduPQGIZhGJtgUYWxnUPnFlGRFYz2JjHex1EWXkBOlUU/OVW4UyV0DPWoD1MzNogqNIAC2KkSRuiBuVSRUbGYvW2EOe5UaUuSNZnwTvYhlCoyKpozocNkp0pFVoR7YS10Dh3mjXPTCKfKQgtOFZPxX8lYFD3acHOuQewNDUF5SSA4JOPuxQi2Sq5UEa457lSxh/E0iSr+c6pkLYi0JJjM1XWqqOe8fosl9YTuWLfqVCFHXzjv+432vd2nRX/dfNEQJEly/LgYhmEY+/BcVPnMZz6DHTt2IJVK4frrr8ejjz664ecvLi7iXe96F8bGxpBMJrF3715885vfdOloGSPURn/xjYE30GBgiTtVGAehh6k5ixtqtdD2d0RaPSBlwkFnzQOzkxFgc6K4l0WVdmK1qOLcQLS2DN2o+JuKR8VgpVHP2fSyFv/Vy8NRs2ztt8Gpom1tGy2qB/TYnIU6okqpIqNUZedl0AhSUT3dd6XiEXZD2QR1qvgx/itrIU6QornqCb/kVBnoau3ZTHeqWBRVqKMspF2KRvveHjiultTfytFfDMMwgcPTydWXvvQl3HHHHfjYxz6GgwcP4sCBA3jlK1+J6enpup9fKpXw8pe/HKdOncKXv/xlHD16FHfffTc2b97s8pEzG3HwjFpSfxWX1HsGRVgs5r2P/+JOlfAybGP8V7akl9SzGBs+EtEIolqjad7BCLB5UVTPw+l2QpIkMRB1sg8hV1avZ7GIhHjU+C009aosNIjkFE4Vjv8yjR2dKiL+y6BTBdDdcPUGlrXOSx54BwfqVAlC/BedMwa7knzPZBPUqTKXLfmuV0eIKibEh43iv0iUa6VTBWg9Bjgf+vgvve+tEXMrRTx9Xo1Nv2kPl9QzDMMEDU9FlU996lN4+9vfjre97W3Yv38/PvvZz6KzsxNf+MIX6n7+F77wBczPz+O//uu/cNNNN2HHjh140YtehAMHDrh85EwjFEXBE1xS7znkVGm0Fesm7FQJL3Z2qtADY2dIIwDaHUmSxENztkEEkh3McVF92+JGH4K+VWvuPEUOiIU61+RSRRZiIMd/mafVThVZVoSoYjT+C6gpq68jqlDMWzIWQcyE+MZ4iy7M+l9UoWsd96nYR7ozLt4DU8v+cquIxSMznSobCL/CqdJq/FdPa471sN/7pwxECj74vFpQf8lYLy9WMAzDBBDP7vRLpRIef/xx3HbbbfrBRCK47bbb8NBDD9X9mq997Wu44YYb8K53vQujo6O47LLLcOedd6Jabaz+F4tFLC8vr/of4xznFvKYXSkiHpVw2eY+rw+nbaEBjp86VXq4UyV0UKfK3EoJstxaOXSuxqnChBN6aHaqrL4qK7aVrzLBw40+BL2k3twAiHLrF+s4VSjvPhaRWs63b0fIqbKQKzfsrNmITLECunz12uRU4T6VYBKs+C/1vDHEQqxtSJKE8bR6PvFbr0rWQvfIRucoEvLtcqpY7VbMWbymBgUj55T7j6nRX7dcxC4VhmGYIOKZqDI7O4tqtYrR0dFVvz86OorJycm6X3PixAl8+ctfRrVaxTe/+U185CMfwZ/92Z/hE5/4RMOfc9ddd6Gvr0/8b+vWrbb+OZjVUPTX/vE+sZ3BuA+JKsseiyqKoohj6GWnSuigiKVKzaavVaiEM6zbagzQqQlmTokqi7mSGI62OihggocbA1F9AGRuWN7f1dg9OpPRh6ORCMf4mKUnFRf3PFbcKnSP0hGPmrpv3cipIkql+XoWKJIBiv+a5f4wR9jUq0aA+a1XJWth8YgEj/k6RfV2LaDonSrWnCoUlWj2mhoUqFOlkftNURQ8cFwtqWdRhWEYJpgEypMuyzJGRkbwuc99Dtdccw1+/ud/Hn/wB3+Az372sw2/5oMf/CCWlpbE/86ePeviEbcfB0+rosrV3KfiKZTf7nX8V6Eso6JNOdmpEj4SsYiIS2k1AixXtDasZIIDbSLW9g3YCW1e9nXETfVdMOHAjT4Eyn/vMLk0Qj1n9TpVuKS+dVrpVaH7JDPRX4AuqszXdaqY7z9gvIeE2VJFhqK05r51mlkR/8XnDTuhXhW/OlXMLB4Jp0odwcNup0qrRfWhdarE9WWPeueU52dWMLFUQCIWwXU7Btw+PIZhGMYGPLvbHxoaQjQaxdTU1Krfn5qawqZNm+p+zdjYGOLxOKJR/cJ7ySWXYHJyEqVSCYnE+huDZDKJZJJvON3iIPep+II+Ef/lbVE99alEJB4uhJXB7gSW8mXMrBRx0WiP5e8jNntD+mDF6A/NThXVz3KfSlvjRlF9XmzVmhRVNug5EyX1PBy1zNb+Tjx9ftmSU4Xuk8jtYhTqIuD4r/BQ61QqVmRfO+7pfTfI5w1b2SREFfMCrZPkNFGl28Q5pTb+S1EUSJLqhCxVZBHN3HKninDDqDHAZt2WYY/+TWlOFVlRXf3x6Oq/n/ufU10q1+8c8PX5hmEYhmmMZ6uciUQC11xzDb73ve+J35NlGd/73vdwww031P2am266CcePH4cs61uIx44dw9jYWF1BhXGXfKmKwxNqZ83V21lU8RK/FNVnNFGlOxnjWJOQom+ptSbg0QMjO1XCS4f22mYdElVo85L7VNoTPxfV92/gVKH4Ly6otU4rThUrJfVATfxXnddU7z/g61mQoHMI4Gw3kx3MithAvt7ZyZhfO1UsRE/SgkmpIq/qm6Jur4hkrkdqo59R22lnBnIum72mBgVyqgD1701IVLl5D0d/MQzDBBVP8zHuuOMO3H333fiHf/gHHD58GO985zuRzWbxtre9DQDw1re+FR/84AfF57/zne/E/Pw83vve9+LYsWO45557cOedd+Jd73qXV38EpoZD5xZRkRWM9iYxrm36MN5AW7GZQgWVqncPhsvaJlSrN+2Mf6HtanrAt0quHO4IAEZ3IeUdiv+iwm/q+mHaC8oud0VUMR3/1XjRYTqjDu9GWFSxzNaBTgDWOlXoNTHrVOnfIFqHnJfd3KkSKGIRCbT/4/eyerrecfyXvYz5sFNFURRLRfWdiZi4VtXGFM7nyJ2XQLTFhbd4NCLOnfVce80QTpWQnisTNVG0a120pYqMh0/MAQBuuWjY1eNiGIZh7MPTFaqf//mfx8zMDD760Y9icnISV155Jb797W+L8vozZ84gEtEvRlu3bsV///d/433vex+uuOIKbN68Ge9973vx+7//+179EZgaaqO/yGLMeEPtxuVyoSI2Kt2GCmB7uKQ+tOgllfZ0qvBmb3ihTUSnnCo03Bzgzd22JEXZ5Y7Gf1kTf8mpsshOFUcQTpUF95wqgxs6VbgjLIhIkoRkLIp8uer7snqOu3SGTT7sVClV9X5Ks/fIg90JnFvIYy5bwvbBLgC6wGLXs+FQdxKLuTJmM0XsNRkDrC8qhPNcGYlISMQiKFXkdeeUg2cWkCtVMdSdwMWbrMcnMwzDMN7i+RXst3/7t/Hbv/3bdf/bD3/4w3W/d8MNN+Dhhx92+KgYKxw8QyX1HP3lNbFoBD3JGDLFChZzJc9EFcrs7eWS+tDSakklkbXYVcAEB72o3iFRhTZ3Of6rLSGnSsGV+C9z1zTa5F2o16nCokrLbO237lQhUSVtsluAxNtcqYpCuboqDz9rof+A8QfJeEQTVdxzquRKFWSLVcPngEpVFmIeOzPthYrqZ1eKKFVkJGKehnoA0EVaAOg06ZIc7NJElRpH3UJWPee12qdS+zOOQ+8HM0POggMnaCRJVFmz8PFATfQXR2QzDMMEF+/vFJhQoCgKniBRZXva24NhAOhl9TQw8AIqqmenSngZ6rGrU4WdKmGHikidiv+ye/uSCRZJF5wqubLFovoNOlWmhajCsalW2aw5VTKFCpZMdsmRe8isU6UnGROlw/NrYm9W2mBQGFaoWLrgUqeKoih442cfwo1/8j1849AFQ1+zkCtDUQBJ4uud3Qx0JYSQMrXsD7cKibSpeASxqLnRDb0/5rO64EHxX/1d9jybtfIc0A7Rv8kG55T7n5sBANzM0V8MwzCBhkUVxhbOzucxu1JCPCrh0vE+rw+HQU2Gu4eiinCqdPCgPKyQU2WOnSpME5yO/5oV8V+8uduOuFFUX7Ac/1W/50xRFOFU4U4V63QmYiKK8qxJtwp1qpgVVSRJErFua0WVnLie8b1P0BDirEtOlWcuLOOZC8soVxW8+1+ewD89fLrp15AzeMCGTgxmNZIkCbeKXyLA6P64y8L5ZLB7veAxv2LvAspwC451q+7PIKHfm+jnlMVcCYfOLwEAbrmIS+oZhmGCDIsqjC1Q9Nf+8b5VEQiMd9CAwOzWpp1Qp0ovO1VCi96p0qJThcoqQ/xg1e7oThVnhlU02OT4r/aE7j1cKao3KarUDuxr3aOZYkUcL8d/tcZmixFgevyX+fsUfQt89fWP4no4/it4iAGoS06VbxyaAKDG5CoK8OH/ehp/9f3noChKw6+Z4z4VR9nUS6KK+Y4mJ8i24OQerHOOIsdkv03xX/QcYHa5qlKVUdKuf10hXqgSfW819yYPHp+DogB7R7sx2ssuVYZhmCDDogpjC3qfStrbA2EE6Y7GxbhuwZ0q4YecKjMrxQ2HAM2geINOjksJLcKpUnQm/ose6Lmovj3Rh6FOxn9pThWTyyOxaAQ92nWwtldlell9z/akYryQ0iJbqax+3twgVIgqHebPGw1FFXZeBhaK6nGjqF5RFBH5ddfPXIF3v3QPAOB//88xfOKew5Dl+vdUoj+MXZmOQE6VSb84VYrWzyf1zlFOFNUD5percjXXarOLCkFCj//S/7wPHFejv27h6C+GYZjAw6IKYwtcUu8/+nwQ/8WdKuGHtqtLFRmZFobl7FQJPzQQyDsw9K5UZXGu4+Le9sSNYWhexH+ZP0/RVnDtogOX1NvH1gFrThWr8V8A0K8NJefWOVW4qD6o1IvqcYpD55ZwbiGPjngUL714BL/7in34yGv3AwA+/8BJvP/Lh1bFBRJ03hhkUcURxtKqQOuX+C+KE7RyPhmsE81FThW7RJV6P8MI1KUYi0hImOyKCRLJNU4VRVFw3zGtpJ6jvxiGYQJPeK9gjGvkS1UcnsgAAK7ezqKKX0hrA4JFD+O/uFMl/KTiUfGgN5ux3qtCm71h3lZrd2gQnXMg/ouKewG9v4JpL9wYhtJwK2XhPEXvy9pr8nRGHdoN83C0ZbaQU2XBnFNlMa8OGK3Ef1G0zsK6onrrcT2Mt5BjzI2i+nueUqO/XnbJiLj3+bWbd+LP3ngA0YiE/zh4Dr/5TwdXbbgDuog3yFGXjqB3qvgr/qvTpvgv+rjfNqeKFgNs8hkgV3PfL0nh7QZKrVn4ODWXw/nFPBLRCK7fOeDloTEMwzA2wKIK0zKHzi2iKisY7U1ivI9zQf0CDQiWvHSq5Nmp0g7Y0auSZ6dK6Ol0MP5LDAk644iFeOORaYzoVHFwGCqcKhaiutKaU2WhjlNlhDPVW2arhU6VQrkqhud9FkQVch+tdarQsLCL4ywDh1tOFUVRcI/Wp/LaK8ZX/befvWYL/vYXr0EyFsF3D0/hrV94VDi/AT3qkh1uzkCdKr6J/xJF9ebPJ9S7Uzf+y7ZOFT3+y0wMcLs41IVTRRNH739Ojf66Znu/JdcrwzAM4y948sC0zMEziwDU6K8wb5oEDcoH91JU0TtVWFQJM0MWrf+1cKdK+KEBoxPxX5Qxb1ecBRM8aHBRcNSpQvFfVkSV9U6VGRqOslOlZbbUdKoYHezR4kdEArotDLdoYLnWqULXM3aqBI+1UT1O8cTZRZxfzKMrEcWL963vVbht/yj+v199AXqSMTx6ch5v/tzD4h6LFljYqeIMY33+iv9qpaie7onmNMFDURTbO1VEDHBVxnLB+NJMK9fTIEFCbUE7p9z/nBr9dctejv5iGIYJAyyqMC3DfSr+RHSqeFhUr3eq8GAhzAwKp4o1UUVRlLbZWGtnOuLqa0sDAjuZoyETD6fbFr2o3rlhKJ2nrMQU9tdzqizzxrldbNZElXy5uq44vhHUw9TXEUckYn4pqFFR/QqJKnw9Cxyim8nh+C9yqdy2f1S47NZy/a5B/MtvvBBD3Qk8c2EZb/zsQzg7nxNOFb7eOcNYWnWqzKwUUXJYXDOCEGmtOFW6dMFjpVhBvlwVgqFd8V+1McBzJp4DyIET9mUq3UVbRbkq46Hn5wAAt+zhknqGYZgwwKIK0xKKouAJElW2p709GGYVVLrqZVG93qnCTpUwI5wqFjtVSlUZFVndLA77w1U7I4rqS87Ff/HmbvviRlE9dRtYiewQTpX8eqfKCIsqLZOMRTHaq/49Gu1VISdv2mIMDsXnzNcIZVVZEZFi7FQJHqm48/Ffstw4+mstl23uw7//5o3YnO7Aydksfu6zP8KpOTXijqJXGXsZ6EwgEY1AUfTeKy8R8V8Wzicdiai495pbKYl7pUQsYkmkaYSVGGA9TjPc50k9UlDGk2cXsVKsoL8zjkvHez0+MoZhGMYOWFRhWuLsfB6zKyXEoxIuHe/z+nCYGkSnikdF9VVZEdua7FQJNySqzFjsVMnVOBesdBUwwYAEs1y5aip32wj65i4PmdoVN4ahrcSVkFNlsU6nCjtV7MFsrwpFsVld/Bio01eQrRGNuVMleJA462RR/cEzC5hcLqAnGcMtFzWPANo51IX/eOeN2DvajanlohADh9ip4giRiITRPvXv1g+9Kq3GCYoIsGwJC1n1vTPQmbA1snvQQgxwu8T+6u63Ku7Tor9u2jNkyR3JMAzD+A8WVZiWoOivS8f7GtrXGW+gTpXFfNn2AaYRVmpydVlUCTdDPa11qtAQKhmLcMl4iKHtfkWxf2A1JzLCecjUrjg9DJVlRfQBWYn/okUHGmoBwLQoquf3rR3U9qoYgQSutFVRpUYoq2puSxoUxqOSeE8ywcGNovpvaC6Vl28Q/bWWTX0p/Ns7bsCVW9Pi93iJwDnGev3Tq5IV8bjWzickeMxnS6J/zq7oL2LIQgxwvtxenSrFiowHtJL6Wy/i6C+GYZiwwJNOpiW4T8W/0ACHHCM9LpfFU59KMhbhwULIGW6xU0X0qXBUSqjpqBke5UoVS4PpRlCnCsehtC9OD0MLNd+3w8ISSXpNp0q5KguHAxfV28PWAXNOFT3+y9r9EQ0mZUX9XgNdCdEZZSUijvGe2gGoE1RlBd98Sov+OjBm6mvTnQl88devxyfueRYDXQl+jzkI9apMLBkTaJ1Ed3RYe70HRVl9EUnN0TnQZe8zoZUYYN35Ge73MQmnM5kifnJ2EQBwswGHGsMwDBMMwn0VYxznIPep+JZUPIpkLIJiRcZSvuyZqMJ9KuGHHqbmLMZ/0QOjlUElExyiEQmpeASFsoxcqYpBG7/3vHCqsKjSriTjzg5DaQAEWDtX9VMkpzbIp/NlLCKJaDCmNYRTxWSnSp/F+5R4NIKeVAyZQgXz2aImqqjXs25eEggkybizRfWPnZrHdKaInlQMN1soqu5KxnDXz1zhwJExtWzqI1HFe6cKReRaPafUxn/RgN/ua46VGOAciUVt4lS599gMZAXYPdyF8XSHx0fFMAzD2AXnrDCWyZUqODyRAQBcxU4VXyKKcT3oVVnOc59KuzBkIUu5Ft2pEu4HK0bfSKwdUNvBrBZpMcjxX22LnlvuzDCUSnVT8YilLPT+NU4VKkAe6k5ytrpNWO1UsRr/Behb4PNarJteKs3XsyDitOPtHs2l8spLNyER48dwvzLWq4oqvuhUKbUmPgzWdD8tOLSAQjHAcyaeA+g+0E7Xsh+hhQ+Kqb2Fo78YhmFCBd/NMZY5dG4JVVnBaG8S49pGD+MvqFeFtjHdJENOFZcdMoz70MNUrlRFrqak1yjtEgHA6EMBK++TjSCnCmfMty9UVF9waBja6nmKlhwKZRmFcpVL6h1gixBV8pDl5l1ywqnSwtZ2vxBV1NeT47+CDTlVnOhmUqO/JgEAr73CXPQX4y6b+nzUqdJiUX1t/Nd8zhlRhWKAj01lUKka+7ejd8WE+1y5tjfpFo7+YhiGCRUsqjCWqe1TkSTesvQjFGnhiVOlwE6VdqErERXDcitbfTne7G0bdFHFvsF3uSqLc9wgx3+1LY47Vaik3mJMYXcyhpjmSFnIlVhUcYCxdAoRCShVZEPOycUW47+AOk4Vjv8KNE46VR45OYfZlSL6OuK4aQ8PVv3MeNpPTpXWxIcBzcE756BT5YW7BpHujOPUXA5/9+ApQ1+Tb9GBExSSNY60WETC9bvsDL9lGIZhvIZFFcYyB08vAuCSej/TR/FfeWtdF63ATpX2QZIkbNMKgk/NZU1/PW/2tg9OxH9RnJIk6WXgTPtROwxVlOYuBbPkWhwASZK0KpJzWhNVRlhUsY14NIKxPupVaR4BtqSdO1qJ/xpY61Rpk0FhWHGyqP6eQ2r0109dugnxKD+C+xnqVJnOFAw7L5xCd6q0Fv81t1ISEVR2d6qkOxP40KsvAQB86jvHDEUwZtvEpU4LHwBw9fZ+FtwZhmFCBt/RMZZQFAVPcEm970l76VTROlV6O/jmsR3YOdQFADg5ayzLvhbhVOEhVOhxIv6LCr8HOhOIcjdF20KDC1kBKgain8ySFwMg6+epdE2vCjtVnIHK6s8ZKKun+C8Su6zQz06VUCEcbzaLKpWqjG8/rUV/HeDoL78z1JVELCJBViAEcC+QZaWmd7C1+C8nO1UA4I3XbMELdg4gX67io199pulygx3X1CBQ61S5hR1qDMMwoYNFFcYSZ+fzmMuWEI9KuHS8z+vDYRpAgwIvO1V62KnSFuzQRJVTsy04VXgIFXqciP+ad3BIwAQHKoMFgELZ/ugeO0p1+1c5VdRYGRZV7IV6Vc7ONxf47Y3/UgevK8XWBqCMt1A3k93xXw+fmMdctoT+zjhu4Pgf3xOJSBjVyuq97FXJ1VzLrMZ/DXar15j5bEncL9ntVAFUN+adb7gc8aiE7x+ZFiJiI9rF1VfbqXLLXi6pZxiGCRssqjCWoD6VS8f71hWwMf6BtmKXPOlUofgvHiy0A+RUsRL/xU6V9sGJ+C/qTuCS+vamdhvUiege2qq12qkCAH0d650qHP9lL1sHjDlVZFmpKapvwami3WfNa/dZOc2p0skdYYGEnCp2F9Xf89QFAMBPXTaGGEd/BQI/9KrQ+SQi6YKfWUj4LVVlEf/l1P3SnpFuvPPFewAAH/vaM+JZsB75Non/ojlJX0ccl2/mRVSGYZiwwXd1jCVocHrJWK/HR8JshCiq96RThYrq2anSDpCocmLGglNFE1U6Qv5gxdQ4VYr2xX/R5uVgFw+n2xlJkpBwsA9B71Sxfp6qdarMrHD8lxNsJadKk0z/TLECSqdpyanSXb9TpZuvZ4Ek6YBTpVyV8S1ta//2Kzj6Kyhs0vqZJpaaRwk6xQr1qSRikCRr8aapeHSdG6SVyMNm/NaLd2PnUBemM0X82X8fbfh5wqkScgH6qm1p3H5gHH/w6ks4opZhGCaEsKjCWII6Oga6eGDuZ/o87FQhUYU7VdqDHYOqqHJhKW86eidHcSnsVAk9FJ2UszGeiTpV2KnCiJJpJ+K/yjbEf2kbw4u5EqaXNVGlO9X6wTEC6lQ5O7/xIJQcvB3x6KoiYbMIp4p2Hspy/Feg0c8h9gmzP3p+Dou5Moa6E3jBzgHbvi/jLGN9Poj/arFPhai9P+pOxlo65zUjFY/ij3/6MgDA//fwafzk7GLdz2uXTpVUPIq/fPNVeNN1W70+FIZhGMYBWFRhLCHKPTt4iOVnvOxUIct3T5KFt3ZgqDuB7mQMimIsy74WemjkTpXwQ5ngeRvjv+a4U4XRoJgNu6N7ALuK6tXr4Zn5nHDTsFPFXrYOqE6VC4t5VOXGRcnk4G11Y5sccvM5ElW0zfKQb1+HFSeK6u85RNFfmzj6K0Bs6vU+/itrU5zgQI2Tt9+Fhcgb9wzhZ67eDEUBPviVp1Cprv/3JAQjdvUxDMMwAYbv7BhLLGoPj61EJjDOQ6KXt04Vfo+0A5IkiQiwkybL6rPcqdI20JZ/1sb4rznRqcLD6XZHbJnbXDIN1HSqtCKqaNfk56ZWAAA9yVhL349Zz2hvCvGohIqsYHK58TB0yYaSekAfUBbKMnKlih7Xw0sCgYR6K8w6bhtRqsiisPu1V4zb8j0Zd6BOFS/jv/T749bOJ0M1SycDDpTU1+MPXn0J0p1xHJ5Yxt89eGrVf5NlRYgqfA1kGIZhggyLKowl7Cj3ZJyHNjC96FRZ1t4jPVxU3zbssCiq5NqkrJLRhTM747/0ThV2qrQ7SSc7VbT3bGe89U4V6qUb7mUh0G6iEQnjaa2sfgPXJC2btCqqdCdjSGjug/lsyba4HsYbap0qitLY6WSUB4/PYrlQwXBPEtft4OivIKF3qnjpVKHzSatOFf3+qN+le6XB7iQ+9KpLAACf+s4xnKvpuSrULD6EPf6LYRiGCTcsqjCWWBTxXyyq+BkSvQpl2batOyMoisJOlTZk56Aau0IDQ6NwXEr7QMKZnUX1cyyqMBpORPcQ9sR/qe9RSqUaZneVI4helYXGG+biPrbF5SBJksTAcj5b0q9nvCQQSKioHgBKdSKLzPJ1LfrrNZePcUl1wKBOlelMsW58lRvYdT4ZqOlUcTMq9Y3XbsELdg4gX67io199RgiVJBZJEpBysN+FYRiGYZyGRRXGElTwmXbJQsxYoycZEw9xyy72qhQrsngYZadK+8BOFaYZoqjezk4VEf/F16N2h6J7HCmq12JYUi0V1a8e4HOfijNs7VcF/trN6LUs29gN2F8jqqzwkkCgIbcb0Lo4W6xU8Z1npgAAr7lirKXvxbjPUHcSsYiEqqxgdsV9xz8AZG1yvg3VdKq4Ff8FqKLznW+4DPGohO8fmRZReCJOMx5FhMVGhmEYJsCwqMKYRlEUseHHnSr+RpIk8RotuNirQiX1kgR086C8baBOlVOzZovqeQjVLtBrnLcxr35Zc8XVFrEy7Qk5VQpOxH+R+BtvQVRZM8wa6Um1dExMfYRTZX4Dpwp1A9oQYztYI6pw+XKwSUQjkLQZb7Hc2nnk/mOzyBQr2NSbwjXb+m04OsZNohEJo73e9qrY5eT2Iv6L2DPSg3e+aDcA4GNfewbLhbLoiuFlKoZhGCbosKjCmCZbqqKqZVe0GpvAOA9FtNEAwQ2W8+rNcncyxhtIbcT/396dR8lV1/n/f93aq9fqJVuTdBKWAGGJCQgDyNcvX/IVGX/4Y1xAJ8Mm45xRUBBBceagMziKyxH9uQyMjIN+f2cc1OMyyLgcRMCDPxBMiAswIWAggZClk96rl+qq+/uj7udW9V5rV926z8c5nCOd7s7F7lrufd/X+2WGKgeGxt1BSSHcndGcXDW8uNNHUami+n7neS1gsY4SudU91UiqVGL918wbUUiqVMeazsWTKpXqVJGmJ1XcYmk6VTzJsiw3rVLu2twHnNVff37aKt4Le9TKdjNUqU2vSqWK6rtqtP7LeP8Fx2tdV5MODU/oCz/flZdQ52YqAIC3MVRB0czF+WgooFgZd2xiaZi7MJcyqTLsJFXaYlzk9JNEU8QdtBaaVklnbDe1EOfkquG5SZUKrf/qc1Z/dTZHuGiF6hbVT5b/PBULBxXPe9/EUKU6TFLllQU6VQYr1Kki5ZIqr/SPyXSbtzBU8axKdDONp9J68FlWf3ldrYcqSeemo6Yyn0+68pK8MxOTSyEWDupTf3GaJOn/PPGyHn+xTxJDFQCA9zFUQdEGkpU7EUX1mTfPg2NLmFRx1vHQp+I/67qcFWAFltXnr4EiqdL4zAn0aIWGKkfdknouTkPujR7VGKqYu9bLXVfSkffeaTlDlaownSqvDY4pNU/B9EAlO1Wc91n7jmZvJghYuX4feE9uOFv669Sjzx/W6GRaPe0xbV6TqNCRYamtctZ/Hajx+q+Wctd/5SVVatU/d97x3Xrb5mNk29KXH3pBEkMVAID38Y4fRRukT8VTEjXoVHGTKvyO+M76IsvqzZowi4tQvhB3LkhXKqlyxCmPrcU6C9SfSq3tmUul1pUk8u4SJqlSHd0tUUVCAWVs6bWBue8wH6zg+i9zwXKfs26sORKSZZGc8yp3jWAZw9kHfv+apGxKhRSld61KZFNvtV7/Ve4wvyu/U6UGSRXj799yshJNYU06w27WJAIAvI4rWCjaYAXv7kP1mQs4A0tZVO90qrSRVPGdoocqeX0qXIRqfM3OBenJdGbeO8iLccQkVWp05yXqSyXW9szHDIDLXVOYn/JlqFIdgYCVtwJs7lWUlVz/1ekmVbJ3s3Oh0Nti5nmkxKL6scm0HnrOrP7qqdhxYemtajdJlRoNVcx75DKTKrFwUKevbtfKtpj73FgLXS1R/d3FJ7v/HmeNOADA4xiqoGhuuSfrvzzBrBpZyqJ6OlX8a50zVHmpwKFK7i48Tqz8IP+CdLICaZUjTqdKF0kVqDJre+YzlqpMUsXcJRwMWO7FeFTeamcF2L55hioDzkrUiiRVnOcf93ekzAugqC2TVBkv8XnkkV2HlJxMa3VHXJtWt1fy0LDEat2pUqmiekn6wfvO1SO3/M+a96G+88zVOmt9pySplfNEAIDHMVRB0cyJaILVTp6QcIcqS5hUcYYqdKr4z/oiO1XMhXXu7PWHSDCgkLMKpRIrwNxOlRbu+Edep0qJd5jPJ5XOKJXONpCXe2eteU3ubomwFqiK1ixQVj+eSmvc+R2pxA1CM9cPUlLvbdEykyo/+eMBSdnVXyRwvc0kVQ4OjSudsZf87zedKpV4jxwKBmo+UJEky7L0xctfp8vOXK1rzltX68MBAKAsDFVQtEGK6j3FrP/qX9KkirP+i8Gb76zrzt4d3Dcy6SaWFmJOGEmq+INlWW5axdyBWQ6z/otOFUjVS6rkp6rKXf9lkiqs/qquNZ1OUuXo7KTKkLP6Kxiw1FqBi5Uzn38qcVc5aqfc55EXD41Ikv5sfVfFjgm1sbw1pmDA0lTGdpOxSym3/quxnlOOScT1uXds0qnHkOQCAHgbQxUUbaCC5Z6ovpokVcZIqvhVayysbic18FLf3GtX8rlJFS5C+YYZoFUiqWIucnTTqQLlFUxXOKlifleDAUuRYHlvnc1r8vLWWNnHhfmtXiCpMjCWex9biSRBx4ybjMrtP0Bt5YYqpT2PHHZelxicel8wYGm583OsxQqw3PovnlMAAKhHDFVQNFPu2c4ucE8wd8WatW1LwU2qsCvXl9Y7aZU/9Y0s+rkmqVLu3d/wDjNAq0SnylE3qcLFK1SvqN6U1DeFg2VfhN968gpt6U3o8tevqcShYR5rFuhUqfTNQaFgYNr3arS7yv3GXSNYwvNIJmO7r0sMVRpDrldl9oC22pINmlQBAKBRMFRB0ehU8RZzot+fTMm2l2YfcK5Thd8RP1pnelWKSapwZ69vVHT914jpVGHIDykWrs76L1NAXonh77ruZv3g/efpolNWlv29MD+TVDk4NDHr92FwrPKJ6668FWBNJC89zU2qpIp/HulPTrrdG6ylbAyralRWPzmV0WQ6O9gjzQ0AQH1iqIKiDdCp4ikdzknd5FTGLWattlynCicBfrSuu/CyenNhnYtQ/mEuDpS7/mtiKq1hJ+nUxcUrKJdUqfRrnfldpfvJOzqbI+7P69UZK8AGnI65Sr6P7ch7DmrhJgFPKyfxZlZ/dTZHFC5zVSDqw6r27ID2wBIPVZJ5N5408ZwCAEBd4t0eilaNO/xQPc2RoMLB7LqSpSqrz3Wq8DviR8c6Q5U9fYsPVcbcThVOGP3CTapMlJdUMStWQgGLVYOQVP2i+jjDX8+wLMtNq+ybMVSpxvvY/FQCq3q8LdfNVPzzSN9w9nWJnq/GUaukyqjzuhMJBRjQAQBQp3iFRtHMyWgizgmDF1iWpXbnZ7VUQxWTVKGo3p/WFTFUGXX2RTdxEco33KL6Ei5Y5TOrvzqaIwoEyi+bhve5F0Mr3qniDFXCvG32EtOr8sqMXpXc+9gKDlXyegZZ1eNt5RTV9zlJle4W+lQaRa06VcyNJ9x0BABA/eLsEEWZmEq7FxfaWf/lGR3Oz2rQWd1WTemM7a7k4e5xfzKdKoNjKfWPLjzIM+sNOGn0j6YKFdUfcX63WP0FI2bW9lR6/VeKNYVe5CZVjs5c/+UkVZoq99zR2UJSpVGUU1R/eDg7VKGkvnHULKlihio8nwAAULcYqqAo5u6+gCW18ibPM8ze8P4lGKqM5K30IaniT/FIUCvbsiehexbpVRl1uwr4XfELk1RJlr3+K3vxipJ6GCapMl619V8Mf71kTefcSZWBaqz/yk+q0H/gaSapMl7K+i+SKg3HdKocHBpXJmMv2d9rktwk3wAAqF8MVVAUk3Roi4dZt+IhCedkf2Cs+uu/TJ9KJBRw7/aD/6w3ZfWLrABLunfi8bviF+5QpdykyohJqnDxClnRaiVVKKr3pMU6VSq6/quZ9V+NohJF9QxVGsey1qgClpRK225CdimMTvL+GACAesdQBUUZqMKJKKrPrP8aWIKkiulTaSOl4muF9qqYk0aSKv7hrv8qt1PFubjRyfovOKpdVM9QxVtWO50qr87sVHH65RIVXGPL+q/GketmKv55hPVfjSccDLg/z6XsVWH9FwAA9Y+hCooyWIU91Kg+N6myBEX1w+NOmok+FV9b3529mLXYUIWLlf5TqfVfR9w7gnk9QlY5d5gvZCxliuq5uOUlpqi+b2TS7e+Sqr/+q4WLoJ5WTjdTn5Og5HWpsax0VoAtZa+KWY9L8g0AgPrFUAVFIaniTUvZqTLkJFXoU/E3U1b/0mKdKhMkVfymKVqZ9V9H3aQKdwQjKxbOdSHYduV237P+y5vam8Lue5FX81aAueu/KplUyUvMNbGux9PK6WaiU6Ux9Thl9QeWcKhibjzh+QQAgPrFUAVFGajCygRUXyJeg6QKgzdfO3aZ6VRJLnhx01ysZGe0f1SqU8XcEUxRPQyTVMnY0lQFC4VNyoGieu8xK8D2OSvAMhnbHaq0xyv33JE/VCGp4m3uGsEikyrpjO0mKJez/quhrHSGKkuaVDHrv7jpCACAusVQBUUZrMLKBFTfUnaqmKJ6kir+tqazSQFLGpmYcotb5zLq3gHO74tfmBVK+et4SmGSKl10qsBh7jCXKrsCzAwA42GGKl6zximrf8VJqgyPT8nM+Sv5XrYpEtTWk1fo9es6tIyUgqeVukawPzmpjC1ZFl1fjWaVm1RZwk4V96Yj3h8DAFCveJVGUQZZ/+VJ7e76r6VIqpiien5H/CwaCqonEdcr/WN6qS+p5a2xOT/PXFgnqeIfzRVa/2XuCO7iAiYckWDeUCWVrlhigPVf3uUmVY5mkyrmfWxTJKhIqHL3llmWpX+96syKfT/UjptUKXL9lymp72yKKBTkvsVGYjpV9tckqcLrDgAA9Yp3fCjKAEX1ntTh/LzMxYRqGhonqYKs9d1mBdjcvSqTUxml0tlbhkmq+Ecl1n+Np9LuXZzcEQwjELDcC+Xj1UiqcHHLc9Z0Tk+qDIw5a2y5OQjziIZLS6rQp9K4atGpQlIFAID6x1AFRaGo3pvMUGUgmapoee9cSKrAMGX1e+Ypq89f/8Qd4P5hBmjlDFWOOKu/wkFLbQxwkSfXh1BeEipfMsWaQq9aM6NTxdwcRO8b5mOeQ8aLfA5xhyqtDPobzcq8oUq1z6MMN6lCkhsAgLrFUAVFGXTWR9Gp4i0JZ/3XVMbW8ER5PQaLIakCwyRV9hyee6hi7sKLhAIKsyrDN3JJldKfi446JfWdzRFZllWR40JjKLUPYSHjrP/yrNWzkirOzUFNvI/F3GJhs/6ruOcQs/6LTp3Gs7w1JsuSJtMZt8+t2nJDFc6nAACoV1zFQlEGORn1pFg46J4kDla5rN5NqjB48z13/dd8SRXnhJELlf5iViiNpdIl3/HZN+rsrm/m4hWmy/UhVHD9Vyr7XMX6L+8xnSoDyZSGx1N53YCkCTA3dzCbKnb9V/ZiO+u/Gk8kFHB/rq8t0QqwUdM5SEISAIC6xVAFReEOP+8yFxCqXVY/NGaSKvyO+N26vKFKJjP74rm7L5oTRl8xP2/blsaLvGhlHHUvXnFhFNOZGwiKXd2zEIrqvaslGlKH8571lf4xEtdYVH5RfTGD/75hs/6LoUojMr0qSzVUSU7QqQIAQL1jqIKCZTK2e4dfO3f4eY4ZhA0sVVKF9V++t7ojrmDA0ngqo4PDs09CSar4Uzyc+3mPlrgC7IibVOG1CNNVY/2XW1Qf5rnKi9Z0Or0qR5PueyBuDsJ8TFF9xs6uzS3U4RHWfzWyXK/K2JL8feb9Ee+RAQCoXwxVULDh8SmZG7a4w897TFl91ZMq4yRVkBUOBtTrXMyaq1fFXKhs4i48XwkELPfi9FiJZfWmqL6L9V+YIRqubFG9bdsac74X67+8aXVHrlfFvTmIoQrmYZIqUnGJt8MkVRraqvbs88iSrf8iqQIAQN1jqIKCDYxlL2I1RYKKhPjV8RpzV6a5oFAtQ26nCicBkNZ1OUOVOXpVcvuiuVDpN+bOy5KTKs76ry7Wf2GGSneqjKcy7g0lTawq9KQ1Tq/Kvv6ku8aWm4Mwn/yhSjHPI32spWxoK5dw/Zdt27n3yFHeIwMAUK+4Mo6C5co9ORH1ooRJqoxWb6gynkpr0jkBJakCKa9XpW+BpAoXKn3H3PGfLDGpctRNqnDxCtPFwpVd/5XMG/yx/subTFJl39ExDSYpqsfCLMtybx4r9HkknbF11FlLuYykSkPqSWSfR16e4yahShtLpd1hPr2DAADUL16lUTCzh7q9iRNRLzJJlWqu/zJ9KpYltRJXh6T1zlBlT19y1p+NTnAXnl+ZiwQlr/8aoVMFczN3mVeqqN4M/qKhgIIBqyLfE0trtbOG8pX+pHuhkk4VLCQaCmhyKlPwGsGjo5PK2Nn3v52cJzWk045plyT9cf+QJqcyVd3aYFZ/WRbDfAAA6hlJFRQstzKBi+Ve1LEE679Mn0pLJKQAF5+g3FDlpTnu7COp4l8mqWIGa8VyO1UoBMYMlS6qN8MZyoK9a01ep4q5sYT1X1hIsYm3PjPob4ooFOT0uhGt62pSZ3NEk1MZPbN/sKp/l3lv1BQOcj4FAEAd410fCjbonIiyMsGbzM9tKZIqbVysgGNdV3aosvdIUumMPe3P6FTxL5NOGisxTeB2qpBUwQy5TpXKJlUY/nrXaqdTZWRiSoedi98MVbCQYhNvpqSe1V+Ny7IsbelNSJK2v9xf1b8r16fC6w4AAPWMoQoK5naqsDLBk8zPzaxxq4Yh53ekNcZJALJ6EnFFggFNpjPaPzA27c+SE9wB7lfxcPY5wqy4KMbYZNodxlBUj5ncO8xTlepUSTvfl7fMXhULB9XtpNpY/4VCRIvsVDFJlW7Skw1ty9oOSdLTeweq+veY90YMVQAAqG+cIaJguU4VTkS9qMO5o3tgKZIqlNTDEQxY6u3K3iW8Z0ZZvbkTr4mTRt9pcovqi1//dcQpA44EA2rhdwczuHeYVyipMpZynqdIqnjams64+7+DAYvnDiyo2DWCJqnSzaC/oZ3Rmx2q/Pblo7Jte5HPLl0uqcJNRwAA1DOGKiiY6VRh/Zc3JZxVFwNL0KlCUgX55utVMUkV1n/5j7v+q4Sienf1V0tElsWucUwXdRIllU6qxHme8jSzAkzKrv7iuQMLibnPI4W9RpmkCuu/GtvpqxMKBSwdHJrQ/sHxqv09uSQ351MAANQzhioomJtUYQ+1JyWassOwwbHUrG6LShlmqII5mKHKnw7PGKqkOGn0K3f9VwlDlaNOSX0nfSqYQ6WL6nOdKgxVvMyU1Uu5m0yA+RT7PNLnDPtZ/9XY4pGgNva0Sapur4opquemIwAA6htDFRRsiE4VTzPDMNvO/SwrbWiMonrMZsrqZydVWG/gV+YC9VgJ67/MHcFdXLzCHNw7zCu1/ouhSkOYllThfSwWYRJvFNVjpi3OCrAd1RyqUFQPAIAnMFRBwQbGsndhcYefN0VCuf6Baq0AI6mCuazrzl7MemlWpwpJFb9qcgZp5SRVukiqYA7uHeYVWv815lxUNekqeFN+pwqJayyGonrM5wynrH7H3qVIqvC6AwBAPWOogoJRVO995kJCf5XK6ocoqsccju1ukSTt6x9TKp27QJGkiNO3msJldKowVMECchdDK5NUYf1XY1iTl1Th5iAspvj1XwxV/MIMVZ7ZP+S+j600c8MJSRUAAOobQxUUxLZtN93AHX7e1dGc/dkNJqudVOF3BDkr2qKKh4NKZ2ztO5p0Pz5KEadvNTkXCkq5IGGK6jtbGKpgNreovkKdKmZFHUMVb1uViMl005uOOWA+xawRnEpn3GE/678aX08irpVtMaUztn7/ymBV/o5R1uMCAOAJDFVQkPFURpPOBQpORr2rw/nZVT2pEuciOXIsy9LaLmcFWF6vSpKLlb5lfualrP86MurcEdzMxSvMFqvw+i+TVImFeZ7ysmgoqJVtMUn0vmFxJqkyXsDzyNHkpGxbClhSJwlKXzBplWqV1ZubjkiqAABQ3xiqoCCDTkolFLDUzAVQz8qt/6pWUT1JFcxtfXe2rH5PXzapksnYeWt1OGn0m1xRfemdKly8wlzcgmmK6jHD6o5srwrrv7CYYtYI9g3nXpOCAauqx4X6sGVtdcvq3fW4vO4AAFDXGKqgIG5JfVNYlsUJg1eZpMpglZIqw26nChfJMd06Z6hiyupN+bPEegM/MoO0ctZ/dbH+C3OodFE9nSqN400bV6olGtLr13XW+lBQ59w1ggU8jxymT8V38svqbduu+Pcfcdd/cT4FAEA945UaBTEl9axM8LZEU5WTKnSqYB65pEp2qGIuVFpWbl0P/MNcoE4WmVSxbdtd/9XF+i/MoeJF9c4AOE6izvPe+z+O1XvesJ40ARZVTFF933D2NYk+Ff/YuKpN0VBA/cmU9vSN6thlLRX9/iS5AQDwBpIqKIgZqrAywdtMH87AWOWHKpmM7d5ZRacKZpo9VHH6VMJBBbjA5Tu5pEpxF76Tk2l3xz1JFcylmIuhhaCovrEwUEEhiimq7yOp4juRUECnr26XVJ1eFYrqAQDwBoYqKIjpyqCk3ts6nKTKQBXWf41MTskk4NtIqmCGdV3Zocr+wTGNp9JuCWcTqw18KZdUKW79l+lTiYYCXOTGnMzF0PFUhTpV3KQKv2+AXxSzRvAwSRVf2pK3AqzSRidZ/wUAgBcwVEFB3E4VkiqelnCHKpVPqpg+lUgw4K5fAYzulohaoiHZtrTvaJISTp8zA5FU2lYqXXiiIP+OYPq9MJdKJ1XcNSxhnqsAvyiqqN59XeLGMz85ozc7VKlOUiX7e9fM+i8AAOoaVz5REHMRvr2JoYqXmaRRfxWSKibN1BoLcbETs1iW5a4A+1PfqEbZF+1r+T/3YlaAmaRKZzMXrzA3t2C6Yuu/SKoAflPM8whF9f5kkiq7D41osMJrlVn/BQCANzBUQUFMB0c7SRVPM0mjaiZV2vgdwTzWOUOVl/pGleSE0dcioYBCTrdBMSvAjowwVMHCzB3m6YytqSJSUPPJFQbzXAX4RTHrv/qGs69LrP/yl+6WqNZ1Ncm2pZ37Bir2fafSGXeYR1IFAID6xlAFBTF34LD+y9s6nKTKyMRUUSt3CpGfVAHmsr6rSZL00pFcUiXOCaNv5XpVCk+qHHGSKpTUYz6xvDVd4xVIq4zxXAX4DkX1KMSWKqwAG817T0SnCgAA9Y2hCgoymKSovhG0xcMym7kqnVYZnsh+P0rqMR+TVNnTN0qnCtwVYMmJIoYqzsWrLpIqmEckmHtrO1FmWf1UOqNJ5wYEOlUA/zBJlfFFkipT6YyOOit1Gar4j1tWX8Ghinl/HA5aitBRCQBAXeOVGgUxRfV0qnhbMGC5Q4/Bscr2qgyNZU8CSKpgPuvd9V9Jt4STThX/yiVVCl//ddRNqnDxCnMLBCx3sFJur0oybyhDpwrgH4UW1R8dnZRtSwGLtZR+dIYzVHl6b7/SGbsi3zPXp8L7YwAA6h1DFRTELapn/ZfndTiDsf5KJ1XGSapgYWaocmBo3E0c0KniX03Ozz5ZRJqgj6J6FCB3QbS8ocq4s4YlYOW+J4DG53aqLPIcYkrqO5ujCjo9YfCPDSta1RINaXQyrecPDlfke5qbjuhTAQCg/nGGiIK4678Yqnheu7PCrX+0wkmVcZIqWFiiKaKEM9R79rUhSSRV/KwpXPz6r6OjZnc9QxXMLxo2q3vKW/+VK6kPybK4YAr4Ra5TZZGhynD2NYmSen8KBixt7k1IqlyvikmqNJGOBACg7jFUwaKm0hkNO2/w6FTxPpNUGRirUlKFwRsWsK4rm1Z5Zn92qEKnin+5SZUi1n8dGTFJFS5gYX6VSqok3ZJ6nqcAP3GTKosMZvtGTJ8K50d+tbm3sr0qpqie9V8AANQ/hipYlEkgSFIbKQTPM2mjgSSdKlh6xzorwAadoV4TJ42+letUKSxNYNu2jphOFdZ/YQFRc5d5mUmVsVT2dS1OST3gK+Y5ZHyRwWyfs/5rGT1fvmV6VbbvrWxShfW4AADUP4YqWJS5+N4aDSkU5FfG60zaaKDCnSpDdKqgAOucoYpBUsW/4mb9V4FDle88tU+TUxlFQwFWrWBBhfYhLCa3/ovnKcBPTNotnbE1lZ7/eYT1X3jdmoQsS3r5SNIdspVj1Env0qkCAED94wo5FmXWRLU3cbG8EXSYTpWKD1VIqmBxM4cqrNXxL3MX5lgB679e6hvV7Q88K0m66X9vUIzkABZg+hAq1anC8xTgL2YwKy08nDUX0btJqvhWezysDctbJVVmBVguqcL5FAAA9Y6hChZl1vQkGKo0BPNzHByr7PovOlVQiPVdM5MqnDT6lblQPbpIUmUqndFN392p5GRaZ63v1F+ff+xSHB48rFKdKmMkVQBfMs8hUoFDlVZWUvrZlgquABudMJ0qvO4AAFDvGKpgUYNOoiER54ShEZihSv9ohZMqdKqgAOu6m6b9exMnjb7VVOD6r7seeVE79g6oNRrSnZdtUjBgLcXhwcMqvf7LrKoD4A+BgKVI0Axn53+Nctd/tcSW5LhQn7b0JiRVJqmSZP0XAACewVAFizKdKu0kEBpCwl3/VaWkCp0qWEBrLDxtTQYnjf5l7sJMLrD+6/evDOj/eWi3JOkf/+9TtLqjad7PBYxcUqXconqSKoBfmeeR8dRCSZXse2mSKv5myup/98qgJssc5o+4SRXeHwMAUO8YqmBRdKo0lg53/VflkioTU2n3jmCGKljM+ry0CusN/Mus/5ovqTI2mdaN39mpqYytPz9tpf5i8zFLeXjwMNO5s9DF0EKYvh+GKoD/RMMLD2dT6YyOjjpDFTpVfG19d7M6msKanMromf2DZX2vJK87AAB4BkMVLMrtVCGp0hDMGrdKJlWGx3N3mrew/guLWJfXq9JEUsW3TEppbJ6hymd++pz+dHhUy1uj+tSlp8myWPuFwlQqqWIGfmZIA8A/3DWC8wxnzUAlGLDU0URSxc8sy3LTKjv2DpT1vSiqBwDAOxiqYFFupwpJlYaQaM7+HMdTGY2nyrvgZJihSks0RN8BFrWuOzdUYf2Xf+WK6mev/3r0+cP61uMvS5I+/85N6mjmghUK595hXmZSJUlRPeBbuaTK3M8jpk+lsznCe1+4ZfXl9qqMsv4LAADPYKiCRQ2MUVTfSFrzBh8DycqsABtyfkcoqUchjs0bqsS5WOlb5kL1zKRK/+ikbvne7yRJV52zVm/csGzJjw3eVqmi+jGGKoBv5Z5H5r4B6fBIdqjC6i9I0pbe7FDlty8flW3bJX+fUbeontcdAADqHUMVLMoU1bex/qshWJblrnKr1Aowk1ShTwWFMEmVSDCgSIiXIb8yq9/yO1Vs29bf/+gPOjQ8oeOWNevWi0+u1eHBw2KLdCEUKumkOeMk6gDfWayovs9JqixrZagCadPqhIIBSweHJrR/cLzk78P6LwAAvIOrWViUm1Rh/VfDMD/LiiVVxkmqoHAnrmjV27es1vsvOK7Wh4IaanKL6nPrv3749Kv6yR8OKBSw9MXLX0eSCSUxd5hTVA+gVIt1M/WNmJJ6kvzIJq9P6WmTJG0vYwWYu/6LYT4AAHWPoQoWNcRQpeEknELNgYolVbK/I6SZUIhAwNIXLtukG7duqPWhoIaaZyRVXulP6hP/+Ywk6YYLT9DpqxO1OjR4XKWK6sdSrP8C/CoaXrio/jBJFcxgVoCV06virv+K8roDAEC9Y6iCBdm27aYZ6FRpHB0mqTJWqU6V7AkASRUAhYq7SZW0ptIZffi7v9PwxJS29Cb0vv9Jigmlyw1VKlNUHw9zcQvwm9gizyN9TqfKMjpV4DjDlNXvLW2oYtu2+7rD+i8AAOofQxUsaHQyralMtmyvnRRCw2h3BmSV61Rxkip0qgAoUP7d/199+AX9Zs9RNUWC+uLlr1MoyNsTlG6xO8wLlSuq5+IW4DfmeWQ8Nd/6L4rqMd0WZ6jyzP6haatNCzUxlVHaOe9mqAIAQP3jqgUWZNZDRUIBt/gV3meSKoMV61QhqQKgOPl3/3/5od2SpI//Xxu1tqu5VoeEBlGxonqTVInw/gfwm8USb6z/wkw97TGtbIspnbH1+1cGi/56U1IvkZAEAMALOEvEggZNn0o8LMuyanw0qJSO5somVYboVAFQpEDAci8aZGxp68krdPnr19T4qNAITFF9uUmV3PovbhgA/GbxonqSKpjOsix3BVgpZfWmpD4eDioY4LwbAIB6x1AFCzJJBkrqG4tZ5dZfqaQKnSoASmCKWLtbIvrM209jeI+KqFhRvbO+haJ6wH9iZo3gHEmVVDrjvofubqFzEjlmBVgpZfW5knrOpwAA8AKGKliQKTKnT6WxdDRlTwArtf6LThUApTCrvj7zttO52xcV4yZVyiiqt21byZTpVGGoAviNO5ydI/F2ZCSb9A4GLPc9NSBNL6u3bbuorzXrv8wNJwAAoL5xGwQWNJA0QxVOGBqJSR5Vbv0XSRUAxfuXK87Q4eEJnbyqrdaHggZiOlXmK5guxMRURuZ6WJyhCuA7Zjg7Pkfizaz+6mqOKMCaJuTZuKpN0VBA/cmU9vSN6thlLQV/7aizcrI5wvkUAABeQFIFC3I7VVj/1VDMz9Mkkco1TKcKgBJ0t0QZqKDiKpFUGZvMXUht4gIX4DvR8PxJFVNST8ISM0VCAZ2+ul1S8b0qSZIqAAB4CkMVLGhgLJtkSHCxvKGYVQUDycmio+lzGRoz67+48AQAqC33YmgZQxWz+isSClAYDPjQQt1Mh52kyrJWhiqYbUveCrBijEzQqQIAgJcwVMGCKKpvTObnmUrbSk6WV+SbydjuSQCdKgCAWst1IZT++mZK6uNh7hgG/Gihonqz/oukCuZyRm92qFJ0UoX1XwAAeApDFSwo16nCxfJGEg8HFXEuOpXbqzI6OaWME3ZpZagCAKgxczF0vJykyiQl9YCf5ZIqC6z/aqVzErOZpMruQyPuKu1CjLD+CwAAT2GoggWZ9V/tTZw0NBLLstyVbmZwVqphp6Q+HLTccmAAAGrFXAxNZ2xNpUsbrJihCiX1gD+5RfVzJN76RrLnR8tIqmAO3S1Rre1qkm1LO/cNFPx1SSchSY8XAADewBVQLGhwLPvmjk6VxpPrVSlvqDLklNS3xsKyLPbOAwBqy1wMlUrvVRkjqQL42kJJlb5hOlWwMLMC7PEXjxT8NaMTzvovkioAAHgCQxUsaNBZDUWnSuNpd36m5a7/MkkVSuoBAPXAXAyVSh+quOu/wry2AX4UDc/fzXSYThUs4n+dvFyS9O9PvKz+0cLOtUYpqgcAwFMYqmBBA2N0qjSqDmeoMlDErt+5DI3lkioAANRaIGApEsy+xZ1rdU8hzBoW1n8B/mS6mSYXKKonqYL5/Pmpq3TyqjYNT0zpaw+/UNDXjDqvOxTVAwDgDQxVMK/JqYx7p2YiTqdKo3HXfxV499R83KRKnBMAAEB9WGh1TyHMMIb1X4A/zfccMjmVcVfnklTBfAIBS7defJIk6f88/rJe6U8u+jW59V+cUwEA4AUMVTCvQSeBYFlSK6udGk5u/VeFOlWiJFUAAPXBXd0zVWpSxSmqDzNUAfxovqL6I6PZlEooYNE5iQX9jxO6de5xXZpMZ3Tng88v+vlJN6nC6w4AAF7AUAXzGhzLJhja42EFAhSQNxo3qTJWmaQKgzcAQL0wF0QnUuV1qrD+C/Cn+ZIqfcPZ981dLRHOj7Agy7L00Tdn0yo/fPpVPffa0IKfP0JSBQAAT2GognmZaDt9Ko3J3F03UG5SxUk0tfF7AgCoEyapUmqnyhjrvwBfmy/tdnhkXBKrv1CYTWsSesvpq2Tb0ud+9t8Lfq6bVInyugMAgBcwVMG8zMV2ou2NKWGSKsnykipDJFUAAHXGTaqU2KmSK6rntQ3wo5jzHJJK20pnbPfjJqlCST0KdfObTlQoYOnhXYf1+ItH5v280QkzVOF1BwAAL6iLocrXvvY1rVu3TrFYTGeffbaefPLJgr7uvvvuk2VZuvTSS6t7gD5lOlXamyipb0QdTZVJqgw7nSptMYZvAID6UG5RvVn/RVIF8CeTVJGy5fTG4ZFspwpJFRRqfXez3n1WryTpMz/7b9m2PefnuUX1DPMBAPCEmg9VvvOd7+imm27SJz7xCe3YsUObNm3SRRddpEOHDi34dS+99JJuvvlmnX/++Ut0pP4zMEZSpZG5SZWxcovqSaoAAOpLbqhS4vovhiqAr0WCudPk/DWCh4cZqqB4H7jweDVFgvrdvgH97I8HZv15OmOzdhIAAI+p+VDlzjvv1Hvf+15dc8012rhxo+6++241NTXp3/7t3+b9mnQ6rW3btukf//Efdeyxxy7h0frLYDJXVI/Gk0uqTCqTmfuOqUK4SRV+TwAAdSIWzl6UGi+xqN5c3IqHubgF+FEoGFDIKaLPT7z1OUkV1n+hGMtbY/rr87PXLT7/811Kpae/NpmVkxLrvwAA8IqaDlUmJye1fft2bd261f1YIBDQ1q1b9fjjj8/7dbfffruWL1+ua6+9dtG/Y2JiQkNDQ9P+QWHcpEoTF8sbUbvzc83Y0vD41CKfPT9TVE9SBQBQL8pNquTWf/HaBviVGc7mP4/0ueu/WI+M4rz3/PXqao7oT32j+u5v9037M7P6Kxiw3NcvAABQ32r6it3X16d0Oq0VK1ZM+/iKFSt04MDsWKwkPfbYY/rGN76he+65p6C/44477lB7e7v7z5o1a8o+br8wXRskVRpTNBR04+UDY6WX1ZuBDJ0qAIB6ETUXQ0tNqjhDlXiEi1uAX83VzWTWfy1j/ReK1BoL6wP/63hJ0pd+sXtaOmXU+d/NkaAsy6rJ8QEAgOJ46kxxeHhYV1xxhe655x51d3cX9DUf+9jHNDg46P6zb9++xb8IknJF9QmK6huW6cvpL6OsfoiiegBAnSm/qD57gSseJqkC+JV5HsnvVOkbyd6IxPovlOIvz16rNZ1xHR6e0L89tsf9eNKU1LP6CwAAz6jpq3Z3d7eCwaAOHjw47eMHDx7UypUrZ33+iy++qJdeekmXXHKJ+7FMJnuyHAqFtGvXLh133HHTviYajSoa5U1vKSiqb3yJpoj2D45rIFlaUmVyKuPuq2+LcxIAAKgPsfDsi6HFoKgegJt4c4azE1Np96YziupRikgooJvfdKJuuG+n7n70T/rLs9eqszmikQknqcJQBQAAz6hpUiUSieiMM87QQw895H4sk8nooYce0jnnnDPr80866ST94Q9/0M6dO91/3vrWt+qCCy7Qzp07We1VYW5RPZ0qDauj2ZTVl5ZUMSX1ktTCSQAAoE5EQ9MvhhYrmWKoAvidm3hzbiA64qRUQgGL9cgo2SWn9+iUnjaNTEzpq798QVIuHdnMaw4AAJ5R86ugN910k6666iqdeeaZOuuss/SlL31Jo6OjuuaaayRJV155pY455hjdcccdisViOvXUU6d9fSKRkKRZH0f5SKo0vkQ8u9qtv8SkiulTaY4EFQp6apsgAKCBVaqoPs4FLsC3ojOK6nMl9VEFAvReoDSBgKVbLz5JV3zjSf2/T7yka85bR1IFAAAPqvmr9uWXX67Dhw/r4x//uA4cOKDXve51+tnPfuaW1+/du1eBABdrl1omY2vIGaqQVGlciabykipm8NZKnwoAoI6Uk1RJZ2xNOl/XFKn5W2UANTKzm8kdqrTSN4nynH/CMr3h+G499kKf7nzweZ21vlMSrzkAAHhJXbxqX3/99br++uvn/LNHHnlkwa/95je/WfkDgoYnppSxs/+beHvjyg1VSkuqvHhoRJLU29lUsWMCAKBc0fD0tT3FGMvrYWH9F+BfM4vqDw/nkipAuT765pP02Fcf0492virLCT41R3nNAQDAK4iAYE6DTnIhHg66d3ui8XQ0Ze+0M4mTYj2zf0iStLGnrWLHBABAuWLmYmgJ67/MbnvLyl1UBeA/MxNvfU6nyjKGKqiA01a365JNPbJt6Qc7XpXE+i8AALyEM0XMaWAse9KQYPVXQzMppP4S1389s39QknQKQxUAQB1xuxBKSaqYPpVwUJZFbwLgV7nE24ykSitDFVTGzW/aoFBePw9F9QAAeAdDFczJdGyw+quxmaTKYAnrv2zb1rOvZZMqp/S0V/S4AAAoRzlF9aakntVfgL/FZiRVDjudKiRVUClru5q17exe999JqgAA4B0MVTCnQWcdFEmVxtbRXHpSZd/RMQ2PTykSDOiEFS2VPjQAAEpWTlG9GarEGaoAvuYmVcz6L5IqqIIPXHiCm1BppqgeAADPYKiCOZmODZIqja09nk2q9JeQVDGrvzasbFE4yFMJAKB+xGas7SmGWf/VFObiFuBns4rqR0xRfaRmx4TG090S1ccv2ag1nXG98cRltT4cAABQIM4WMSezDioR56ShkXU4SaTh8SlNpTMKFTEccVd/rWL1FwCgvpSXVMkW1ZNUAfxtVlG9k1RZTlIFFXb563t1+et7F/9EAABQN7i9HHMynSqs/2ps+Ukks/KtUM/szw5VNlJSDwCoMzPX9hRjLEWnCoDp3UwTU2kNjWcHrt10qgAAAPgeQxXMyVxgb2eo0tBCwYBaY9nA2kDRQ5Xs+q9TGKoAAOqMezG0nPVfDFUAX4uFnaRKKqO+kWyKPxy0WI8MAAAAhiqYm7nAzvqvxtfRlP0ZDxTRq9I3MqGDQxOyLOnkVQxVAAD1xVwMHS+jqN58DwD+lEuqZHIl9S1RWZZVy8MCAABAHWCogjkNJimq9wuz4q1/tPCkiln9tb6rWc1RqpkAAPWlrKQK678AKLdGcDyVVt9IbqgCAAAAMFTBnAbGnKJ61n81vIRJqhSx/sus/qJPBQBQjypRVN8U4aYBwM/yn0cOu0kVUvwAAABgqIJ5uJ0qJFUaXsL5GRez/utZJ6lySk97VY4JAIBymKTKVMbWVLq4wYpZ/xUnqQL4WiycK6o3SZVlrSRVAAAAwFAF8xhw1n+RVGl8HU1mqFJ4UsUMVUiqAADqUX4fSrFpFbeonk4VwNfykyqmqJ71XwAAAJAYqmAO46m0ewGCpErja3fWf/UXmFQZnZjSniOjkqRTGKoAAOpQJJR7i1vsUIWkCgApv5spf/0XQxUAAAAwVMEcTGIhGLDUQgl5w3OTKgV2qjz32pBsW1rRFuXEEgBQl4IBS+GgJSm7uqcYuaJ63gMBfmaGKuNTaR1m/RcAAADyMFTBLG5JfTwsy7JqfDSotg5TVF9gUuUZ+lQAAB7gru5Jlbb+Kx7hbTLgZ9Fw7jmkj6QKAAAA8nC2iFkGnaRKO30qvmB+zv2jhSVVntk/KInVXwCA+mZKpseLTKokJ6ckSfEwSRXAz3JF9RmSKgAAAJiGs0XMYtZA0afiDyapMljg+q9nXzNJFYYqAID6VWpSxXSqNNGpAviaeQ4ZHk+53UzLSKoAAABAJFUwB5NUSTBU8QXzcy6kqD6Vzuj5AyOSWP8FAKhvbsl0kUX1uU4VhiqAn818DokEA2qLc08iAAAAGKpgDm6nipNgQGMzSZXkZHrRMt/dB0c0mc6oNRbS6o74UhweAAAlibgXRItd/2U6VRiqAH5mhipGd0uEvkkAAABIYqiCOQyy/stXWmMhBZzzQ5NSmo/pU9m4qo2TSgBAXYs5JdPjJRbVN0W4Ix3wM1NUb3TTpwIAAAAHQxXMMpBkqOIngYDl/qz7Fx2qmD4VVn8BAOpbtISkim3brP8CIEmKzUqqMFQBAABAFkMVzGKK6hNNDFX8wqwAG1ikV+XZ/ZTUAwC8wdxlXkxR/WQ6o3TGlsT6L8DvQsGAgoFcMpuSegAAABgMVTCLW1TPUMU32psWT6pkMraefc0ZqhzDUAUAUN9KKao3q78kKR5mqAL4XX6vSncrfZMAAADIYqiCWUynSiLOiYNfmKTK4Nj8SZV9/UmNTEwpEgrouGUtS3VoAACUJNepUvj6r31HxyRJbbGQwkHeJgN+N22oQlIFAAAADs4WMcuAc2G9naSKbyQK6FQxfSonrmjlQhMAoO6VklR5el+/JOl1vR1VOSYA3hIN5RJryyiqBwAAgIMro5iFonr/SbidKgsNVQYl0acCAPCGUorqd7ycHaps6U1U45AAeEwsTFIFAAAAszFUwTRT6YyGx6ck5dILaHwdTippoaL6ZyipBwB4iLnDvLikyoAkaTNJFQCanlRhqAIAAACDoQqmGXIGKhJJFT9JuEX1iw9VNva0L8kxAQBQjqhzh3mhnSp9IxN6+UhSkvS6NYlqHRYAD4nmJVVY/wUAAACDoQqmMSX1rdGQQvRm+MZi678ODY/r8PCELEs6eVXrUh4aAAAliRWZVHl674Ak6YTlLdxYAkBSbo1gJBhQWyxU46MBAABAveCqOaYx65/auJjgKwl3/dfcQ5VnnZTKsd3NaopwQgkAqH/mDvOJVKFDlWyfymb6VAA4YuHscLa7JSLLsmp8NAAAAKgXDFUwzYCTVDEX2eEPHSapMjb3+i9WfwEAvKbYovode01JPX0qALLM8wirvwAAAJCPoQqmGUwyVPEjs+akP5mSbduz/vxZSuoBAB5jCqbHC0iqTKUz+v0rg5IoqQeQY55HKKkHAABAPoYqmMZ0qiTikRofCZZSR3P25z05lZnz4tMz+7MXmhiqAAC8IhYuPKmy6+CwkpNptUZDOmF5S7UPDYBHkFQBAADAXBiqYBrTqUGnir80R4IKB7N7ovuT01eADY+n9NKRpCTpFNZ/AQA8IlpEUf0Op6T+db0JBQL0JgDIikeyzyPLGaoAAAAgD43TmMZ0arD+y18sy1J7PKK+kQn1JyfVk4i7f/bca8OSpFXtMXU2k2ACAHhDrlNl8aGKW1K/JlHNQwLgMe8+q1cDYym9/YzVtT4UAAAA1BGGKpjG7VQhqeI7HU1h9Y1MuL8DxrOs/gIAeFDUrP9KLb7+62knqbJ5LX0qAHJOPaZdX/vLLbU+DAAAANQZ1n9hGrdThaSK75ifef+MocozTkn9RlZ/AQA8JBYubP1X/+ik9vSNSiKpAgAAAABYHEMVTDPgDFXaKar3nURT9mduVsAZ7lBlFUkVAIB3uOu/FkmqPL0vu/rr2GXN7mshAAAAAADzYaiCaQackvJ21n/5ToeTVBnIS6pMTmW0+1C2U4X1XwAALym0qH7HywOSpC29rP4CAAAAACyOoQqmYf2Xf5m7c/tHc0mV5w8OK5W21R4Pa3VHfL4vBQCg7hRaVG+SKpt7E9U+JAAAAABAA2CoApdt225KgaGK/5ifuVkBJ0nP5q3+siyrJscFAEApTKfK+ALrv9IZWzudknqSKgAAAACAQjBUgSs5mdZUxpYkJehU8R3zMzcr4CTp2deyQxVWfwEAvMYkVaYytqbSc6dVdh8a1uhkWs2RoDasaF3KwwMAAAAAeBRDFbhMQiESDCgW5lfDb+bqVHlm/6Ak6ZRjGKoAALwlmvdeZnKeoYrpU9m0JqFggEQmAAAAAGBxXDmHyy2pbwqz6smH2p2hSr/ze5DJ2Hnrv9prdlwAAJTCFNVL0kRqnqHK3myfCqu/AAAAAACFYqgC16DpU4nTp+JHHU5R/aCTWHr5aFKjk2lFQwEdt6y5locGAEDRggFL4WD2JpHxqbl7VZ7eS0k9AAAAAKA4DFXgMhfTKan3JzNUGUimZNu2u/rrpJWtCgV5qgAAeI9Jq8yVVBlITurFw6OSpM0kVQAAAAAABeJKKVymU6WdpIovmWHaVMbW8MSUnjGrv3pY/QUA8CZTVj8xNXuosnPfgCRpfXezOpsjS3lYAAAAAAAPY6gClykob49zYcGPYuGgYk6p72Ay5fapnNJDST0AwJtyQ5XZ67927B2QJG1ek1jCIwIAAAAAeB1DFbgGxrIF5az/8q+EM1DrT066SRWGKgAAr4qFs+u/xudY/+X2qaxl9RcAAAAAoHAMVeAaGqOo3u/MQO35gyPqG5lQwJJOWslQBQDgTZF5kiqZjK2dJFUAAAAAACVgqAKXu/6LpIpvmaHK//dCnyTp2GUtikeCtTwkAABKFg3PXVT/wuERDU9MqSkS1EkrW2txaAAAAAAAj2KoAleuU4Whil91NGXXfz3mDFVY/QUA8LL5iurN6q/TV7crFOTtMAAAAACgcJxFwjVg1n81UVTvV+Znf2h4QhJDFQCAt+U6Vaav/9rx8oAkaXMvfSoAAAAAgOIwVIFrMOkU1ZNU8a3EjNVvp/S01+hIAAAo33xJlR1OUmULQxUAAAAAQJEYqsA16CZVGKr4VceMn/3GVSRVAADeFZ2jqH5wLKXdh0YkSZt7E7U4LAAAAACAhzFUgSRpciqj0cnsBQc6VfwrEc+tfutpj6mjmVVwAADvioacovq8pMrv9g1Ikno7m9TdEq3FYQEAAAAAPIyhCiTlUiqWJbXGGKr4VX5KaSOrvwAAHhcNZ9/q5neq5FZ/JWpxSAAAAAAAj2OoAknS4Fi2T6UtFlYwYNX4aFAr+ckUSuoBAF4XmyOp8vTeAUmU1AMAAAAASsNQBZLoU0FWIm/1G0MVAIDXmaTKRCo7VMlkbD1NST0AAAAAoAwMVSBJGkhmhyr0qfhboikvqXIM678AAN42s6j+T32jGhqfUiwc0EmrWmt5aAAAAAAAjwrV+gBQH+LhoM5c26Hjl7fU+lBQQ90tEV10ygpFQkH1tMdqfTgAAJTFFNWPO0kV06dy+jEJhYPcWwQAAAAAKB5DFUiSzj2+W+ce313rw0CNWZalf7nizFofBgAAFRELT0+qmNVfm9cmanVIAAAAAACP4xY9AAAANKTojKJ6t6R+DX0qAAAAAIDSMFQBAABAQ8p1qmQ0PJ7SroPDkqQtJFUAAAAAACViqAIAAICGFHXWf42n0vr9K4OybWl1R1zLW+kNAwAAAACUhqEKAAAAGlIsb/3XjpedPpVeVn8BAAAAAErHUAUAAAANySRVJlJp7XBK6rf0Jmp4RAAAAAAAr2OoAgAAgIaUX1T/9L4BSSRVAAAAAADlCdX6AAAAAIBqMEX1+44mNZWxFQ0FtHFVW42PCgAAAADgZSRVAAAA0JBi4WxSZSpjS5JOO6ZdkRBvfwEAAAAApeOsEgAAAA0pOmOAspk+FQAAAABAmRiqAAAAoCGZonpjC30qAAAAAIAyMVQBAABAQzJF9caWtQxVAAAAAADlYagCAACAhhTLS6r0tMe0oi1Ww6MBAAAAADQChioAAABoSJFg7q3uZlIqAAAAAIAKYKgCAACAhhQKBhQKWJKkzWsStT0YAAAAAEBDYKgCAACAhhWPZHtV6FMBAAAAAFRCqNYHAAAAAFTLTf97g17qG9XrVidqfSgAAAAAgAbAUAUAAAAN65rz1tf6EAAAAAAADYT1XwAAAAAAAAAAAAVgqAIAAAAAAAAAAFAAhioAAAAAAAAAAAAFYKgCAAAAAAAAAABQAIYqAAAAAAAAAAAABWCoAgAAAAAAAAAAUACGKgAAAAAAAAAAAAVgqAIAAAAAAAAAAFAAhioAAAAAAAAAAAAFYKgCAAAAAAAAAABQAIYqAAAAAAAAAAAABWCoAgAAAAAAAAAAUACGKgAAAAAAAAAAAAVgqAIAAAAAAAAAAFAAhioAAAAAAAAAAAAFYKgCAAAAAAAAAABQAIYqAAAAAAAAAAAABWCoAgAAAAAAAAAAUACGKgAAAAAAAAAAAAVgqAIAAAAAAAAAAFAAhioAAAAAAAAAAAAFYKgCAAAAAAAAAABQAIYqAAAAAAAAAAAABWCoAgAAAAAAAAAAUACGKgAAAAAAAAAAAAVgqAIAAAAAAAAAAFAAhioAAAAAAAAAAAAFYKgCAAAAAAAAAABQAIYqAAAAAAAAAAAABWCoAgAAAAAAAAAAUACGKgAAAAAAAAAAAAVgqAIAAAAAAAAAAFCAUK0PYKnZti1JGhoaqvGRAAAAAAAAAACAWjPzAjM/WIjvhirDw8OSpDVr1tT4SAAAAAAAAAAAQL0YHh5We3v7gp9j2YWMXhpIJpPR/v371draKsuyan04dWVoaEhr1qzRvn371NbWVuvDAbAIHrOAd/B4BbyFxyzgLTxmAW/hMQt4i18es7Zta3h4WD09PQoEFm5N8V1SJRAIaPXq1bU+jLrW1tbW0A8QoNHwmAW8g8cr4C08ZgFv4TELeAuPWcBb/PCYXSyhYlBUDwAAAAAAAAAAUACGKgAAAAAAAAAAAAVgqAJXNBrVJz7xCUWj0VofCoAC8JgFvIPHK+AtPGYBb+ExC3gLj1nAW3jMzua7onoAAAAAAAAAAIBSkFQBAAAAAAAAAAAoAEMVAAAAAAAAAACAAjBUAQAAAAAAAAAAKABDFQAAAAAAAAAAgAIwVIEk6Wtf+5rWrVunWCyms88+W08++WStDwmApDvuuEOvf/3r1draquXLl+vSSy/Vrl27pn3O+Pi4rrvuOnV1damlpUVvf/vbdfDgwRodMQDjM5/5jCzL0o033uh+jMcrUF9effVV/dVf/ZW6uroUj8d12mmn6be//a3757Zt6+Mf/7hWrVqleDyurVu3avfu3TU8YsC/0um0brvtNq1fv17xeFzHHXecPvnJT8q2bfdzeMwCtfOrX/1Kl1xyiXp6emRZln70ox9N+/NCHp9Hjx7Vtm3b1NbWpkQioWuvvVYjIyNL+F8B+MdCj9lUKqWPfvSjOu2009Tc3Kyenh5deeWV2r9//7Tv4efHLEMV6Dvf+Y5uuukmfeITn9COHTu0adMmXXTRRTp06FCtDw3wvUcffVTXXXednnjiCT344INKpVJ605vepNHRUfdzPvShD+nHP/6xvve97+nRRx/V/v379ba3va2GRw3gqaee0r/8y7/o9NNPn/ZxHq9A/ejv79d5552ncDisn/70p3r22Wf1hS98QR0dHe7nfO5zn9OXv/xl3X333frNb36j5uZmXXTRRRofH6/hkQP+9NnPflZ33XWXvvrVr+q5557TZz/7WX3uc5/TV77yFfdzeMwCtTM6OqpNmzbpa1/72px/Xsjjc9u2bXrmmWf04IMP6oEHHtCvfvUr/c3f/M1S/ScAvrLQYzaZTGrHjh267bbbtGPHDv3gBz/Qrl279Na3vnXa5/n6MWvD98466yz7uuuuc/89nU7bPT099h133FHDowIwl0OHDtmS7EcffdS2bdseGBiww+Gw/b3vfc/9nOeee86WZD/++OO1OkzA14aHh+0TTjjBfvDBB+03vvGN9g033GDbNo9XoN589KMftd/whjfM++eZTMZeuXKl/fnPf9792MDAgB2NRu3/+I//WIpDBJDnLW95i/2e97xn2sfe9ra32du2bbNtm8csUE8k2T/84Q/dfy/k8fnss8/akuynnnrK/Zyf/vSntmVZ9quvvrpkxw740czH7FyefPJJW5L98ssv27bNY5akis9NTk5q+/bt2rp1q/uxQCCgrVu36vHHH6/hkQGYy+DgoCSps7NTkrR9+3alUqlpj+GTTjpJvb29PIaBGrnuuuv0lre8ZdrjUuLxCtSb+++/X2eeeabe+c53avny5dq8ebPuuece98/37NmjAwcOTHvMtre36+yzz+YxC9TAueeeq4ceekjPP/+8JOl3v/udHnvsMV188cWSeMwC9ayQx+fjjz+uRCKhM8880/2crVu3KhAI6De/+c2SHzOA6QYHB2VZlhKJhCQes6FaHwBqq6+vT+l0WitWrJj28RUrVui///u/a3RUAOaSyWR044036rzzztOpp54qSTpw4IAikYj7omasWLFCBw4cqMFRAv523333aceOHXrqqadm/RmPV6C+/OlPf9Jdd92lm266SX/3d3+np556Sh/84AcViUR01VVXuY/Lud4n85gFlt6tt96qoaEhnXTSSQoGg0qn0/rUpz6lbdu2SRKPWaCOFfL4PHDggJYvXz7tz0OhkDo7O3kMAzU2Pj6uj370o3r3u9+ttrY2STxmGaoAgEdcd911+uMf/6jHHnus1ocCYA779u3TDTfcoAcffFCxWKzWhwNgEZlMRmeeeaY+/elPS5I2b96sP/7xj7r77rt11VVX1fjoAMz03e9+V//+7/+ub3/72zrllFO0c+dO3Xjjjerp6eExCwBAlaRSKV122WWybVt33XVXrQ+nbrD+y+e6u7sVDAZ18ODBaR8/ePCgVq5cWaOjAjDT9ddfrwceeEAPP/ywVq9e7X585cqVmpyc1MDAwLTP5zEMLL3t27fr0KFD2rJli0KhkEKhkB599FF9+ctfVigU0ooVK3i8AnVk1apV2rhx47SPnXzyydq7d68kuY9L3icD9eGWW27Rrbfeqne961067bTTdMUVV+hDH/qQ7rjjDkk8ZoF6Vsjjc+XKlTp06NC0P5+amtLRo0d5DAM1YgYqL7/8sh588EE3pSLxmGWo4nORSERnnHGGHnroIfdjmUxGDz30kM4555waHhkASbJtW9dff71++MMf6pe//KXWr18/7c/POOMMhcPhaY/hXbt2ae/evTyGgSV24YUX6g9/+IN27tzp/nPmmWdq27Zt7v/m8QrUj/POO0+7du2a9rHnn39ea9eulSStX79eK1eunPaYHRoa0m9+8xses0ANJJNJBQLTL2EEg0FlMhlJPGaBelbI4/Occ87RwMCAtm/f7n7OL3/5S2UyGZ199tlLfsyA35mByu7du/WLX/xCXV1d0/7c749Z1n9BN910k6666iqdeeaZOuuss/SlL31Jo6Ojuuaaa2p9aIDvXXfddfr2t7+t//zP/1Rra6u7l7K9vV3xeFzt7e269tprddNNN6mzs1NtbW36wAc+oHPOOUd/9md/VuOjB/yltbXV7Tsympub1dXV5X6cxytQPz70oQ/p3HPP1ac//WlddtllevLJJ/X1r39dX//61yVJlmXpxhtv1D/90z/phBNO0Pr163Xbbbepp6dHl156aW0PHvChSy65RJ/61KfU29urU045RU8//bTuvPNOvec975HEYxaotZGREb3wwgvuv+/Zs0c7d+5UZ2enent7F318nnzyyXrzm9+s9773vbr77ruVSqV0/fXX613vepd6enpq9F8FNK6FHrOrVq3SO97xDu3YsUMPPPCA0um0ez2qs7NTkUiEx6wN2Lb9la98xe7t7bUjkYh91lln2U888UStDwmAbduS5vzn3nvvdT9nbGzMfv/73293dHTYTU1N9l/8xV/Yr732Wu0OGoDrjW98o33DDTe4/87jFagvP/7xj+1TTz3Vjkaj9kknnWR//etfn/bnmUzGvu222+wVK1bY0WjUvvDCC+1du3bV6GgBfxsaGrJvuOEGu7e3147FYvaxxx5r//3f/709MTHhfg6PWaB2Hn744TnPXa+66irbtgt7fB45csR+97vfbbe0tNhtbW32NddcYw8PD9fgvwZofAs9Zvfs2TPv9aiHH37Y/R5+fsxatm3bSznEAQAAAAAAAAAA8CI6VQAAAAAAAAAAAArAUAUAAAAAAAAAAKAADFUAAAAAAAAAAAAKwFAFAAAAAAAAAACgAAxVAAAAAAAAAAAACsBQBQAAAAAAAAAAoAAMVQAAAAD4zsGDB3X77bfr6NGjtT4UAAAAAB7CUAUAAACAr0xNTemyyy5TLBZTZ2dnSd/jkUcekWVZGhgYqOzBAQAAAKhrDFUAAAAA1K2rr75almXJsixFIhEdf/zxuv322zU1NVXy97zlllu0adMmfeQjH6ngkQIAAADwg1CtDwAAAAAAFvLmN79Z9957ryYmJvSTn/xE1113ncLhsD72sY8V9X3S6bQsy9IXv/jFKh0pAAAAgEZHUgUAAABAXYtGo1q5cqXWrl2r973vfdq6davuv/9+TUxM6Oabb9Yxxxyj5uZmnX322XrkkUfcr/vmN7+pRCKh+++/Xxs3blQ0GtXevXt19dVX69JLL3U/b2JiQh/84Ae1fPlyxWIxveENb9BTTz017Rh+8pOfaMOGDYrH47rgggv00ksvzTrO73//+zrllFMUjUa1bt06feELX6jS/yMAAAAAaoWhCgAAAABPicfjmpyc1PXXX6/HH39c9913n37/+9/rne98p9785jdr9+7d7ucmk0l99rOf1b/+67/qmWee0fLly2d9v4985CP6/ve/r29961vasWOHjj/+eF100UVuif2+ffv0tre9TZdccol27typv/7rv9att9467Xts375dl112md71rnfpD3/4g/7hH/5Bt912m775zW9W9f8LAAAAAEuLoQoAAAAAT7BtW7/4xS/085//XKeffrruvfdefe9739P555+v4447TjfffLPe8IY36N5773W/JpVK6Z//+Z917rnn6sQTT1RTU9O07zk6Oqq77rpLn//853XxxRdr48aNuueeexSPx/WNb3xDknTXXXfpuOOO0xe+8AWdeOKJ2rZtm66++upp3+fOO+/UhRdeqNtuu00bNmzQ1Vdfreuvv16f//znq/7/CwAAAIClw1AFAAAAQF174IEH1NLSolgsposvvliXX3653vGOdyidTmvDhg1qaWlx/3n00Uf14osvul8biUR0+umnz/u9X3zxRaVSKZ133nnux8LhsM466yw999xzkqTnnntOZ5999rSvO+ecc6b9+3PPPTfte0jSeeedp927dyudTpf83w4AAACgvlBUDwAAAKCuXXDBBbrrrrsUiUTU09OjUCik73znOwoGg9q+fbuCweC0z29paXH/dzwel2VZS33IAAAAABoUQxUAAAAAda25uVnHH3/8tI9t3rxZ6XRahw4d0vnnn1/y9z7uuOMUiUT061//WmvXrpWUXRn21FNP6cYbb5QknXzyybr//vunfd0TTzwx7d9PPvlk/frXv572sV//+tfasGHDrKEPAAAAAO9i/RcAAAAAz9mwYYO2bdumK6+8Uj/4wQ+0Z88ePfnkk7rjjjv0X//1XwV/n+bmZr3vfe/TLbfcop/97Gd69tln9d73vlfJZFLXXnutJOlv//ZvtXv3bt1yyy3atWuXvv3tb88qoP/whz+shx56SJ/85Cf1/PPP61vf+pa++tWv6uabb67kfzYAAACAGmOoAgAAAMCT7r33Xl155ZX68Ic/rBNPPFGXXnqpnnrqKfX29hb1fT7zmc/o7W9/u6644gpt2bJFL7zwgn7+85+ro6NDktTb26vvf//7+tGPfqRNmzbp7rvv1qc//elp32PLli367ne/q/vuu0+nnnqqPv7xj+v222+fVWgPAAAAwNss27btWh8EAAAAAAAAAABAvSOpAgAAAAAAAAAAUACGKgAAAAAAAAAAAAVgqAIAAAAAAAAAAFAAhioAAAAAAAAAAAAFYKgCAAAAAAAAAABQAIYqAAAAAAAAAAAABWCoAgAAAAAAAAAAUACGKgAAAAAAAAAAAAVgqAIAAAAAAAAAAFAAhioAAAAAAAAAAAAFYKgCAAAAAAAAAABQAIYqAAAAAAAAAAAABfj/AZbcBSL6KqbWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of train data:  (96, 23)\n",
      "Dimension of test data:  (24, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_series_data(df_despesas_agrupado, 'valor_pago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_despesas_agrupado.to_csv('../../data/dados_despesas.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelagem dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df_despesas_agrupado) * 0.75)\n",
    "train_dataset, test_dataset = df_despesas_agrupado.iloc[:train_size], df_despesas_agrupado.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.drop(['valor_pago'], axis=1)\n",
    "y_train = train_dataset.loc[:, ['valor_pago']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_dataset.drop(['valor_pago'], axis=1)\n",
    "y_test = test_dataset.loc[:, ['valor_pago']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_x = MinMaxScaler(feature_range=(0,1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scaler = scaler_x.fit(X_train)\n",
    "output_scaler = scaler_y.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizando os dados de treino e teste\n",
    "train_y_norm = output_scaler.transform(y_train)\n",
    "train_x_norm = input_scaler.transform(X_train)\n",
    "\n",
    "test_y_norm = output_scaler.transform(y_test)\n",
    "test_x_norm = input_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_x_norm.reshape((test_x_norm.shape[0], 1, test_x_norm.shape[1]))\n",
    "X_train = train_x_norm.reshape((train_x_norm.shape[0], 1, train_x_norm.shape[1]))\n",
    "y_test = test_y_norm.reshape((test_y_norm.shape[0], 1))\n",
    "y_train = train_y_norm.reshape((train_y_norm.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste no modelo com 32, 64 e 128 neurônios para verficação do mais adequado para a aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 82ms/step - loss: 0.2301 - val_loss: 0.0677\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1243 - val_loss: 0.0154\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0544 - val_loss: 0.0478\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0370 - val_loss: 0.0309\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0375 - val_loss: 0.0208\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0350 - val_loss: 0.0220\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0352 - val_loss: 0.0181\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.0158\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0327 - val_loss: 0.0143\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0325 - val_loss: 0.0132\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0274 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0284 - val_loss: 0.0126\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0256 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0241 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0226 - val_loss: 0.0130\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0126\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0231 - val_loss: 0.0126\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0209 - val_loss: 0.0131\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0142\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0146\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0137\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0129\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0146\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0152\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0124\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0173\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0114\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0138\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0113\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0130\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0111\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0129\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0152\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0135\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0155\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0136\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0157\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0121\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0140\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0131\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0149\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0160\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0167\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0188\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0126\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0145\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0143\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0124\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0138\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0109\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0143\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0154\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0188\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0159\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0227\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0207\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0201\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0213\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0147\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0211\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0142\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0161\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0147\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0155\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0138\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0155\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0149\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0152\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0150\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0190\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0260\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0211\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0187\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0129\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0169\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0188\n",
      ">Neurons=32, Score=3.5059139132499695\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 66ms/step - loss: 0.2337 - val_loss: 0.0681\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1295 - val_loss: 0.0148\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0549 - val_loss: 0.0562\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0402 - val_loss: 0.0326\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0381 - val_loss: 0.0276\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0373 - val_loss: 0.0272\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0345 - val_loss: 0.0221\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0351 - val_loss: 0.0214\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0153\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0171\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0148\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0289 - val_loss: 0.0126\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0253 - val_loss: 0.0132\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0245 - val_loss: 0.0126\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0116\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0215 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0108\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0108\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0107\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0105\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0105\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0103\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0108\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0101\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0094\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0093\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0091\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0090\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0090\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0084\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0088\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0082\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0082\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0075\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0089\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0075\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0074\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0085\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0093\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0068\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0068\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0072\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0062\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0065\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0066\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0058\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0095\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0052\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0070\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0092\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0049\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0060\n",
      ">Neurons=32, Score=1.1991625651717186\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 65ms/step - loss: 0.1987 - val_loss: 0.0431\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0756 - val_loss: 0.0262\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0413 - val_loss: 0.0412\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0356 - val_loss: 0.0229\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0314 - val_loss: 0.0222\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0305 - val_loss: 0.0214\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0350 - val_loss: 0.0171\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0314 - val_loss: 0.0168\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0324 - val_loss: 0.0153\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0348 - val_loss: 0.0147\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0308 - val_loss: 0.0141\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0266 - val_loss: 0.0134\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0269 - val_loss: 0.0135\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0127\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0257 - val_loss: 0.0125\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0250 - val_loss: 0.0124\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0130\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0127\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0128\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0208 - val_loss: 0.0134\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0137\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0196 - val_loss: 0.0130\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0140\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0135\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0161\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0130\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0156\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0140\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0143\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0146\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0125\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0140\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0221\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0134\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0179\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0160\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0172\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0168\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0168\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0135\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0155\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0169\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0173\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0189\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0174\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0202\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0177\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0159\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0157\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0189\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0283\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0180\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0262\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0170\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0222\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0204\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0153\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0243\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0222\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0097\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0134\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0306\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0183\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0153\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0193\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0243\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0239\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0285\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0234\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0206\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0188\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0239\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0250\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0226\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0185\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0305\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0226\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0236\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0206\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0303\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0273\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0287\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0216\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0181\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0155\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0296\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0310\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0275\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0209\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0253\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0240\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0369\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0279\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0174\n",
      ">Neurons=32, Score=2.6677152141928673\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 67ms/step - loss: 0.2287 - val_loss: 0.0629\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1194 - val_loss: 0.0150\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0502 - val_loss: 0.0584\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0388 - val_loss: 0.0356\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0424 - val_loss: 0.0277\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0339 - val_loss: 0.0227\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0323 - val_loss: 0.0199\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0338 - val_loss: 0.0185\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0323 - val_loss: 0.0165\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0289 - val_loss: 0.0148\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0271 - val_loss: 0.0142\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0133\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0259 - val_loss: 0.0127\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0255 - val_loss: 0.0127\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0258 - val_loss: 0.0126\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0131\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0142\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0126\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 0.0215 - val_loss: 0.0142\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0135\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0137\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0174\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0136\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0164\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0147\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0140\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0143\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0124\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0149\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0131\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0156\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0167\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0143\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0123\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0142\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0181\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0169\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0165\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0148\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0146\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0140\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0179\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0201\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0140\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0198\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0167\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0244\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0137\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0136\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0158\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0188\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0178\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0160\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0145\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0176\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0144\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0177\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0178\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0168\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0268\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0180\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0154\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0153\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0178\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0203\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0158\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0186\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0165\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0207\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0181\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0175\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0220\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0246\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0169\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0181\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0227\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0237\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0173\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0168\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0212\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0193\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0182\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0185\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0176\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0225\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0217\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0227 - val_loss: 0.0087\n",
      ">Neurons=32, Score=1.3839381746947765\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 72ms/step - loss: 0.2265 - val_loss: 0.0714\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1084 - val_loss: 0.0149\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0445 - val_loss: 0.0425\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0343 - val_loss: 0.0232\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0347 - val_loss: 0.0216\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0212\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0387 - val_loss: 0.0189\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0184\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0318 - val_loss: 0.0155\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0286 - val_loss: 0.0147\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0143\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0275 - val_loss: 0.0133\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0261 - val_loss: 0.0129\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0128\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0126\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0125\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0124\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0123\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0125\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0126\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0120\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0113\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0115\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0115\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0116\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0112\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0096\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0094\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0091\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0087\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0085\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0085\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0089\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0082\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0089\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0085\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0089\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0075\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0069\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0067\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0072\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0073\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0066\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0063\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0068\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0058\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0057\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0062\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0052\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0060\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0069\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0094\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0062\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0056\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0049\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0047\n",
      ">Neurons=32, Score=2.7371013537049294\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 66ms/step - loss: 0.2093 - val_loss: 0.0434\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0833 - val_loss: 0.0236\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0477 - val_loss: 0.0514\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0380 - val_loss: 0.0289\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0416 - val_loss: 0.0258\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0390 - val_loss: 0.0236\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0358 - val_loss: 0.0196\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0299 - val_loss: 0.0207\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0345 - val_loss: 0.0178\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0165\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0325 - val_loss: 0.0157\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0317 - val_loss: 0.0155\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0271 - val_loss: 0.0141\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0274 - val_loss: 0.0138\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0263 - val_loss: 0.0136\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.0136\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0137\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0208 - val_loss: 0.0146\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0244 - val_loss: 0.0136\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.0145\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0142\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0224 - val_loss: 0.0159\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0147\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0138\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0173\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0129\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0160\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0142\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0162\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0138\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0139\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0128\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0186\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0135\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0135\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0136\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0160\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0126\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0152\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0136\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0134\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0208\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0163\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0143\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0180\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0146\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0144\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0136\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0161\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0174\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0170\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0173\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0197\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0166\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0216\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0186\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0173\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0214\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0174\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0183\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0206\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0211\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0193\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0181\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0209\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0205\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0155\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0226\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0215\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0239\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0198\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0126\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0199\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0245 - val_loss: 0.0132\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0390\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0215\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0178\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0193\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0194\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0236\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0264\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0259\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0191\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0191\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0202\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0182\n",
      ">Neurons=32, Score=6.926059722900391\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 66ms/step - loss: 0.2253 - val_loss: 0.0659\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1120 - val_loss: 0.0149\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0483 - val_loss: 0.0401\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0381 - val_loss: 0.0246\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0392 - val_loss: 0.0200\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0359 - val_loss: 0.0206\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0372 - val_loss: 0.0185\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0323 - val_loss: 0.0165\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0315 - val_loss: 0.0163\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0145\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0298 - val_loss: 0.0138\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0323 - val_loss: 0.0138\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0268 - val_loss: 0.0132\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0252 - val_loss: 0.0131\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0253 - val_loss: 0.0130\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0135\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0135\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0141\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.0148\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0216 - val_loss: 0.0151\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0152\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0161\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0169\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0198\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0244\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0189\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0185\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0180\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0220\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0215\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0230\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0227\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0186\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0186\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0199\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0178\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0196\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0209\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0208\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0217\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0169\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0221\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0193\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0153\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0189\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0199\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0190\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0227\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0207\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0149\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0199\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0213\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0240\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0230\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0191\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0214\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0189\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0206\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0173\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0136\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0196\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0148\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0180\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0247\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0178\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0248\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0182\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0180\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0186\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0196\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0151\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0199\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0193\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0170\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0178\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0170\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0205\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0176\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0196\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0148\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0156\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0146\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0159\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0174\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0153\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0185\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0152\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0169\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0164\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0188\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0143\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0187\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0137\n",
      ">Neurons=32, Score=2.5342976674437523\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 79ms/step - loss: 0.2392 - val_loss: 0.0600\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1126 - val_loss: 0.0167\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0545 - val_loss: 0.0579\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0378 - val_loss: 0.0337\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0403 - val_loss: 0.0274\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.0256\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0363 - val_loss: 0.0215\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0334 - val_loss: 0.0170\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0148\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0133\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0258 - val_loss: 0.0131\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0238 - val_loss: 0.0133\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0144\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0134\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0136\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0150\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0136\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0139\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0130\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0131\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0130\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0130\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0188\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0150\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0114\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0160\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0124\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0144\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0108\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0165\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0120\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0130\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0155\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0169\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0130\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0136\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0144\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0150\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0149\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0143\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0158\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0159\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0171\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0182\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0156\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0126\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0123\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0176\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0153\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0148\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0143\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0165\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0132\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0198\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0156\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0122\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0171\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0087\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0203\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0125\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0123\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0141\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0137\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0160\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0152\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0153\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0173\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0148\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0146\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0143\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0170\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0168\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0118\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0144\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0230\n",
      ">Neurons=32, Score=6.055384129285812\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 64ms/step - loss: 0.2400 - val_loss: 0.0781\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1331 - val_loss: 0.0173\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0546 - val_loss: 0.0411\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0352 - val_loss: 0.0307\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0384 - val_loss: 0.0258\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0342 - val_loss: 0.0223\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0365 - val_loss: 0.0194\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0323 - val_loss: 0.0176\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0303 - val_loss: 0.0164\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0295 - val_loss: 0.0146\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0259 - val_loss: 0.0135\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0130\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0278 - val_loss: 0.0128\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0227 - val_loss: 0.0131\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0220 - val_loss: 0.0136\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0148\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0145\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0169\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0144\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0152\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0167\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0135\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0160\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0131\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0163\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0140\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0158\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0125\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0161\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0166\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0177\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0140\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0186\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0161\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0196\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0169\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0145\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0183\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0138\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0147\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0180\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0176\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0189\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0234\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0166\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0148\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0183\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0208\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0191\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0178\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0152\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0141\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0172\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0175\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0159\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0188\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0234\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0151\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0204\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0201\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0204\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0167\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0220\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0253\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0206\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0178\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0146\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0223\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0165\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0233\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0185\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0223\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0166\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0231\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0248\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0209\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0188\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0158\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0218\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0171\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0146\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0196\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0207\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0176\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0208\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0222\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0294\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0233\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0177\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0205\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0135\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0101\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0271\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0259\n",
      ">Neurons=32, Score=6.534507125616074\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 65ms/step - loss: 0.2008 - val_loss: 0.0358\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0829 - val_loss: 0.0282\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0455 - val_loss: 0.0540\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0340 - val_loss: 0.0285\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0389 - val_loss: 0.0270\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0362 - val_loss: 0.0275\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0340 - val_loss: 0.0203\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0323 - val_loss: 0.0192\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0320 - val_loss: 0.0165\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0254 - val_loss: 0.0163\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0281 - val_loss: 0.0137\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0231 - val_loss: 0.0128\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0248 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0234 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0131\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0126\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0120\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0138\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0118\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0124\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0116\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0127\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0131\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0122\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0141\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0085\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0082\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0110\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0091\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0069\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0092\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0079\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0143\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0076\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0092\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0113\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0071\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0064\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0075\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0134\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0117\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0068\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      ">Neurons=32, Score=1.715458557009697\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 65ms/step - loss: 0.2072 - val_loss: 0.0423\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0720 - val_loss: 0.0423\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0374 - val_loss: 0.0250\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0363 - val_loss: 0.0203\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0337 - val_loss: 0.0198\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0290 - val_loss: 0.0152\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0274 - val_loss: 0.0146\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0128\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.0124\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0126\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0126\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0119\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0129\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0119\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0107\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0207 - val_loss: 0.0150\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0095\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0098\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0096\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0087\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0074\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0074\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0072\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0072\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0097\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0080\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0076\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0067\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0066\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0061\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0058\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0065\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0063\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0077\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0058\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0061\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0093\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0064\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0061\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0066\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      ">Neurons=60, Score=4.380348697304726\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 68ms/step - loss: 0.1924 - val_loss: 0.0232\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0606 - val_loss: 0.0640\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0363 - val_loss: 0.0279\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0366 - val_loss: 0.0252\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0339 - val_loss: 0.0236\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0304 - val_loss: 0.0174\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0151\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0273 - val_loss: 0.0138\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0254 - val_loss: 0.0128\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0268 - val_loss: 0.0126\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.0124\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0226 - val_loss: 0.0123\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0124\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0132\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0118\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0125\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0126\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0125\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0114\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0095\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0207\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0136\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0093\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0111\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0154\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0156\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0089\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0108\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0118\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0124\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0140\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0112\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0152\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0079\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0159\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0140\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0094\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0134\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0064\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0065\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0141\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0078\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0091\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0119\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0097\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0094\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      ">Neurons=60, Score=4.330588132143021\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 78ms/step - loss: 0.1782 - val_loss: 0.0246\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0539 - val_loss: 0.0493\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0179\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 0.0182\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0139\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0128\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0119\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0125\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0112\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0134\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0115\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0132\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0115\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0101\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0099\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0110\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0169\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0139\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0092\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0127\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0143\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0128\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0125\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0136\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0093\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0077\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0168\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0161\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0091\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0184\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0148\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0170\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0149\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0122\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0131\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0161\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0145\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0117\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0141\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0144\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0118\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0151\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0172\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0062\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0130\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0159\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0128\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0123\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0123\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0165\n",
      ">Neurons=60, Score=6.269596517086029\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 107ms/step - loss: 0.1989 - val_loss: 0.0313\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0650 - val_loss: 0.0521\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0381 - val_loss: 0.0262\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0350 - val_loss: 0.0235\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0319 - val_loss: 0.0206\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0188\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0151\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0124\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0130\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0129\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0153\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0137\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0137\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0173\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0196\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0178\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0178\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0172\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0162\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0171\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0234\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0166\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0122\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0158\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0211\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0128 - val_loss: 0.0172\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0188\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0166\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0194\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0215\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0185\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0199\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0173\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0217\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0231\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0196\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0174\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0271\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0204\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0164\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0209\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0246\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0207\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0206\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0246\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0197\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0202\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0227\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0244\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0196\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0229\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0264\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0263\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0216\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0226\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0193\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0255\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0311\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0248\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0217\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0246\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0250\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0293\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0202\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0194 - val_loss: 0.0094\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0170\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0261\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0249\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0212\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0238\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0260\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0280\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0271\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0240\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0230\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0204\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0177\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0176\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0223\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0266\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0355\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0188\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0159\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0230\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0342\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0218\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0213\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0272\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0294\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0286\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0216\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0226\n",
      ">Neurons=60, Score=8.06451365351677\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 101ms/step - loss: 0.2004 - val_loss: 0.0260\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0661 - val_loss: 0.0611\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0404 - val_loss: 0.0336\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0342 - val_loss: 0.0258\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0332 - val_loss: 0.0232\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0317 - val_loss: 0.0186\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0188\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0293 - val_loss: 0.0150\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0138\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0131\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0126\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0127\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0127\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0123\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0124\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0133\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0115\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0119\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0108\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0111\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0099\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0097\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0101\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0095\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0107\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0101\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0107\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0094\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0093\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0089\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0092\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0092\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0106\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0087\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0093\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0087\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0079\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0078\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0083\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0072\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0118\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0071\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0080\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0102\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0118\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0095\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0138\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0124\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0129\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0074\n",
      ">Neurons=60, Score=5.231796205043793\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 99ms/step - loss: 0.1935 - val_loss: 0.0245\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0623 - val_loss: 0.0593\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0368 - val_loss: 0.0239\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.0231\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0329 - val_loss: 0.0203\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0313 - val_loss: 0.0165\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0277 - val_loss: 0.0155\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0136\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0127\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0130\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0126\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0221 - val_loss: 0.0127\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0127\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0124\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0120\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0126\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0120\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0119\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0115\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0120\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0113\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0137\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0138\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0111\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0152\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0103\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0164\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0106\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0097\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0090\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0186\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0138\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0087\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0130\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0117\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0120\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0130\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0156\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0078\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0156\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0160\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0128\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0122\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0146\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0172\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0068\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0064\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0170\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0136\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0132\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0095\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0104\n",
      ">Neurons=60, Score=2.2668398916721344\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 72ms/step - loss: 0.1761 - val_loss: 0.0239\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0569 - val_loss: 0.0439\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0368 - val_loss: 0.0204\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0352 - val_loss: 0.0179\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0296 - val_loss: 0.0155\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0302 - val_loss: 0.0137\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0303 - val_loss: 0.0133\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0281 - val_loss: 0.0129\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0265 - val_loss: 0.0129\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0145\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0129\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0230 - val_loss: 0.0143\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0131\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0155\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0129\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0139\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0137\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0148\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0125\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0128\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0150\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0144\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0124\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0132\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0174\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0174\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0105\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0189\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0159\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0107\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0138\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0141\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0144\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0139\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0124\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0146\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0187\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0167\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0091\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0148\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0171\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0120\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0182\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0148\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0141\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0134\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0168\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0106\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0147\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0153\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0139\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0219\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0099\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0089\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0163\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0231\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0190\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0154\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0168\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0186\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0134\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0159\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0165\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0168\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0186\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0170\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0146\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0254\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0208\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0075\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0162\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0216\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0136\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0112\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0189\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0171\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0190\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0211\n",
      ">Neurons=60, Score=8.524983376264572\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 101ms/step - loss: 0.1922 - val_loss: 0.0251\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0569 - val_loss: 0.0567\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0347 - val_loss: 0.0219\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0374 - val_loss: 0.0199\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0318 - val_loss: 0.0187\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0271 - val_loss: 0.0158\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0284 - val_loss: 0.0143\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0138\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0245 - val_loss: 0.0128\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.0134\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0124\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0126\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0131\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0119\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0120\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0113\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0115\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0117\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0130\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0101\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0104\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0102\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0105\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0126\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0120\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0096\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0175\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0113\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0125\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0160\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0187\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0076\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0160\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0112\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0125\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0123\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0143\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0144\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0166\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0109\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0154\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0123\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0174\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0065\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0111\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0154\n",
      ">Neurons=60, Score=6.2706440687179565\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 68ms/step - loss: 0.2016 - val_loss: 0.0294\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0687 - val_loss: 0.0614\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0399 - val_loss: 0.0314\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0383 - val_loss: 0.0279\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0358 - val_loss: 0.0210\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0327 - val_loss: 0.0200\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0315 - val_loss: 0.0163\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0313 - val_loss: 0.0148\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0137\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0284 - val_loss: 0.0126\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0124\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0232 - val_loss: 0.0118\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0119\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0118\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0116\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0113\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0109\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0101\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0097\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0132\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0102\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0094\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0129\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0076\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0107\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0102\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0263 - val_loss: 0.0125\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0077\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0110\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0120\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0110\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0078\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0086\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0067\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0127\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0073\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0130\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0073\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0070\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0131\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0118\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0093\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0127\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0088\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0095\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0092\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0103\n",
      ">Neurons=60, Score=3.7436265498399734\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 79ms/step - loss: 0.1842 - val_loss: 0.0228\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0576 - val_loss: 0.0593\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0370 - val_loss: 0.0226\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0368 - val_loss: 0.0206\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0327 - val_loss: 0.0191\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 0.0155\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0278 - val_loss: 0.0143\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0130\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0124\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0126\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0132\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0134\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0111\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0113\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0103\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0095\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0102\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0104\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0097\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0093\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0140\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0127\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0134\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0098\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0143\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0098\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0113\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0143\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0127\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0151\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0122\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0117\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0090\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0090\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0079\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0174\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0143\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0144\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0133\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0141\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0139\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0087\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0166\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0110\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0123\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0124\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0123\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0137\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0121\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0114\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0116\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      ">Neurons=60, Score=4.408218339085579\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 66ms/step - loss: 0.1811 - val_loss: 0.0195\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0567 - val_loss: 0.0536\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0355 - val_loss: 0.0210\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0334 - val_loss: 0.0185\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0330 - val_loss: 0.0156\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0291 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0277 - val_loss: 0.0126\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0124\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0215 - val_loss: 0.0127\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0214 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0138\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0132\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0134\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0133\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0120\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0122\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0139\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0134\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0117\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0101\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0122\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 0.0114\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0111\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0102\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0091\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0095\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0081\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0075\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0096\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0115\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0125\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0091\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0073\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0116\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0085\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0147\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0143\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0096\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0107\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0094\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      ">Neurons=64, Score=7.17611089348793\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 75ms/step - loss: 0.1885 - val_loss: 0.0246\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0574 - val_loss: 0.0563\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0346 - val_loss: 0.0205\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0329 - val_loss: 0.0212\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0298 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0134\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0289 - val_loss: 0.0124\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0117\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0118\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0113\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0106\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0109\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0140\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0130\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0099\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0141\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0209 - val_loss: 0.0202\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0110\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0132\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0140\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0124\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0124\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0137\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0139\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0140\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0161\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0165\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0170\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0134\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0134\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0166\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0171\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0083\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0186\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0157\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0167\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0137\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0131\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0134\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0142\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0178\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0147\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0124\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0139\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0161\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0154\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0181\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0107\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0100\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0063\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0223\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0270\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0189\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0172\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0163\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0224\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0177\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0231\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0164\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0176\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0214\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0242\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0142\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0107\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0197\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0238\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0201\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0220\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0178\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0148\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0234\n",
      ">Neurons=64, Score=5.181409418582916\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 87ms/step - loss: 0.1796 - val_loss: 0.0178\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0518 - val_loss: 0.0554\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0364 - val_loss: 0.0240\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0324 - val_loss: 0.0243\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0185\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0298 - val_loss: 0.0165\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0157\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0136\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 0.0131\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0124\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0122\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0133\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0119\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0120\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0119\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0116\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0124\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0124\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0113\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0104\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0108\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0105\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0124\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0101\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0100\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0103\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0090\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0085\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0092\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0116\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0086\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0122\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0077\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0137\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0075\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0079\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0112\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0076\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0074\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0115\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0064\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0095\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0108\n",
      ">Neurons=64, Score=3.5147927701473236\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 73ms/step - loss: 0.1817 - val_loss: 0.0204\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0521 - val_loss: 0.0480\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0327 - val_loss: 0.0181\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0181\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0292 - val_loss: 0.0165\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0285 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0295 - val_loss: 0.0131\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0123\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0120\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0228 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0109\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0119\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0106\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0122\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0122\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0098\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0151\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0106\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0125\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0122\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0138\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0119\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0100\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0176\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0143\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0089\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0078\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0146\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0130\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0122\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0111\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0183\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0135\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0168\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0142\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0134\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0131\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0130\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0109\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0167\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0222\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0133\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0089\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0069\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0058\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0146\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0128\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0186\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0117\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0092\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0135\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0125\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0156\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0130\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0110\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0107\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0183\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0158\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0068\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0065\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0071\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0321 - val_loss: 0.0070\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0076\n",
      ">Neurons=64, Score=4.541607573628426\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 67ms/step - loss: 0.1693 - val_loss: 0.0166\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0486 - val_loss: 0.0498\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0341 - val_loss: 0.0187\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0349 - val_loss: 0.0229\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0282 - val_loss: 0.0146\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0134\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.0125\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0130\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0122\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0123\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0118\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0142\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0215 - val_loss: 0.0152\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0105\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0103\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0144\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0108\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0092\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0139\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0089\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0091\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0111\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0115\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0092\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0113\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0119\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0132\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0140\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.0129\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0106\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0094\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0078\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0168\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0143\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0128\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0120\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0114\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0112\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0103\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0111\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0132\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0156\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0123\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0053\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0083\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0081\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0298 - val_loss: 0.0078\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0200\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0093\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0126\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0127\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0124\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0119\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0127\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0100\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0078\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0139\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0135\n",
      ">Neurons=64, Score=5.343576893210411\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 94ms/step - loss: 0.1766 - val_loss: 0.0168\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0542 - val_loss: 0.0564\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0343 - val_loss: 0.0258\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0357 - val_loss: 0.0268\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0322 - val_loss: 0.0223\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0318 - val_loss: 0.0199\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0285 - val_loss: 0.0156\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0154\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0250 - val_loss: 0.0142\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0126\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0195 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0125\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0123\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0120\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0123\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0120\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0113\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0109\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0107\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0107\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0104\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0145\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0102\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0104\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0085\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0094\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0093\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0094\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0086\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0130\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0083\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0094\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0068\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0077\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0089\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0090\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0073\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0088\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0085\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0075\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0063\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0065\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0103\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0077\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0061\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      ">Neurons=64, Score=3.130517154932022\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 68ms/step - loss: 0.1930 - val_loss: 0.0270\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0564 - val_loss: 0.0506\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0350 - val_loss: 0.0190\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0338 - val_loss: 0.0211\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0326 - val_loss: 0.0180\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0294 - val_loss: 0.0159\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0143\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0136\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0134\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0130\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0230 - val_loss: 0.0131\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0129\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0134\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0130\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0130\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0129\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0128\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0129\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0128\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0130\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0128\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0129\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0128\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0121\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0120\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0117\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0125\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0122\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0121\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0129\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0125\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0118\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0120\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0111\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0123\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0126\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0128\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0117\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0104\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0213\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0146\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0121\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0118\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0144\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0124\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0140\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.0090\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0090\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0138\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0156\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0109\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0134\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0112\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0103\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0089\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0161\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0110\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0078\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0135\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0135\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0109\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0126\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0151\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0118\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0130\n",
      ">Neurons=64, Score=2.3181091994047165\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 71ms/step - loss: 0.1748 - val_loss: 0.0156\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0579 - val_loss: 0.0626\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0377 - val_loss: 0.0261\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0293\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0322 - val_loss: 0.0208\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0185\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0124\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0117\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0112\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0110\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0229 - val_loss: 0.0104\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0114\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0139\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0111\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0105\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0093\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0095\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0213 - val_loss: 0.0087\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0101\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0091\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0100\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0088\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0085\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0099\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0078\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0078\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0076\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0071\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0072\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0070\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0085\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0065\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0072\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0076\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0067\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0106\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0072\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0076\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0060\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0068\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0060\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0112\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0067\n",
      ">Neurons=64, Score=2.8617167845368385\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 107ms/step - loss: 0.2020 - val_loss: 0.0303\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0611 - val_loss: 0.0515\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0372 - val_loss: 0.0222\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0378 - val_loss: 0.0201\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0342 - val_loss: 0.0177\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0148\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0289 - val_loss: 0.0136\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0133\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0138\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0137\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0154\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0150\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0147\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0157\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0140\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0149\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0146\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0147\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0135\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0134\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0151\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0140\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0112\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0128\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0139\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0136\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0138\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0129\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0134\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0124\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0101\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0171\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0138\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0201\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0155\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0126\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0151\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0183\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0153\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0128\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0186\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0155\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0138\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0125\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0168\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0137\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0166\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0163\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0162\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0078\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0084\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0227\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0212\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0139\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0133\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0128\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0144\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0148\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0136\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0143\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0133\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0139\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0158\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0184\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0114\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0067\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0166\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0120\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0123\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0159\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.0125\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0138\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0099\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0097\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0154\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0144\n",
      ">Neurons=64, Score=5.075203254818916\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 69ms/step - loss: 0.1751 - val_loss: 0.0235\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0500 - val_loss: 0.0408\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0167\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0156\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0289 - val_loss: 0.0139\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0130\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0270 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0129\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0129\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0138\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0133\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0135\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0123\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0133\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0134\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0137\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0121\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0139\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0134\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0131\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0129\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0124\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0109\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0124\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0163\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0166\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0199\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0167\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0136\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0190\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0135\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0157\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0179\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0138\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0159\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0166\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0118\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0179\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0199\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0110\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0193\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0201\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0167\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0177\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0119\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0136\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0167\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0185\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0163\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0130\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0170\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0105\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0143\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0190\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0182\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0121\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0196\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0207\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0196\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0158\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0212\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0204\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0177\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0239\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0114\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0201\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0248\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0187\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0149\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0183\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0209\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0166\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0232\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0206\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0196\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0191\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0262\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0206\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0136\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0215\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0264\n",
      ">Neurons=64, Score=7.290741801261902\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 67ms/step - loss: 0.1911 - val_loss: 0.0228\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0601 - val_loss: 0.0611\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0358 - val_loss: 0.0250\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0335 - val_loss: 0.0249\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0311 - val_loss: 0.0205\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0299 - val_loss: 0.0160\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0136\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0121\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0119\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 0.0125\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0113\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0115\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0121\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0127\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0100\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0126\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0111\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0084\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0111\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0090\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0096\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0087\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0116\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0095\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0097\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0110\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0091\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0078\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0082\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0178\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0071\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0093\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0122\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0088\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0096\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0074\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0132\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0142\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0134\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0128\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0113\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      ">Neurons=65, Score=3.346208482980728\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 70ms/step - loss: 0.1883 - val_loss: 0.0227\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0591 - val_loss: 0.0543\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0365 - val_loss: 0.0234\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0362 - val_loss: 0.0222\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0306 - val_loss: 0.0185\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0290 - val_loss: 0.0164\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0142\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0295 - val_loss: 0.0133\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0259 - val_loss: 0.0130\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0126\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0128\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0193 - val_loss: 0.0136\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0128\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0133\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0131\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0120\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0130\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0122\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0121\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0121\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0255 - val_loss: 0.0153\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0118\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0123\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0124\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0133\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0128\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0116\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0125\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0100\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0172\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0131\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0145\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0144\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0129\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0160\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0092\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0091\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0161\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0137\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0123\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0117\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0148\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0125\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0143\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0078\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0203\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0079\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0083\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0128\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0149\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0115\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0118\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0125\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0154\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0152\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0098\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0114\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0133\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0113\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0134\n",
      ">Neurons=65, Score=4.428412392735481\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 70ms/step - loss: 0.1892 - val_loss: 0.0237\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0571 - val_loss: 0.0521\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0346 - val_loss: 0.0185\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0335 - val_loss: 0.0197\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0154\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0130\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0260 - val_loss: 0.0126\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0123\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0224 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0110\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0110\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0110\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0106\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0187 - val_loss: 0.0107\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0110\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0105\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0107\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0106\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0102\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0100\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0097\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0095\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0094\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0100\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0092\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0093\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0093\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0094\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0090\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0093\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0094\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0091\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0119\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0086\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0080\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0082\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0077\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0090\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0202 - val_loss: 0.0079\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0079\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0069\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0064\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0074\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0137\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0136\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0099\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0088\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0121\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0120\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0078\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0142\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0139\n",
      ">Neurons=65, Score=3.792063891887665\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 71ms/step - loss: 0.1835 - val_loss: 0.0217\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0545 - val_loss: 0.0470\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0326 - val_loss: 0.0194\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0345 - val_loss: 0.0193\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0167\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0290 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0277 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0124\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0120\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0110\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0118\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0103\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0100\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0154\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0105\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0100\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0103\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0085\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0086\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0141\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0118\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0101\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0113\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0073\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0092\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0235 - val_loss: 0.0066\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0147\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0191\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0074\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0124\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0126\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0093\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0119\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0149\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0097\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0098\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0106\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0094\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0104\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0115\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0107\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0132\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0095\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0056\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0117\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0163\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0121\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0097\n",
      ">Neurons=65, Score=5.681546777486801\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 75ms/step - loss: 0.1638 - val_loss: 0.0157\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0503 - val_loss: 0.0494\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0353 - val_loss: 0.0207\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0360 - val_loss: 0.0206\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0311 - val_loss: 0.0188\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0140\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0263 - val_loss: 0.0136\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0262 - val_loss: 0.0128\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0125\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.0124\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0211 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0181 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0115\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0110\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0105\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0105\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0103\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0151\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0101\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0124\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0092\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0098\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0125\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0096\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0086\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0113\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0133\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0082\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0128\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0091\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0160\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0143\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0150\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0152\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0141\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0137\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0153\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0168\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0119\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0170\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0123\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0082\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0134\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0189\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0148\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0120\n",
      ">Neurons=65, Score=4.377694800496101\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 67ms/step - loss: 0.1745 - val_loss: 0.0200\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0530 - val_loss: 0.0495\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.0185\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0365 - val_loss: 0.0219\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0332 - val_loss: 0.0162\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0311 - val_loss: 0.0151\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0135\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0128\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0134\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0132\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0204 - val_loss: 0.0129\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0144\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0128\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0132\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0133\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0123\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0124\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0129\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0170 - val_loss: 0.0163\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0128\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0126\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0119\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0177\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0121\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0139\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0163\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0139\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0154\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0147\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0174\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0154\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0135\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0162\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0108\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0087\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0181\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0141\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0146\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0144\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0162\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0152\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0142\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0152\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0151\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0172\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0179\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0167\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0141\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0087\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0220\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0228\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0132\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0138\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0153\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0147\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0177\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0183\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0173\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0143\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0165\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0143\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0078\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0185\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0155\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0135\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0217\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0211\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0174\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0129\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0143\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0221\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0200\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0116\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0146\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0193\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0204\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0171\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0225\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0220\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0213\n",
      ">Neurons=65, Score=5.50900474190712\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 71ms/step - loss: 0.1787 - val_loss: 0.0171\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0514 - val_loss: 0.0532\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0348 - val_loss: 0.0225\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0342 - val_loss: 0.0242\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0309 - val_loss: 0.0168\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0149\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0132\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0128\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0124\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0178 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0105\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0180 - val_loss: 0.0107\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0197 - val_loss: 0.0111\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0113\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0104\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0095\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0096\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0089\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0095\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0086\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0086\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0092\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0093\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0086\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0132\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0081\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0083\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0134\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0076\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0074\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0075\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0069\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0097\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0121\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0089\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0134\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0088\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0113\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0129\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0065\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0119\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0095\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0123\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0120\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0121\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0110\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0109\n",
      ">Neurons=65, Score=1.4874236658215523\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 70ms/step - loss: 0.1647 - val_loss: 0.0170\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0527 - val_loss: 0.0500\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0344 - val_loss: 0.0213\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0223\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0175\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0303 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0126\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0253 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0137\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0215 - val_loss: 0.0124\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0148\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0146\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0137\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0137\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0127\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0114\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0147\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0138\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0108\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0136\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0135\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0141\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0131\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0136\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0132\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0147\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0165\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0165\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0147\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0185\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0129\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0133\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0222\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0169\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0147\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0165\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0158\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0159\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0188\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0192\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0172\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0182\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0142\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0172\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0229\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0182\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0160\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0231\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0171\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0193\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0200\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0145\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0175\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0211\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0200\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0187\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0187 - val_loss: 0.0168\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0199\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0064\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0137\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0213\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0225\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0164\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0163\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 0.0204\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0191\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0186\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0175\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0199\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0198\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0196\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0194\n",
      ">Neurons=65, Score=7.41645023226738\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 70ms/step - loss: 0.1881 - val_loss: 0.0220\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0556 - val_loss: 0.0563\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0380 - val_loss: 0.0221\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0372 - val_loss: 0.0230\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0333 - val_loss: 0.0182\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0296 - val_loss: 0.0171\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0298 - val_loss: 0.0149\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0286 - val_loss: 0.0144\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0134\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0250 - val_loss: 0.0131\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.0132\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0137\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0130\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0142\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0149\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0138\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0136\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0140\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0135\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0140\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0140\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0166\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0162\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0163\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0166\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0182\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0176\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0160\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0188 - val_loss: 0.0121\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0216\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0202\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0131\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0171\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0171\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0180\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0140\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0173\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0200\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0219\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0187\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0203\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0208\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0163\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0168\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0228\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0200\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0168\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0178\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0190\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0189\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0312\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0315\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0167\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0175\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0252 - val_loss: 0.0120\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0156\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0365\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0163\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0207\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0224\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0215\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0194\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0259\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0200\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0204\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0187\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0180\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0265\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0233\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0127\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0251\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0249\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0129\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0270\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0246\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0168\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0185\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0291\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0250\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0173\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0253\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0186\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0236\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0216\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0264\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0169\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0164\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0304\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0262\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0218\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0175\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0219\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0343\n",
      ">Neurons=65, Score=9.967401623725891\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 112ms/step - loss: 0.1630 - val_loss: 0.0152\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0524 - val_loss: 0.0512\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0336 - val_loss: 0.0187\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0336 - val_loss: 0.0200\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0334 - val_loss: 0.0172\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0302 - val_loss: 0.0143\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0126\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0118\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0117\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0203 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0122\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0107\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0107\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0125\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0160\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0101\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0204 - val_loss: 0.0108\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0109\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0157\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0136\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.0095\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0104\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0160\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0104\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0145\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0153\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0132\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0141\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0137\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0099\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0094\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0099\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0163\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0140\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0129\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0165\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0139\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0097\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0125\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0075\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0084\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0158\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0148\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0147\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0102\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0144\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0153\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0121\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0172\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0161\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0066\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0173\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0135\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0123\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0054 - val_loss: 0.0125\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0123\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0131\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.0161\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0119\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0147\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0110\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0143\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0073\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0223\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0064\n",
      ">Neurons=65, Score=3.2132942229509354\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 73ms/step - loss: 0.1656 - val_loss: 0.0151\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0511 - val_loss: 0.0480\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0324 - val_loss: 0.0223\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0352 - val_loss: 0.0205\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0164\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0304 - val_loss: 0.0146\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0275 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0277 - val_loss: 0.0127\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0126\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0232 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0216 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0129\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0125\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0140\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0115\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0119\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0127\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0126\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0127\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0209 - val_loss: 0.0108\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0106\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0200 - val_loss: 0.0184\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0148\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0117\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0126\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0113\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0166 - val_loss: 0.0135\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0226 - val_loss: 0.0158\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0100\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0183 - val_loss: 0.0099\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0144\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0145\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0137\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0125\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0128\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0130\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0120\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0121\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0140\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0152\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0133\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0089\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.0109\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0089\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0267 - val_loss: 0.0275\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0098\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0077\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0148\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0148\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0133\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0129\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0129\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0160\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0137\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0151\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0113\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0154\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0149\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0129\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0226 - val_loss: 0.0178\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0162\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0072\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0147\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0080 - val_loss: 0.0168\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0119\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0125\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0155\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0187\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0113\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0129\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0186\n",
      ">Neurons=70, Score=3.4469980746507645\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 71ms/step - loss: 0.1698 - val_loss: 0.0167\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0513 - val_loss: 0.0401\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0365 - val_loss: 0.0207\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0338 - val_loss: 0.0221\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0167\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0306 - val_loss: 0.0167\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0142\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0136\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.0126\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0211 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0104\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0106\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0100\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0241 - val_loss: 0.0125\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0115\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0123\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0103\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0094\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0099\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0087\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0083\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0088\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0098\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0089\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0095\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0073\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0085\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0081\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0074\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0075\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0097\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0098\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0065\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0064\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0189 - val_loss: 0.0132\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0068\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0061\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0064\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0056\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0057\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0067\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      ">Neurons=70, Score=3.4369252622127533\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 70ms/step - loss: 0.1812 - val_loss: 0.0149\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0550 - val_loss: 0.0614\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0361 - val_loss: 0.0244\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0351 - val_loss: 0.0269\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0313 - val_loss: 0.0214\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0303 - val_loss: 0.0164\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0297 - val_loss: 0.0142\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0123\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0245 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0113\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0116\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0142\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0103\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0189 - val_loss: 0.0117\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0130\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0134\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0096\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0130\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0122\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0122\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0114\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0142\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0129\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0193 - val_loss: 0.0089\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0092\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0146\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0144\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0137\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0133\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0143\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0157\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0117\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0156\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0152\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0074\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0117\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0200\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0140\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0070 - val_loss: 0.0100\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0114\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0123\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0163\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0133\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0078\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0208\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0150\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0076\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0121\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0141\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0168\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0127\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0082\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0070 - val_loss: 0.0131\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0140\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0134\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0143\n",
      ">Neurons=70, Score=4.894213005900383\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 71ms/step - loss: 0.1739 - val_loss: 0.0160\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0516 - val_loss: 0.0531\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0349 - val_loss: 0.0237\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0367 - val_loss: 0.0228\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0331 - val_loss: 0.0184\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0311 - val_loss: 0.0172\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0305 - val_loss: 0.0155\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0144\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0138\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0140\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0244 - val_loss: 0.0138\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0136\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0140\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0138\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0185 - val_loss: 0.0149\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0139\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0158\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0136\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0163\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0163\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0159\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0186\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0169\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0125\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0125\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0141\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0128\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0127\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0134\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0151\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0148\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0149\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0132\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0136\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0126\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0127\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0183 - val_loss: 0.0154\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0126\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0148\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0164\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0093\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0138\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0139\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0139\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0140\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0128\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0152\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0158\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0146\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0117\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0164\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0170\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0081\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0156\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0161\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0113\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0148\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0139\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0161\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0169\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0158\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0166\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0072\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0164\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0124\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0119\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0120\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0158\n",
      ">Neurons=70, Score=5.1280394196510315\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 88ms/step - loss: 0.1908 - val_loss: 0.0242\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0609 - val_loss: 0.0588\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0326 - val_loss: 0.0194\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0353 - val_loss: 0.0216\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0309 - val_loss: 0.0178\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0309 - val_loss: 0.0152\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0269 - val_loss: 0.0132\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0256 - val_loss: 0.0128\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0233 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0237 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0194 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0201 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0120\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0119\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0123\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0116\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0113\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0113\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0137\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0112\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0124\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0113\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0096\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0137\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0098\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0093\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0100\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0149\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0099\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0117\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0111\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0099\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0090\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0114\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0176 - val_loss: 0.0080\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0086\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0122\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0110\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0093\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0098\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0092\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0152\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0073\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0122\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0161\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0117\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0116\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0125\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0124\n",
      ">Neurons=70, Score=3.3906199038028717\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 74ms/step - loss: 0.1689 - val_loss: 0.0166\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0476 - val_loss: 0.0361\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0326 - val_loss: 0.0194\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0328 - val_loss: 0.0191\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0145\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0290 - val_loss: 0.0140\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0267 - val_loss: 0.0133\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0260 - val_loss: 0.0131\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0264 - val_loss: 0.0129\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.0134\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0209 - val_loss: 0.0125\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0123\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0122\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.0122\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0125\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0125\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0106\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0107\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0241 - val_loss: 0.0174\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0110\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0114\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0123\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0091\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0089\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0087\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0083\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0072\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0141\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0085\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0071\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0064\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0121\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0068\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0134\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0147\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0075\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0058\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0137\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0110\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0135\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0116\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0060 - val_loss: 0.0071\n",
      ">Neurons=70, Score=4.9217864871025085\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 78ms/step - loss: 0.1641 - val_loss: 0.0161\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0521 - val_loss: 0.0420\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0350 - val_loss: 0.0200\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0349 - val_loss: 0.0187\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0308 - val_loss: 0.0155\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0293 - val_loss: 0.0132\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0265 - val_loss: 0.0133\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0250 - val_loss: 0.0130\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0243 - val_loss: 0.0141\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0196 - val_loss: 0.0131\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0136\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0130\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0160\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0139\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0123\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0120\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0166 - val_loss: 0.0130\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0131\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0229 - val_loss: 0.0173\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0178 - val_loss: 0.0103\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0138\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0111\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0193 - val_loss: 0.0104\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0138\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0185 - val_loss: 0.0170\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0141\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0147\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0167\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0146\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0095 - val_loss: 0.0137\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0116\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0169 - val_loss: 0.0098\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0099\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0157\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0142\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0121\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0128\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0126\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0129\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0121\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0127\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0169\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0130\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0118\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0157\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0137\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0248\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0153\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0073\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0187\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0166\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0062 - val_loss: 0.0142\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0111\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0181\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0118\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0110\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0139\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0166\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0155\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0141\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0180\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0125\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0058\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0152\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0165\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0154\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0105\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0152\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0133\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0141\n",
      ">Neurons=70, Score=6.718461960554123\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 68ms/step - loss: 0.1907 - val_loss: 0.0213\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0568 - val_loss: 0.0619\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0330 - val_loss: 0.0247\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0365 - val_loss: 0.0242\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0293 - val_loss: 0.0193\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0317 - val_loss: 0.0168\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0311 - val_loss: 0.0147\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0268 - val_loss: 0.0132\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0251 - val_loss: 0.0127\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0242 - val_loss: 0.0125\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0126\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0126\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0115\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0115\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0131\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0149\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0187 - val_loss: 0.0112\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0101\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0112\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0141\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0158 - val_loss: 0.0122\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0095\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0132\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0123\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0098\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0097\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0148\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0159\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0134\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0080\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0178\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0144\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0157\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0142\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0142\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0141\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0129\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0066\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0151\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0122\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0114\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0134\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0070 - val_loss: 0.0145\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0159\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0156\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0151\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0069 - val_loss: 0.0171\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0140\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0068\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0153\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0275\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0139\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0139\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0177\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0152\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0060 - val_loss: 0.0159\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0143\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0060 - val_loss: 0.0189\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0132\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0155\n",
      ">Neurons=70, Score=10.556245595216751\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 70ms/step - loss: 0.1772 - val_loss: 0.0163\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0532 - val_loss: 0.0565\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0341 - val_loss: 0.0216\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0364 - val_loss: 0.0243\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0313 - val_loss: 0.0213\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0290 - val_loss: 0.0170\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0264 - val_loss: 0.0157\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0261 - val_loss: 0.0131\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0233 - val_loss: 0.0130\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0220 - val_loss: 0.0125\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0203 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0125\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0116\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0116\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0119\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0204 - val_loss: 0.0122\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0194 - val_loss: 0.0113\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0139\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0113\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0188 - val_loss: 0.0098\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0091\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0139\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0125\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0151\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0125\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0135\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0088\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0118\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0125\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0121\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0150\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0071\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0075\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0137\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0137\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0096\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0097\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0104\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0116\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0136\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0065\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0115\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0080 - val_loss: 0.0156\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0122\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0133\n",
      ">Neurons=70, Score=4.609418287873268\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 70ms/step - loss: 0.1792 - val_loss: 0.0180\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0544 - val_loss: 0.0538\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0314 - val_loss: 0.0240\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0319 - val_loss: 0.0242\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0298 - val_loss: 0.0198\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0294 - val_loss: 0.0174\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0248 - val_loss: 0.0141\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0250 - val_loss: 0.0133\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 0.0132\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0128\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0192 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0125\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0122\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0116\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0116\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0113\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0098\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0097\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0096\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0178 - val_loss: 0.0094\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0094\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0114\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0090\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0083\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0083\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0078\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0076\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0096\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0083\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0076\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0074\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0076\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0109\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0120\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0069\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0065\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0090\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0063\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0062\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0134\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0058\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0059\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0076\n",
      ">Neurons=70, Score=2.284086123108864\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 102ms/step - loss: 0.1656 - val_loss: 0.0151\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0515 - val_loss: 0.0465\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0380 - val_loss: 0.0249\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0320 - val_loss: 0.0227\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0316 - val_loss: 0.0184\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0310 - val_loss: 0.0174\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0281 - val_loss: 0.0145\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0282 - val_loss: 0.0135\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0132\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0256 - val_loss: 0.0124\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0125\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0120\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0119\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0166 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0107\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0106\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0139 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 0.0105\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0218 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0171 - val_loss: 0.0131\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0220 - val_loss: 0.0111\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0132\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0126\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0098\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0092\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0094\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0086\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0138\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0084\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0090\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0174\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0138\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0112\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0082\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0189 - val_loss: 0.0171\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0112\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0071\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0135\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0079\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0141\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0119\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0140\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0127\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0088 - val_loss: 0.0111\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0114\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0170\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0124\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0144\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0107\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.0105\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0136\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0073\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0079\n",
      ">Neurons=75, Score=7.129444181919098\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 86ms/step - loss: 0.1900 - val_loss: 0.0218\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0559 - val_loss: 0.0468\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0318 - val_loss: 0.0210\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0347 - val_loss: 0.0230\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0329 - val_loss: 0.0177\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0174\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0269 - val_loss: 0.0134\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0256 - val_loss: 0.0134\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0233 - val_loss: 0.0121\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0236 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0203 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0224 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0180 - val_loss: 0.0112\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0111\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0131\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0238 - val_loss: 0.0105\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0231 - val_loss: 0.0115\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.0106\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0138\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0099\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0092\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0089\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0095\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0086\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0090 - val_loss: 0.0124\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0117\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0086\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0106\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0091\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0074\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0072\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0092\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0091\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 0.0101\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0094\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0107\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0123\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0126\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0085\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0060\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0073\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0130\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0097\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0101\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0151\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0115\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0141\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0072\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0113\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0119\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0065\n",
      ">Neurons=75, Score=3.4354317933321\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 118ms/step - loss: 0.1735 - val_loss: 0.0158\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0531 - val_loss: 0.0459\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0319 - val_loss: 0.0194\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0338 - val_loss: 0.0198\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0297 - val_loss: 0.0153\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0289 - val_loss: 0.0136\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0263 - val_loss: 0.0122\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0236 - val_loss: 0.0119\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0246 - val_loss: 0.0118\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0207 - val_loss: 0.0115\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0178 - val_loss: 0.0117\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0195 - val_loss: 0.0111\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0177 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0161 - val_loss: 0.0115\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0153 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0158 - val_loss: 0.0110\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0141 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0171 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0177 - val_loss: 0.0113\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0172 - val_loss: 0.0109\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0171 - val_loss: 0.0107\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0165 - val_loss: 0.0124\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0171 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0176 - val_loss: 0.0104\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0103\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0098\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0141 - val_loss: 0.0095\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0161 - val_loss: 0.0119\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0091\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0148 - val_loss: 0.0095\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0131 - val_loss: 0.0087\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0161 - val_loss: 0.0087\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0094\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0145\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0156\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0157 - val_loss: 0.0115\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0072\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0156\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0123\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0119\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0091\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0114\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0116\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0079 - val_loss: 0.0091\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0105\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0156 - val_loss: 0.0154\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0107\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0228 - val_loss: 0.0186\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0241 - val_loss: 0.0186\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0237 - val_loss: 0.0086\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0075\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0125\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0073 - val_loss: 0.0139\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0069 - val_loss: 0.0104\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.0119\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0116\n",
      ">Neurons=75, Score=6.715402007102966\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 74ms/step - loss: 0.1687 - val_loss: 0.0178\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0478 - val_loss: 0.0358\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0329 - val_loss: 0.0168\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0346 - val_loss: 0.0187\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0293 - val_loss: 0.0151\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0298 - val_loss: 0.0139\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0262 - val_loss: 0.0131\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0274 - val_loss: 0.0127\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0214 - val_loss: 0.0128\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0231 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0126\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0123\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0157 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0122\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0119\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0128\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0122\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0106\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0195 - val_loss: 0.0120\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0113\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0217 - val_loss: 0.0140\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 0.0137\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0106\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0133\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0129\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0153 - val_loss: 0.0134\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0143\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0122\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0143\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0091\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0094\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0146\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0136\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0149\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0163\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0127\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0163\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0144\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0086\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0148\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0166\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0145\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0124\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0178\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0121\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0136\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0090\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0169\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0081 - val_loss: 0.0134\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0187\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0074 - val_loss: 0.0140\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0130\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0094 - val_loss: 0.0120\n",
      ">Neurons=75, Score=2.001207135617733\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 93ms/step - loss: 0.1630 - val_loss: 0.0143\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0475 - val_loss: 0.0469\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0373 - val_loss: 0.0236\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0322 - val_loss: 0.0224\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0290 - val_loss: 0.0179\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0261 - val_loss: 0.0140\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0270 - val_loss: 0.0131\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0122\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0217 - val_loss: 0.0121\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0195 - val_loss: 0.0120\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0188 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0104\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0104\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0107\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0106\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0223 - val_loss: 0.0102\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0134\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0221 - val_loss: 0.0127\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0097\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0094\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0088\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0087\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0243 - val_loss: 0.0104\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0180 - val_loss: 0.0095\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0227 - val_loss: 0.0112\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0085\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0087\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0085\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0077\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0071\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0146\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0079\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0073\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0145 - val_loss: 0.0071\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0084\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0111\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0067\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0062\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0075\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0073\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0064\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0055\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0065\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0051\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.0090\n",
      ">Neurons=75, Score=2.0308030769228935\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 72ms/step - loss: 0.1578 - val_loss: 0.0147\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0464 - val_loss: 0.0381\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0351 - val_loss: 0.0205\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0331 - val_loss: 0.0196\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0307 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0285 - val_loss: 0.0148\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0139\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0128\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0232 - val_loss: 0.0125\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0214 - val_loss: 0.0129\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0125\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 0.0129\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0132\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0140\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0122\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0161\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0165\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0244 - val_loss: 0.0147\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0122\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0114\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0140\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0153\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0130\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0109\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0141\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0219 - val_loss: 0.0167\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0092\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0167\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0140\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0177\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0175\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0141\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0138\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0174\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0154\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0104\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0181\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0149\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0170\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0116\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0073 - val_loss: 0.0148\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0144\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0079 - val_loss: 0.0132\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0139\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.0116\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0168\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0145\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0133\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0127\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0157\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0166\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0184\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 0.0243\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0117\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0069\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0077 - val_loss: 0.0201\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0144\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0206\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0250\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0202\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0199\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0197\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0173\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0164\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0177\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0132\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0129\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0179\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0178\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0226\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0210\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0106\n",
      ">Neurons=75, Score=5.844376236200333\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 80ms/step - loss: 0.1718 - val_loss: 0.0155\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0541 - val_loss: 0.0459\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0362 - val_loss: 0.0213\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0334 - val_loss: 0.0220\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0291 - val_loss: 0.0177\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0288 - val_loss: 0.0157\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0254 - val_loss: 0.0139\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0263 - val_loss: 0.0131\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0126\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0216 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0122\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0114\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0185 - val_loss: 0.0109\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0111\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0110\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0121\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0195 - val_loss: 0.0113\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0107\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0111\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0145\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0105\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0094\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0108\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0115\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0099\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0093\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0093\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0090\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0096\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0082\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0084\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0188 - val_loss: 0.0130\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0109\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0082\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0077\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0110\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0114\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0116\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0094\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0071\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0095\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0094\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0093\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 0.0099\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0079\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0125\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0083\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0063\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0111\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0116\n",
      ">Neurons=75, Score=4.075299575924873\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 80ms/step - loss: 0.1835 - val_loss: 0.0154\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0618 - val_loss: 0.0764\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0380 - val_loss: 0.0317\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0377 - val_loss: 0.0303\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0349 - val_loss: 0.0254\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0317 - val_loss: 0.0185\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0300 - val_loss: 0.0163\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0263 - val_loss: 0.0132\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0266 - val_loss: 0.0125\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0246 - val_loss: 0.0121\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0181 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 0.0115\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0111\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0112\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0104\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0119\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0116\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0102\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 0.0109\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0094\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0127\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0090\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0087\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0082\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0091\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0088\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0082\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0178 - val_loss: 0.0093\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0077\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.0092\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0113\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0163 - val_loss: 0.0095\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0081\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0070\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0075\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0115\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0103\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0101\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0121\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0064\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0064\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      ">Neurons=75, Score=5.861566960811615\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 74ms/step - loss: 0.1711 - val_loss: 0.0156\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0566 - val_loss: 0.0461\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0362 - val_loss: 0.0224\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0337 - val_loss: 0.0202\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0297 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0291 - val_loss: 0.0146\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0288 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0235 - val_loss: 0.0124\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0241 - val_loss: 0.0120\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0219 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0178 - val_loss: 0.0115\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0113\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0155 - val_loss: 0.0128\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0368 - val_loss: 0.0136\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0229 - val_loss: 0.0110\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0265 - val_loss: 0.0174\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0104\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0101\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0188 - val_loss: 0.0109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0139\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0160 - val_loss: 0.0107\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0096\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0089\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0136\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0093\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0125\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0115\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0083\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0129\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0087\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0125\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0127\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0081\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0147\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0076\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0138\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0118\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0136\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0106\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0118\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0110\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0070\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0094\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0243 - val_loss: 0.0066\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0066\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0168 - val_loss: 0.0203\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0100\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0102\n",
      ">Neurons=75, Score=2.676970511674881\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 78ms/step - loss: 0.1783 - val_loss: 0.0203\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0508 - val_loss: 0.0415\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0332 - val_loss: 0.0177\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0334 - val_loss: 0.0200\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0298 - val_loss: 0.0158\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0289 - val_loss: 0.0159\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0259 - val_loss: 0.0133\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0239 - val_loss: 0.0131\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0239 - val_loss: 0.0127\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0193 - val_loss: 0.0124\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0125\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0125\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0128\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0113\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0117\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0122\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0193 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0171 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0117\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0146 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 0.0119\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0126 - val_loss: 0.0113\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0100\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0103\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0196 - val_loss: 0.0097\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0095\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0135\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0204 - val_loss: 0.0141\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0085\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0082\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0086\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0079\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0075\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0135\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0127\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0115\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0118\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0065 - val_loss: 0.0114\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0090\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0105\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0130\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0127\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0073\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0069\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0218 - val_loss: 0.0068\n",
      ">Neurons=75, Score=1.2517493218183517\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 73ms/step - loss: 0.1612 - val_loss: 0.0149\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0439 - val_loss: 0.0381\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0342 - val_loss: 0.0200\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0321 - val_loss: 0.0204\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0305 - val_loss: 0.0156\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0292 - val_loss: 0.0140\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0245 - val_loss: 0.0126\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0247 - val_loss: 0.0122\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0223 - val_loss: 0.0121\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0136\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0181 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0119\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0129\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0110\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0111\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0142\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0183 - val_loss: 0.0116\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0105\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0108\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0142\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0121\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0131\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0151\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0109\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0146\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0170\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0095\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0089\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0126\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0130\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0122\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0118\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0169\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0095\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0169\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0127\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0081\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0110\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0149\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0154\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0113\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0132\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0134\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0138\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0138\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0139\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0140\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0155\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0080\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0076\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0148\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0152\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0130\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0154\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0122\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0114\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0148\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0116\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0143\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0107\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0150\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0127\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0097\n",
      ">Neurons=80, Score=1.524375006556511\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 110ms/step - loss: 0.1428 - val_loss: 0.0162\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0447 - val_loss: 0.0280\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0353 - val_loss: 0.0216\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0319 - val_loss: 0.0185\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0311 - val_loss: 0.0155\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0315 - val_loss: 0.0137\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0270 - val_loss: 0.0128\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0274 - val_loss: 0.0123\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0236 - val_loss: 0.0125\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0206 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0189 - val_loss: 0.0131\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0129\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0100\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0194 - val_loss: 0.0137\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0245 - val_loss: 0.0101\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0223 - val_loss: 0.0166\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0215 - val_loss: 0.0177\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0127\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0129\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0109\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0220 - val_loss: 0.0191\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0115\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0088\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0135\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0107\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0151\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0134\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0243 - val_loss: 0.0182\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0083\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0071\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0121\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0156\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0111\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0115\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0126\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0138\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0118\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0078 - val_loss: 0.0141\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0145\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0112\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0068 - val_loss: 0.0114\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0179\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0190\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0241 - val_loss: 0.0171\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0089\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0181 - val_loss: 0.0060\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0112\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0171\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0132\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0115\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0070 - val_loss: 0.0121\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0111\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0070 - val_loss: 0.0120\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0137\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0164\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0143\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0094\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0142\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0228\n",
      ">Neurons=80, Score=9.732113033533096\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 80ms/step - loss: 0.1565 - val_loss: 0.0152\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0468 - val_loss: 0.0322\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0334 - val_loss: 0.0205\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0305 - val_loss: 0.0181\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0263 - val_loss: 0.0150\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0266 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0237 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.0131\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0207 - val_loss: 0.0130\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0135\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0199 - val_loss: 0.0137\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0134\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0142\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0126\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0191 - val_loss: 0.0130\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0141\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0214 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0151\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0132\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0126\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0127\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0129\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0114\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0112\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0124\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0163 - val_loss: 0.0109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0138\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0144\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0153\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0108\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0095\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0094\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0182\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0119\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0153\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0108\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0130\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0140\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0080\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0101\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0076\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0117\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0123\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0120\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0124\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0103\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0149\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 0.0070\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0112\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0131\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0130\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0121\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0144\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0122\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0094\n",
      ">Neurons=80, Score=3.1997453421354294\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 76ms/step - loss: 0.1545 - val_loss: 0.0159\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0447 - val_loss: 0.0300\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0349 - val_loss: 0.0223\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0344 - val_loss: 0.0201\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0316 - val_loss: 0.0159\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0274 - val_loss: 0.0140\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0268 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0246 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0218 - val_loss: 0.0119\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0117\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0118\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 0.0113\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0111\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0116\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0243 - val_loss: 0.0111\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0109\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0276 - val_loss: 0.0120\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.0098\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0123\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0126\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0146\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.0090\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0104\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0179 - val_loss: 0.0143\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0201 - val_loss: 0.0154\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0197 - val_loss: 0.0090\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0160 - val_loss: 0.0088\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0175\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 0.0101\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0138\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0166\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0139\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0102\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0108\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0202 - val_loss: 0.0207\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0218 - val_loss: 0.0231\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.0075\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0077\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0139\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0156\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0127\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0108\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0140\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0128\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0155\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0064 - val_loss: 0.0127\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0122\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0107\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0111\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0143\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0169\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0129\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0133\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0223 - val_loss: 0.0064\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0223\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0087\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0139\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0167\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0152\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0111\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0145\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0157\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0140\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0115\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0118\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0134\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0140\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0119\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0110\n",
      ">Neurons=80, Score=8.148586004972458\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 73ms/step - loss: 0.1499 - val_loss: 0.0166\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0484 - val_loss: 0.0399\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0354 - val_loss: 0.0224\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0325 - val_loss: 0.0223\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0161\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0149\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0257 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 0.0127\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0218 - val_loss: 0.0128\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0211 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0189 - val_loss: 0.0125\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0163 - val_loss: 0.0135\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0157 - val_loss: 0.0126\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.0127\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0125\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0134\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0130\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0127\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0120\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0264 - val_loss: 0.0119\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0152\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0133\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0127\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0143\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0148\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0119\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0138\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0142\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0136\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0137\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0116\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0125\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0152\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0142\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0151\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0144\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0153\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0153\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0132\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0103\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0174\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0133\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0135\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0147\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0168\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0138\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0140\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0143\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0143\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0186\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0104\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0094\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0189\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0171\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0157\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0122\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0127\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0138\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0153\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0122\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0133\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0144\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0125\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0136\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0192\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0129\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0109\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      ">Neurons=80, Score=3.421610966324806\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 75ms/step - loss: 0.1778 - val_loss: 0.0179\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0479 - val_loss: 0.0381\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0303 - val_loss: 0.0166\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0337 - val_loss: 0.0161\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0286 - val_loss: 0.0138\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0269 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0260 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0248 - val_loss: 0.0123\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0224 - val_loss: 0.0128\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0120\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0117\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0163 - val_loss: 0.0118\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0127\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0181 - val_loss: 0.0120\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0167 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0213 - val_loss: 0.0139\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0225 - val_loss: 0.0136\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 0.0116\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0136\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0109\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0102\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0107\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.0145\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0126\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0180 - val_loss: 0.0094\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0089\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0088\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0080\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0124\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0108\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0090\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0125\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0143\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0077\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0067\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0122\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0113\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0117\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0120\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0086\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0086\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0161\n",
      ">Neurons=80, Score=4.787920042872429\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 77ms/step - loss: 0.1742 - val_loss: 0.0154\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0520 - val_loss: 0.0471\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0323 - val_loss: 0.0214\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0346 - val_loss: 0.0215\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0170\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0259 - val_loss: 0.0146\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0252 - val_loss: 0.0128\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0241 - val_loss: 0.0124\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0124\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0214 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0180 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0169 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0146 - val_loss: 0.0124\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0208 - val_loss: 0.0116\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.0110\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0120\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0127\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0166 - val_loss: 0.0110\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0130\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0101\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0098\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0129\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0131\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0110\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0159\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0093\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0156\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0123\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0107\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0181\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0084\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0162\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0126\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0142\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0158\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0125\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0120\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0145\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0160\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0101\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0185\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0080\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0150\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0179\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0135\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0143\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0128\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0194\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0162\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0157\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0130\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0168\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0138\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0136\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0123\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0120\n",
      ">Neurons=80, Score=2.0766405388712883\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 77ms/step - loss: 0.1522 - val_loss: 0.0149\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0482 - val_loss: 0.0301\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0365 - val_loss: 0.0198\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0348 - val_loss: 0.0198\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0322 - val_loss: 0.0151\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0295 - val_loss: 0.0142\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0281 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0227 - val_loss: 0.0122\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0231 - val_loss: 0.0122\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0115\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0104\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0136\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0103\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0292 - val_loss: 0.0129\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0234 - val_loss: 0.0127\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0214 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0095\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0099\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0089\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0177 - val_loss: 0.0081\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0180 - val_loss: 0.0162\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0086\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0087\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0097\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0164 - val_loss: 0.0127\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0095\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0167 - val_loss: 0.0070\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0118\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0102\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0114\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0079\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0074\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0064\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0151\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0069\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0140\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.0093\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0098\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0114\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0092\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0093\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0085\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0059\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0116\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0109\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0112\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0111\n",
      ">Neurons=80, Score=3.7398777902126312\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 75ms/step - loss: 0.1613 - val_loss: 0.0146\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0476 - val_loss: 0.0468\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0328 - val_loss: 0.0192\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0307 - val_loss: 0.0219\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0311 - val_loss: 0.0150\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0282 - val_loss: 0.0135\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0282 - val_loss: 0.0128\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0125\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0242 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 0.0119\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0115\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 0.0114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0186 - val_loss: 0.0104\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0109\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0109\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 0.0106\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0214 - val_loss: 0.0158\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0128\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0153 - val_loss: 0.0130\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0113\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0095\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0139\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0091\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0083\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0157\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0144\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0132\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0132\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0139\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0099\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0135\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0225\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0096\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0076\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0145\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0117\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0127\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0137\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0150\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0149\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0181\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0204\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0065 - val_loss: 0.0186\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 0.0134\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0113\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0195\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0259\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0191\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0097\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0247 - val_loss: 0.0179\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0285 - val_loss: 0.0074\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0064\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0154\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0133\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 0.0108\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0167\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0126\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0157\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0062 - val_loss: 0.0181\n",
      ">Neurons=80, Score=3.8864850997924805\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 77ms/step - loss: 0.1746 - val_loss: 0.0146\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0523 - val_loss: 0.0419\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0374 - val_loss: 0.0205\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0338 - val_loss: 0.0191\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0310 - val_loss: 0.0163\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0285 - val_loss: 0.0147\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0265 - val_loss: 0.0131\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0244 - val_loss: 0.0122\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 0.0120\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0194 - val_loss: 0.0120\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.0126\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0156 - val_loss: 0.0136\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0130\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0116\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0165 - val_loss: 0.0145\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0203 - val_loss: 0.0128\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0177 - val_loss: 0.0116\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0222 - val_loss: 0.0111\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0152\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0141\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0138\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0103\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0133\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0098\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0093\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0151\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0093\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0131\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0135\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0110\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0109\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0114\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0097\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0111\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0227 - val_loss: 0.0077\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0092\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0183\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0129\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0121\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0115\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0075\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0087\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0192\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0070\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0144\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0138\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0098\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0110\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0131\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0163\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0116\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0061 - val_loss: 0.0136\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.0141\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0119\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.0111\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0166\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0266\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0150\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0219 - val_loss: 0.0090\n",
      ">Neurons=80, Score=3.8491375744342804\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 76ms/step - loss: 0.1689 - val_loss: 0.0150\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0499 - val_loss: 0.0494\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0382 - val_loss: 0.0260\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0353 - val_loss: 0.0237\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0308 - val_loss: 0.0199\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0283 - val_loss: 0.0151\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0290 - val_loss: 0.0142\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0242 - val_loss: 0.0128\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0223 - val_loss: 0.0125\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0200 - val_loss: 0.0124\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0210 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0123\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0118\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0210 - val_loss: 0.0120\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0237 - val_loss: 0.0107\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0205 - val_loss: 0.0154\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0230 - val_loss: 0.0207\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0169\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0135\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0132\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 0.0142\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0135\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0094\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0145\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0121\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0156\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0127\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0096\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0180 - val_loss: 0.0080\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0082\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0094\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0161\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0147\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0094\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0150\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0152\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0148\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0123\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0146\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0105\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0137\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0165\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0076\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0194\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0148\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0074 - val_loss: 0.0118\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0114\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0151\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0180\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0104\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0150\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0147\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0120\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0145\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0200\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0120\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      ">Neurons=85, Score=4.5433226972818375\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 73ms/step - loss: 0.1484 - val_loss: 0.0185\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0430 - val_loss: 0.0239\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0371 - val_loss: 0.0213\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0311 - val_loss: 0.0193\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0303 - val_loss: 0.0150\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0261 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0237 - val_loss: 0.0131\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0249 - val_loss: 0.0134\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0226 - val_loss: 0.0135\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0203 - val_loss: 0.0130\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0197 - val_loss: 0.0131\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0126\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0126\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0142\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0150\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0132\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0149\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0220 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0253 - val_loss: 0.0152\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0130\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 0.0103\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0130\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0126\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0121\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0134\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0254 - val_loss: 0.0163\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0114\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0089\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0095\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0153\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0127\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0146\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0119\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0131\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.0078\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0130\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0101\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0166\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0172\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0136\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0134\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0141\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0137\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0173\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0125\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0116\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0124\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0131\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0077\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0132\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0139\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0156\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 0.0154\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0139\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0164\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0152\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0213\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0149\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0124\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0150\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0160\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0143\n",
      ">Neurons=85, Score=5.557816103100777\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 73ms/step - loss: 0.1660 - val_loss: 0.0152\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0509 - val_loss: 0.0409\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0375 - val_loss: 0.0232\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0336 - val_loss: 0.0217\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0330 - val_loss: 0.0165\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0301 - val_loss: 0.0147\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0303 - val_loss: 0.0137\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0277 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0215 - val_loss: 0.0132\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0228 - val_loss: 0.0133\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0197 - val_loss: 0.0130\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0134\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0172 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0154 - val_loss: 0.0109\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0135\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0164\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0337 - val_loss: 0.0219\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0124\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0218 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0134\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0129\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0165\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0158\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0147\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0099\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0143\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0180 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0175\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0094\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0165\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0185\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0167\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0133\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0140\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0169\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0173\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0147\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0131 - val_loss: 0.0169\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0222\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0086\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0177\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0174\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0152\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0122\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0172\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0165\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0182\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0178\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0143\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0177\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0139\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0105\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0126\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0171\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0179\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0216\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0173\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0148\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0166\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0151\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0141\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0133\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0177\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0145\n",
      ">Neurons=85, Score=5.3981713950634\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 82ms/step - loss: 0.1788 - val_loss: 0.0159\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0511 - val_loss: 0.0491\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0337 - val_loss: 0.0210\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0349 - val_loss: 0.0213\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0300 - val_loss: 0.0157\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0288 - val_loss: 0.0144\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0250 - val_loss: 0.0124\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0120\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0220 - val_loss: 0.0119\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.0115\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0164 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0107\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0104\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0195 - val_loss: 0.0114\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0250 - val_loss: 0.0127\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0197 - val_loss: 0.0146\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0167 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0094\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0100\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0110\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0091\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0088\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0099\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0090\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0124\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0089\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0095\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0107\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0081\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0091\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0085\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0080\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0077\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0091\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0069\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0070\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0131\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0164\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0119\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0126\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0119\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0111\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0106\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0093\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0067\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0065\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0063\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0124\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0121\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0134\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0112\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.0134\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      ">Neurons=85, Score=4.305335134267807\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 79ms/step - loss: 0.1601 - val_loss: 0.0166\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0503 - val_loss: 0.0473\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0361 - val_loss: 0.0267\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0330 - val_loss: 0.0242\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0293 - val_loss: 0.0164\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0236 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0260 - val_loss: 0.0124\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0221 - val_loss: 0.0119\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0201 - val_loss: 0.0122\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0186 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0116\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0113\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0108\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0129\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 0.0174\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0106\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0104\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0136\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0107\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0161 - val_loss: 0.0119\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0100\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0203 - val_loss: 0.0113\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0197 - val_loss: 0.0129\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0167 - val_loss: 0.0093\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0174 - val_loss: 0.0090\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0146\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0130\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0237 - val_loss: 0.0146\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0081\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0147 - val_loss: 0.0077\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0117\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0141\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0113\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0097\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0158\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0073\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0068\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0128\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0119\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0164\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0084\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0109\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0162\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0058\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0135\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0129\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0118\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0137\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0110\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0069 - val_loss: 0.0121\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0112\n",
      ">Neurons=85, Score=3.537578508257866\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 124ms/step - loss: 0.1717 - val_loss: 0.0162\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0487 - val_loss: 0.0282\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0360 - val_loss: 0.0170\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0325 - val_loss: 0.0165\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0302 - val_loss: 0.0141\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0261 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0249 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0239 - val_loss: 0.0128\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0223 - val_loss: 0.0126\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0206 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0192 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0120\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0213 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0128\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0184 - val_loss: 0.0124\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0116\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0114\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0168 - val_loss: 0.0102\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0195 - val_loss: 0.0137\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0100\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0092\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0096\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0133\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0092\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0087\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0126\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0091\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0080\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0122\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0154\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0136\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0119\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0150\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0125\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0114\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0126\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0113\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0132\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0075\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0085\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0160\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0118\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0097\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0165\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0140\n",
      ">Neurons=85, Score=3.2942034304142\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 73ms/step - loss: 0.1585 - val_loss: 0.0162\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0482 - val_loss: 0.0338\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0365 - val_loss: 0.0234\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0337 - val_loss: 0.0206\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0317 - val_loss: 0.0162\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0297 - val_loss: 0.0145\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0260 - val_loss: 0.0135\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0253 - val_loss: 0.0132\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0136\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0208 - val_loss: 0.0128\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0200 - val_loss: 0.0135\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0133\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0155 - val_loss: 0.0132\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0131\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0128\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0127\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0156\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0133\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0115\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0120\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0123\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0176 - val_loss: 0.0121\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0127\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0129\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0132\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0149\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0182\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0150\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0141\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0169\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0169\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0144\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0156\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0151\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0131\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0147\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0214\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0178\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0132\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0153\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0155\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0149\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0140\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0139\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0163\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0136\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0138\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0145\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0161\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0128\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0186\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0240\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0111\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0085\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0148\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0177\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0175\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0167\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0161\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0173\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0132\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0211\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0219\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0143\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0175\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0153\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0139\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0264\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0219\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0106\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0203\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0156\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0149\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0153\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0156\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0170\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0190\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0178\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0175\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0213\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0160\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0156\n",
      ">Neurons=85, Score=3.437059372663498\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 78ms/step - loss: 0.1655 - val_loss: 0.0146\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0481 - val_loss: 0.0362\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0380 - val_loss: 0.0213\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0344 - val_loss: 0.0190\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0294 - val_loss: 0.0150\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0284 - val_loss: 0.0136\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0255 - val_loss: 0.0129\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0257 - val_loss: 0.0126\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0227 - val_loss: 0.0128\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0226 - val_loss: 0.0125\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0126\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0130\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0124\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0120\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0128\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0120\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0126\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0221 - val_loss: 0.0111\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0109\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0204 - val_loss: 0.0156\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0128\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0170 - val_loss: 0.0105\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0094\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0161 - val_loss: 0.0130\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0156 - val_loss: 0.0133\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0237 - val_loss: 0.0201\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0091\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0086\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0163\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0144\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0111\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0124\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0156\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0117\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0102\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0137\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0094\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0086\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0158 - val_loss: 0.0174\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0142 - val_loss: 0.0201\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0177\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0149\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.0122\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0137\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0151\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0138\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0171\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0173\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0129\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.0075\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0199\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0175\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0077\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0092\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0159\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0152\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0163\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0141\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0087\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0148\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0167\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0150\n",
      ">Neurons=85, Score=8.680994063615799\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 72ms/step - loss: 0.1559 - val_loss: 0.0167\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0502 - val_loss: 0.0450\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0373 - val_loss: 0.0217\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0343 - val_loss: 0.0214\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0300 - val_loss: 0.0167\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0287 - val_loss: 0.0136\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0244 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0246 - val_loss: 0.0132\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.0124\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.0126\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0193 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0181 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0171 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0114\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0131\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0279 - val_loss: 0.0133\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0193 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0261 - val_loss: 0.0124\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0184 - val_loss: 0.0168\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0136\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0135\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0136\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.0157\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0107\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0111\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0097\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0213 - val_loss: 0.0166\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0148\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0095\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0150\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0150\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0131\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0152\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0138\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 0.0209\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0086\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0127\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0173\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0133\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0126\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0166\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0155\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0158\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0141\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0145\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0087\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0076\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0166\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.0121\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0130\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0109\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0150\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0158\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0115\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0144\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0206\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0159\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0120\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0171\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0164\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0139\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0089\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0126\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0207\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0145\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0110\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0116\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0184\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0141\n",
      ">Neurons=85, Score=7.927357405424118\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 75ms/step - loss: 0.1622 - val_loss: 0.0155\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0495 - val_loss: 0.0420\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0365 - val_loss: 0.0239\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0345 - val_loss: 0.0257\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0293 - val_loss: 0.0185\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0281 - val_loss: 0.0165\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0270 - val_loss: 0.0136\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0251 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0226 - val_loss: 0.0126\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0222 - val_loss: 0.0121\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0183 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0118\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0184 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0115\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0111\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0241 - val_loss: 0.0158\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0111\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0165 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0108\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0106\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0096\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0094\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0101\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0102\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0122\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0092\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0094\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0180 - val_loss: 0.0127\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0104\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0098\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0191 - val_loss: 0.0112\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0117\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0091\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0124\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0113\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0123\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0095\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0083\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0127\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0116\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0115\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0067\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0073\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0156\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0130\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 0.0119\n",
      ">Neurons=85, Score=4.743765667080879\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 89ms/step - loss: 0.1652 - val_loss: 0.0157\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0548 - val_loss: 0.0424\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0377 - val_loss: 0.0235\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0343 - val_loss: 0.0250\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0286 - val_loss: 0.0168\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0280 - val_loss: 0.0148\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0272 - val_loss: 0.0128\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0123\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0236 - val_loss: 0.0131\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0227 - val_loss: 0.0120\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0196 - val_loss: 0.0117\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0123\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0110\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0204 - val_loss: 0.0108\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0109\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0220 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0106\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0127\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0124\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0090\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0097\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0095\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0170 - val_loss: 0.0125\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0092\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0098\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0154 - val_loss: 0.0091\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0086\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0082\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0127\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0080\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0081 - val_loss: 0.0096\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0074\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0194 - val_loss: 0.0111\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0171 - val_loss: 0.0073\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0069\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0099\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0079 - val_loss: 0.0093\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.0109\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0111\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0086\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0235 - val_loss: 0.0147\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0084\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0197 - val_loss: 0.0077\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0135\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0121\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0099\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0123\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0059 - val_loss: 0.0104\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0059 - val_loss: 0.0101\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0055 - val_loss: 0.0109\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.0109\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0133\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0132\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0068\n",
      ">Neurons=90, Score=6.172853335738182\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 74ms/step - loss: 0.1639 - val_loss: 0.0167\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0505 - val_loss: 0.0390\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0374 - val_loss: 0.0222\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0362 - val_loss: 0.0232\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0166\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0289 - val_loss: 0.0134\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0262 - val_loss: 0.0123\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0244 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0247 - val_loss: 0.0119\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0224 - val_loss: 0.0117\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0203 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0128\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0125\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0143\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0182 - val_loss: 0.0105\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0185 - val_loss: 0.0125\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0305 - val_loss: 0.0166\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0105\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0232 - val_loss: 0.0119\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0116\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0154\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0125\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0129\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0131\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0146\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0138\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0148\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0154\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0179\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0141\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0153\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0126\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0163\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0174\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0138\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0163\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0187\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0097\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0128\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0183\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0213\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0132\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0149\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0191\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0172\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0136\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0130\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0207\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0229\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0116\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0165\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0169\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0133\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0140\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0077 - val_loss: 0.0194\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0170\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0153\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0158\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0232\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0197\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0142\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0214 - val_loss: 0.0222\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.0077\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0084\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0181\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0242\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0172\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0154\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0213\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0200\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0062 - val_loss: 0.0202\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0170\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0155\n",
      ">Neurons=90, Score=3.4595001488924026\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 76ms/step - loss: 0.1475 - val_loss: 0.0208\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0470 - val_loss: 0.0318\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0388 - val_loss: 0.0231\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0342 - val_loss: 0.0208\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0311 - val_loss: 0.0152\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0251 - val_loss: 0.0126\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0241 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0218 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.0111\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0111\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0118\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0239 - val_loss: 0.0114\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0218 - val_loss: 0.0106\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0123\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0103\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0102\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0096\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0083\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0076\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0085\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0080\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0241 - val_loss: 0.0155\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0084\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0086\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0080\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0077\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0076\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0078\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0083\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0070\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0074\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0063\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0088\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0084\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0127\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0063\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0057\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0085\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0096\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0115\n",
      ">Neurons=90, Score=3.066147118806839\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 5s 82ms/step - loss: 0.1525 - val_loss: 0.0198\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0467 - val_loss: 0.0306\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0387 - val_loss: 0.0226\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0339 - val_loss: 0.0224\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0302 - val_loss: 0.0167\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0267 - val_loss: 0.0144\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0230 - val_loss: 0.0118\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0205 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0200 - val_loss: 0.0113\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0109\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0107\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0107\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0151 - val_loss: 0.0095\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0260 - val_loss: 0.0097\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0111\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0296 - val_loss: 0.0135\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0171 - val_loss: 0.0097\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0119\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0101\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0097\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0218 - val_loss: 0.0111\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0222 - val_loss: 0.0135\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0237 - val_loss: 0.0094\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0168 - val_loss: 0.0085\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0085\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0080\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0142\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0076\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0071\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0104\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0084 - val_loss: 0.0106\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0081 - val_loss: 0.0103\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0071 - val_loss: 0.0102\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0079 - val_loss: 0.0091\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 0.0061\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.0095\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0085\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0111\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0082 - val_loss: 0.0103\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0117\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0117\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0113\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0107\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0080\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0196 - val_loss: 0.0060\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0054\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0130\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0134\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      ">Neurons=90, Score=4.694279283285141\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 117ms/step - loss: 0.1761 - val_loss: 0.0147\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0470 - val_loss: 0.0437\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0346 - val_loss: 0.0211\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0318 - val_loss: 0.0201\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0284 - val_loss: 0.0159\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0260 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0122\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0119\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0214 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0201 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0115\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0117\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0115\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0244 - val_loss: 0.0115\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0244 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0344 - val_loss: 0.0193\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0202 - val_loss: 0.0133\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0114\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0101\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0095\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0145 - val_loss: 0.0095\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0186 - val_loss: 0.0093\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0090\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0207 - val_loss: 0.0092\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0094\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0173 - val_loss: 0.0109\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0088\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0087\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0084\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0078\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0084\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0171 - val_loss: 0.0083\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0077\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0075\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0131 - val_loss: 0.0090\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0084\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0152 - val_loss: 0.0075\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0119 - val_loss: 0.0070\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0087\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.0075\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0072\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0054\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0064\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0219 - val_loss: 0.0061\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0178 - val_loss: 0.0056\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0198 - val_loss: 0.0135\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      ">Neurons=90, Score=1.898462139070034\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 105ms/step - loss: 0.1440 - val_loss: 0.0212\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0459 - val_loss: 0.0322\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0409 - val_loss: 0.0255\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0344 - val_loss: 0.0210\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0328 - val_loss: 0.0172\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0271 - val_loss: 0.0140\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0242 - val_loss: 0.0126\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0213 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0183 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 0.0113\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0181 - val_loss: 0.0110\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0163 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0158 - val_loss: 0.0105\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0216 - val_loss: 0.0111\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0170 - val_loss: 0.0109\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0258 - val_loss: 0.0132\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 0.0140\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0107\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0120\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0095\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0184 - val_loss: 0.0100\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0099\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0202 - val_loss: 0.0127\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0179 - val_loss: 0.0142\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0216 - val_loss: 0.0099\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 0.0093\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0143\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0099\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0123\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0095\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0093\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0129\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0109\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0097\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0085\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0120\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0124\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0113\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0139 - val_loss: 0.0079\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0138\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0176\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0092\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0135\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0139\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0143\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0126\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0132\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0111\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0091\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0137\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0210\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0163 - val_loss: 0.0074\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0080 - val_loss: 0.0163\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0152\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0070 - val_loss: 0.0130\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0114\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0139\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0115\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0109\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0180\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0153\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0077 - val_loss: 0.0093\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      ">Neurons=90, Score=6.563924252986908\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 99ms/step - loss: 0.1571 - val_loss: 0.0171\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0506 - val_loss: 0.0439\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0402 - val_loss: 0.0252\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0375 - val_loss: 0.0242\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0307 - val_loss: 0.0179\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0271 - val_loss: 0.0145\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0261 - val_loss: 0.0129\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 0.0125\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0226 - val_loss: 0.0125\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0121\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0201 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0123\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0266 - val_loss: 0.0115\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 0.0117\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0297 - val_loss: 0.0184\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0123\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0225 - val_loss: 0.0126\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0113\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0108\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0114\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0095\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0095\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0091\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0095\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0093\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0107\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0083\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0150 - val_loss: 0.0079\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0129\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0078\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0078\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0083\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0118\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0094\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0089\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0071\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0083\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0070\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0103\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0094\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0097\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0097\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      ">Neurons=90, Score=3.3863671123981476\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 101ms/step - loss: 0.1720 - val_loss: 0.0157\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0571 - val_loss: 0.0494\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0390 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0353 - val_loss: 0.0263\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0285 - val_loss: 0.0169\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0282 - val_loss: 0.0139\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0265 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0232 - val_loss: 0.0119\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 0.0138\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0184 - val_loss: 0.0132\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0134\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0135\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0124\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0234\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0213 - val_loss: 0.0104\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0243 - val_loss: 0.0137\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0292 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0110\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0163\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0174\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0131 - val_loss: 0.0140\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0150\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0142\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0142\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0149\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0167 - val_loss: 0.0109\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0189 - val_loss: 0.0201\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0183 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0090\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0172\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0192\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0175\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0155\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0127\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0152\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0155\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0162\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0179\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0149\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0139 - val_loss: 0.0206\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0152 - val_loss: 0.0156\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0102\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0165\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0207\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0173\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0141\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0192\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0179\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 0.0160\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0173\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0230\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0165\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0157\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0151\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0134\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0197 - val_loss: 0.0238\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0065\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0164\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0237\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.0231\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0229\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0059 - val_loss: 0.0188\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0214\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0207\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.0171\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0272\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0234\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0177\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0172\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0165 - val_loss: 0.0094\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      ">Neurons=90, Score=4.959448054432869\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 104ms/step - loss: 0.1575 - val_loss: 0.0179\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0461 - val_loss: 0.0376\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0372 - val_loss: 0.0242\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0322 - val_loss: 0.0254\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0302 - val_loss: 0.0170\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0279 - val_loss: 0.0146\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0249 - val_loss: 0.0129\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0256 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0221 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0182 - val_loss: 0.0116\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0165 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.0114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0112\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0243 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0110\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0194 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0214 - val_loss: 0.0159\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0101\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0101\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0105\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0217 - val_loss: 0.0091\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0138\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0098\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0130\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0117\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0090\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0086\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0126\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0134\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0090\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0097\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0154\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0080\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0130\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0097\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0115\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0111\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0134\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0122\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0131\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0117\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0139\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0074\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0080\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0132\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0140\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0075\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0140\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0161\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0108\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      ">Neurons=90, Score=3.24605330824852\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 102ms/step - loss: 0.1761 - val_loss: 0.0154\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0504 - val_loss: 0.0417\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0347 - val_loss: 0.0218\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0342 - val_loss: 0.0214\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0317 - val_loss: 0.0151\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0286 - val_loss: 0.0139\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0261 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0252 - val_loss: 0.0124\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0120\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0187 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0153 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0119\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0106\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0248 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0212 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 0.0127\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0134\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0106\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0115\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0099\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0126\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0164 - val_loss: 0.0092\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0101\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 0.0098\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0187 - val_loss: 0.0090\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0113\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0090\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0096\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0091\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0081\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0073\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0148\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0104\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0085\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0122\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0107\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0088\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0095\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0073\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0062\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0120\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0084\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0102\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0129\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0073\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0107\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      ">Neurons=90, Score=2.6924407109618187\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 112ms/step - loss: 0.1343 - val_loss: 0.0429\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0410 - val_loss: 0.0163\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0406 - val_loss: 0.0258\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0298 - val_loss: 0.0162\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0277 - val_loss: 0.0143\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0257 - val_loss: 0.0130\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0233 - val_loss: 0.0128\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0216 - val_loss: 0.0124\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0195 - val_loss: 0.0121\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0168 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0177 - val_loss: 0.0117\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0163 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0202 - val_loss: 0.0110\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.0111\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0268 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0274 - val_loss: 0.0119\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0273 - val_loss: 0.0154\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0231 - val_loss: 0.0148\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0220 - val_loss: 0.0121\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0124\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0107 - val_loss: 0.0170\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0167\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0077\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0271 - val_loss: 0.0097\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0207 - val_loss: 0.0094\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0345 - val_loss: 0.0167\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0159 - val_loss: 0.0092\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0168 - val_loss: 0.0157\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0090\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0122\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0129\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0065\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0223 - val_loss: 0.0077\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0178 - val_loss: 0.0067\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0206 - val_loss: 0.0123\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0194 - val_loss: 0.0150\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0173 - val_loss: 0.0075\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0115 - val_loss: 0.0072\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0117\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0098\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0074 - val_loss: 0.0088\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0089 - val_loss: 0.0121\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0094\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0108\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0078\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0180 - val_loss: 0.0060\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0112 - val_loss: 0.0085\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0169\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0064\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0119\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0103\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0070\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0157\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0127 - val_loss: 0.0095\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0141 - val_loss: 0.0059\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0097\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0131\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0089\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0106\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0106\n",
      ">Neurons=128, Score=3.8630787283182144\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 83ms/step - loss: 0.1426 - val_loss: 0.0360\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0372 - val_loss: 0.0192\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0409 - val_loss: 0.0241\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0315 - val_loss: 0.0150\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0285 - val_loss: 0.0136\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0253 - val_loss: 0.0127\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0242 - val_loss: 0.0125\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0205 - val_loss: 0.0123\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 0.0122\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0120\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0164 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0128\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0177\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0141\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0212 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0304 - val_loss: 0.0131\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0272 - val_loss: 0.0119\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0313 - val_loss: 0.0163\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0177 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0189 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0223 - val_loss: 0.0105\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0159\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0101\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0142\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0161 - val_loss: 0.0098\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0134\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0141\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0136 - val_loss: 0.0091\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0153\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0130\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0091\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0142\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0127\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0126\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0115\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0154 - val_loss: 0.0087\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0132 - val_loss: 0.0080\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.0096\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0126\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0134\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0152\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0143\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0163\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0144\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0128\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0170\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0156\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0118\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0130\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0133\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0136\n",
      ">Neurons=128, Score=2.938386984169483\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 120ms/step - loss: 0.1381 - val_loss: 0.0401\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0397 - val_loss: 0.0153\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0386 - val_loss: 0.0263\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0298 - val_loss: 0.0139\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0285 - val_loss: 0.0147\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0239 - val_loss: 0.0123\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0223 - val_loss: 0.0120\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0202 - val_loss: 0.0117\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0195 - val_loss: 0.0118\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0178 - val_loss: 0.0113\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0126\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 0.0139\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0176 - val_loss: 0.0109\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0315 - val_loss: 0.0104\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0248 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0447 - val_loss: 0.0275\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0183 - val_loss: 0.0106\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0105\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 0.0091\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0179 - val_loss: 0.0103\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0201 - val_loss: 0.0096\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0186 - val_loss: 0.0098\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0114\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0094\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0190 - val_loss: 0.0093\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0098\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 0.0159\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.0121\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0172 - val_loss: 0.0085\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0097\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0097\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0131\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0063\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0071\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0079\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0087\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0148 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 0.0150\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0147\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0073\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0115\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0118\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0106\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0119\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0120\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0086\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0155 - val_loss: 0.0110\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0084\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0184 - val_loss: 0.0059\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0145\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0089 - val_loss: 0.0106\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0070\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0109\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0121\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0116\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0076\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0077\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0099\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0146 - val_loss: 0.0054\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0086\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      ">Neurons=128, Score=4.007925465703011\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 99ms/step - loss: 0.1415 - val_loss: 0.0391\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0434 - val_loss: 0.0166\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0440 - val_loss: 0.0286\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0301 - val_loss: 0.0185\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0302 - val_loss: 0.0164\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0275 - val_loss: 0.0134\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0242 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0219 - val_loss: 0.0126\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0193 - val_loss: 0.0125\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0193 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0166 - val_loss: 0.0129\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0158 - val_loss: 0.0122\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0128\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.0128\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0154 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0275 - val_loss: 0.0110\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0254 - val_loss: 0.0113\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0310 - val_loss: 0.0161\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0254 - val_loss: 0.0145\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0169 - val_loss: 0.0125\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0111\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0111\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0174 - val_loss: 0.0110\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0208 - val_loss: 0.0116\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.0100\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0187 - val_loss: 0.0098\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0118\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0094\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0154 - val_loss: 0.0118\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0086\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0170 - val_loss: 0.0109\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0094\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0176 - val_loss: 0.0081\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0097\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0133\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0080\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0079\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0106\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0085\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0077\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0104\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0076\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0061\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0064\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0071 - val_loss: 0.0109\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.0099\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0062 - val_loss: 0.0104\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0062 - val_loss: 0.0115\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0086\n",
      ">Neurons=128, Score=4.659424722194672\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 105ms/step - loss: 0.1354 - val_loss: 0.0477\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0370 - val_loss: 0.0173\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0366 - val_loss: 0.0274\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0278 - val_loss: 0.0142\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0275 - val_loss: 0.0143\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0240 - val_loss: 0.0124\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0218 - val_loss: 0.0124\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0196 - val_loss: 0.0120\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0117\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0166 - val_loss: 0.0150\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0210 - val_loss: 0.0218\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0126\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0456 - val_loss: 0.0206\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0250 - val_loss: 0.0112\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0107\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0120\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0151\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0117\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0190 - val_loss: 0.0129\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0210 - val_loss: 0.0118\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0206 - val_loss: 0.0147\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0297 - val_loss: 0.0189\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0251 - val_loss: 0.0101\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0158 - val_loss: 0.0093\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0130\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0155\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0124\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0129\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0137\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0142\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0165\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0149\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 0.0152\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0223 - val_loss: 0.0085\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0090\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0150\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0119\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0134\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0161 - val_loss: 0.0140\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0155 - val_loss: 0.0137\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0072\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.0140\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0159\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0117\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0144\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0124\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0151\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0112\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0134\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0125\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0163 - val_loss: 0.0090\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0190\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0081\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.0129\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0150\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0163\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0138\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0162\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0057\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0127\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0095 - val_loss: 0.0187\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0163\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.0156\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0113\n",
      ">Neurons=128, Score=2.5838516652584076\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 112ms/step - loss: 0.1309 - val_loss: 0.0400\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0363 - val_loss: 0.0163\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0380 - val_loss: 0.0221\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0285 - val_loss: 0.0143\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0259 - val_loss: 0.0137\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0218 - val_loss: 0.0129\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0213 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0189 - val_loss: 0.0125\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0189 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0173 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0133\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0135 - val_loss: 0.0152\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0146 - val_loss: 0.0139\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.0111\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0244 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0213 - val_loss: 0.0124\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0390 - val_loss: 0.0160\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0204 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0221 - val_loss: 0.0166\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0158 - val_loss: 0.0128\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0141\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0148 - val_loss: 0.0129\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0128 - val_loss: 0.0146\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0143\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0127\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0207 - val_loss: 0.0121\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0231 - val_loss: 0.0103\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0182 - val_loss: 0.0195\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0131\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0136\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0114 - val_loss: 0.0158\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0163\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0147\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0156\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0168 - val_loss: 0.0115\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0162\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0154\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0170\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0136\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0169\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0159\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0148\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0089 - val_loss: 0.0141\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0151\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0180\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0135 - val_loss: 0.0093\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0171\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0145\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0119\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0094 - val_loss: 0.0135\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0150\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0121 - val_loss: 0.0165\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0128\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0183\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0152\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0132\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0086 - val_loss: 0.0158\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0172\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0135\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 0.0144\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0183\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0159\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0135\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0176\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0174\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0145\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0139\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0171\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0166\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0147\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0132\n",
      ">Neurons=128, Score=5.712057650089264\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 81ms/step - loss: 0.1386 - val_loss: 0.0398\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0388 - val_loss: 0.0169\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0378 - val_loss: 0.0231\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0304 - val_loss: 0.0151\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0274 - val_loss: 0.0138\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0239 - val_loss: 0.0123\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0232 - val_loss: 0.0120\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.0120\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0205 - val_loss: 0.0115\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0181 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0110\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0318 - val_loss: 0.0130\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0205 - val_loss: 0.0107\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0279 - val_loss: 0.0175\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0108\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0176 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0106\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0124\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0114\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0115\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0127\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0119\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0098\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0165 - val_loss: 0.0096\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0138\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0092\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0134\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0126\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0148 - val_loss: 0.0124\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.0084\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0090\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0159 - val_loss: 0.0172\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0127 - val_loss: 0.0132\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0144 - val_loss: 0.0083\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0106 - val_loss: 0.0085\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 0.0112\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0088\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0079\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0077\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0086 - val_loss: 0.0130\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0138\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0106\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0080 - val_loss: 0.0114\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0073\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0109\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0136 - val_loss: 0.0068\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0114 - val_loss: 0.0069\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0081 - val_loss: 0.0112\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0092 - val_loss: 0.0124\n",
      ">Neurons=128, Score=4.224162176251411\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 12s 178ms/step - loss: 0.1258 - val_loss: 0.0523\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0411 - val_loss: 0.0152\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0389 - val_loss: 0.0233\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0306 - val_loss: 0.0141\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0274 - val_loss: 0.0132\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0267 - val_loss: 0.0126\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0242 - val_loss: 0.0123\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0178 - val_loss: 0.0118\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0168 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0150 - val_loss: 0.0112\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0139 - val_loss: 0.0111\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0143 - val_loss: 0.0112\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0133 - val_loss: 0.0169\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0165 - val_loss: 0.0230\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0402 - val_loss: 0.0102\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0306 - val_loss: 0.0128\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0399 - val_loss: 0.0273\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0169 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0127\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0140\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0150\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0082\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0213 - val_loss: 0.0079\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0195 - val_loss: 0.0096\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0320 - val_loss: 0.0123\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0217 - val_loss: 0.0097\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0183 - val_loss: 0.0151\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0167 - val_loss: 0.0091\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0160 - val_loss: 0.0132\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0119\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0173 - val_loss: 0.0079\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0133 - val_loss: 0.0076\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0131\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0084 - val_loss: 0.0104\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0079 - val_loss: 0.0095\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0137 - val_loss: 0.0075\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0160 - val_loss: 0.0110\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0098\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0182 - val_loss: 0.0069\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0104\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0074\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0112 - val_loss: 0.0081\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0101 - val_loss: 0.0078\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0117 - val_loss: 0.0088\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0165 - val_loss: 0.0058\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0121\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0119\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0097\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0106\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 1s 78ms/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0090\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0099\n",
      ">Neurons=128, Score=4.390404745936394\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 12s 175ms/step - loss: 0.1504 - val_loss: 0.0345\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0433 - val_loss: 0.0213\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0412 - val_loss: 0.0312\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0327 - val_loss: 0.0171\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0300 - val_loss: 0.0173\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0259 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0240 - val_loss: 0.0122\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0211 - val_loss: 0.0118\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0201 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0190 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0166\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0163\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0173 - val_loss: 0.0102\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0443 - val_loss: 0.0116\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0297 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0357 - val_loss: 0.0228\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0159 - val_loss: 0.0107\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0105\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0102\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0108\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0196 - val_loss: 0.0104\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0103\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0256 - val_loss: 0.0141\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0208 - val_loss: 0.0128\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0237 - val_loss: 0.0126\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0090\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0105\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0089 - val_loss: 0.0121\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0124\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0145\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0121\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0071\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0149 - val_loss: 0.0069\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0139 - val_loss: 0.0090\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0268 - val_loss: 0.0103\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0249 - val_loss: 0.0072\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0268 - val_loss: 0.0207\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0160 - val_loss: 0.0133\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0079\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0124\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0089 - val_loss: 0.0133\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0121\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0083 - val_loss: 0.0124\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0084 - val_loss: 0.0125\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0110\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0148\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0140\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0194 - val_loss: 0.0135\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0089\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0178 - val_loss: 0.0069\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0137\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0132\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.0141\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0078 - val_loss: 0.0122\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0131\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0154 - val_loss: 0.0155\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0076\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0153\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0131\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0071 - val_loss: 0.0106\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.0122\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0134\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0066 - val_loss: 0.0102\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0104\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0121\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      ">Neurons=128, Score=3.057877905666828\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 135ms/step - loss: 0.1425 - val_loss: 0.0376\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0433 - val_loss: 0.0169\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0414 - val_loss: 0.0250\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0314 - val_loss: 0.0142\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0295 - val_loss: 0.0143\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0280 - val_loss: 0.0127\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0244 - val_loss: 0.0123\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0200 - val_loss: 0.0120\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0178 - val_loss: 0.0120\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0117\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0155 - val_loss: 0.0133\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0186 - val_loss: 0.0159\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.0150\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0219 - val_loss: 0.0108\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0236 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0248 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0138\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0158 - val_loss: 0.0134\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0138\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0157 - val_loss: 0.0135\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0140 - val_loss: 0.0134\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0158\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0164 - val_loss: 0.0150\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0136\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0243 - val_loss: 0.0166\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0206 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0165\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0133\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0169\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0162 - val_loss: 0.0137\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0152\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0165 - val_loss: 0.0159\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0168 - val_loss: 0.0117\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0161\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0143 - val_loss: 0.0098\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0150\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0134\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0106 - val_loss: 0.0178\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0155\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0145 - val_loss: 0.0119\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0187 - val_loss: 0.0083\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0143\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0145 - val_loss: 0.0179\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0119 - val_loss: 0.0140\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0128\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0169\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0193\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0142\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0163\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0169\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0143\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0206\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0166\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0150\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0193\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0138\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0096\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0203\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0197\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0131\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0140\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0194\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0172\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0176\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0134\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0142\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0184\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0192\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0170\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0074\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0148\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0230\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0183\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0187\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0216\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0062 - val_loss: 0.0159\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0175\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0163\n",
      ">Neurons=128, Score=5.891258642077446\n",
      "[[3.5059139132499695, 1.1991625651717186, 2.6677152141928673, 1.3839381746947765, 2.7371013537049294, 6.926059722900391, 2.5342976674437523, 6.055384129285812, 6.534507125616074, 1.715458557009697], [4.380348697304726, 4.330588132143021, 6.269596517086029, 8.06451365351677, 5.231796205043793, 2.2668398916721344, 8.524983376264572, 6.2706440687179565, 3.7436265498399734, 4.408218339085579], [7.17611089348793, 5.181409418582916, 3.5147927701473236, 4.541607573628426, 5.343576893210411, 3.130517154932022, 2.3181091994047165, 2.8617167845368385, 5.075203254818916, 7.290741801261902], [3.346208482980728, 4.428412392735481, 3.792063891887665, 5.681546777486801, 4.377694800496101, 5.50900474190712, 1.4874236658215523, 7.41645023226738, 9.967401623725891, 3.2132942229509354], [3.4469980746507645, 3.4369252622127533, 4.894213005900383, 5.1280394196510315, 3.3906199038028717, 4.9217864871025085, 6.718461960554123, 10.556245595216751, 4.609418287873268, 2.284086123108864], [7.129444181919098, 3.4354317933321, 6.715402007102966, 2.001207135617733, 2.0308030769228935, 5.844376236200333, 4.075299575924873, 5.861566960811615, 2.676970511674881, 1.2517493218183517], [1.524375006556511, 9.732113033533096, 3.1997453421354294, 8.148586004972458, 3.421610966324806, 4.787920042872429, 2.0766405388712883, 3.7398777902126312, 3.8864850997924805, 3.8491375744342804], [4.5433226972818375, 5.557816103100777, 5.3981713950634, 4.305335134267807, 3.537578508257866, 3.2942034304142, 3.437059372663498, 8.680994063615799, 7.927357405424118, 4.743765667080879], [6.172853335738182, 3.4595001488924026, 3.066147118806839, 4.694279283285141, 1.898462139070034, 6.563924252986908, 3.3863671123981476, 4.959448054432869, 3.24605330824852, 2.6924407109618187], [3.8630787283182144, 2.938386984169483, 4.007925465703011, 4.659424722194672, 2.5838516652584076, 5.712057650089264, 4.224162176251411, 4.390404745936394, 3.057877905666828, 5.891258642077446]] [32, 60, 64, 65, 70, 75, 80, 85, 90, 128]\n",
      "Param=32, Mean=3.526, Std=2.065\n",
      "Param=60, Mean=5.349, Std=1.847\n",
      "Param=64, Mean=4.643, Std=1.629\n",
      "Param=65, Mean=4.922, Std=2.272\n",
      "Param=70, Mean=4.939, Std=2.209\n",
      "Param=75, Mean=4.102, Std=2.035\n",
      "Param=80, Mean=4.437, Std=2.443\n",
      "Param=85, Mean=5.143, Std=1.750\n",
      "Param=90, Mean=4.014, Std=1.447\n",
      "Param=128, Mean=4.133, Std=1.049\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, neurons):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=4, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=4)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # resumindo a média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = np.mean(scores[i]), np.std(scores[i])\n",
    "        print(f'Param={params[i]}, Mean={m:.3f}, Std={s:.3f}')\n",
    "    # boxplot das pontuações\n",
    "    plt.boxplot(scores, labels=params)\n",
    "    plt.savefig('../../src/static/images/despesas/figura[0].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repetindo o experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            score = score * 100.0\n",
    "            scores.append(score)\n",
    "            print(f'>Neurons={p}, Score={score}')\n",
    "        all_scores.append(scores)\n",
    "    # resumindo os resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = [32, 60, 64, 65, 70, 75, 80, 85, 90, 128]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste de modelo com tamanho do lote 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 e 12, para verificação do mais adequado para a aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "72/72 [==============================] - 8s 26ms/step - loss: 0.0790 - val_loss: 0.0154\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0366 - val_loss: 0.0139\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0289 - val_loss: 0.0143\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0230 - val_loss: 0.0196\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0194 - val_loss: 0.0208\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0208 - val_loss: 0.0180\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0201 - val_loss: 0.0229\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0162 - val_loss: 0.0136\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0169 - val_loss: 0.0129\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0171 - val_loss: 0.0140\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0133 - val_loss: 0.0144\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0158\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0165\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0132 - val_loss: 0.0167\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0139 - val_loss: 0.0237\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0158\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0201\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0172\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0170\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0173\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0108 - val_loss: 0.0255\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0105 - val_loss: 0.0139\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0255\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0091 - val_loss: 0.0186\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0108 - val_loss: 0.0143\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0309\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0265\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0293\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0084 - val_loss: 0.0343\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0221\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0091 - val_loss: 0.0256\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0088 - val_loss: 0.0287\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0240\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0384\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0269\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0537\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0080 - val_loss: 0.0321\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0382\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0092 - val_loss: 0.0310\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0081 - val_loss: 0.0387\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0256\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0079 - val_loss: 0.0440\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0328\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0207\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0157\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0091 - val_loss: 0.0323\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0079 - val_loss: 0.0291\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      ">p=1: 1, Score=2.529481053352356\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 7s 28ms/step - loss: 0.0732 - val_loss: 0.0155\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0326 - val_loss: 0.0133\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0268 - val_loss: 0.0174\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0219 - val_loss: 0.0338\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0301\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0191\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0185 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0161 - val_loss: 0.0098\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0097\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0170\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0249\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0419\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0341\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0289\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0135 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0120 - val_loss: 0.0211\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0115 - val_loss: 0.0073\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.0177\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0113 - val_loss: 0.0259\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0097 - val_loss: 0.0293\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0123 - val_loss: 0.0075\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0227\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0251\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0241\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0090 - val_loss: 0.0246\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0156\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0162\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0075 - val_loss: 0.0259\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0322\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0071 - val_loss: 0.0422\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0078 - val_loss: 0.0545\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0090 - val_loss: 0.0567\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0115 - val_loss: 0.0272\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0091 - val_loss: 0.0350\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0084 - val_loss: 0.0145\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0073 - val_loss: 0.0325\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0058 - val_loss: 0.0183\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0063 - val_loss: 0.0165\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0059 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0064 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0054 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0052 - val_loss: 0.0130\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0065 - val_loss: 0.0180\n",
      ">p=1: 2, Score=5.148728564381599\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 17s 50ms/step - loss: 0.0777 - val_loss: 0.0154\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0363 - val_loss: 0.0141\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0300 - val_loss: 0.0155\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0261 - val_loss: 0.0210\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0306\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0163 - val_loss: 0.0285\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0190 - val_loss: 0.0370\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0169 - val_loss: 0.0291\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0138 - val_loss: 0.0254\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0208\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0335\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0379\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0140 - val_loss: 0.0321\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0112 - val_loss: 0.0410\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0132 - val_loss: 0.0255\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0272\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0169\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0347\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0113 - val_loss: 0.0182\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0207\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0117 - val_loss: 0.0374\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0116 - val_loss: 0.0395\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0102 - val_loss: 0.0382\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0091 - val_loss: 0.0321\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0100 - val_loss: 0.0480\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0095 - val_loss: 0.0330\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0080 - val_loss: 0.0315\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0083 - val_loss: 0.0314\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0471\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0632\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0487\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0548\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0300\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0077 - val_loss: 0.0185\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0294\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0134\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0098\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0153\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0114\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0128\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0189\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.0545\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0324\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0086 - val_loss: 0.0530\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0546\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0078 - val_loss: 0.0245\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0077 - val_loss: 0.0290\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0159\n",
      ">p=1: 3, Score=4.757227003574371\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 8s 28ms/step - loss: 0.0774 - val_loss: 0.0144\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0332 - val_loss: 0.0133\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0269 - val_loss: 0.0147\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0185\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0159\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0194\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0142\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0155\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0223\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0130 - val_loss: 0.0301\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0250\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0119 - val_loss: 0.0434\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0678\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0237\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0114 - val_loss: 0.0162\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0107 - val_loss: 0.0216\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0093 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0275\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0228\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0376\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0449\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0638\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0423\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0744\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0437\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0077 - val_loss: 0.0537\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0531\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0700\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0641\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0080 - val_loss: 0.0616\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0807\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0531\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0579\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0524\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0102 - val_loss: 0.0366\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0358\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0497\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0097 - val_loss: 0.0229\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0329\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0252\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0134\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0241\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0457\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0323\n",
      ">p=1: 4, Score=2.150413393974304\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 8s 28ms/step - loss: 0.0751 - val_loss: 0.0146\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0359 - val_loss: 0.0131\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0265 - val_loss: 0.0165\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0211 - val_loss: 0.0260\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0457\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0232\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0125\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0226\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0195\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.0163\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0188\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0192\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0241\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0361\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0125 - val_loss: 0.0380\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0107 - val_loss: 0.0426\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0804\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0611\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0365\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0279\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0250\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0091 - val_loss: 0.0384\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0228\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0334\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0163\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0083 - val_loss: 0.0134\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0078 - val_loss: 0.0208\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0402\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0071 - val_loss: 0.0501\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0091 - val_loss: 0.0570\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0077 - val_loss: 0.0297\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0248\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0317\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0487\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0384\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0600\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0517\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0516\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0675\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0576\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0633\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0589\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0585\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0414\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0520\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0251\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0319\n",
      ">p=1: 5, Score=11.434897780418396\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 8s 34ms/step - loss: 0.0740 - val_loss: 0.0147\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0356 - val_loss: 0.0136\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0279 - val_loss: 0.0162\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0248 - val_loss: 0.0245\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0291\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0270\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0241\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0177 - val_loss: 0.0186\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0138\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0309\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0224\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0310\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0126 - val_loss: 0.0404\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0162 - val_loss: 0.0539\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0129 - val_loss: 0.0331\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0415\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0121 - val_loss: 0.0492\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0264\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0114 - val_loss: 0.0248\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0186\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0364\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0190\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0500\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0449\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0987\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0885\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0566\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0637\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0682\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0099 - val_loss: 0.0373\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0267\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0265\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0208\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0234\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0216\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0083 - val_loss: 0.0153\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0360\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0288\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0218\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0253\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0501\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0513\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0432\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0698\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0778\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0593\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0553\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0624\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0059 - val_loss: 0.0668\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0056 - val_loss: 0.0427\n",
      ">p=1: 6, Score=21.125386655330658\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 6s 20ms/step - loss: 0.0739 - val_loss: 0.0150\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0346 - val_loss: 0.0142\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0296 - val_loss: 0.0142\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0192\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0204 - val_loss: 0.0248\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0146\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0139\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0121\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0167\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0204\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0369\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0275\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0154 - val_loss: 0.0291\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0330\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0461\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0180\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0215\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0198\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0291\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0299\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0681\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0612\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0455\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0739\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0613\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0628\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0712\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0880\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0645\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0331\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0240\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0330\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0135\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0129\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0119\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0277\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0195\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0236\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.0229\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0406\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0309\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0582\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0623\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0513\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0695\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0553\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0346\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0711\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0297\n",
      ">p=1: 7, Score=12.574678659439087\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 5s 21ms/step - loss: 0.0780 - val_loss: 0.0145\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0362 - val_loss: 0.0135\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0288 - val_loss: 0.0141\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.0189\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0287\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0295\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0213\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0145\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0134\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.0103\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0140\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.0108\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0162\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0241\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0255\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0295\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0459\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0387\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0430\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0206\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0435\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0464\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0261\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0463\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0302\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0466\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0378\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0365\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0212\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0189\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0366\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0538\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0640\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0673\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0809\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0685\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0706\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0604\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0432\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0340\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0270\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0247\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0362\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0240\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0303\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0271\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0231\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0252\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0075\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0252\n",
      ">p=1: 8, Score=5.308747291564941\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 6s 20ms/step - loss: 0.0777 - val_loss: 0.0145\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0349 - val_loss: 0.0137\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0271 - val_loss: 0.0140\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0215 - val_loss: 0.0152\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0299\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0315\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0251\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0301\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0153\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0167\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0200\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0211\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0270\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0366\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0316\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0322\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0651\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0404\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0338\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0345\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0187\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0369\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0160\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0270\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0251\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0349\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0435\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0238\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0687\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0480\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0494\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0629\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0639\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0086 - val_loss: 0.0856\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0882\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0870\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0913\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0771\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0451\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0444\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0332\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0215\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0192\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0147\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0126\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0245\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0163\n",
      ">p=1: 9, Score=10.938658565282822\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 6s 23ms/step - loss: 0.0835 - val_loss: 0.0146\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0318 - val_loss: 0.0137\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0281 - val_loss: 0.0163\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0200 - val_loss: 0.0217\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0248\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0207 - val_loss: 0.0141\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0198 - val_loss: 0.0207\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0221\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.0295\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0303\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.0165\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0190\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.0190\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0228\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0230\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0348\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0334\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0393\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0462\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0655\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0262\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.0465\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0263\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0380\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0412\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0335\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0440\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0485\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0401\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0369\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0349\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0375\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0377\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0318\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0224\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.0370\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0223\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0235\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0239\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.0236\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0181\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0248\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0251\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0290\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0458\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0331\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.0505\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0321\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0454\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0282\n",
      ">p=1: 10, Score=10.537935048341751\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 5s 36ms/step - loss: 0.1138 - val_loss: 0.0284\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0141\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0131\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0278 - val_loss: 0.0126\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0264 - val_loss: 0.0121\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0253 - val_loss: 0.0119\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0111\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0108\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0105\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0136\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0108\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0102\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0186\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0196\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0132\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0085\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0080\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0082\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0083\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0082\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0083\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0166\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0208\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0079\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0070\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0059\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0040\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      ">p=2: 1, Score=2.413821965456009\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 6s 34ms/step - loss: 0.1150 - val_loss: 0.0342\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0336 - val_loss: 0.0152\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0333 - val_loss: 0.0138\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0131\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0126\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0126\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0116\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0143\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0139\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0094\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0084\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0078\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0081\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0145\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0187\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0189\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0270\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0207\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0216\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0147\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0196\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0392\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0140\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0167\n",
      ">p=2: 2, Score=7.015466690063477\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 6s 41ms/step - loss: 0.1209 - val_loss: 0.0364\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0366 - val_loss: 0.0160\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0309 - val_loss: 0.0142\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0128\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.0125\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0209 - val_loss: 0.0116\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0113\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0234 - val_loss: 0.0119\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0135\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0150\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0152\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0135\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0128\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0104\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0102\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0096\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0091\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0095\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0076\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0078\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0083\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0062\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0075\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0051\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0088\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0099\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0115\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0036\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0028\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0032\n",
      ">p=2: 3, Score=0.9716580621898174\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 5s 36ms/step - loss: 0.1185 - val_loss: 0.0281\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0365 - val_loss: 0.0151\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0323 - val_loss: 0.0142\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0300 - val_loss: 0.0135\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0305 - val_loss: 0.0131\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0274 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.0122\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0121\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0130\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0157\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0133\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0101\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0105\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0277\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0234\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0247\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0254\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0171\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0132\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0082\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0120\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0167\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0221\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0335\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0191\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0202\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0188\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0276\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0407\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0392\n",
      ">p=2: 4, Score=9.157665818929672\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 6s 42ms/step - loss: 0.1089 - val_loss: 0.0287\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0332 - val_loss: 0.0146\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0302 - val_loss: 0.0131\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0272 - val_loss: 0.0127\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0265 - val_loss: 0.0120\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0216 - val_loss: 0.0115\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.0112\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0108\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0104\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0102\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0103\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0100\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0096\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0087\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0072\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0078\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0075\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0059\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0195\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0081\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0303\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0341\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0183\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0145\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0231\n",
      ">p=2: 5, Score=6.82673305273056\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 5s 36ms/step - loss: 0.1175 - val_loss: 0.0290\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0315 - val_loss: 0.0149\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0317 - val_loss: 0.0135\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0286 - val_loss: 0.0129\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0124\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0222 - val_loss: 0.0117\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0220 - val_loss: 0.0125\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0110\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0110\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0141\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0135\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0136\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0154\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0163\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0187\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0185\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0092\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0087\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0092\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0076\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0133\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0144\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0203\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0165\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0075\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0158\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0207\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0157\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0239\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0234\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0187\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0138\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0138\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0405\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0274\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0061\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0110\n",
      ">p=2: 6, Score=3.803769499063492\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 5s 39ms/step - loss: 0.1166 - val_loss: 0.0336\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0342 - val_loss: 0.0151\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0328 - val_loss: 0.0134\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0292 - val_loss: 0.0128\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0256 - val_loss: 0.0125\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0258 - val_loss: 0.0118\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0253 - val_loss: 0.0113\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0119\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0182\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0195\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0174\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0090\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0092\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0130\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0129\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0099\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0095\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0103\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0184\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0218\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0329\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0337\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0180\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0075\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0080\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0083\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0084\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0206\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0236\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0482\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0297\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0180\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0144\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      ">p=2: 7, Score=1.7137140035629272\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 6s 35ms/step - loss: 0.1198 - val_loss: 0.0320\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0344 - val_loss: 0.0185\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0305 - val_loss: 0.0146\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0291 - val_loss: 0.0134\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0256 - val_loss: 0.0124\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0116\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0113\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0116\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0132\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0119\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0137\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0110\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0173\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0090\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0092\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0089\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0095\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0083\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0082\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0076\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0069\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0076\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0052\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0052\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0058\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0055\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0103\n",
      ">p=2: 8, Score=4.933109134435654\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 5s 37ms/step - loss: 0.1215 - val_loss: 0.0346\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0331 - val_loss: 0.0163\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0326 - val_loss: 0.0143\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0134\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0278 - val_loss: 0.0125\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0117\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0207 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0133\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0164\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0126\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0094\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0143\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0078\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0073\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0074\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0073\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0071\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0084\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0064\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0072\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0184\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0059\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0092\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0068\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0110\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0130\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0169\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0159\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0281\n",
      ">p=2: 9, Score=2.6076767593622208\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 6s 51ms/step - loss: 0.1246 - val_loss: 0.0334\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0369 - val_loss: 0.0157\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0138\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0315 - val_loss: 0.0132\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0128\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0122\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0220 - val_loss: 0.0120\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0126\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0143\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0174\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0141\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0139\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0136\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0137\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0131\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0096\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0083\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0124\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0160\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0149\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0124\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0084\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0071\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0056\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      ">p=2: 10, Score=0.995152723044157\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 5s 50ms/step - loss: 0.1539 - val_loss: 0.0208\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0407 - val_loss: 0.0186\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0429 - val_loss: 0.0238\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0144\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0127\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0121\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0117\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0119\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0130\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0110\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0108\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0150\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0177\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0173\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0333 - val_loss: 0.0124\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.0120\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0133\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0129\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0101\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0131\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0100\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0119\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0141\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0087\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0142\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0092\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0099\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0128\n",
      ">p=3: 1, Score=3.525311127305031\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 5s 50ms/step - loss: 0.1438 - val_loss: 0.0313\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0395 - val_loss: 0.0185\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0208\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0316 - val_loss: 0.0141\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0294 - val_loss: 0.0132\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0264 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0134\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0132\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0123\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0124\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0124\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0139\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0159\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0185\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0223\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0158\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0101\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0103\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0098\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0275 - val_loss: 0.0144\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0113\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0255 - val_loss: 0.0171\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0134\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0134\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0137\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0158\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0157\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0168\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0173\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0204\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0140\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0159\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0162\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0200\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0135\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0132\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0126\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0144\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0196\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0221\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0147\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0126\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0161\n",
      ">p=3: 2, Score=5.642277374863625\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 6s 51ms/step - loss: 0.1361 - val_loss: 0.0327\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0382 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0389 - val_loss: 0.0237\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0306 - val_loss: 0.0143\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0284 - val_loss: 0.0128\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0122\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0119\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0118\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0135\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0160\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0212\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0163\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0101\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0110\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0130\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0126\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0134\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0123\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0169\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0207\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0141\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0227 - val_loss: 0.0133\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0120\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0105\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0126\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0145\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      ">p=3: 3, Score=3.9245855063199997\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 5s 50ms/step - loss: 0.1387 - val_loss: 0.0326\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0397 - val_loss: 0.0162\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0416 - val_loss: 0.0242\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0327 - val_loss: 0.0160\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0126\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0252 - val_loss: 0.0123\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0120\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0120\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0129\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0231 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0222 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0131\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0241 - val_loss: 0.0124\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0293 - val_loss: 0.0160\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0108\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0152\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0181\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0114\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0127\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0138\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0158\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0128\n",
      ">p=3: 4, Score=4.1545070707798\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 5s 51ms/step - loss: 0.1537 - val_loss: 0.0241\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0411 - val_loss: 0.0190\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0439 - val_loss: 0.0247\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0305 - val_loss: 0.0158\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0296 - val_loss: 0.0133\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0124\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0136\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0124\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0133\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0172\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0113\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0111\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0141\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0157\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0166\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0106\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0122\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0135\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0147\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0120\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0123\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0163\n",
      ">p=3: 5, Score=3.891213983297348\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 6s 50ms/step - loss: 0.1389 - val_loss: 0.0389\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0406 - val_loss: 0.0193\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0421 - val_loss: 0.0249\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0315 - val_loss: 0.0166\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0134\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0127\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0126\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0122\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0134\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0152\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0276 - val_loss: 0.0141\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0147\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0329 - val_loss: 0.0142\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0143\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0153\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0139\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0172\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0158\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0126\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0123\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0134\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0138\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0213\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0141\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0140\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0172\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0160\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0144\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0170\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0170\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0187\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0162\n",
      ">p=3: 6, Score=4.112539812922478\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 5s 51ms/step - loss: 0.1521 - val_loss: 0.0233\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0434 - val_loss: 0.0184\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0417 - val_loss: 0.0268\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0329 - val_loss: 0.0163\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0140\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0263 - val_loss: 0.0126\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0121\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0122\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0117\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0123\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0183\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0156\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 0.0103\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0327 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0109\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0106\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0109\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0160\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0100\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0102\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0103\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0158\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0132\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0097\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0120\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0135\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0154\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0105\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0133\n",
      ">p=3: 7, Score=5.110540613532066\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 6s 50ms/step - loss: 0.1602 - val_loss: 0.0258\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0452 - val_loss: 0.0230\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0406 - val_loss: 0.0291\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0325 - val_loss: 0.0164\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0291 - val_loss: 0.0134\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0277 - val_loss: 0.0126\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.0124\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0216 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0112\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0240 - val_loss: 0.0168\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0159\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0248 - val_loss: 0.0137\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0300 - val_loss: 0.0143\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0208 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0108\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0127\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0133\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0135\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0160\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0095\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0159\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0195\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0168\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0163\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0227 - val_loss: 0.0132\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0107\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0151\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0148\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0149\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0177\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0233\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0147\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0126\n",
      ">p=3: 8, Score=4.789769276976585\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 6s 49ms/step - loss: 0.1343 - val_loss: 0.0336\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0410 - val_loss: 0.0167\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0437 - val_loss: 0.0244\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0331 - val_loss: 0.0150\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0280 - val_loss: 0.0138\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0270 - val_loss: 0.0127\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0124\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0196 - val_loss: 0.0119\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0120\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0115\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0122\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0229\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0349\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0227\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0334 - val_loss: 0.0102\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0357 - val_loss: 0.0145\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0265 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0110\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0137\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0136\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0160\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0164\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0200\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0143\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0093\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0091\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0148\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0210\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0222\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0176\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0153\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0168\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0123\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0142\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0206\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0202\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0109\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0126\n",
      ">p=3: 9, Score=7.642696797847748\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 5s 50ms/step - loss: 0.1294 - val_loss: 0.0349\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0402 - val_loss: 0.0154\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0378 - val_loss: 0.0235\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0143\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0132\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0127\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0125\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0120\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0182\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0325\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0255\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0261 - val_loss: 0.0154\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0323 - val_loss: 0.0137\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0134\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0246 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0131\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0147\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0187\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0215\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0124\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0169\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0169\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0138\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0125\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0141\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0146\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0164\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0168\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0166\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0154\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0149\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0185\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0168\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0146\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0141\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0179\n",
      ">p=3: 10, Score=3.8978256285190582\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 5s 68ms/step - loss: 0.1531 - val_loss: 0.0147\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0484 - val_loss: 0.0354\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0369 - val_loss: 0.0184\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0179\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0300 - val_loss: 0.0146\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0257 - val_loss: 0.0122\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0124\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0121\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0122\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0155 - val_loss: 0.0131\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0153\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0142\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0142\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0125\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0133\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0145\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0134\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0240 - val_loss: 0.0195\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0139\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0169\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0164\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0136\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0157\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0158\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0179\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0135\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0125\n",
      ">p=4: 1, Score=3.0441325157880783\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 6s 89ms/step - loss: 0.1658 - val_loss: 0.0144\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0509 - val_loss: 0.0484\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0332 - val_loss: 0.0241\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0344 - val_loss: 0.0224\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0304 - val_loss: 0.0178\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0287 - val_loss: 0.0167\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0127\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0122\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0119\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0115\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0109\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 0.0106\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0108\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0109\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0103\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0108\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0100\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0100\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0121\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0099\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0091\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0089\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0082\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0080\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0088\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0080\n",
      ">p=4: 2, Score=2.446366287767887\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 5s 72ms/step - loss: 0.1623 - val_loss: 0.0148\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0510 - val_loss: 0.0406\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0385 - val_loss: 0.0220\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0328 - val_loss: 0.0221\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0163\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.0132\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0124\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0120\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0111\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0108\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0124\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0110\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0108\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0096\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0105\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0129\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0093\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0104\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0092\n",
      ">p=4: 3, Score=2.247363142669201\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 6s 71ms/step - loss: 0.1771 - val_loss: 0.0162\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0467 - val_loss: 0.0552\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0330 - val_loss: 0.0191\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0340 - val_loss: 0.0207\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0152\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0247 - val_loss: 0.0140\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0111\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.0113\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0111\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0109\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0114\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0106\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0099\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0095\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0076\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0083\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0088\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0146\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0080\n",
      ">p=4: 4, Score=1.9286179915070534\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 5s 74ms/step - loss: 0.1772 - val_loss: 0.0160\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0495 - val_loss: 0.0483\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0359 - val_loss: 0.0217\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0325 - val_loss: 0.0202\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0323 - val_loss: 0.0168\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0325 - val_loss: 0.0164\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0144\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0131\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0222 - val_loss: 0.0104\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0217 - val_loss: 0.0135\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0150\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0103\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0092\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0167 - val_loss: 0.0098\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0091\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0100\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0094\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0097\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0085\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0079\n",
      ">p=4: 5, Score=1.705697923898697\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 5s 66ms/step - loss: 0.1622 - val_loss: 0.0148\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0473 - val_loss: 0.0364\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0353 - val_loss: 0.0209\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0336 - val_loss: 0.0198\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0148\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0304 - val_loss: 0.0145\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0127\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0124\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0124\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0137\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0136\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0110\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0145\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0099\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0121\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0105\n",
      ">p=4: 6, Score=2.1279575303196907\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 6s 66ms/step - loss: 0.1572 - val_loss: 0.0153\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0443 - val_loss: 0.0331\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0374 - val_loss: 0.0207\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0331 - val_loss: 0.0186\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0282 - val_loss: 0.0158\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0275 - val_loss: 0.0133\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0129\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0181 - val_loss: 0.0131\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0121\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0130\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0185 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0111\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0154\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0140\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0160\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0133\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0129\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0141\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0145\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0157\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0185\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0162\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0118\n",
      ">p=4: 7, Score=2.338826283812523\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 7s 94ms/step - loss: 0.1679 - val_loss: 0.0153\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0477 - val_loss: 0.0466\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0344 - val_loss: 0.0232\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0344 - val_loss: 0.0219\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0296 - val_loss: 0.0188\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0300 - val_loss: 0.0144\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0130\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0130\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0131\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0124\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0131\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0127\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0110\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0134\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0117\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0094\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0131\n",
      ">p=4: 8, Score=2.981008030474186\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 5s 67ms/step - loss: 0.1697 - val_loss: 0.0144\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0551 - val_loss: 0.0497\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0360 - val_loss: 0.0203\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0362 - val_loss: 0.0227\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.0152\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0295 - val_loss: 0.0139\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0123\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0122\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0128\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0129\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0131\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0127\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0240 - val_loss: 0.0139\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0141\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0128\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0127\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0137\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0138\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0132\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0102\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0150\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0154\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0127\n",
      ">p=4: 9, Score=3.0032899230718613\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 6s 73ms/step - loss: 0.1666 - val_loss: 0.0147\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0497 - val_loss: 0.0456\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0353 - val_loss: 0.0209\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0192\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0288 - val_loss: 0.0159\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0135\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0130\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0229 - val_loss: 0.0134\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0138\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0108\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0157\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0129\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0141\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0146\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0130\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0126\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0131\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0108\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0144\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0195\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0178 - val_loss: 0.0094\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0092\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0129\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0133\n",
      ">p=4: 10, Score=3.597913682460785\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 91ms/step - loss: 0.1702 - val_loss: 0.0172\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0498 - val_loss: 0.0440\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0337 - val_loss: 0.0172\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0340 - val_loss: 0.0177\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0307 - val_loss: 0.0148\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0301 - val_loss: 0.0139\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0128\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0276 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0241 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0258 - val_loss: 0.0131\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0130\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 0.0134\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0147\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0159\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0153\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0164\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0139\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0155\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0171\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0148\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0167\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0168\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.0173\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0230 - val_loss: 0.0084\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0201\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0170\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0142\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0139\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0161\n",
      ">p=5: 1, Score=6.043743342161179\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 123ms/step - loss: 0.1923 - val_loss: 0.0277\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0569 - val_loss: 0.0491\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0372 - val_loss: 0.0178\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0342 - val_loss: 0.0166\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0327 - val_loss: 0.0166\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0308 - val_loss: 0.0142\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0288 - val_loss: 0.0133\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0275 - val_loss: 0.0130\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0261 - val_loss: 0.0135\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0224 - val_loss: 0.0137\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0140\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0141\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0148\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0136\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0152\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0147\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0158\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0143\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0141\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0233 - val_loss: 0.0207\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0101\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0228\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0148\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0165\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0129\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0184\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0165\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0208\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0146\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0179\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0191\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0252\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0082\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0083\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0189\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0207\n",
      ">p=5: 2, Score=5.097687989473343\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 99ms/step - loss: 0.1819 - val_loss: 0.0229\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0511 - val_loss: 0.0388\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0374 - val_loss: 0.0158\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0355 - val_loss: 0.0155\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0325 - val_loss: 0.0154\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0294 - val_loss: 0.0137\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0307 - val_loss: 0.0132\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0271 - val_loss: 0.0128\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0262 - val_loss: 0.0128\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0262 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0133\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0136\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0220 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0133\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0129\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0141\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0135\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0154\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0121\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0135\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0158\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0160\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0153\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0199 - val_loss: 0.0150\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0127\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0324 - val_loss: 0.0323\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0133\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0175\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0161\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0166\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0185\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0191\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0141\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0189\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0197\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0214\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0167\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0183\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0161\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0194\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0221\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0134\n",
      ">p=5: 3, Score=4.3740469962358475\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 81ms/step - loss: 0.1715 - val_loss: 0.0149\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0536 - val_loss: 0.0565\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0334 - val_loss: 0.0220\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0230\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0314 - val_loss: 0.0177\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0297 - val_loss: 0.0151\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0279 - val_loss: 0.0134\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0128\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0115\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0111\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0111\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0109\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0107\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0104\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0156 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0102\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0099\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0101\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0096\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0107\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0092\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0089\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0083\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0106\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0082\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0079\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0090\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0088\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      ">p=5: 4, Score=2.788768522441387\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 115ms/step - loss: 0.1974 - val_loss: 0.0246\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0620 - val_loss: 0.0674\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0350 - val_loss: 0.0253\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0357 - val_loss: 0.0205\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0321 - val_loss: 0.0218\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0293 - val_loss: 0.0157\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0274 - val_loss: 0.0145\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0263 - val_loss: 0.0133\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0230 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0128\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0201 - val_loss: 0.0133\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0141\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0165\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0125\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0154\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0164\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0126\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0122\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0137\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0135\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0150\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0139\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0142\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0185\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0144\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0115\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0128\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0137\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0281\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0171\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0154\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0153\n",
      ">p=5: 5, Score=5.854256451129913\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 89ms/step - loss: 0.1776 - val_loss: 0.0164\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0576 - val_loss: 0.0630\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0353 - val_loss: 0.0232\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0354 - val_loss: 0.0222\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0334 - val_loss: 0.0199\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0293 - val_loss: 0.0154\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0276 - val_loss: 0.0145\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0270 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0247 - val_loss: 0.0124\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0257 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0187 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0130\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0127\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0093\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0123\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0164 - val_loss: 0.0125\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0081\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0245 - val_loss: 0.0215\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0079\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0072\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      ">p=5: 6, Score=3.6121390759944916\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 90ms/step - loss: 0.1952 - val_loss: 0.0256\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0559 - val_loss: 0.0607\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0346 - val_loss: 0.0212\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0350 - val_loss: 0.0198\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0302 - val_loss: 0.0184\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0146\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0139\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0255 - val_loss: 0.0131\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0129\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.0126\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0107\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.0141 - val_loss: 0.0104\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0097\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0211 - val_loss: 0.0096\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0163\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0096\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0099\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0086\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0085\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0078\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0076\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0225 - val_loss: 0.0126\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0077\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0090\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      ">p=5: 7, Score=2.0955098792910576\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 80ms/step - loss: 0.1927 - val_loss: 0.0257\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0563 - val_loss: 0.0527\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0365 - val_loss: 0.0176\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0352 - val_loss: 0.0185\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0321 - val_loss: 0.0172\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0314 - val_loss: 0.0143\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0288 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0258 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0232 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0110\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0111\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0139\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0102\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0098\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0097\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0100\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0083\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0088\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0150\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0080\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      ">p=5: 8, Score=1.9322657957673073\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 84ms/step - loss: 0.1904 - val_loss: 0.0255\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0618 - val_loss: 0.0521\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0352 - val_loss: 0.0217\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0374 - val_loss: 0.0186\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0335 - val_loss: 0.0184\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0303 - val_loss: 0.0148\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0261 - val_loss: 0.0135\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0267 - val_loss: 0.0126\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0241 - val_loss: 0.0122\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0221 - val_loss: 0.0126\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0121\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0125\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0130\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0128\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0158\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0157\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0159\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0176\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      ">p=5: 9, Score=3.4546662122011185\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 89ms/step - loss: 0.1701 - val_loss: 0.0162\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0508 - val_loss: 0.0548\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0359 - val_loss: 0.0185\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0354 - val_loss: 0.0206\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0329 - val_loss: 0.0184\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0153\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0277 - val_loss: 0.0141\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0252 - val_loss: 0.0131\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0241 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0124\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0123\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0129\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0193 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0109\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0109\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0100\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0085\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0086\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0089\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0089\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0129\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0079\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0079\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0143\n",
      ">p=5: 10, Score=3.3850014209747314\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 5s 104ms/step - loss: 0.2064 - val_loss: 0.0444\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0721 - val_loss: 0.0388\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0434 - val_loss: 0.0406\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0323 - val_loss: 0.0176\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0343 - val_loss: 0.0217\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0315 - val_loss: 0.0193\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0282 - val_loss: 0.0155\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0271 - val_loss: 0.0142\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0233 - val_loss: 0.0130\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0207 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0125\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0188 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0123\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0188 - val_loss: 0.0154\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0107\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0092\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0133\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0087\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0142\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0075\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0111\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0071\n",
      ">p=6: 1, Score=1.8402667716145515\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 7s 136ms/step - loss: 0.1792 - val_loss: 0.0255\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0600 - val_loss: 0.0568\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0391 - val_loss: 0.0269\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0341 - val_loss: 0.0163\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0352 - val_loss: 0.0207\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0300 - val_loss: 0.0167\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0295 - val_loss: 0.0141\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.0133\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0250 - val_loss: 0.0123\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0223 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0119\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0129\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0133\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0143\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0139\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0099\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0129\n",
      ">p=6: 2, Score=4.336967691779137\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 6s 99ms/step - loss: 0.2002 - val_loss: 0.0378\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0691 - val_loss: 0.0489\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0423 - val_loss: 0.0358\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0316 - val_loss: 0.0178\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0353 - val_loss: 0.0233\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0305 - val_loss: 0.0181\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0287 - val_loss: 0.0145\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0265 - val_loss: 0.0141\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0231 - val_loss: 0.0123\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0135\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0178 - val_loss: 0.0123\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0141\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0130\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0131\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0111\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0127\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0101\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0114\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0096\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0125\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0086\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0133\n",
      ">p=6: 3, Score=4.0391214191913605\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 6s 123ms/step - loss: 0.2006 - val_loss: 0.0364\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0739 - val_loss: 0.0484\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0440 - val_loss: 0.0428\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0328 - val_loss: 0.0213\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0381 - val_loss: 0.0261\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0306 - val_loss: 0.0230\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0303 - val_loss: 0.0192\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0294 - val_loss: 0.0158\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0284 - val_loss: 0.0145\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0256 - val_loss: 0.0131\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.0125\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0233 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0194 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0159 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0110\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0109\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0104\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0170\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0098\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0137\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0113 - val_loss: 0.0128\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0162\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0165\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0113\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0147\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      ">p=6: 4, Score=2.363472990691662\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 5s 109ms/step - loss: 0.1875 - val_loss: 0.0276\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0617 - val_loss: 0.0653\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0397 - val_loss: 0.0319\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0349 - val_loss: 0.0196\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0354 - val_loss: 0.0241\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0314 - val_loss: 0.0191\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0281 - val_loss: 0.0164\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0268 - val_loss: 0.0153\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 0.0130\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0126\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0123\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0203 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0130\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0131\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0164 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0104\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0089\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0086\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0141\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0083\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0079\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      ">p=6: 5, Score=2.004420943558216\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 6s 137ms/step - loss: 0.2103 - val_loss: 0.0413\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0737 - val_loss: 0.0439\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0467 - val_loss: 0.0425\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0355 - val_loss: 0.0189\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0365 - val_loss: 0.0205\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0320 - val_loss: 0.0187\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0282 - val_loss: 0.0148\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0280 - val_loss: 0.0141\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0232 - val_loss: 0.0124\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0221 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0123\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0174 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0136 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0103\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0089\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0085\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0124\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      ">p=6: 6, Score=6.683607399463654\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 7s 157ms/step - loss: 0.1971 - val_loss: 0.0329\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0696 - val_loss: 0.0513\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0420 - val_loss: 0.0404\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0349 - val_loss: 0.0193\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0324 - val_loss: 0.0203\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0309 - val_loss: 0.0174\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0280 - val_loss: 0.0139\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0263 - val_loss: 0.0137\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0126\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0219 - val_loss: 0.0129\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0203 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0181 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0124\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0131\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0136\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0144\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0165 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0105\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0162\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0150\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0102 - val_loss: 0.0145\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0115\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0136\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0245 - val_loss: 0.0088\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0141\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0184 - val_loss: 0.0321\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0129\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0138\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0120\n",
      ">p=6: 7, Score=3.2584797590970993\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 9s 207ms/step - loss: 0.1765 - val_loss: 0.0245\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0533 - val_loss: 0.0556\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0366 - val_loss: 0.0212\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0338 - val_loss: 0.0163\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0347 - val_loss: 0.0196\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0150\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0284 - val_loss: 0.0136\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 0.0130\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0279 - val_loss: 0.0128\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0246 - val_loss: 0.0124\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0224 - val_loss: 0.0135\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0230 - val_loss: 0.0135\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0215 - val_loss: 0.0139\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0191 - val_loss: 0.0133\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0141\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0131\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0130\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0141\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0159\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0128 - val_loss: 0.0133\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0137\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 0.0098\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0162\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0109\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0097\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0154 - val_loss: 0.0157\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0108\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0117\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0082\n",
      ">p=6: 8, Score=1.829002983868122\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 8s 144ms/step - loss: 0.2175 - val_loss: 0.0532\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0909 - val_loss: 0.0242\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0507 - val_loss: 0.0555\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0346 - val_loss: 0.0195\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0348 - val_loss: 0.0218\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0329 - val_loss: 0.0223\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0306 - val_loss: 0.0164\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0260 - val_loss: 0.0158\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.0138\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0263 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0249 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 0.0128\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0131\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0124\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0135\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0148\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0137\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0130\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0149\n",
      ">p=6: 9, Score=4.328582063317299\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 5s 99ms/step - loss: 0.1891 - val_loss: 0.0290\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0618 - val_loss: 0.0532\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0458 - val_loss: 0.0312\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0336 - val_loss: 0.0164\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0349 - val_loss: 0.0211\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0292 - val_loss: 0.0162\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0284 - val_loss: 0.0140\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0271 - val_loss: 0.0131\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0124\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0211 - val_loss: 0.0131\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0187 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0129\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0175 - val_loss: 0.0126\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0110\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0139\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0159 - val_loss: 0.0102\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0139 - val_loss: 0.0184\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0148\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0118\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0123\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0137\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0126\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      ">p=6: 10, Score=1.8393738195300102\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 122ms/step - loss: 0.2114 - val_loss: 0.0393\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0806 - val_loss: 0.0368\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0474 - val_loss: 0.0491\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0348 - val_loss: 0.0201\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0365 - val_loss: 0.0223\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0333 - val_loss: 0.0232\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0303 - val_loss: 0.0176\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0287 - val_loss: 0.0170\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0271 - val_loss: 0.0140\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0254 - val_loss: 0.0130\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0196 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0175 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0107\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0109\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0095\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0091\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0087\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0097\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0077\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0077\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0073\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0071\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0068\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0065\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0064\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0066\n",
      ">p=7: 1, Score=2.143971063196659\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 6s 111ms/step - loss: 0.1879 - val_loss: 0.0268\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0614 - val_loss: 0.0518\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0393 - val_loss: 0.0341\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0337 - val_loss: 0.0175\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0346 - val_loss: 0.0221\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0332 - val_loss: 0.0195\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0322 - val_loss: 0.0149\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0289 - val_loss: 0.0149\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0261 - val_loss: 0.0135\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0246 - val_loss: 0.0131\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0247 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.0126\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0204 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0188 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0103\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0123\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0086\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0075\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0077\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      ">p=7: 2, Score=3.2623816281557083\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 144ms/step - loss: 0.2083 - val_loss: 0.0418\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0775 - val_loss: 0.0349\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0404 - val_loss: 0.0405\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0319 - val_loss: 0.0181\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0338 - val_loss: 0.0184\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0317 - val_loss: 0.0196\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0274 - val_loss: 0.0144\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0287 - val_loss: 0.0133\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0274 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0236 - val_loss: 0.0123\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0242 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0129\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0222 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0194 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0139\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0096\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0107\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0139\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0084\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0104\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0074\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0155\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0071\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0066\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0091\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0074\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0121\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0079\n",
      ">p=7: 3, Score=4.8967815935611725\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 6s 114ms/step - loss: 0.2038 - val_loss: 0.0289\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0735 - val_loss: 0.0557\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0454 - val_loss: 0.0466\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0342 - val_loss: 0.0220\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0370 - val_loss: 0.0211\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0340 - val_loss: 0.0214\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0304 - val_loss: 0.0168\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0306 - val_loss: 0.0140\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0279 - val_loss: 0.0134\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0280 - val_loss: 0.0123\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0254 - val_loss: 0.0119\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0222 - val_loss: 0.0112\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0196 - val_loss: 0.0107\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0193 - val_loss: 0.0105\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0104\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0101\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0098\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0096\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0158 - val_loss: 0.0120\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0091\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0089\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0087\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0087\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0085\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0082\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0078\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0063\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0094\n",
      ">p=7: 4, Score=3.718111291527748\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 6s 111ms/step - loss: 0.2054 - val_loss: 0.0365\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0775 - val_loss: 0.0438\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0433 - val_loss: 0.0458\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0351 - val_loss: 0.0187\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0352 - val_loss: 0.0203\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0310 - val_loss: 0.0217\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0281 - val_loss: 0.0176\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0285 - val_loss: 0.0144\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0281 - val_loss: 0.0136\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0270 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0234 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0229 - val_loss: 0.0125\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0238 - val_loss: 0.0141\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0238 - val_loss: 0.0126\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0219 - val_loss: 0.0145\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0187 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0136\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0128\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0085\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0091\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0077\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0076\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0076\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0072\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0069\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0147\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      ">p=7: 5, Score=3.5210836678743362\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 113ms/step - loss: 0.2190 - val_loss: 0.0467\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0867 - val_loss: 0.0277\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0476 - val_loss: 0.0457\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0329 - val_loss: 0.0183\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0367 - val_loss: 0.0175\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0337 - val_loss: 0.0189\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0316 - val_loss: 0.0146\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0310 - val_loss: 0.0135\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0130\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0290 - val_loss: 0.0132\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0135\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0225 - val_loss: 0.0138\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0220 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0219 - val_loss: 0.0140\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0145\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0138\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0142\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0147\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0130\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0151\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0179\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0178\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0123\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0227\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0084\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0143\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0153\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0126\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0173\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0092\n",
      ">p=7: 6, Score=5.2708495408296585\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 6s 115ms/step - loss: 0.1884 - val_loss: 0.0261\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0644 - val_loss: 0.0598\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0425 - val_loss: 0.0359\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0324 - val_loss: 0.0171\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0368 - val_loss: 0.0195\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0295 - val_loss: 0.0175\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0270 - val_loss: 0.0140\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0263 - val_loss: 0.0129\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0256 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0213 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0225 - val_loss: 0.0141\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0181 - val_loss: 0.0142\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0126\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0095\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0099\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0085\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0098\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0097\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0179\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0070\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0117\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0126\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0121\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      ">p=7: 7, Score=2.215207554399967\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 176ms/step - loss: 0.2021 - val_loss: 0.0366\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0709 - val_loss: 0.0417\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0467 - val_loss: 0.0392\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0348 - val_loss: 0.0167\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0375 - val_loss: 0.0173\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0342 - val_loss: 0.0162\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0293 - val_loss: 0.0144\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0136\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0281 - val_loss: 0.0133\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0283 - val_loss: 0.0135\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0263 - val_loss: 0.0138\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0148\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0148\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0211 - val_loss: 0.0156\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0153\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0158\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0164\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0135\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0149\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0127\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0170\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0165\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0174\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0143\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0200\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0128\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0170\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0224\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0150\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0136\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0141\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0175\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0174\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0140\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0220\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0075\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0141\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0301\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0163\n",
      ">p=7: 8, Score=4.249922558665276\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 124ms/step - loss: 0.1851 - val_loss: 0.0302\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0606 - val_loss: 0.0440\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0418 - val_loss: 0.0274\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0322 - val_loss: 0.0149\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0346 - val_loss: 0.0177\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0311 - val_loss: 0.0160\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0282 - val_loss: 0.0135\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0295 - val_loss: 0.0129\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0287 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0231 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0247 - val_loss: 0.0134\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.0129\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0213 - val_loss: 0.0139\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0188 - val_loss: 0.0124\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0156\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0139\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0162\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0155\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0133\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0170\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0170\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0172\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0177\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0216\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0092\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0141\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0170\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0116\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0121\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0149\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0231\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0150\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0114\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0158\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0148\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0181\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0192\n",
      ">p=7: 9, Score=4.957892745733261\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 118ms/step - loss: 0.1956 - val_loss: 0.0296\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0715 - val_loss: 0.0481\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0447 - val_loss: 0.0497\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0340 - val_loss: 0.0215\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0368 - val_loss: 0.0220\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0344 - val_loss: 0.0223\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0311 - val_loss: 0.0170\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0317 - val_loss: 0.0143\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0266 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0269 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0178 - val_loss: 0.0111\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0140\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0136\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0111\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0147\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0120\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0169\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0162\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0145\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0147\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0138\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0071\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0209 - val_loss: 0.0300\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0173\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0064\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0071 - val_loss: 0.0183\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0194\n",
      ">p=7: 10, Score=4.4030386954545975\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 162ms/step - loss: 0.2140 - val_loss: 0.0527\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0957 - val_loss: 0.0161\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0439 - val_loss: 0.0687\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0414 - val_loss: 0.0349\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0340 - val_loss: 0.0194\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0367 - val_loss: 0.0218\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0318 - val_loss: 0.0242\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0326 - val_loss: 0.0188\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0299 - val_loss: 0.0152\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0274 - val_loss: 0.0148\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0261 - val_loss: 0.0139\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0235 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0215 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0223 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0096\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0086\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0091 - val_loss: 0.0111\n",
      ">p=8: 1, Score=4.477187618613243\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 151ms/step - loss: 0.2265 - val_loss: 0.0631\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1098 - val_loss: 0.0151\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0490 - val_loss: 0.0662\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0430 - val_loss: 0.0430\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0332 - val_loss: 0.0207\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0343 - val_loss: 0.0204\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0328 - val_loss: 0.0233\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0304 - val_loss: 0.0192\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0306 - val_loss: 0.0166\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0326 - val_loss: 0.0160\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0305 - val_loss: 0.0152\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - val_loss: 0.0138\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0273 - val_loss: 0.0131\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0222 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0235 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0193 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0132\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0124\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0193 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0158 - val_loss: 0.0135\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0131\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0145 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0134\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0151\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0120\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0129\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0089\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0082\n",
      ">p=8: 2, Score=1.7817877233028412\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 5s 146ms/step - loss: 0.2228 - val_loss: 0.0629\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1011 - val_loss: 0.0144\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0462 - val_loss: 0.0539\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0405 - val_loss: 0.0311\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0305 - val_loss: 0.0167\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0336 - val_loss: 0.0166\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0187\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0321 - val_loss: 0.0152\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0291 - val_loss: 0.0134\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0275 - val_loss: 0.0133\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 0.0130\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0126\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0273 - val_loss: 0.0133\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0218 - val_loss: 0.0134\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - val_loss: 0.0158\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0131\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0146\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0161\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0132\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0138\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0165 - val_loss: 0.0144\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.0137\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0147\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0169 - val_loss: 0.0143\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0138 - val_loss: 0.0129\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0135\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0127 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0141\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0141 - val_loss: 0.0162\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0135\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0130\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0141\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0125\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0125\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0146\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0158\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0128\n",
      ">p=8: 3, Score=3.346036374568939\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 147ms/step - loss: 0.2058 - val_loss: 0.0515\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0927 - val_loss: 0.0187\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0483 - val_loss: 0.0760\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0381 - val_loss: 0.0352\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0335 - val_loss: 0.0197\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0347 - val_loss: 0.0209\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0321 - val_loss: 0.0227\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0302 - val_loss: 0.0192\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0284 - val_loss: 0.0152\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0297 - val_loss: 0.0139\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0270 - val_loss: 0.0131\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0251 - val_loss: 0.0125\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0139\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0152\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0137\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0147 - val_loss: 0.0161\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0132\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0145\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0149\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0175\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0128\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0151\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0186\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0146\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0182\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0154\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0161\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0146\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0188\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0135\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0205\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0159\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0186\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0132\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0205\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0109 - val_loss: 0.0153\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0233\n",
      ">p=8: 4, Score=6.140544638037682\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 5s 153ms/step - loss: 0.2337 - val_loss: 0.0630\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1187 - val_loss: 0.0147\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0496 - val_loss: 0.0639\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0444 - val_loss: 0.0432\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0329 - val_loss: 0.0200\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0333 - val_loss: 0.0197\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0318 - val_loss: 0.0219\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0300 - val_loss: 0.0191\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0301 - val_loss: 0.0163\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0308 - val_loss: 0.0155\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0267 - val_loss: 0.0143\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0262 - val_loss: 0.0130\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - val_loss: 0.0128\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0222 - val_loss: 0.0124\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0238 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0221 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0196 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0131\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0157 - val_loss: 0.0119\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0128\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0104\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0101\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      ">p=8: 5, Score=1.8307887017726898\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 218ms/step - loss: 0.2115 - val_loss: 0.0508\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0964 - val_loss: 0.0163\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0472 - val_loss: 0.0726\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0396 - val_loss: 0.0412\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0341 - val_loss: 0.0206\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0315 - val_loss: 0.0202\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0334 - val_loss: 0.0226\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0309 - val_loss: 0.0191\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0284 - val_loss: 0.0151\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0266 - val_loss: 0.0132\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0245 - val_loss: 0.0126\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0227 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0226 - val_loss: 0.0130\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0133\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0172 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0130\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0108\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0104\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0144 - val_loss: 0.0108\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0098\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0098\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0136\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0086\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      ">p=8: 6, Score=1.7741767689585686\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 5s 153ms/step - loss: 0.2212 - val_loss: 0.0599\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1036 - val_loss: 0.0148\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0520 - val_loss: 0.0620\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0393 - val_loss: 0.0406\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0331 - val_loss: 0.0200\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0335 - val_loss: 0.0190\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0333 - val_loss: 0.0227\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0304 - val_loss: 0.0177\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0271 - val_loss: 0.0153\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0301 - val_loss: 0.0151\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.0140\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0131\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0247 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0239 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0193 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0128\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0164 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0128\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0120\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0137\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0166 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0135\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0158\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0128\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0139\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0127\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0140\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0166\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0125\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0137\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0117\n",
      ">p=8: 7, Score=3.0195990577340126\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 179ms/step - loss: 0.1860 - val_loss: 0.0405\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0732 - val_loss: 0.0237\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0491 - val_loss: 0.0564\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0347 - val_loss: 0.0218\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0328 - val_loss: 0.0163\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0335 - val_loss: 0.0191\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0298 - val_loss: 0.0192\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0288 - val_loss: 0.0148\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0276 - val_loss: 0.0132\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 0.0130\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0264 - val_loss: 0.0121\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0225 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0224 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0202 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0111\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0159 - val_loss: 0.0143\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0124\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0125\n",
      ">p=8: 8, Score=4.370783641934395\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 153ms/step - loss: 0.2137 - val_loss: 0.0525\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1014 - val_loss: 0.0161\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0446 - val_loss: 0.0722\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0414 - val_loss: 0.0397\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0309 - val_loss: 0.0202\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0329 - val_loss: 0.0206\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0330 - val_loss: 0.0229\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0301 - val_loss: 0.0209\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0288 - val_loss: 0.0167\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0293 - val_loss: 0.0147\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0287 - val_loss: 0.0138\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0252 - val_loss: 0.0130\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0247 - val_loss: 0.0126\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0227 - val_loss: 0.0130\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0202 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0228 - val_loss: 0.0136\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0192 - val_loss: 0.0136\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0185 - val_loss: 0.0140\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0159\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0159 - val_loss: 0.0140\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0159\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0136\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0172\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0141 - val_loss: 0.0148\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0209\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0134\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0171\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0143\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0192\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0184\n",
      ">p=8: 9, Score=4.355087131261826\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 5s 152ms/step - loss: 0.2109 - val_loss: 0.0599\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1096 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0475 - val_loss: 0.0718\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0457 - val_loss: 0.0421\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0345 - val_loss: 0.0198\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0379 - val_loss: 0.0203\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0321 - val_loss: 0.0253\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0347 - val_loss: 0.0232\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0315 - val_loss: 0.0176\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0294 - val_loss: 0.0163\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0279 - val_loss: 0.0163\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0267 - val_loss: 0.0147\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0131\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0127\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0219 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0137\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0140\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0136\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0090\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0090\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0121\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0099\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0101 - val_loss: 0.0140\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      ">p=8: 10, Score=5.448578298091888\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 165ms/step - loss: 0.2234 - val_loss: 0.0660\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1152 - val_loss: 0.0155\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0492 - val_loss: 0.0618\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0446 - val_loss: 0.0551\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0295 - val_loss: 0.0221\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0337 - val_loss: 0.0176\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0329 - val_loss: 0.0203\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0305 - val_loss: 0.0213\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0286 - val_loss: 0.0177\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0284 - val_loss: 0.0153\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0275 - val_loss: 0.0147\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0256 - val_loss: 0.0135\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0273 - val_loss: 0.0131\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0219 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0130\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0193 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.0126\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0170 - val_loss: 0.0124\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      ">p=9: 1, Score=1.8616300076246262\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 169ms/step - loss: 0.2340 - val_loss: 0.0729\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1251 - val_loss: 0.0190\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0542 - val_loss: 0.0401\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0480 - val_loss: 0.0458\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0355 - val_loss: 0.0197\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0354 - val_loss: 0.0160\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0354 - val_loss: 0.0189\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0335 - val_loss: 0.0205\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0298 - val_loss: 0.0172\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0151\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0288 - val_loss: 0.0149\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0142\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0283 - val_loss: 0.0131\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0262 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0222 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0247 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0121\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0179 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0133\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0103\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0130 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      ">p=9: 2, Score=1.8633583560585976\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 190ms/step - loss: 0.2231 - val_loss: 0.0634\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1117 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0477 - val_loss: 0.0514\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0452 - val_loss: 0.0450\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0316 - val_loss: 0.0192\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0341 - val_loss: 0.0163\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0340 - val_loss: 0.0187\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0196\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0305 - val_loss: 0.0168\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0287 - val_loss: 0.0141\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0261 - val_loss: 0.0137\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0260 - val_loss: 0.0132\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0253 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0244 - val_loss: 0.0126\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0217 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0215 - val_loss: 0.0136\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0135\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0130\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0191 - val_loss: 0.0129\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0183 - val_loss: 0.0129\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0172 - val_loss: 0.0134\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0139\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0128\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0130\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0124\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0123\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0155\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0137\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0126\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0149\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0166\n",
      ">p=9: 3, Score=4.855586215853691\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 253ms/step - loss: 0.2247 - val_loss: 0.0677\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1128 - val_loss: 0.0152\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0498 - val_loss: 0.0570\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0495 - val_loss: 0.0448\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0196\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0337 - val_loss: 0.0170\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0334 - val_loss: 0.0204\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0322 - val_loss: 0.0194\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0322 - val_loss: 0.0156\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0296 - val_loss: 0.0142\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0280 - val_loss: 0.0137\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0269 - val_loss: 0.0131\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0262 - val_loss: 0.0130\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0250 - val_loss: 0.0130\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0256 - val_loss: 0.0135\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0213 - val_loss: 0.0130\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 0.0135\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0193 - val_loss: 0.0140\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0195 - val_loss: 0.0139\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0142\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0130\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0138\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0138\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0164 - val_loss: 0.0152\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0154 - val_loss: 0.0156\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0141\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0146\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0134\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0172\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0153\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0136\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0129\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0138\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0159\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0159\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0107 - val_loss: 0.0151\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      ">p=9: 4, Score=2.762399800121784\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 166ms/step - loss: 0.2288 - val_loss: 0.0664\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1206 - val_loss: 0.0162\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0516 - val_loss: 0.0521\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0483 - val_loss: 0.0585\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0354 - val_loss: 0.0236\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0345 - val_loss: 0.0181\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0336 - val_loss: 0.0210\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0303 - val_loss: 0.0224\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0297 - val_loss: 0.0184\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0274 - val_loss: 0.0148\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0250 - val_loss: 0.0139\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0294 - val_loss: 0.0141\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0257 - val_loss: 0.0129\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0251 - val_loss: 0.0127\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 0.0131\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0194 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0133\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0135\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0156 - val_loss: 0.0142\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0139\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0139\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0130\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0136\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0155\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0130 - val_loss: 0.0136\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0157\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0134\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0151\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0147\n",
      ">p=9: 5, Score=5.603282153606415\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 166ms/step - loss: 0.2203 - val_loss: 0.0635\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1135 - val_loss: 0.0151\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0505 - val_loss: 0.0613\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0487 - val_loss: 0.0504\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0333 - val_loss: 0.0223\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0206\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0347 - val_loss: 0.0257\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0311 - val_loss: 0.0258\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0296 - val_loss: 0.0197\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0283 - val_loss: 0.0163\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0267 - val_loss: 0.0153\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0240 - val_loss: 0.0144\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0131\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0229 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0213 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0125\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0195 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0160 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0119\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0118\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0092\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      ">p=9: 6, Score=2.195138856768608\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 173ms/step - loss: 0.2150 - val_loss: 0.0571\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1111 - val_loss: 0.0143\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0485 - val_loss: 0.0693\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0469 - val_loss: 0.0518\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0323 - val_loss: 0.0225\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0341 - val_loss: 0.0189\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0328 - val_loss: 0.0229\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0293 - val_loss: 0.0220\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0277 - val_loss: 0.0156\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0267 - val_loss: 0.0144\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 0.0136\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0251 - val_loss: 0.0129\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0211 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0202 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0209 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0133\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0123\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0134\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0114\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0141\n",
      ">p=9: 7, Score=2.461331896483898\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 177ms/step - loss: 0.2188 - val_loss: 0.0654\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1153 - val_loss: 0.0162\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0496 - val_loss: 0.0502\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0426 - val_loss: 0.0496\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0346 - val_loss: 0.0204\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0328 - val_loss: 0.0162\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0324 - val_loss: 0.0186\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0310 - val_loss: 0.0189\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0147\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0268 - val_loss: 0.0135\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0265 - val_loss: 0.0128\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.0123\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0235 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0236 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0211 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0193 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0125\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0156 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0119 - val_loss: 0.0101\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0139\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0124\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      ">p=9: 8, Score=1.8504669889807701\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 174ms/step - loss: 0.2018 - val_loss: 0.0514\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0989 - val_loss: 0.0159\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0485 - val_loss: 0.0721\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0440 - val_loss: 0.0432\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0331 - val_loss: 0.0207\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0353 - val_loss: 0.0195\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0359 - val_loss: 0.0234\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0318 - val_loss: 0.0205\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0296 - val_loss: 0.0152\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0298 - val_loss: 0.0141\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0265 - val_loss: 0.0137\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0273 - val_loss: 0.0129\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0254 - val_loss: 0.0131\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0230 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0227 - val_loss: 0.0140\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0200 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0130\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0131\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0134 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0100\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      ">p=9: 9, Score=1.7473988234996796\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 173ms/step - loss: 0.2267 - val_loss: 0.0691\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1249 - val_loss: 0.0166\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0519 - val_loss: 0.0564\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0499 - val_loss: 0.0600\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0341 - val_loss: 0.0224\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0381 - val_loss: 0.0179\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0363 - val_loss: 0.0215\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0322 - val_loss: 0.0241\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0301 - val_loss: 0.0186\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0301 - val_loss: 0.0153\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0289 - val_loss: 0.0146\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0266 - val_loss: 0.0139\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0266 - val_loss: 0.0129\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0231 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0229 - val_loss: 0.0129\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0198 - val_loss: 0.0140\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0139\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0180 - val_loss: 0.0146\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0153\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0149\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0151\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0143\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0153 - val_loss: 0.0140\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0150\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0152\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0150\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0166\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0137\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0181\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0173\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0129\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0169\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0130\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0161\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0146\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0148\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0160\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0163\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0140\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0177\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0128\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0197\n",
      ">p=9: 10, Score=6.228341162204742\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 166ms/step - loss: 0.2267 - val_loss: 0.0608\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1178 - val_loss: 0.0153\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0498 - val_loss: 0.0574\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0441 - val_loss: 0.0408\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0327 - val_loss: 0.0189\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0376 - val_loss: 0.0168\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0335 - val_loss: 0.0195\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0325 - val_loss: 0.0207\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0296 - val_loss: 0.0167\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0297 - val_loss: 0.0147\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0304 - val_loss: 0.0139\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0284 - val_loss: 0.0134\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0267 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0258 - val_loss: 0.0136\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0228 - val_loss: 0.0135\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0235 - val_loss: 0.0132\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0228 - val_loss: 0.0138\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0212 - val_loss: 0.0138\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0195 - val_loss: 0.0138\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0193 - val_loss: 0.0143\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0131\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0134\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0144\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0153\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0142 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0142\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0162\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0148\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0091\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0095\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      ">p=10: 1, Score=1.7720134928822517\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 174ms/step - loss: 0.2267 - val_loss: 0.0624\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1132 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0496 - val_loss: 0.0471\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0405 - val_loss: 0.0375\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0344 - val_loss: 0.0176\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0361 - val_loss: 0.0153\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0344 - val_loss: 0.0166\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0330 - val_loss: 0.0168\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0324 - val_loss: 0.0137\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0279 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0277 - val_loss: 0.0125\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0259 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0255 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0242 - val_loss: 0.0124\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0240 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0223 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0108\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0165 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0105\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0107\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0094\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0092\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0142\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0093\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0110 - val_loss: 0.0168\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0108\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0088\n",
      ">p=10: 2, Score=3.6140192300081253\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 170ms/step - loss: 0.2337 - val_loss: 0.0695\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1282 - val_loss: 0.0175\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0546 - val_loss: 0.0404\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0466 - val_loss: 0.0375\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0333 - val_loss: 0.0179\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0341 - val_loss: 0.0147\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0379 - val_loss: 0.0156\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0155\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0306 - val_loss: 0.0143\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0288 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0274 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0276 - val_loss: 0.0123\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0271 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0238 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0252 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0216 - val_loss: 0.0125\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0218 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0210 - val_loss: 0.0127\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0107\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0118\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0112\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0086 - val_loss: 0.0106\n",
      ">p=10: 3, Score=4.183923825621605\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 172ms/step - loss: 0.2257 - val_loss: 0.0569\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1194 - val_loss: 0.0146\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0519 - val_loss: 0.0621\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0404 - val_loss: 0.0486\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0328 - val_loss: 0.0229\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0336 - val_loss: 0.0186\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0331 - val_loss: 0.0215\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0220\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0291 - val_loss: 0.0177\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0266 - val_loss: 0.0148\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0264 - val_loss: 0.0136\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0247 - val_loss: 0.0131\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0240 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0223 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0208 - val_loss: 0.0133\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0135\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0184 - val_loss: 0.0137\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 0.0144\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0142\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0164 - val_loss: 0.0153\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0129\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0162\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0138\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0151\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0138\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0142\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0151\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0116 - val_loss: 0.0146\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0126\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0162\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0143\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0203\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0127\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0181\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0165\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0161\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0218\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0162\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0216\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0109\n",
      ">p=10: 4, Score=3.012540563941002\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 192ms/step - loss: 0.2285 - val_loss: 0.0669\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1326 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0569 - val_loss: 0.0489\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0441 - val_loss: 0.0523\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0214\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0364 - val_loss: 0.0160\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0375 - val_loss: 0.0185\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0330 - val_loss: 0.0208\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0293 - val_loss: 0.0161\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0274 - val_loss: 0.0139\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0303 - val_loss: 0.0133\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0263 - val_loss: 0.0131\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0253 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0227 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0234 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0216 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0203 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0175 - val_loss: 0.0122\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0159 - val_loss: 0.0113\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0109\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0108\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0092\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      ">p=10: 5, Score=7.6979681849479675\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 175ms/step - loss: 0.2192 - val_loss: 0.0543\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1090 - val_loss: 0.0146\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0464 - val_loss: 0.0612\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0407 - val_loss: 0.0392\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0309 - val_loss: 0.0194\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0348 - val_loss: 0.0175\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0328 - val_loss: 0.0189\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0311 - val_loss: 0.0193\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0294 - val_loss: 0.0163\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0277 - val_loss: 0.0139\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0263 - val_loss: 0.0137\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0258 - val_loss: 0.0130\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0254 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0247 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0225 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0216 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0196 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0125\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0131\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.0149\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0145 - val_loss: 0.0138\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0139\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0074\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0069\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0169\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      ">p=10: 6, Score=2.7316292747855186\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 167ms/step - loss: 0.2346 - val_loss: 0.0728\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1279 - val_loss: 0.0183\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0534 - val_loss: 0.0402\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0424 - val_loss: 0.0406\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0349 - val_loss: 0.0178\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0359 - val_loss: 0.0151\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0354 - val_loss: 0.0168\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0327 - val_loss: 0.0162\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0149\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0285 - val_loss: 0.0136\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0256 - val_loss: 0.0129\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0266 - val_loss: 0.0128\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0255 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0253 - val_loss: 0.0126\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0254 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0227 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0214 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0102\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0141 - val_loss: 0.0124\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0107\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0089\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0108 - val_loss: 0.0072\n",
      ">p=10: 7, Score=2.138137072324753\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 165ms/step - loss: 0.2133 - val_loss: 0.0522\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0997 - val_loss: 0.0151\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0473 - val_loss: 0.0532\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0399 - val_loss: 0.0306\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0321 - val_loss: 0.0158\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0350 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0318 - val_loss: 0.0162\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0303 - val_loss: 0.0155\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0132\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0263 - val_loss: 0.0130\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0253 - val_loss: 0.0130\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0246 - val_loss: 0.0135\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0244 - val_loss: 0.0138\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 0.0149\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0190 - val_loss: 0.0148\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0152\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0136\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0159\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 0.0139\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0138\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0159 - val_loss: 0.0176\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0167\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0131\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0203\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0201\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0179\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0155\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0132 - val_loss: 0.0163\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0170\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0161\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 0.0151\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0128\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0194\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0206\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0164\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0117 - val_loss: 0.0162\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0095 - val_loss: 0.0213\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0166\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0111 - val_loss: 0.0233\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0145\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0254\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0163\n",
      ">p=10: 8, Score=6.606797873973846\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 171ms/step - loss: 0.2279 - val_loss: 0.0589\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1248 - val_loss: 0.0153\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0522 - val_loss: 0.0551\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0458 - val_loss: 0.0561\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0334 - val_loss: 0.0237\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0352 - val_loss: 0.0183\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0356 - val_loss: 0.0219\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0220\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0313 - val_loss: 0.0177\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0270 - val_loss: 0.0157\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0268 - val_loss: 0.0145\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0287 - val_loss: 0.0130\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0256 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0227 - val_loss: 0.0124\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0246 - val_loss: 0.0131\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0240 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0221 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0193 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0142 - val_loss: 0.0107\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0123\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0113 - val_loss: 0.0086\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0084\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0080\n",
      ">p=10: 9, Score=2.970423176884651\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 157ms/step - loss: 0.2295 - val_loss: 0.0708\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1194 - val_loss: 0.0172\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0476 - val_loss: 0.0398\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0406 - val_loss: 0.0340\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0329 - val_loss: 0.0168\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0348 - val_loss: 0.0151\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0340 - val_loss: 0.0166\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0332 - val_loss: 0.0164\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0297 - val_loss: 0.0140\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0303 - val_loss: 0.0135\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0280 - val_loss: 0.0132\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0262 - val_loss: 0.0128\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0265 - val_loss: 0.0129\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0246 - val_loss: 0.0130\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0255 - val_loss: 0.0130\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0218 - val_loss: 0.0132\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0202 - val_loss: 0.0133\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0180 - val_loss: 0.0132\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0133\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0128\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0134\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0122\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0168\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0131\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0164\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0144\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0151\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0153\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0092 - val_loss: 0.0123\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0132\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0137\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      ">p=10: 10, Score=3.0399007722735405\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 199ms/step - loss: 0.2308 - val_loss: 0.0734\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1404 - val_loss: 0.0220\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0656 - val_loss: 0.0330\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0526 - val_loss: 0.0749\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0379 - val_loss: 0.0382\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0361 - val_loss: 0.0215\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0351 - val_loss: 0.0203\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0362 - val_loss: 0.0240\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0314 - val_loss: 0.0243\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0336 - val_loss: 0.0205\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0281 - val_loss: 0.0170\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0298 - val_loss: 0.0166\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0300 - val_loss: 0.0163\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0267 - val_loss: 0.0145\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0260 - val_loss: 0.0135\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0238 - val_loss: 0.0131\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0241 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0216 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0207 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0191 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0195 - val_loss: 0.0119\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0131\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0125\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0118\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0086\n",
      ">p=11: 1, Score=1.9533604383468628\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 221ms/step - loss: 0.2281 - val_loss: 0.0626\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1303 - val_loss: 0.0171\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0596 - val_loss: 0.0449\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0473 - val_loss: 0.0788\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0392 - val_loss: 0.0388\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0388 - val_loss: 0.0221\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0393 - val_loss: 0.0213\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0349 - val_loss: 0.0252\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0327 - val_loss: 0.0253\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0310 - val_loss: 0.0208\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0310 - val_loss: 0.0179\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0294 - val_loss: 0.0159\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0272 - val_loss: 0.0150\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0259 - val_loss: 0.0141\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0271 - val_loss: 0.0133\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0230 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0249 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0228 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 0.0125\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0197 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0175 - val_loss: 0.0120\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0161 - val_loss: 0.0119\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0150 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0125\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0141 - val_loss: 0.0124\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0132\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0140\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0133\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0111 - val_loss: 0.0151\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0156\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0112 - val_loss: 0.0124\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0140\n",
      ">p=11: 2, Score=5.102546140551567\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 223ms/step - loss: 0.2419 - val_loss: 0.0803\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1580 - val_loss: 0.0283\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0808 - val_loss: 0.0238\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0487 - val_loss: 0.0826\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0447 - val_loss: 0.0492\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0326 - val_loss: 0.0226\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0347 - val_loss: 0.0192\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0354 - val_loss: 0.0223\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0316 - val_loss: 0.0240\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0306 - val_loss: 0.0201\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0301 - val_loss: 0.0171\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0283 - val_loss: 0.0160\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0255 - val_loss: 0.0153\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0283 - val_loss: 0.0141\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0243 - val_loss: 0.0132\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0244 - val_loss: 0.0129\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0227 - val_loss: 0.0125\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0209 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0216 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0171 - val_loss: 0.0118\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0183 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0080 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      ">p=11: 3, Score=1.6917398199439049\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 185ms/step - loss: 0.2355 - val_loss: 0.0763\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.1381 - val_loss: 0.0232\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0641 - val_loss: 0.0298\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0479 - val_loss: 0.0656\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0410 - val_loss: 0.0320\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0367 - val_loss: 0.0171\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0375 - val_loss: 0.0165\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0336 - val_loss: 0.0198\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0306 - val_loss: 0.0215\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0327 - val_loss: 0.0182\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0274 - val_loss: 0.0152\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0291 - val_loss: 0.0141\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0269 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0262 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0249 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0263 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0233 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0203 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0177 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0165 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0099\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0099\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      ">p=11: 4, Score=2.350104972720146\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 180ms/step - loss: 0.2438 - val_loss: 0.0893\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.1542 - val_loss: 0.0329\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0733 - val_loss: 0.0196\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0461 - val_loss: 0.0601\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0439 - val_loss: 0.0358\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0333 - val_loss: 0.0176\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0356 - val_loss: 0.0158\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0337 - val_loss: 0.0184\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0314 - val_loss: 0.0197\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0289 - val_loss: 0.0167\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0284 - val_loss: 0.0148\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0300 - val_loss: 0.0142\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0292 - val_loss: 0.0135\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0251 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0259 - val_loss: 0.0128\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0258 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0226 - val_loss: 0.0132\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0206 - val_loss: 0.0148\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0148\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0188 - val_loss: 0.0147\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0180 - val_loss: 0.0163\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0167\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0193\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0133\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0155\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0162\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0140\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0153\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0152\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0119 - val_loss: 0.0159\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0143\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0164\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0203\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0126\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0119 - val_loss: 0.0170\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0172\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0155\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0183\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0086 - val_loss: 0.0146\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0165\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0202\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0237\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0092 - val_loss: 0.0186\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0210\n",
      ">p=11: 5, Score=9.020527452230453\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 185ms/step - loss: 0.2175 - val_loss: 0.0592\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.1203 - val_loss: 0.0152\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0563 - val_loss: 0.0546\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0474 - val_loss: 0.0727\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0362 - val_loss: 0.0330\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0328 - val_loss: 0.0213\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0329 - val_loss: 0.0226\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0341 - val_loss: 0.0261\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0302 - val_loss: 0.0228\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0290 - val_loss: 0.0181\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0293 - val_loss: 0.0172\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0277 - val_loss: 0.0163\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0261 - val_loss: 0.0138\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0256 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0232 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0245 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0221 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0194 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0220 - val_loss: 0.0129\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0141\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0180 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0169 - val_loss: 0.0162\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 0.0138\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0152\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0132\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0153\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0140\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0143 - val_loss: 0.0163\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0136\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0136\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0141\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0135 - val_loss: 0.0151\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0160\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0164\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0150\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0157\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0145\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0199\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      ">p=11: 6, Score=2.03249529004097\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 176ms/step - loss: 0.2396 - val_loss: 0.0690\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.1434 - val_loss: 0.0205\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0696 - val_loss: 0.0338\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0514 - val_loss: 0.0732\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0430 - val_loss: 0.0409\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0369 - val_loss: 0.0226\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0384 - val_loss: 0.0203\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0371 - val_loss: 0.0232\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0350 - val_loss: 0.0225\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0314 - val_loss: 0.0190\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0319 - val_loss: 0.0164\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0273 - val_loss: 0.0155\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0280 - val_loss: 0.0152\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0258 - val_loss: 0.0136\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0250 - val_loss: 0.0132\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0235 - val_loss: 0.0129\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0223 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0206 - val_loss: 0.0141\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0195 - val_loss: 0.0130\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0205 - val_loss: 0.0138\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 0.0142\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0159 - val_loss: 0.0143\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0177 - val_loss: 0.0137\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0154 - val_loss: 0.0141\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0130 - val_loss: 0.0136\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0162\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0142\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0126\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0148\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0170\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0145\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0128 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0174\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0114 - val_loss: 0.0187\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0132\n",
      ">p=11: 7, Score=2.634270302951336\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 191ms/step - loss: 0.2300 - val_loss: 0.0816\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.1488 - val_loss: 0.0303\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0704 - val_loss: 0.0206\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0484 - val_loss: 0.0622\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0429 - val_loss: 0.0354\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0335 - val_loss: 0.0178\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0341 - val_loss: 0.0162\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0337 - val_loss: 0.0198\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0305 - val_loss: 0.0214\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0285 - val_loss: 0.0178\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0304 - val_loss: 0.0148\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0272 - val_loss: 0.0138\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0255 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0255 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0242 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0223 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0215 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0108\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0108\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0106\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0106\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0095\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0103 - val_loss: 0.0083\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0078\n",
      ">p=11: 8, Score=1.5994461253285408\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 208ms/step - loss: 0.2293 - val_loss: 0.0655\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1344 - val_loss: 0.0170\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0599 - val_loss: 0.0452\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0517 - val_loss: 0.0788\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0374 - val_loss: 0.0374\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0324 - val_loss: 0.0213\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0334 - val_loss: 0.0202\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0329 - val_loss: 0.0239\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0303 - val_loss: 0.0253\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0309 - val_loss: 0.0202\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0282 - val_loss: 0.0169\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0293 - val_loss: 0.0158\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0256 - val_loss: 0.0150\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0275 - val_loss: 0.0138\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0255 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0231 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0223 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0208 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0209 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0179 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0167 - val_loss: 0.0111\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0123\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0108\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      ">p=11: 9, Score=3.6476071923971176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 210ms/step - loss: 0.2325 - val_loss: 0.0697\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1372 - val_loss: 0.0205\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0617 - val_loss: 0.0361\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0500 - val_loss: 0.0759\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0408 - val_loss: 0.0381\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0357 - val_loss: 0.0194\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0403 - val_loss: 0.0183\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0365 - val_loss: 0.0226\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0335 - val_loss: 0.0241\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0317 - val_loss: 0.0198\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0306 - val_loss: 0.0167\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0316 - val_loss: 0.0158\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0279 - val_loss: 0.0145\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0273 - val_loss: 0.0134\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0248 - val_loss: 0.0130\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0239 - val_loss: 0.0129\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0248 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0181 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0125\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0212 - val_loss: 0.0137\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0171 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0151\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0143\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0143\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0135\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0147 - val_loss: 0.0153\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0138\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0134\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0131\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0139 - val_loss: 0.0161\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0111 - val_loss: 0.0140\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      ">p=11: 10, Score=2.7634086087346077\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 5s 241ms/step - loss: 0.2359 - val_loss: 0.0792\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1515 - val_loss: 0.0292\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0773 - val_loss: 0.0178\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0461 - val_loss: 0.0667\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0446 - val_loss: 0.0676\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0348 - val_loss: 0.0342\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0322 - val_loss: 0.0210\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0349 - val_loss: 0.0195\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0328 - val_loss: 0.0226\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0311 - val_loss: 0.0242\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0290 - val_loss: 0.0215\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0295 - val_loss: 0.0177\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0286 - val_loss: 0.0150\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0255 - val_loss: 0.0143\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0252 - val_loss: 0.0140\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0236 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0239 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0223 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0215 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0193 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0216 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0189 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0173 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0198 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0136 - val_loss: 0.0105\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0124 - val_loss: 0.0101\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0098\n",
      ">p=12: 1, Score=2.448391169309616\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 5s 224ms/step - loss: 0.2455 - val_loss: 0.0796\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1668 - val_loss: 0.0349\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0960 - val_loss: 0.0152\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0494 - val_loss: 0.0576\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0479 - val_loss: 0.0925\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0421 - val_loss: 0.0525\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0367 - val_loss: 0.0264\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0342 - val_loss: 0.0207\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0355 - val_loss: 0.0226\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0320 - val_loss: 0.0265\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0330 - val_loss: 0.0261\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0288 - val_loss: 0.0227\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0300 - val_loss: 0.0194\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0275 - val_loss: 0.0172\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0277 - val_loss: 0.0160\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0262 - val_loss: 0.0147\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0260 - val_loss: 0.0138\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0236 - val_loss: 0.0135\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0246 - val_loss: 0.0134\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0250 - val_loss: 0.0129\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 0.0128\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0203 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0207 - val_loss: 0.0131\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0193 - val_loss: 0.0128\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0189 - val_loss: 0.0129\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0194 - val_loss: 0.0140\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0188 - val_loss: 0.0129\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0182 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0137\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0135\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0126\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0164 - val_loss: 0.0138\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0127\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0129\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0127\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0138\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      ">p=12: 2, Score=2.0751556381583214\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 227ms/step - loss: 0.2290 - val_loss: 0.0762\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1428 - val_loss: 0.0275\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0701 - val_loss: 0.0190\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0446 - val_loss: 0.0658\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0474 - val_loss: 0.0532\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0348 - val_loss: 0.0254\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0333 - val_loss: 0.0174\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0340 - val_loss: 0.0176\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0330 - val_loss: 0.0205\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0308 - val_loss: 0.0223\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0319 - val_loss: 0.0190\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0272 - val_loss: 0.0163\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0293 - val_loss: 0.0145\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0243 - val_loss: 0.0140\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0261 - val_loss: 0.0138\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0264 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0227 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0225 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0204 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0209 - val_loss: 0.0124\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0201 - val_loss: 0.0132\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0192 - val_loss: 0.0140\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0182 - val_loss: 0.0135\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0187 - val_loss: 0.0144\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0176 - val_loss: 0.0138\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0167 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0127\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0118\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0138 - val_loss: 0.0127\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0124\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0116\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0134 - val_loss: 0.0112\n",
      ">p=12: 3, Score=2.522263489663601\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 5s 219ms/step - loss: 0.2550 - val_loss: 0.0903\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.1790 - val_loss: 0.0438\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.1108 - val_loss: 0.0151\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0563 - val_loss: 0.0490\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0515 - val_loss: 0.0962\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0453 - val_loss: 0.0560\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0333 - val_loss: 0.0287\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0362 - val_loss: 0.0227\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0357 - val_loss: 0.0249\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0326 - val_loss: 0.0289\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0331 - val_loss: 0.0283\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0306 - val_loss: 0.0231\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0293 - val_loss: 0.0187\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0263 - val_loss: 0.0170\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0269 - val_loss: 0.0162\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0279 - val_loss: 0.0155\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0240 - val_loss: 0.0139\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0243 - val_loss: 0.0127\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0238 - val_loss: 0.0123\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0213 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0192 - val_loss: 0.0121\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0197 - val_loss: 0.0126\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0194 - val_loss: 0.0124\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0179 - val_loss: 0.0121\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0189 - val_loss: 0.0128\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0169 - val_loss: 0.0127\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0165 - val_loss: 0.0119\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0125\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0125\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0135 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      ">p=12: 4, Score=2.1394550800323486\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 249ms/step - loss: 0.2341 - val_loss: 0.0887\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1597 - val_loss: 0.0403\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0909 - val_loss: 0.0152\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0470 - val_loss: 0.0533\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0513 - val_loss: 0.0650\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0388 - val_loss: 0.0309\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0320 - val_loss: 0.0186\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0364 - val_loss: 0.0174\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0359 - val_loss: 0.0203\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0329 - val_loss: 0.0234\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0321 - val_loss: 0.0206\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0324 - val_loss: 0.0168\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0307 - val_loss: 0.0150\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0268 - val_loss: 0.0145\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0259 - val_loss: 0.0143\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0251 - val_loss: 0.0136\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0265 - val_loss: 0.0129\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0239 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0231 - val_loss: 0.0127\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0212 - val_loss: 0.0125\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0214 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 0.0132\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0209 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0186 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0129\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0165 - val_loss: 0.0120\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0155 - val_loss: 0.0134\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0103\n",
      ">p=12: 5, Score=2.765905484557152\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 222ms/step - loss: 0.2320 - val_loss: 0.0644\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.1407 - val_loss: 0.0205\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0694 - val_loss: 0.0281\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0427 - val_loss: 0.0885\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0489 - val_loss: 0.0728\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0376 - val_loss: 0.0341\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0349 - val_loss: 0.0222\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0372 - val_loss: 0.0223\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0367 - val_loss: 0.0259\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0322 - val_loss: 0.0277\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0298 - val_loss: 0.0259\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0296 - val_loss: 0.0229\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0308 - val_loss: 0.0196\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0285 - val_loss: 0.0172\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0269 - val_loss: 0.0161\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0249 - val_loss: 0.0147\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0246 - val_loss: 0.0136\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0266 - val_loss: 0.0132\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0229 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0213 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0214 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 0.0122\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0206 - val_loss: 0.0123\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0171 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0133\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0158 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0138\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0126\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0159 - val_loss: 0.0124\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0136\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      ">p=12: 6, Score=2.7308059856295586\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 5s 232ms/step - loss: 0.2239 - val_loss: 0.0702\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1390 - val_loss: 0.0257\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0678 - val_loss: 0.0201\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0482 - val_loss: 0.0660\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0490 - val_loss: 0.0574\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0335 - val_loss: 0.0294\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0345 - val_loss: 0.0199\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0347 - val_loss: 0.0185\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0345 - val_loss: 0.0211\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0324 - val_loss: 0.0239\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0331 - val_loss: 0.0225\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0316 - val_loss: 0.0187\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0300 - val_loss: 0.0158\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0284 - val_loss: 0.0152\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0301 - val_loss: 0.0153\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0266 - val_loss: 0.0149\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0269 - val_loss: 0.0136\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0273 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0250 - val_loss: 0.0126\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0236 - val_loss: 0.0124\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0223 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0220 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0200 - val_loss: 0.0122\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0186 - val_loss: 0.0134\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0165 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0136\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0173 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0113\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0119\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0139 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0136 - val_loss: 0.0113\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0133 - val_loss: 0.0110\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0130 - val_loss: 0.0128\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0115 - val_loss: 0.0132\n",
      ">p=12: 7, Score=4.538753256201744\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 352ms/step - loss: 0.2111 - val_loss: 0.0613\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1217 - val_loss: 0.0199\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0595 - val_loss: 0.0268\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0472 - val_loss: 0.0652\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0424 - val_loss: 0.0425\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0326 - val_loss: 0.0226\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0342 - val_loss: 0.0173\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0335 - val_loss: 0.0178\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0313 - val_loss: 0.0205\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0290 - val_loss: 0.0216\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0311 - val_loss: 0.0184\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0286 - val_loss: 0.0149\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0274 - val_loss: 0.0142\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0277 - val_loss: 0.0141\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0263 - val_loss: 0.0138\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0255 - val_loss: 0.0131\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0257 - val_loss: 0.0127\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0239 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0216 - val_loss: 0.0129\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0217 - val_loss: 0.0133\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0208 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0194 - val_loss: 0.0135\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0197 - val_loss: 0.0142\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0170 - val_loss: 0.0149\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0180 - val_loss: 0.0142\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0145\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0132\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0159\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0164\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0139\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0136\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0134\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0119 - val_loss: 0.0139\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0140\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0117\n",
      ">p=12: 8, Score=2.346636727452278\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 5s 230ms/step - loss: 0.2257 - val_loss: 0.0729\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1370 - val_loss: 0.0241\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0646 - val_loss: 0.0230\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0441 - val_loss: 0.0689\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0480 - val_loss: 0.0522\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0378 - val_loss: 0.0253\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0336 - val_loss: 0.0175\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0354 - val_loss: 0.0176\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0337 - val_loss: 0.0205\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0320 - val_loss: 0.0223\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0292 - val_loss: 0.0203\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0282 - val_loss: 0.0178\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0286 - val_loss: 0.0157\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0279 - val_loss: 0.0148\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0258 - val_loss: 0.0145\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0248 - val_loss: 0.0135\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0252 - val_loss: 0.0127\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0206 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0231 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0205 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0200 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0176 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0194 - val_loss: 0.0135\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0173 - val_loss: 0.0133\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0161 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0120\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0138\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0129 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0118\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      ">p=12: 9, Score=2.0975954830646515\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 5s 228ms/step - loss: 0.2441 - val_loss: 0.0902\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1628 - val_loss: 0.0406\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0892 - val_loss: 0.0142\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0456 - val_loss: 0.0428\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0449 - val_loss: 0.0588\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0382 - val_loss: 0.0326\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0346 - val_loss: 0.0185\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0344 - val_loss: 0.0160\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0351 - val_loss: 0.0175\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0309 - val_loss: 0.0199\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0319 - val_loss: 0.0191\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0285 - val_loss: 0.0161\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0290 - val_loss: 0.0140\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0258 - val_loss: 0.0131\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0273 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0243 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0211 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0223 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0194 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0222 - val_loss: 0.0128\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0201 - val_loss: 0.0127\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0176 - val_loss: 0.0130\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0172 - val_loss: 0.0135\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0167 - val_loss: 0.0127\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0150 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0154 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0126\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0141 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0137 - val_loss: 0.0140\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0126 - val_loss: 0.0130\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0147 - val_loss: 0.0115\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0118\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0124\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0126\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      ">p=12: 10, Score=2.3272134363651276\n",
      "[[2.529481053352356, 5.148728564381599, 4.757227003574371, 2.150413393974304, 11.434897780418396, 21.125386655330658, 12.574678659439087, 5.308747291564941, 10.938658565282822, 10.537935048341751], [2.413821965456009, 7.015466690063477, 0.9716580621898174, 9.157665818929672, 6.82673305273056, 3.803769499063492, 1.7137140035629272, 4.933109134435654, 2.6076767593622208, 0.995152723044157], [3.525311127305031, 5.642277374863625, 3.9245855063199997, 4.1545070707798, 3.891213983297348, 4.112539812922478, 5.110540613532066, 4.789769276976585, 7.642696797847748, 3.8978256285190582], [3.0441325157880783, 2.446366287767887, 2.247363142669201, 1.9286179915070534, 1.705697923898697, 2.1279575303196907, 2.338826283812523, 2.981008030474186, 3.0032899230718613, 3.597913682460785], [6.043743342161179, 5.097687989473343, 4.3740469962358475, 2.788768522441387, 5.854256451129913, 3.6121390759944916, 2.0955098792910576, 1.9322657957673073, 3.4546662122011185, 3.3850014209747314], [1.8402667716145515, 4.336967691779137, 4.0391214191913605, 2.363472990691662, 2.004420943558216, 6.683607399463654, 3.2584797590970993, 1.829002983868122, 4.328582063317299, 1.8393738195300102], [2.143971063196659, 3.2623816281557083, 4.8967815935611725, 3.718111291527748, 3.5210836678743362, 5.2708495408296585, 2.215207554399967, 4.249922558665276, 4.957892745733261, 4.4030386954545975], [4.477187618613243, 1.7817877233028412, 3.346036374568939, 6.140544638037682, 1.8307887017726898, 1.7741767689585686, 3.0195990577340126, 4.370783641934395, 4.355087131261826, 5.448578298091888], [1.8616300076246262, 1.8633583560585976, 4.855586215853691, 2.762399800121784, 5.603282153606415, 2.195138856768608, 2.461331896483898, 1.8504669889807701, 1.7473988234996796, 6.228341162204742], [1.7720134928822517, 3.6140192300081253, 4.183923825621605, 3.012540563941002, 7.6979681849479675, 2.7316292747855186, 2.138137072324753, 6.606797873973846, 2.970423176884651, 3.0399007722735405], [1.9533604383468628, 5.102546140551567, 1.6917398199439049, 2.350104972720146, 9.020527452230453, 2.03249529004097, 2.634270302951336, 1.5994461253285408, 3.6476071923971176, 2.7634086087346077], [2.448391169309616, 2.0751556381583214, 2.522263489663601, 2.1394550800323486, 2.765905484557152, 2.7308059856295586, 4.538753256201744, 2.346636727452278, 2.0975954830646515, 2.3272134363651276]] [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Param=1, Mean=8.651, Std=5.531\n",
      "Param=2, Mean=4.044, Std=2.692\n",
      "Param=3, Mean=4.669, Std=1.168\n",
      "Param=4, Mean=2.542, Std=0.562\n",
      "Param=5, Mean=3.864, Std=1.377\n",
      "Param=6, Mean=3.252, Std=1.520\n",
      "Param=7, Mean=3.864, Std=1.042\n",
      "Param=8, Mean=3.654, Std=1.481\n",
      "Param=9, Mean=3.143, Std=1.640\n",
      "Param=10, Mean=3.777, Std=1.821\n",
      "Param=11, Mean=3.280, Std=2.159\n",
      "Param=12, Mean=2.599, Std=0.686\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1+klEQVR4nO3de3RU5b3/8c9kkBAwBC+QiwYS5JJIuEi0IYFUOFAwCs0YYy2FgqC2qyf0SANWQ4tIsUy9oK2FA9qj0FMErKwQ2/QUD1KB+DNeSMw5pCUQOAnBkkSxJpMECJiZ3x82o2MmlwkzmT3J+7XWLJ29n73nmywy85lnP8+zTQ6HwyEAAAADC/J3AQAAAJ0hsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMPr5+8CvMFut+vMmTMKDQ2VyWTydzkAAKALHA6HGhoaFBUVpaCgjvtQekVgOXPmjKKjo/1dBgAA6IbTp0/r+uuv77BNrwgsoaGhkj7/gQcPHuznagAAQFfYbDZFR0c7P8c70isCS+tloMGDBxNYAAAIMF0ZzsGgWwAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHi9YuE4b2tpaVFBQYGqq6sVGRmp1NRUmc1mf5cFAECfRQ/LV+Tm5mrUqFGaMWOGvvOd72jGjBkaNWqUcnNz/V0aAAB9FoHlS3Jzc5WZmanx48ersLBQDQ0NKiws1Pjx45WZmUloAQDAT0wOh8Ph7yIul81mU1hYmOrr67t9L6GWlhaNGjVK48ePV15ensttru12uywWi0pLS1VeXs7lIQAAvMCTz296WP6poKBAlZWVWrVqlUtYkaSgoCDl5OSooqJCBQUFfqoQAIC+i8DyT9XV1ZKkhIQEt/tbt7e2AwAAPYfA8k+RkZGSpNLSUrf7W7e3tgMAAD2HwPJPqampiomJ0fr162W321322e12Wa1WxcbGKjU11U8VAgDQdxFY/slsNmvDhg3Kz8+XxWJxmSVksViUn5+vp59+mgG3AAD4AQvHfUlGRoZ2796tFStWKCUlxbk9NjZWu3fvVkZGhh+rAwCg72JasxusdAsAgO958vlND4sbZrNZ06dP93cZAADgnxjDAgAADI/AAgAADI/AAgAADI/AAgAADI/AAgAADI/AAgAADI/AAgAADI/AAgAADM+jwGK1WnXLLbcoNDRUw4YNk8Vi0bFjx1zaXLhwQVlZWbrmmmt05ZVX6q677lJtbW2H53U4HHr00UcVGRmpkJAQzZo1S+Xl5Z7/NAAAoFfyKLAcPHhQWVlZeuedd7Rv3z5dunRJs2fPVlNTk7PNj370I/3xj3/Uq6++qoMHD+rMmTOd3oPnySef1HPPPactW7bo3Xff1aBBgzRnzhxduHChez8VAADoVS7rXkIff/yxhg0bpoMHD+rrX/+66uvrNXToUO3YsUOZmZmSpLKyMsXHx6uwsFBTpkxpcw6Hw6GoqCitWLFCK1eulCTV19crPDxc27Zt07e//e1O6/D2vYQAAIDvefL5fVljWOrr6yVJV199tSSpqKhIly5d0qxZs5xt4uLiNHz4cBUWFro9R0VFhWpqalyOCQsLU1JSUrvHNDc3y2azuTwAAEDv1e3AYrfbtXz5ck2dOlUJCQmSpJqaGvXv319DhgxxaRseHq6amhq352ndHh4e3uVjrFarwsLCnI/o6Oju/hgAACAAdDuwZGVlqbS0VLt27fJmPV2Sk5Oj+vp65+P06dM9XgMAAOg53Qosy5YtU35+vt58801df/31zu0RERG6ePGi6urqXNrX1tYqIiLC7blat391JlFHxwQHB2vw4MEuDwAA0Ht5FFgcDoeWLVumPXv26C9/+YtiY2Nd9icmJuqKK67Q/v37nduOHTumqqoqJScnuz1nbGysIiIiXI6x2Wx699132z0GAAD0LR4FlqysLG3fvl07duxQaGioampqVFNTo/Pnz0v6fLDsfffdp+zsbL355psqKirSkiVLlJyc7DJDKC4uTnv27JEkmUwmLV++XI8//rj+8Ic/6MiRI1q0aJGioqJksVi895MCAICA1c+Txps3b5YkTZ8+3WX71q1bde+990qSnn32WQUFBemuu+5Sc3Oz5syZo3//9393aX/s2DHnDCNJ+vGPf6ympiZ973vfU11dnaZNm6a9e/dqwIAB3fiRAABAb3NZ67AYBeuwAAAQeHpsHRYAAICeQGABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACGR2ABAACG53FgOXTokObNm6eoqCiZTCbl5eW57DeZTG4fTz31VLvnfOyxx9q0j4uL8/iHAQAAvZPHgaWpqUkTJ07Upk2b3O6vrq52ebz00ksymUy66667OjzvuHHjXI576623PC0NAAD0Uv08PSAtLU1paWnt7o+IiHB5/tprr2nGjBkaOXJkx4X069fmWAAAAMnHY1hqa2v1pz/9Sffdd1+nbcvLyxUVFaWRI0dqwYIFqqqqardtc3OzbDabywMAAPRePg0sv/3tbxUaGqqMjIwO2yUlJWnbtm3au3evNm/erIqKCqWmpqqhocFte6vVqrCwMOcjOjraF+UDAACDMDkcDke3DzaZtGfPHlksFrf74+Li9I1vfEO//vWvPTpvXV2dRowYoWeeecZt70xzc7Oam5udz202m6Kjo1VfX6/Bgwd79FoAAMA/bDabwsLCuvT57fEYlq4qKCjQsWPH9Morr3h87JAhQzRmzBidOHHC7f7g4GAFBwdfbokAACBA+OyS0IsvvqjExERNnDjR42MbGxt18uRJRUZG+qAyAAAQaDwOLI2NjSopKVFJSYkkqaKiQiUlJS6DZG02m1599VXdf//9bs8xc+ZMbdy40fl85cqVOnjwoCorK/X222/rzjvvlNls1vz58z0tDwAA9EIeXxI6fPiwZsyY4XyenZ0tSVq8eLG2bdsmSdq1a5ccDke7gePkyZM6e/as8/mHH36o+fPn65NPPtHQoUM1bdo0vfPOOxo6dKin5QEAgF7osgbdGoUng3YAAIAxePL5zb2EAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4RFYAACA4XkcWA4dOqR58+YpKipKJpNJeXl5LvvvvfdemUwml8dtt93W6Xk3bdqkmJgYDRgwQElJSXrvvfc8LQ0AAPRSHgeWpqYmTZw4UZs2bWq3zW233abq6mrnY+fOnR2e85VXXlF2drbWrFmj4uJiTZw4UXPmzNFHH33kaXkAAKAX6ufpAWlpaUpLS+uwTXBwsCIiIrp8zmeeeUYPPPCAlixZIknasmWL/vSnP+mll17SI4884mmJAACgl/HJGJYDBw5o2LBhGjt2rH7wgx/ok08+abftxYsXVVRUpFmzZn1RVFCQZs2apcLCQl+UBwAAAozHPSydue2225SRkaHY2FidPHlSq1atUlpamgoLC2U2m9u0P3v2rFpaWhQeHu6yPTw8XGVlZW5fo7m5Wc3Nzc7nNpvNuz8EAAAwFK8Hlm9/+9vO/x8/frwmTJigG264QQcOHNDMmTO98hpWq1Vr1671yrkAAIDx+Xxa88iRI3XttdfqxIkTbvdfe+21MpvNqq2tddleW1vb7jiYnJwc1dfXOx+nT5/2et0AAMA4fB5YPvzwQ33yySeKjIx0u79///5KTEzU/v37ndvsdrv279+v5ORkt8cEBwdr8ODBLg8AANB7eRxYGhsbVVJSopKSEklSRUWFSkpKVFVVpcbGRj300EN65513VFlZqf379ys9PV2jRo3SnDlznOeYOXOmNm7c6HyenZ2t3/zmN/rtb3+ro0eP6gc/+IGampqcs4YAAEDf5vEYlsOHD2vGjBnO59nZ2ZKkxYsXa/Pmzfrf//1f/fa3v1VdXZ2ioqI0e/ZsrVu3TsHBwc5jTp48qbNnzzqf33PPPfr444/16KOPqqamRpMmTdLevXvbDMQFAAB9k8nhcDj8XcTlstlsCgsLU319PZeHAAAIEJ58fnMvIQAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgEFgAAYHgeB5ZDhw5p3rx5ioqKkslkUl5ennPfpUuX9PDDD2v8+PEaNGiQoqKitGjRIp05c6bDcz722GMymUwuj7i4OI9/GAAA0Dt5HFiampo0ceJEbdq0qc2+c+fOqbi4WKtXr1ZxcbFyc3N17NgxffOb3+z0vOPGjVN1dbXz8dZbb3laGgAA6KX6eXpAWlqa0tLS3O4LCwvTvn37XLZt3LhRX/va11RVVaXhw4e3X0i/foqIiPC0HK84d+6cysrKXLadP39elZWViomJUUhIiMu+uLg4DRw4sCdLBACgT/M4sHiqvr5eJpNJQ4YM6bBdeXm5oqKiNGDAACUnJ8tqtbYbcJqbm9Xc3Ox8brPZLqvGsrIyJSYmdrl9UVGRJk+efFmvCQAAus6ngeXChQt6+OGHNX/+fA0ePLjddklJSdq2bZvGjh2r6upqrV27VqmpqSotLVVoaGib9larVWvXrvVanXFxcSoqKnLZdvToUS1cuFDbt29XfHx8m/YAAKDnmBwOh6PbB5tM2rNnjywWS5t9ly5d0l133aUPP/xQBw4c6DCwfFVdXZ1GjBihZ555Rvfdd1+b/e56WKKjo1VfX+/R63SkuLhYiYmJ9KYAAOAjNptNYWFhXfr89kkPy6VLl/Stb31Lp06d0l/+8hePQ8SQIUM0ZswYnThxwu3+4OBgBQcHe6NUAAAQALy+DktrWCkvL9cbb7yha665xuNzNDY26uTJk4qMjPR2eQAAIAB5HFgaGxtVUlKikpISSVJFRYVKSkpUVVWlS5cuKTMzU4cPH9bLL7+slpYW1dTUqKamRhcvXnSeY+bMmdq4caPz+cqVK3Xw4EFVVlbq7bff1p133imz2az58+df/k8IAAACnseXhA4fPqwZM2Y4n2dnZ0uSFi9erMcee0x/+MMfJEmTJk1yOe7NN9/U9OnTJUknT57U2bNnnfs+/PBDzZ8/X5988omGDh2qadOm6Z133tHQoUM9LQ8AAPRCHgeW6dOnq6Nxul0Zw1tZWenyfNeuXZ6WAQAA+hDuJQQAAAyPwAIAAAyPwAIAAAyPwAIAAAyPwAIAAAyPwAIAAAyPwAIAAAyPwAIAAAyPwAIAAAyPwAIAAAyPwAIAAAyPwAIAAAzP45sf9gbl5eVqaGjosM3Ro0dd/tuR0NBQjR492iu1AQCAtvpcYCkvL9eYMWO63H7hwoVdanf8+HFCCwAAPtLnAktrz8r27dsVHx/fbrvz58+rsrJSMTExCgkJabfd0aNHtXDhwk57bAAAQPf1ucDSKj4+XpMnT+6wzdSpU3uoGgAA0BEG3QIAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMMjsAAAAMPzOLAcOnRI8+bNU1RUlEwmk/Ly8lz2OxwOPfroo4qMjFRISIhmzZql8vLyTs+7adMmxcTEaMCAAUpKStJ7773naWkAAKCX8jiwNDU1aeLEidq0aZPb/U8++aSee+45bdmyRe+++64GDRqkOXPm6MKFC+2e85VXXlF2drbWrFmj4uJiTZw4UXPmzNFHH33kaXkAAKAX8jiwpKWl6fHHH9edd97ZZp/D4dAvf/lL/fSnP1V6eromTJig//zP/9SZM2fa9MR82TPPPKMHHnhAS5Ys0Y033qgtW7Zo4MCBeumllzwtDwAA9EJeHcNSUVGhmpoazZo1y7ktLCxMSUlJKiwsdHvMxYsXVVRU5HJMUFCQZs2a1e4xzc3NstlsLg8AANB7eTWw1NTUSJLCw8NdtoeHhzv3fdXZs2fV0tLi0TFWq1VhYWHOR3R0tBeqBwAARhWQs4RycnJUX1/vfJw+fdrfJQEAAB/yamCJiIiQJNXW1rpsr62tde77qmuvvVZms9mjY4KDgzV48GCXBwAA6L28GlhiY2MVERGh/fv3O7fZbDa9++67Sk5OdntM//79lZiY6HKM3W7X/v372z0GAAD0Lf08PaCxsVEnTpxwPq+oqFBJSYmuvvpqDR8+XMuXL9fjjz+u0aNHKzY2VqtXr1ZUVJQsFovzmJkzZ+rOO+/UsmXLJEnZ2dlavHixbr75Zn3ta1/TL3/5SzU1NWnJkiWX/xMCAICA53FgOXz4sGbMmOF8np2dLUlavHixtm3bph//+MdqamrS9773PdXV1WnatGnau3evBgwY4Dzm5MmTOnv2rPP5Pffco48//liPPvqoampqNGnSJO3du7fNQFwAANA3mRwOh8PfRVwum82msLAw1dfXdzqepbi4WImJiSoqKtLkyZMv+7W9fT4AAPoKTz6/A3KWEAAA6FsILAAAwPAILAAAwPAILAAAwPA8niUEAAC8p6WlRQUFBaqurlZkZKRSU1NlNpv9XZbh0MMCAICf5ObmatSoUZoxY4a+853vaMaMGRo1apRyc3P9XZrh0MMSIM6dO6eysjKXbefPn1dlZaViYmIUEhLS5pi4uDgNHDiwp0oEAHggNzdXmZmZmjt3rnbu3KmEhASVlpZq/fr1yszM1O7du5WRkeHvMg2DwBIgysrKlJiY6NExrA0DAMbU0tKiFStWaO7cucrLy1NQ0OcXPKZMmaK8vDxZLBatXLlS6enpXB76JwJLgIiLi1NRUZHLtqNHj2rhwoXavn274uPj3R4DADCegoICVVZWaufOnc6w0iooKEg5OTlKSUlRQUGBpk+f7p8iDYbAEiAGDhzYbm9JfHw8PSkAEECqq6slSQkJCW73t25vbQcG3QIA0OMiIyMlSaWlpW73t25vbQcCCwAAPS41NVUxMTFav3697Ha7yz673S6r1arY2Filpqb6qULjIbAAANDDzGazNmzYoPz8fFksFhUWFqqhoUGFhYWyWCzKz8/X008/zYDbL2EMCwAAfpCRkaHdu3drxYoVSklJcW6PjY1lSrMbBBYAAPwkIyND6enprHTbBQQWAAD8yGw2M3W5CxjDAgAADI/AAgAADI/AAgAADI/AAgAADI/AAgAADI/AAgAADI/AAgAADI/AAgAADI/AAgAADI/AAgAADI+l+QEAvVZLSwv36ekl+lxgMX12QTdFBCmk7rh05vI7mELqjuumiCCZPrvghep6H94sAPhLbm6uVqxYocrKSue2mJgYbdiwgTshB6A+F1gGNFap+PtXSoe+Lx26/PPFSyr+/pU62lglKaWz5n0KbxYA/CU3N1eZmZmaO3eudu7cqYSEBJWWlmr9+vXKzMzU7t27eR8KMH0usFy4crgmP9+ol19+WfFxcZd9vqNlZVqwYIFevH24F6rrPXizAOAvLS0tWrFihebOnau8vDwFBX3emz5lyhTl5eXJYrFo5cqVSk9Pp8c3gHg9sMTExOjUqVNttv/rv/6rNm3a1Gb7tm3btGTJEpdtwcHBunDBN5dYHP0G6IMau84PGSNFTbrs852vseuDGrsc/QZcfnG9BG8WAPypoKBAlZWV2rlzp/P9p1VQUJBycnKUkpKigoICTZ8+3T9FwmNeDyzvv/++WlpanM9LS0v1jW98Q3fffXe7xwwePFjHjh1zPjeZTN4uCz2INwsA/lRdXS1JSkhIcLu/dXtrOwQGrweWoUOHujz/xS9+oRtuuEG33npru8eYTCZFRER4uxT4CW8WAPwpMjJS0udfmKdMmdJmf2lpqUs7BAafrsNy8eJFbd++XUuXLu2w16SxsVEjRoxQdHS00tPT9de//tWXZcHHvvxm4Q5vFgB8KTU1VTExMVq/fr3sdrvLPrvdLqvVqtjYWKWmpvqpQnSHTwNLXl6e6urqdO+997bbZuzYsXrppZf02muvafv27bLb7UpJSdGHH37Y7jHNzc2y2WwuDxgHbxYA/MlsNmvDhg3Kz8+XxWJRYWGhGhoaVFhYKIvFovz8fD399NOMoQswPg0sL774otLS0hQVFdVum+TkZC1atEiTJk3SrbfeqtzcXA0dOlTPP/98u8dYrVaFhYU5H9HR0b4oH93EmwUAf8vIyNDu3bt15MgRpaSkaPDgwUpJSVFpaSmzFAOUz6Y1nzp1Sm+88YZyc3M9Ou6KK67QTTfdpBMnTrTbJicnR9nZ2c7nNpuN0GIwrW8WK1asUErKF+vTxMbG8mYBoEdkZGQoPT2dxSt7CZ8Flq1bt2rYsGG64447PDqupaVFR44c0e23395um+DgYAUHB19uifAx3iwA+JvZbGY2Yi/hk8Bit9u1detWLV68WP36ub7EokWLdN1118lqtUqSfvazn2nKlCkaNWqU6urq9NRTT+nUqVO6//77fVEaehhvFgAAb/BJYHnjjTdUVVWlpUuXttlXVVXlsjbHp59+qgceeEA1NTW66qqrlJiYqLfffls33nijL0oDAAAByCeBZfbs2XI4HG73HThwwOX5s88+q2effdYXZQAAgF7Cp7OEAAAAvIHAAgAADI/AAgAADI/AAgAADM9n67AAAOBvLS0trAXVS9DDAgDolXJzczVq1CjNmDFD3/nOdzRjxgyNGjXK4xXYYQz0sADotnPnzqmsrMxl2/nz51VZWamYmBiFhIS47IuLi9PAgQN7skT0Ubm5ucrMzNTcuXO1c+dOJSQkqLS0VOvXr1dmZia3CAlABBYA3VZWVqbExMQuty8qKtLkyZN9WBHw+WWgFStWaO7cucrLy3MuVjplyhTl5eXJYrFo5cqVSk9P5/JQACGwAOi2uLg4FRUVuWw7evSoFi5cqO3btys+Pr5Ne8DXCgoKVFlZqZ07d7qsrC5JQUFBysnJUUpKigoKCrh1SAAhsADotoEDB7bbYxIfH09vCvyiurpakpSQkOB2f+v21nYIDAy6BQD0KpGRkZKk0tJSt/tbt7e2Q2AgsAAAepXU1FTFxMRo/fr1stvtLvvsdrusVqtiY2OVmprqpwrRHVwSMqjy8nI1NDR02Obo0aMu/+1MaGioRo8efdm1AYCRmc1mbdiwQZmZmbJYLMrJyXHOErJarcrPz9fu3bsZcBtgCCwGVF5erjFjxnS5/cKFC7vc9vjx44QWAL1eRkaGdu/erRUrViglJcW5PTY2linNAYrAYkCtPSvuZll8WUfrXXxV68yNznptAKA9gbbuTkZGhtLT01nptpcgsBhYV2ZZTJ06tYeqAeArngYByT9hIBDX3TGbzUxd7iUILADgZ54GAck/YYB1d+BPBBbAgALlGze8w9Mg0HpMT2PdHfgTgQUwoED5xg3vIAgAnSOwAAYUKN+4AaCnEFgAA+IbNwC4YqVbAABgeAQWAABgeAQWAABgeIxhgVcF2kqYAIDAQGCBVwXiSpgAAOMjsMCrWAkTAOALBBZ4FdNxAQC+wKBbAABgeAQWAABgeFwSAtCrMXMN6B28Hlgee+wxrV271mXb2LFj27xhfNmrr76q1atXq7KyUqNHj9YTTzyh22+/3dulAeiDmLkG9A4+6WEZN26c3njjjS9epF/7L/P2229r/vz5slqtmjt3rnbs2CGLxaLi4mIlJCT4ojwAfQgz14DewSeBpV+/foqIiOhS21/96le67bbb9NBDD0mS1q1bp3379mnjxo3asmWLL8oD0Icwcw1G4+llSolLlZKPAkt5ebmioqI0YMAAJScny2q1avjw4W7bFhYWKjs722XbnDlzlJeX1+75m5ub1dzc7Hxus9m8Ujc8U15eroaGhk7bHT161OW/HQkNDdXo0aMvuzYAMCpPL1NKXKqUfBBYkpKStG3bNo0dO1bV1dVau3atUlNTVVpaqtDQ0Dbta2pqFB4e7rItPDxcNTU17b6G1WptM04GPau8vFxjxozx6JiFCxd2qd3x48cJLQB6LU8vU7Ye09d5PbCkpaU5/3/ChAlKSkrSiBEj9Pvf/1733XefV14jJyfHpVfGZrMpOjraK+dG17T2rLT3x/VlnXV1tmr9g+1Kr01v05XeKk96qiR6qwCj4jJl9/h8WvOQIUM0ZswYnThxwu3+iIgI1dbWumyrra3tcAxMcHCwgoODu1XPuXPnJEnFxcUdtvPkQ7Yv6+of19SpU3ugmsDkaW9VV3uqJHqrAPQePg8sjY2NOnnypL773e+63Z+cnKz9+/dr+fLlzm379u1TcnKyT+ppHej0wAMPePW87i53AV3R1d6qroZoid4qb/ZW0VMFfK6lpUUFBQWqrq5WZGSkUlNTZTabe+z1vR5YVq5cqXnz5mnEiBE6c+aM1qxZI7PZrPnz50uSFi1apOuuu05Wq1WS9OCDD+rWW2/Vhg0bdMcdd2jXrl06fPiwXnjhBW+XJkmyWCySOh9x3dn1xC/jDQ3e0JXeKnqqOuar3ip6qtDX5ebmasWKFaqsrHRui4mJ0YYNG5SRkdEjNXg9sHz44YeaP3++PvnkEw0dOlTTpk3TO++8o6FDh0qSqqqqFBT0xR0BUlJStGPHDv30pz/VqlWrNHr0aOXl5flsDZZrr71W999/f5fbcz0RCBze7q3qyz1VQKvc3FxlZmZq7ty52rlzpxISElRaWqr169crMzNTu3fv7pHQ4vXAsmvXrg73HzhwoM22u+++W3fffbe3SwHQR9FbBXhHS0uLVqxYoblz5yovL8/Z4TBlyhTl5eXJYrFo5cqVSk9P9/nlIW5+CAAA3CooKFBlZaVWrVrlcnVEkoKCgpSTk6OKigoVFBT4vBZufggAPYxp7AgU1dXVktTuMI3W7a3tfInAAgA9iGnsCCSRkZGSpNLSUk2ZMqXN/tLSUpd2vkRgAYAeFCjT2Ln1BiQpNTVVMTExWr9+vcsYFkmy2+2yWq2KjY1Vamqqz2shsACAHxh5YDC33kArs9msDRs2KDMzUxaLRTk5Oc5ZQlarVfn5+dq9e3ePrMdCYAHQJXzj7ju49Qa+LCMjQ7t379aKFSuUkpLi3B4bG9tjU5olAguALuAbd98UiLfeOHfunHNF81YdharOFhHF5zIyMpSent67VrpF32D67IJuighSSN1x6Yx3ZseH1B3XTRFBMn12wSvng/fwjRuBoqysTImJiV1uX1RUxOKgXWQ2mzV9+nS/vT6BBd0yoLFKxd+/Ujr0femQd84ZL6n4+1fqaGOVpJTOmsMPAvEbN3q3r16qPH/+vLZv3+7SpqKiQqtXr9a6desUGxvrsu/8+fMuN8PlMqVxEVjQLReuHK7Jzzfq5ZdfVnxcnFfOebSsTAsWLNCLtw/3yvnQ93i7549eP2Pz9FLl6tWru9SOy5TGRGBBtzj6DdAHNXadHzJGiprklXOer7Hrgxq7HP0GeOV86Hu83fNHr5+xce+ovoXAgm45d+6cJLl0pbbHkzcL4HJ4u+fPF71+jP/yPiNPEYf3EFjQLa2j8B944AGvnzs0NNTr50Tf4O2eP1/0+jH+C+geAgu6xWKxSOralMDWbtauzDBhwBt6O8Z/Ad1DYEG3XHvttbr//vs9OqarM0yA3ozxX0D3eOcCKgAAgA/Rw4I+h5UwASDwEFjgVe7CQEf3lvFHGDDaSpjMGgGAzhFY4FUdhQF395bxx7LYcXFxKioqctnW0cDgOC8NjGwPs0YAoHMEFniVuzDQ2eWWnjZw4MB2Q5I/BgYzawTo3bpyp3NP7nIu9c0ZlQQWeFV7YYBFm9rHrBHv6eqChixmiJ7i6e0DunqXc6nv3UKAwAKg1/DVgoYsZoju8vbtA6S+ewsBAosBMQgT6J6uLmjIYoboadw+4PIRWAyIQZhA93i6oCGLGQKBg8BiQAzCBADAFYHFgBiECQCd8/blcy6dGxuBBb2et6cUMqYBMAZvXz7n0rmxEVjQq/lqSqE3pxN6eyquxHRc9A3evnzOpXNjI7CgV/P2lEJfTCf01VRciem46N28ffmcS+fGRmBBn2DkKYW+mIoreffSFVPtYUQsFNi3EFgAPwuEqbhMtYcRsVCgbxntzvZeDyxWq1W5ubkqKytTSEiIUlJS9MQTT2js2LHtHrNt2zYtWbLEZVtwcLAuXOCbF2AETLWHEbFQoPe4m5zQ+nvrqq/+fr39u/R6YDl48KCysrJ0yy236LPPPtOqVas0e/Zs/e1vf9OgQYPaPW7w4ME6duyY87nJZPJ2aQC6ian2MKJA6J0MBJ5OTmiPu3DjzQkKXg8se/fudXm+bds2DRs2TEVFRfr617/e7nEmk0kRERHeLgcAAHSgq5MTJP9OUPD5GJb6+npJ0tVXX91hu8bGRo0YMUJ2u12TJ0/W+vXrNW7cOLdtm5ub1dzc7Hxus9m8VzAAAF4SSAPWu9oD5a8JCj4NLHa7XcuXL9fUqVOVkJDQbruxY8fqpZde0oQJE1RfX6+nn35aKSkp+utf/6rrr7++TXur1aq1a9f6snQAAC4bA9a9x6eBJSsrS6WlpXrrrbc6bJecnKzk5GTn85SUFMXHx+v555/XunXr2rTPyclRdna287nNZlN0dLT3CkevwdLdAPwpEAasB0ovkM8Cy7Jly5Sfn69Dhw657SXpyBVXXKGbbrpJJ06ccLs/ODhYwcHB3igTvRxLdwOeC5QPsEAQCAPWA6UXyOuBxeFw6Ic//KH27NmjAwcOKDY21uNztLS06MiRI7r99tu9XR76GJbuBjwXKB9g8I5A6AWSfBBYsrKytGPHDr322msKDQ1VTU2NJCksLMw5onjRokW67rrrZLVaJUk/+9nPNGXKFI0aNUp1dXV66qmndOrUKY+mqwHusHQ34LlA+QCDdzRd/Px97f/9X6POD7F32LbLs4SqW7z+Xun1wLJ582ZJ0vTp0122b926Vffee68kqaqqSkFBX3Qzfvrpp3rggQdUU1Ojq666SomJiXr77bd14403ers8t9yt5tfR3Xt9vZofvIelu2G0v+9AuNllIFzGgPcEyv3MfHJJqDMHDhxwef7ss8/q2Wef9XYpXVZWVqbExES3+9wthFNUVMTiQwGCpbthtL/vQPlwQN/R3orBraH5yyoqKrR69WqtW7euzZCPr4Zrw690G4ji4uJUVFTksq2z+yUgMLB0N4z29x0IN7tE39LeisHFxcXtLs2/evXqNtt8HfYJLJIGDhzo9pfsr8Vx4D2BunS3p5cxJC5Vtsdof9+B+m8S3RMIlwDbY7SwT2AxoED+Bw7v8PQyhuTbbzdd/TcpMR4I+LJAvgRotLBPYDGgQP4HDu/w9JtN6zG+wr/JvoWA6j1cAvQeAosB8Q8cRvtm096/SaPdfj5QGe0SYCAHVKPNCuMSoPcQWAyIf+C+ZbQ3tEDQ3r/J7lzj7uu/S3eMdgkwUGaNuGO0WWHwHpOjK/OQDc5msyksLEz19fUaPHiwv8vpMcXFxUpMTOQPzkOtv7eu4vcLX3MXortyCbCnw18g/O14+rs0Sojuq+/nnnx+08OCPsdoI98Bo10CbE8g/O0Ewu/SaJcAAwU9LAGsryZyAAhknvZUSb23p5ceFgAADMposwADBYEFAIAeFAiXrYwoqPMmAAAA/kVgAQAAhkdgAQAAhkdgAQAAhkdgAQAAhkdgAQAAhse05gDByogAgL6MwBIgjHZzNAAAehKBJUCwMiIAoC/jXkIAAMAvPPn8ZtAtAAAwPAILAAAwPAILAAAwPAILAAAwPAILAAAwPAILAAAwPAILAAAwPAILAAAwPAILAAAwPJ8Flk2bNikmJkYDBgxQUlKS3nvvvQ7bv/rqq4qLi9OAAQM0fvx4/dd//ZevSgMAAAHGJ4HllVdeUXZ2ttasWaPi4mJNnDhRc+bM0UcffeS2/dtvv6358+frvvvu0wcffCCLxSKLxaLS0lJflAcAAAKMT+4llJSUpFtuuUUbN26UJNntdkVHR+uHP/yhHnnkkTbt77nnHjU1NSk/P9+5bcqUKZo0aZK2bNnS6etxLyEAAAKPX+8ldPHiRRUVFWnWrFlfvEhQkGbNmqXCwkK3xxQWFrq0l6Q5c+a02x4AAPQt/bx9wrNnz6qlpUXh4eEu28PDw1VWVub2mJqaGrfta2pq3LZvbm5Wc3Oz83l9fb2kz5MaAAAIDK2f21252OP1wNITrFar1q5d22Z7dHS0H6oBAACXo6GhQWFhYR228Xpgufbaa2U2m1VbW+uyvba2VhEREW6PiYiI8Kh9Tk6OsrOznc/tdrv+8Y9/6JprrpHJZLrMn+BzNptN0dHROn36tGHHxQRCjVJg1EmN3hMIdVKj9wRCndToPd6u0+FwqKGhQVFRUZ229Xpg6d+/vxITE7V//35ZLBZJnweK/fv3a9myZW6PSU5O1v79+7V8+XLntn379ik5Odlt++DgYAUHB7tsGzJkiDfKb2Pw4MGG/scjBUaNUmDUSY3eEwh1UqP3BEKd1Og93qyzs56VVj65JJSdna3Fixfr5ptv1te+9jX98pe/VFNTk5YsWSJJWrRoka677jpZrVZJ0oMPPqhbb71VGzZs0B133KFdu3bp8OHDeuGFF3xRHgAACDA+CSz33HOPPv74Yz366KOqqanRpEmTtHfvXufA2qqqKgUFfTFBKSUlRTt27NBPf/pTrVq1SqNHj1ZeXp4SEhJ8UR4AAAgwPht0u2zZsnYvAR04cKDNtrvvvlt33323r8rxWHBwsNasWdPm0pORBEKNUmDUSY3eEwh1UqP3BEKd1Og9/qzTJwvHAQAAeBM3PwQAAIZHYAEAAIZHYAEAAIZHYAEAAIZHYPmKQ4cOad68eYqKipLJZFJeXp6/S2rDarXqlltuUWhoqIYNGyaLxaJjx475uywXmzdv1oQJE5yLCyUnJ+vPf/6zv8vq0C9+8QuZTCaXBQyN4LHHHpPJZHJ5xMXF+busNv7+979r4cKFuuaaaxQSEqLx48fr8OHD/i7LRUxMTJvfpclkUlZWlr9Lc2ppadHq1asVGxurkJAQ3XDDDVq3bl2X7rXSkxoaGrR8+XKNGDFCISEhSklJ0fvvv+/Xmjp7/3Y4HHr00UcVGRmpkJAQzZo1S+Xl5YaqMTc3V7Nnz3au3F5SUtKj9XWlzkuXLunhhx/W+PHjNWjQIEVFRWnRokU6c+aMT2sisHxFU1OTJk6cqE2bNvm7lHYdPHhQWVlZeuedd7Rv3z5dunRJs2fPVlNTk79Lc7r++uv1i1/8QkVFRTp8+LD+5V/+Renp6frrX//q79Lcev/99/X8889rwoQJ/i7FrXHjxqm6utr5eOutt/xdkotPP/1UU6dO1RVXXKE///nP+tvf/qYNGzboqquu8ndpLt5//32X3+O+ffskyVBLKjzxxBPavHmzNm7cqKNHj+qJJ57Qk08+qV//+tf+Ls3F/fffr3379ul3v/udjhw5otmzZ2vWrFn6+9//7reaOnv/fvLJJ/Xcc89py5YtevfddzVo0CDNmTNHFy5cMEyNTU1NmjZtmp544okeq6m9Otqr89y5cyouLtbq1atVXFys3NxcHTt2TN/85jd9W5QD7ZLk2LNnj7/L6NRHH33kkOQ4ePCgv0vp0FVXXeX4j//4D3+X0UZDQ4Nj9OjRjn379jluvfVWx4MPPujvklysWbPGMXHiRH+X0aGHH37YMW3aNH+X4bEHH3zQccMNNzjsdru/S3G64447HEuXLnXZlpGR4ViwYIGfKmrr3LlzDrPZ7MjPz3fZPnnyZMdPfvITP1Xl6qvv33a73REREeF46qmnnNvq6uocwcHBjp07d/qhwo4/YyoqKhySHB988EGP1uROVz4L33vvPYckx6lTp3xWBz0svUB9fb0k6eqrr/ZzJe61tLRo165dampqavf+UP6UlZWlO+64Q7NmzfJ3Ke0qLy9XVFSURo4cqQULFqiqqsrfJbn4wx/+oJtvvll33323hg0bpptuukm/+c1v/F1Why5evKjt27dr6dKlXrtpqjekpKRo//79On78uCTpf/7nf/TWW28pLS3Nz5V94bPPPlNLS4sGDBjgsj0kJMRwvX+tKioqVFNT4/J3HhYWpqSkJBUWFvqxst6hvr5eJpPJZ/f1k3y40i16ht1u1/LlyzV16lTD3crgyJEjSk5O1oULF3TllVdqz549uvHGG/1dlotdu3apuLjY79feO5KUlKRt27Zp7Nixqq6u1tq1a5WamqrS0lKFhob6uzxJ0v/93/9p8+bNys7O1qpVq/T+++/r3/7t39S/f38tXrzY3+W5lZeXp7q6Ot17773+LsXFI488IpvNpri4OJnNZrW0tOjnP/+5FixY4O/SnEJDQ5WcnKx169YpPj5e4eHh2rlzpwoLCzVq1Ch/l+dWTU2NJDlvEdMqPDzcuQ/dc+HCBT388MOaP3++T2/cSGAJcFlZWSotLTXkt5qxY8eqpKRE9fX12r17txYvXqyDBw8aJrScPn1aDz74oPbt29fmm6KRfPmb9YQJE5SUlKQRI0bo97//ve677z4/VvYFu92um2++WevXr5ck3XTTTSotLdWWLVsMG1hefPFFpaWldem29j3p97//vV5++WXt2LFD48aNU0lJiZYvX66oqChD/S5/97vfaenSpbruuutkNps1efJkzZ8/X0VFRf4uDT3o0qVL+ta3viWHw6HNmzf79LW4JBTAli1bpvz8fL355pu6/vrr/V1OG/3799eoUaOUmJgoq9WqiRMn6le/+pW/y3IqKirSRx99pMmTJ6tfv37q16+fDh48qOeee079+vVTS0uLv0t0a8iQIRozZoxOnDjh71KcIiMj2wTR+Ph4w126anXq1Cm98cYbuv/++/1dShsPPfSQHnnkEX3729/W+PHj9d3vflc/+tGPnHe3N4obbrhBBw8eVGNjo06fPq333ntPly5d0siRI/1dmlsRERGSpNraWpfttbW1zn3wTGtYOXXqlPbt2+fT3hWJwBKQHA6Hli1bpj179ugvf/mLYmNj/V1Sl9jtdjU3N/u7DKeZM2fqyJEjKikpcT5uvvlmLViwQCUlJTKbzf4u0a3GxkadPHlSkZGR/i7FaerUqW2m1h8/flwjRozwU0Ud27p1q4YNG6Y77rjD36W0ce7cOZe72UuS2WyW3W73U0UdGzRokCIjI/Xpp5/q9ddfV3p6ur9Lcis2NlYRERHav3+/c5vNZtO7775ryLF1RtcaVsrLy/XGG2/ommuu8flrcknoKxobG12+uVZUVKikpERXX321hg8f7sfKvpCVlaUdO3botddeU2hoqPP6a1hYmEJCQvxc3edycnKUlpam4cOHq6GhQTt27NCBAwf0+uuv+7s0p9DQ0DbjfgYNGqRrrrnGUOOBVq5cqXnz5mnEiBE6c+aM1qxZI7PZrPnz5/u7NKcf/ehHSklJ0fr16/Wtb31L7733nl544QW98MIL/i6tDbvdrq1bt2rx4sXq1894b4Hz5s3Tz3/+cw0fPlzjxo3TBx98oGeeeUZLly71d2kuXn/9dTkcDo0dO1YnTpzQQw89pLi4OC1ZssRvNXX2/r18+XI9/vjjGj16tGJjY7V69WpFRUXJYrEYpsZ//OMfqqqqcq5p0vpFICIiokd7gjqqMzIyUpmZmSouLlZ+fr5aWlqcn0NXX321+vfv75uifDb/KEC9+eabDkltHosXL/Z3aU7u6pPk2Lp1q79Lc1q6dKljxIgRjv79+zuGDh3qmDlzpuO///u//V1Wp4w4rfmee+5xREZGOvr37++47rrrHPfcc4/jxIkT/i6rjT/+8Y+OhIQER3BwsCMuLs7xwgsv+Lskt15//XWHJMexY8f8XYpbNpvN8eCDDzqGDx/uGDBggGPkyJGOn/zkJ47m5mZ/l+bilVdecYwcOdLRv39/R0REhCMrK8tRV1fn15o6e/+22+2O1atXO8LDwx3BwcGOmTNn9vi/g85q3Lp1q9v9a9asMUydrVOu3T3efPNNn9VkcjgMtnwiAADAVzCGBQAAGB6BBQAAGB6BBQAAGB6BBQAAGB6BBQAAGB6BBQAAGB6BBQAAGB6BBQAAGB6BBQAAGB6BBQAAGB6BBQAAGB6BBQAAGN7/B3C69Wr0fiCKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = 80, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = 80))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=batch_size, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=batch_size)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # resumindo a média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = np.mean(scores[i]), np.std(scores[i])\n",
    "        print(f'Param={params[i]}, Mean={m:.3f}, Std={s:.3f}')\n",
    "    # boxplot das pontuações\n",
    "    plt.boxplot(scores, labels=params)\n",
    "    plt.savefig('../../src/static/images/despesas/figura[1].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repetindo o experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            score = score * 100.0\n",
    "            scores.append(score)\n",
    "            print(f'>p={p}: {r+1}, Score={score}')\n",
    "        all_scores.append(scores)\n",
    "    # resumindo os resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = np.arange(1, 13)\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste no modelo com diluição - dropout - 0.05, 0.1, 0.2, 0.3, para verficação do mais adequado para a aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 91ms/step - loss: 0.1913 - val_loss: 0.0195\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0348 - val_loss: 0.0220\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0352 - val_loss: 0.0199\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0316 - val_loss: 0.0186\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0152\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0142\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0276 - val_loss: 0.0131\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0270 - val_loss: 0.0129\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0128\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0128\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0104\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0161 - val_loss: 0.0130\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0209 - val_loss: 0.0177\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0101\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0126\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0146\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0146\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0268 - val_loss: 0.0184\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0271 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0125\n",
      ">p=0.05: 1, Score=0.053069107234478\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 85ms/step - loss: 0.1724 - val_loss: 0.0158\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0524 - val_loss: 0.0576\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0357 - val_loss: 0.0200\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0195\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0314 - val_loss: 0.0166\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0294 - val_loss: 0.0141\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0266 - val_loss: 0.0132\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0253 - val_loss: 0.0134\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0140\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.0140\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0140\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0130\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0139\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0136\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0137\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0136\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0139\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0139\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0141\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0136\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0125\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0180\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0181\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0160\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0126\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0131\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0172\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0147\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0187\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0142\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0147\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0142\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0199\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0138\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      ">p=0.05: 2, Score=0.04370881989598274\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 131ms/step - loss: 0.1710 - val_loss: 0.0165\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0505 - val_loss: 0.0576\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0334 - val_loss: 0.0202\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0368 - val_loss: 0.0190\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0163\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0139\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0127\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0247 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0125\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0122\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0091\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0161\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0151\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0096\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0073\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0159\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0089\n",
      ">p=0.05: 3, Score=0.029154280200600624\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 90ms/step - loss: 0.1820 - val_loss: 0.0177\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0565 - val_loss: 0.0633\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0217\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0361 - val_loss: 0.0230\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0307 - val_loss: 0.0190\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0306 - val_loss: 0.0153\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0277 - val_loss: 0.0146\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0257 - val_loss: 0.0129\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0245 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0222 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0218 - val_loss: 0.0121\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0110\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0109\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0101\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0095\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0093\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0156 - val_loss: 0.0092\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0091\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0203 - val_loss: 0.0127\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0137 - val_loss: 0.0089\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0134 - val_loss: 0.0089\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0084\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0087\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0077\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0072\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0145 - val_loss: 0.0097\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0165 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0078\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0073\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0091\n",
      ">p=0.05: 4, Score=0.01891261525452137\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 112ms/step - loss: 0.1848 - val_loss: 0.0235\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0525 - val_loss: 0.0489\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0165\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0339 - val_loss: 0.0169\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0287 - val_loss: 0.0158\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0269 - val_loss: 0.0136\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0261 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0241 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0241 - val_loss: 0.0124\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.0125\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0119\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0111\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0135 - val_loss: 0.0110\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0158 - val_loss: 0.0103\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0150 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0105\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0126 - val_loss: 0.0098\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0184 - val_loss: 0.0111\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0152 - val_loss: 0.0109\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0164 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0094\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0141 - val_loss: 0.0120\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0098\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0090\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0083\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0083\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0136\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0081\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0076\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0125\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0083\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      ">p=0.05: 5, Score=0.022899584844708443\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 136ms/step - loss: 0.1742 - val_loss: 0.0177\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0534 - val_loss: 0.0549\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0320 - val_loss: 0.0194\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0346 - val_loss: 0.0198\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0175\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0287 - val_loss: 0.0140\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0265 - val_loss: 0.0130\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0243 - val_loss: 0.0122\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0220 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0229 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0180 - val_loss: 0.0112\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0106\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0103\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0103\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0099\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0094\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0091\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0207 - val_loss: 0.0122\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0090\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0087\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0089\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0126\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0191 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0078\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0079\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0089\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0127\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0074\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0283 - val_loss: 0.0064\n",
      ">p=0.05: 6, Score=0.01458222046494484\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 91ms/step - loss: 0.1754 - val_loss: 0.0185\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0482 - val_loss: 0.0458\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0335 - val_loss: 0.0167\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0320 - val_loss: 0.0176\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0296 - val_loss: 0.0151\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0139\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0223 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0119\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0170 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0199 - val_loss: 0.0099\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0097\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0222 - val_loss: 0.0194\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0113\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0135\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0135\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0144\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0140\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0290 - val_loss: 0.0208\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0151\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0083\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0161\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0128\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0152\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0145\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0151\n",
      ">p=0.05: 7, Score=0.05917920917272568\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 99ms/step - loss: 0.1803 - val_loss: 0.0183\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0518 - val_loss: 0.0477\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0181\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0307 - val_loss: 0.0184\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0161\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0274 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0257 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0125\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0126\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0120\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0129\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0099\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0092\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0138\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0090\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0084\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0140\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0084\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0084\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0139\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0092\n",
      ">p=0.05: 8, Score=0.022707998752593994\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 89ms/step - loss: 0.1825 - val_loss: 0.0166\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0566 - val_loss: 0.0647\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0348 - val_loss: 0.0240\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0354 - val_loss: 0.0230\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0323 - val_loss: 0.0190\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0309 - val_loss: 0.0151\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0281 - val_loss: 0.0136\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0255 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0120\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0107\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0109\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0108\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0106\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0106\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0128\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0128\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0097\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0090\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0143\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0084\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0084\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0108\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0104\n",
      ">p=0.05: 9, Score=0.02039160393178463\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 92ms/step - loss: 0.1811 - val_loss: 0.0179\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0533 - val_loss: 0.0625\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0327 - val_loss: 0.0211\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0322 - val_loss: 0.0210\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0296 - val_loss: 0.0183\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0286 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0281 - val_loss: 0.0135\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0251 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0176 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0113\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0112\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0091\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0096\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0090\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0086\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0092\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0084\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0088\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0078\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0083\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0074\n",
      ">p=0.05: 10, Score=0.01430086325854063\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 90ms/step - loss: 0.1718 - val_loss: 0.0163\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0521 - val_loss: 0.0521\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0341 - val_loss: 0.0199\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0378 - val_loss: 0.0197\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0304 - val_loss: 0.0173\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0300 - val_loss: 0.0147\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0233 - val_loss: 0.0124\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0100\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0103\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0137\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0097\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0079\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0108\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0091\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0253 - val_loss: 0.0092\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0136\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0118\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0109\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0130\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0129\n",
      ">p=0.1: 1, Score=0.044327009469270706\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 131ms/step - loss: 0.1880 - val_loss: 0.0209\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0536 - val_loss: 0.0558\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0352 - val_loss: 0.0197\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0347 - val_loss: 0.0184\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0314 - val_loss: 0.0165\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0285 - val_loss: 0.0137\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0268 - val_loss: 0.0134\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0278 - val_loss: 0.0132\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0242 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0247 - val_loss: 0.0137\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0128\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0125\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0132\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0131\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0132\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0130\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0134\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0138 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0144\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0161\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0132\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0138\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0139\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0141\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 0.0125\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0211 - val_loss: 0.0083\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0154\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0212 - val_loss: 0.0260\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0083\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0164\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0142\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0123\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0166\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0152\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0086\n",
      ">p=0.1: 2, Score=0.02651285007596016\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 130ms/step - loss: 0.1823 - val_loss: 0.0192\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0552 - val_loss: 0.0633\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0331 - val_loss: 0.0221\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0365 - val_loss: 0.0222\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.0192\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0311 - val_loss: 0.0157\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0305 - val_loss: 0.0142\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0267 - val_loss: 0.0134\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0259 - val_loss: 0.0130\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0248 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0229 - val_loss: 0.0129\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0236 - val_loss: 0.0137\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0130\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0198 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0187 - val_loss: 0.0123\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0175 - val_loss: 0.0125\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0106\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0144\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0101\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0102\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0092\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0085\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0081\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0096\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0083\n",
      ">p=0.1: 3, Score=0.014993914403021336\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 92ms/step - loss: 0.1826 - val_loss: 0.0190\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0502 - val_loss: 0.0586\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0364 - val_loss: 0.0177\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0332 - val_loss: 0.0190\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0308 - val_loss: 0.0179\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0282 - val_loss: 0.0162\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0133\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0261 - val_loss: 0.0132\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0193 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0221 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0125\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0104\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0134\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0110\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0077\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0240 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0284 - val_loss: 0.0134\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0080\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0139\n",
      ">p=0.1: 4, Score=0.06013624370098114\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 91ms/step - loss: 0.1809 - val_loss: 0.0183\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0557 - val_loss: 0.0652\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0355 - val_loss: 0.0232\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0205\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0349 - val_loss: 0.0191\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0315 - val_loss: 0.0148\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0293 - val_loss: 0.0142\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0276 - val_loss: 0.0130\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0273 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 0.0132\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0259 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0231 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0184 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0178 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0104\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0191 - val_loss: 0.0137\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0187 - val_loss: 0.0101\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0121\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0141\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0154 - val_loss: 0.0113\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0138\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0166 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0093\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0170 - val_loss: 0.0145\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0090\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0124\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0130\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0149\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0076\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0081\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0114\n",
      ">p=0.1: 5, Score=0.045856576412916183\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 88ms/step - loss: 0.1844 - val_loss: 0.0205\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0561 - val_loss: 0.0583\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0215\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0335 - val_loss: 0.0206\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0313 - val_loss: 0.0194\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0275 - val_loss: 0.0160\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0151\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0287 - val_loss: 0.0133\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.0124\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0108\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0108\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0105\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0104\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0109\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0085\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0139 - val_loss: 0.0095\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0084\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0185 - val_loss: 0.0138\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0086\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0129\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0078\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      ">p=0.1: 6, Score=0.02107188291847706\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 88ms/step - loss: 0.1879 - val_loss: 0.0218\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0558 - val_loss: 0.0526\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0195\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0343 - val_loss: 0.0188\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0315 - val_loss: 0.0162\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0290 - val_loss: 0.0136\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0290 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0126\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0247 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0214 - val_loss: 0.0129\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0096\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0099\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0089\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0131\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0085\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0098\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0124\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0121\n",
      ">p=0.1: 7, Score=0.035709962248802185\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 137ms/step - loss: 0.1901 - val_loss: 0.0188\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0574 - val_loss: 0.0645\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0365 - val_loss: 0.0217\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0395 - val_loss: 0.0211\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0337 - val_loss: 0.0205\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0308 - val_loss: 0.0157\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0282 - val_loss: 0.0145\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0277 - val_loss: 0.0131\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0123\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0232 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0240 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0232 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0235 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0207 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0098\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0231 - val_loss: 0.0182\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0096\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0089\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0148\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0089\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0084\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      ">p=0.1: 8, Score=0.03753787279129028\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 105ms/step - loss: 0.1660 - val_loss: 0.0149\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0489 - val_loss: 0.0571\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0194\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0340 - val_loss: 0.0222\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0320 - val_loss: 0.0183\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0158\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0281 - val_loss: 0.0149\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0274 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0257 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0247 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0119\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0109\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0144 - val_loss: 0.0108\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0171 - val_loss: 0.0102\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0160 - val_loss: 0.0100\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0164 - val_loss: 0.0101\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0221 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0174 - val_loss: 0.0111\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0132 - val_loss: 0.0093\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0146 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0127 - val_loss: 0.0101\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0109\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0142 - val_loss: 0.0088\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0127 - val_loss: 0.0099\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0107 - val_loss: 0.0077\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0078\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0112 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0083\n",
      ">p=0.1: 9, Score=0.023952197283506393\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 9s 108ms/step - loss: 0.1942 - val_loss: 0.0240\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0583 - val_loss: 0.0586\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0373 - val_loss: 0.0211\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0382 - val_loss: 0.0203\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0342 - val_loss: 0.0191\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.0159\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0283 - val_loss: 0.0147\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0261 - val_loss: 0.0141\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0253 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0252 - val_loss: 0.0123\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0232 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0202 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0111\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0126\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0107\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 0.0109\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0142\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0104\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0103\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0098\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0184 - val_loss: 0.0133\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0126\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0092\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0082\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0139\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      ">p=0.1: 10, Score=0.02384311705827713\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 97ms/step - loss: 0.1781 - val_loss: 0.0192\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0536 - val_loss: 0.0485\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0396 - val_loss: 0.0189\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0386 - val_loss: 0.0172\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0331 - val_loss: 0.0164\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0350 - val_loss: 0.0142\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0298 - val_loss: 0.0147\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0289 - val_loss: 0.0132\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0265 - val_loss: 0.0123\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0268 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0217 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0135\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0139\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0124\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0108\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0133\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0107\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0139\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0166\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0134\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0131\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0139\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0130\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0152\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0146\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0140\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0150\n",
      ">p=0.2: 1, Score=0.04527435824275017\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 125ms/step - loss: 0.1806 - val_loss: 0.0217\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0571 - val_loss: 0.0465\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0321 - val_loss: 0.0182\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0348 - val_loss: 0.0176\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0312 - val_loss: 0.0171\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0301 - val_loss: 0.0157\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0294 - val_loss: 0.0132\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0276 - val_loss: 0.0122\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0259 - val_loss: 0.0123\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0221 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0243 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0220 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0215 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0106\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 0.0137\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0172 - val_loss: 0.0147\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0147\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0187 - val_loss: 0.0114\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0097\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0091\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0097\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0088\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0158\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0130\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0086\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0172\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0090\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0096\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0080\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0136\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0076\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      ">p=0.2: 2, Score=0.03966522216796875\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 86ms/step - loss: 0.1720 - val_loss: 0.0185\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0531 - val_loss: 0.0559\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0358 - val_loss: 0.0189\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0403 - val_loss: 0.0193\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0333 - val_loss: 0.0191\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0349 - val_loss: 0.0144\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0298 - val_loss: 0.0133\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0267 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0312 - val_loss: 0.0125\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0267 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0259 - val_loss: 0.0131\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0222 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0112\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0127\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0110\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0146 - val_loss: 0.0104\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0101\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0104\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0102\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0099\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0110\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0123\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0094\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0096\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0121\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0091\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0091\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0112\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0107\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      ">p=0.2: 3, Score=0.08920320123434067\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 114ms/step - loss: 0.1871 - val_loss: 0.0227\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0584 - val_loss: 0.0584\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0368 - val_loss: 0.0231\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0333 - val_loss: 0.0198\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0342 - val_loss: 0.0219\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0301 - val_loss: 0.0161\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0301 - val_loss: 0.0135\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0288 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0124\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 0.0126\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0226 - val_loss: 0.0130\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0229 - val_loss: 0.0162\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0198 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0203 - val_loss: 0.0129\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0107\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0106\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0107\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0187 - val_loss: 0.0108\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0157\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0096\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0108\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0166 - val_loss: 0.0131\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0090\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0180\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0124\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0153\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0128\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0134\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0182\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      ">p=0.2: 4, Score=0.07370650768280029\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 88ms/step - loss: 0.1810 - val_loss: 0.0179\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0575 - val_loss: 0.0595\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0369 - val_loss: 0.0233\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0354 - val_loss: 0.0207\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0340 - val_loss: 0.0202\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0155\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0137\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0129\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0257 - val_loss: 0.0129\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0161\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0142\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0132\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0169\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0161\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0169\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0180\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0160\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0127\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0163\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0121\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0169\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0154\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0165\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0173\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0193\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0261\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0163\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0183\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0202\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0169\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0220\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0206\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0216\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0195\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0170\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0253\n",
      ">p=0.2: 5, Score=0.10577915608882904\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 102ms/step - loss: 0.1929 - val_loss: 0.0229\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0562 - val_loss: 0.0630\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0402 - val_loss: 0.0207\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0422 - val_loss: 0.0191\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0320 - val_loss: 0.0234\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0322 - val_loss: 0.0173\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0298 - val_loss: 0.0148\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0287 - val_loss: 0.0136\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0305 - val_loss: 0.0133\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0233 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0125\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0190 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0129\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0124\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0130\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0194 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0111\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0103\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0113\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0092\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0084\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0129\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0107\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0090\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0088\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0097\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0136\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      ">p=0.2: 6, Score=0.027681978419423103\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 91ms/step - loss: 0.1716 - val_loss: 0.0170\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0518 - val_loss: 0.0491\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0362 - val_loss: 0.0201\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0355 - val_loss: 0.0191\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0319 - val_loss: 0.0161\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0138\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0292 - val_loss: 0.0132\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0267 - val_loss: 0.0128\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0131\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0272 - val_loss: 0.0130\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0240 - val_loss: 0.0128\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0122\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0128\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0188 - val_loss: 0.0123\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0132\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0135\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0106\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0159\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0102\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0140\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0137\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0122\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0100\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0114\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0098\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0096\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0101\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0118\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0114\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0085\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0083\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0166\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0085\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0082\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0139\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0092\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0078\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0105\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0108\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0075\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      ">p=0.2: 7, Score=0.041055526584386826\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 91ms/step - loss: 0.1927 - val_loss: 0.0292\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0620 - val_loss: 0.0450\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0332 - val_loss: 0.0212\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0344 - val_loss: 0.0170\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0318 - val_loss: 0.0175\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0308 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0292 - val_loss: 0.0133\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0270 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0270 - val_loss: 0.0124\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0248 - val_loss: 0.0125\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0237 - val_loss: 0.0131\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0208 - val_loss: 0.0123\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0207 - val_loss: 0.0128\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0204 - val_loss: 0.0140\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0194 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0108\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0105\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0104\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0128\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0121\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0159 - val_loss: 0.0125\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0155\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0129\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0135\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0128\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0082\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      ">p=0.2: 8, Score=0.031004538759589195\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 93ms/step - loss: 0.1902 - val_loss: 0.0251\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0577 - val_loss: 0.0500\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0358 - val_loss: 0.0201\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0360 - val_loss: 0.0169\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0337 - val_loss: 0.0158\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0264 - val_loss: 0.0141\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0259 - val_loss: 0.0132\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0276 - val_loss: 0.0129\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0288 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0123\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0132\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0212 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0130\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0128\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0106\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0105\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0100\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0098\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0098\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0099\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0112\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0095\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0092\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0079\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0130\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0117\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0077\n",
      ">p=0.2: 9, Score=0.020235896110534668\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 88ms/step - loss: 0.1731 - val_loss: 0.0172\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0559 - val_loss: 0.0647\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0219\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0381 - val_loss: 0.0209\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0335 - val_loss: 0.0177\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0294 - val_loss: 0.0150\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0297 - val_loss: 0.0141\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0277 - val_loss: 0.0131\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0266 - val_loss: 0.0122\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0193 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0110\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0108\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0151\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0100\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 0.0095\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0134\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0128\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0132\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0167\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0177\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0158\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0182\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0151\n",
      ">p=0.2: 10, Score=0.06545118242502213\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 99ms/step - loss: 0.1903 - val_loss: 0.0244\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0653 - val_loss: 0.0591\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0460 - val_loss: 0.0284\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0401 - val_loss: 0.0194\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0340 - val_loss: 0.0216\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0336 - val_loss: 0.0175\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0340 - val_loss: 0.0148\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0310 - val_loss: 0.0143\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0305 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0342 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0320 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0259 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0254 - val_loss: 0.0110\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0111\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0183 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0130\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0106\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0171 - val_loss: 0.0121\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0196 - val_loss: 0.0106\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0144\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0103\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0125\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0160\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0096\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0137\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0182 - val_loss: 0.0138\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0144\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0109\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0177\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0108\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0159\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0187\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      ">p=0.3: 1, Score=0.05940794199705124\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 91ms/step - loss: 0.1970 - val_loss: 0.0250\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0644 - val_loss: 0.0624\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0445 - val_loss: 0.0253\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0435 - val_loss: 0.0206\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0375 - val_loss: 0.0229\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0388 - val_loss: 0.0178\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0313 - val_loss: 0.0187\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0273 - val_loss: 0.0162\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0280 - val_loss: 0.0132\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0268 - val_loss: 0.0136\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0277 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0153 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0129\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0175 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0103\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0104\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0170 - val_loss: 0.0110\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0128\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0101\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0147\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0178 - val_loss: 0.0165\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0114\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0171 - val_loss: 0.0098\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0091\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0166 - val_loss: 0.0118\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0088\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0091\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0089\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0124 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      ">p=0.3: 2, Score=0.047046199440956116\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 88ms/step - loss: 0.1893 - val_loss: 0.0324\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0532 - val_loss: 0.0354\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0364 - val_loss: 0.0173\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0349 - val_loss: 0.0147\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0348 - val_loss: 0.0148\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0330 - val_loss: 0.0133\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0313 - val_loss: 0.0129\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0275 - val_loss: 0.0132\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0280 - val_loss: 0.0146\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0294 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0255 - val_loss: 0.0133\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0257 - val_loss: 0.0126\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0252 - val_loss: 0.0141\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0236 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0231 - val_loss: 0.0135\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0163\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0189 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0148\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0106\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0142\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0104\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0219\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0122\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0195\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0096\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0138\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0098\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      ">p=0.3: 3, Score=0.03168710321187973\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 89ms/step - loss: 0.2021 - val_loss: 0.0280\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0682 - val_loss: 0.0533\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0388 - val_loss: 0.0299\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0227\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0315 - val_loss: 0.0237\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0352 - val_loss: 0.0163\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0355 - val_loss: 0.0162\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0316 - val_loss: 0.0146\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0281 - val_loss: 0.0131\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0292 - val_loss: 0.0131\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0277 - val_loss: 0.0128\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0251 - val_loss: 0.0129\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0240 - val_loss: 0.0126\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0247 - val_loss: 0.0130\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0125\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0156\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0210 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.0131\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0130\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0107\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0128\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0136\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0188 - val_loss: 0.0103\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0101\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0192\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0192 - val_loss: 0.0115\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0257 - val_loss: 0.0198\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0124\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0087\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0089\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0180 - val_loss: 0.0103\n",
      ">p=0.3: 4, Score=0.030743015930056572\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 89ms/step - loss: 0.1873 - val_loss: 0.0275\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0540 - val_loss: 0.0480\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0408 - val_loss: 0.0188\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0340 - val_loss: 0.0159\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.0346 - val_loss: 0.0188\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0283 - val_loss: 0.0145\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0299 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0327 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0285 - val_loss: 0.0122\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0263 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0285 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0146\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0269 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0213 - val_loss: 0.0141\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0206 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0135\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0199 - val_loss: 0.0111\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0207 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0146 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0103\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0171 - val_loss: 0.0120\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0102\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0087\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0178\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0096\n",
      ">p=0.3: 5, Score=0.03148967772722244\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 94ms/step - loss: 0.1878 - val_loss: 0.0254\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0667 - val_loss: 0.0610\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0415 - val_loss: 0.0304\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0402 - val_loss: 0.0229\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0352 - val_loss: 0.0234\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0341 - val_loss: 0.0201\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0315 - val_loss: 0.0161\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0355 - val_loss: 0.0151\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0344 - val_loss: 0.0138\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0273 - val_loss: 0.0137\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0311 - val_loss: 0.0132\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0283 - val_loss: 0.0129\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0281 - val_loss: 0.0150\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0301 - val_loss: 0.0126\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0227 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0241 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0125\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0126\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0129\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0151\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0113\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0261 - val_loss: 0.0173\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0113\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0145\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0115\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0129\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0100\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0163 - val_loss: 0.0098\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0187 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0154 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0089\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0131\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0172 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0106\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 0.0147\n",
      ">p=0.3: 6, Score=0.07625234872102737\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 89ms/step - loss: 0.1961 - val_loss: 0.0295\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0598 - val_loss: 0.0538\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0386 - val_loss: 0.0253\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0396 - val_loss: 0.0177\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0323 - val_loss: 0.0203\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0325 - val_loss: 0.0160\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0355 - val_loss: 0.0136\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0277 - val_loss: 0.0133\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0328 - val_loss: 0.0129\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0291 - val_loss: 0.0125\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0267 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0210 - val_loss: 0.0110\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0195 - val_loss: 0.0111\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0107\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0106\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0156 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0134\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0129\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0100\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0156 - val_loss: 0.0104\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0096\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0096\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0134\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0099\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0120\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0166 - val_loss: 0.0096\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0084\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0088\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0082\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0078\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0142\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0076\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0076\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0082\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0071\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0143\n",
      ">p=0.3: 7, Score=0.0535082146525383\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 88ms/step - loss: 0.1932 - val_loss: 0.0270\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0579 - val_loss: 0.0462\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0366 - val_loss: 0.0213\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0384 - val_loss: 0.0178\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0350 - val_loss: 0.0193\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0321 - val_loss: 0.0143\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0297 - val_loss: 0.0140\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0313 - val_loss: 0.0132\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0259 - val_loss: 0.0131\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0283 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0284 - val_loss: 0.0130\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0294 - val_loss: 0.0148\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.0140\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0138\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.0129\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0131\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0154\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0132\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0192 - val_loss: 0.0135\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0131\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0110\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0136\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0128\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0110\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0098\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0223 - val_loss: 0.0153\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0163 - val_loss: 0.0109\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 0.0090\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0162\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0130\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0156\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0163\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0232\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0165\n",
      ">p=0.3: 8, Score=0.07412690669298172\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 92ms/step - loss: 0.1991 - val_loss: 0.0270\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 0.0587\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0379 - val_loss: 0.0264\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0326 - val_loss: 0.0181\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0377 - val_loss: 0.0213\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0311 - val_loss: 0.0174\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0328 - val_loss: 0.0149\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0314 - val_loss: 0.0143\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0316 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0310 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0297 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0263 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0191 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0108\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0139\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0170 - val_loss: 0.0107\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0213 - val_loss: 0.0106\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0101\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0191 - val_loss: 0.0108\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0100\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0100\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0096\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0105\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0119\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0089\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0091\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0144 - val_loss: 0.0096\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0084\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0089\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0079\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0083\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      ">p=0.3: 9, Score=0.05331667885184288\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 6s 82ms/step - loss: 0.1875 - val_loss: 0.0246\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0609 - val_loss: 0.0540\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0420 - val_loss: 0.0275\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0398 - val_loss: 0.0191\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0350 - val_loss: 0.0170\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0331 - val_loss: 0.0143\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0318 - val_loss: 0.0146\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0312 - val_loss: 0.0134\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0308 - val_loss: 0.0131\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0251 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0254 - val_loss: 0.0132\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0246 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0244 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0131\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0133\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0134\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0218 - val_loss: 0.0147\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0193 - val_loss: 0.0169\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0138\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0147\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0124\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0183\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0166 - val_loss: 0.0159\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0163\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0124\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0199\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0164 - val_loss: 0.0158\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0109\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0155\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0159\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0136\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0180 - val_loss: 0.0185\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0186\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0128\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0154\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0136\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0178\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      ">p=0.3: 10, Score=0.061169400811195374\n",
      "[[0.053069107234478, 0.04370881989598274, 0.029154280200600624, 0.01891261525452137, 0.022899584844708443, 0.01458222046494484, 0.05917920917272568, 0.022707998752593994, 0.02039160393178463, 0.01430086325854063], [0.044327009469270706, 0.02651285007596016, 0.014993914403021336, 0.06013624370098114, 0.045856576412916183, 0.02107188291847706, 0.035709962248802185, 0.03753787279129028, 0.023952197283506393, 0.02384311705827713], [0.04527435824275017, 0.03966522216796875, 0.08920320123434067, 0.07370650768280029, 0.10577915608882904, 0.027681978419423103, 0.041055526584386826, 0.031004538759589195, 0.020235896110534668, 0.06545118242502213], [0.05940794199705124, 0.047046199440956116, 0.03168710321187973, 0.030743015930056572, 0.03148967772722244, 0.07625234872102737, 0.0535082146525383, 0.07412690669298172, 0.05331667885184288, 0.061169400811195374]] [0.05, 0.1, 0.2, 0.3]\n",
      "Param=0.05, Mean=0.030:, Std=0.015\n",
      "Param=0.1, Mean=0.033:, Std=0.013\n",
      "Param=0.2, Mean=0.054:, Std=0.027\n",
      "Param=0.3, Mean=0.052:, Std=0.016\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, dropout):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = 80, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units = 80))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=5, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=5)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # resumindo a média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = np.mean(scores[i]), np.std(scores[i])\n",
    "        print(f'Param={params[i]}, Mean={m:.3f}:, Std={s:.3f}')\n",
    "    # boxplot das pontuações\n",
    "    plt.boxplot(scores, labels=params)\n",
    "    plt.savefig('../../src/static/images/despesas/figura[2].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repetindo o experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            score = score\n",
    "            scores.append(score)\n",
    "            print(f'>p={p}: {r+1}, Score={score}')\n",
    "        all_scores.append(scores)\n",
    "    # resumindo os resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = [0.05, 0.1, 0.2, 0.3]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando o modelo com os padrões mais adequados visualizados nos testes anteriores.\n",
    "<p>Neurônios = 80</p>\n",
    "<p>Tamanho do lote/batch = 4</p>\n",
    "<p>Dopout = 0.2</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 80\n",
    "batch_size = 4\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18/18 [==============================] - 6s 81ms/step - loss: 0.1686 - val_loss: 0.0141\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0490 - val_loss: 0.0531\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0366 - val_loss: 0.0235\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0326 - val_loss: 0.0260\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0316 - val_loss: 0.0163\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0322 - val_loss: 0.0149\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0150\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0120\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0116\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0115\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0220 - val_loss: 0.0113\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0111\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0110\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0110\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0108\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0106\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0108\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0110\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0107\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0111\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0291 - val_loss: 0.0117\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0103\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0123\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0102\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0101\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0109\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0098\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0097\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0128\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0092\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0109\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0097\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0092\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0086\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0080\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0076\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0115\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0084\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0092\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0091\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0152\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0120\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0105\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0124\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0083\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0079\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0089\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0139\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0075\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0250 - val_loss: 0.0100\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0150\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0096\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0112\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0092\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0121\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0129\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0123\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0120\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0092\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0068\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0155\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0144\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0131\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0122\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0173\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0132\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0169\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0128\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0166\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0104\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0142\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0223\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0204\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0062\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0050\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0156\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0153\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0117\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0165\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0115\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0166\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0151\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0174\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0136\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0197\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0116\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0154\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0104\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0075\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0124\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0181\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0150\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0046\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0092\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0248\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0138\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0148\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0208\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0160\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0116\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0134\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0135\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0157\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0179\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0202\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0110\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0077\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0158\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0188\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0158\n",
      ">1: Score=0.10362408310174942\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 6s 76ms/step - loss: 0.1818 - val_loss: 0.0156\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0567 - val_loss: 0.0630\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0369 - val_loss: 0.0237\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0406 - val_loss: 0.0241\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0353 - val_loss: 0.0177\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0314 - val_loss: 0.0150\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0137\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0127\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0122\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.0140\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0124\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0123\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0114\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0113\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0112\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0113\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0114\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0131\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0155\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0121\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0126\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0112\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0101\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0129\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0128\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0112\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0127\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0127\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0142\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0102\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0133\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 0.0118\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0213 - val_loss: 0.0090\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0163\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0111\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0096\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0168\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0129\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0157\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0176\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0136\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0164\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0143\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0163\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0174\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0222\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0123\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0135\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0116\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0213 - val_loss: 0.0079\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 0.0249\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0170\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0122\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0223\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0169\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0160\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0160\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0160\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0139\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0165\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0143\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0131\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0132\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0196\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0162\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0095\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0189\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0139\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0071\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0114\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0210\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0139\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0122\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0152\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0122\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0125\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0136\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0143\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0163\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0205\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0175\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0159\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0244\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0245\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0167\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0200\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0167\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0129\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0172\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0129\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0127\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0175\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0213\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0166\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0145\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0165\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0169\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0196\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0215\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0081\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0228\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0217\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0127\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0177\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0185\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0184\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0132\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0111\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0204\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0136\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0192\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0152\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0202\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0070\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0055\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0192\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0156\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0127\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0162\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0131\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0215\n",
      ">2: Score=0.06366556137800217\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 6s 114ms/step - loss: 0.1709 - val_loss: 0.0146\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0526 - val_loss: 0.0528\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0351 - val_loss: 0.0238\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0394 - val_loss: 0.0204\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0178\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0135\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0272 - val_loss: 0.0134\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0124\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0121\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0123\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0134\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0119\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0114\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0120\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0114\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0113\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0108\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0107\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0108\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0131\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0104\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0120\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0100\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0103\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0100\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0097\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0121\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0096\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0092\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0131\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0090\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0088\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0094\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0088\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0079\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0093\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0081\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0078\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0127\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0079\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0073\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0120\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0065\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0149\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0070\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0151\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0093\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0060\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0176\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0128\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0098\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0093\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 0.0094\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0081\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0130\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0092\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0052\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0103\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0094\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0121\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0126\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0144\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0093\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0106\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0112\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0136\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0096\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0093\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0139\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0090\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0093\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0102\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0064\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0098\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0134\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0133\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0057\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0118\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0152\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0117\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0129\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0133\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0111\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0105\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0105\n",
      ">3: Score=0.053350020200014114\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 5s 74ms/step - loss: 0.1626 - val_loss: 0.0146\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0475 - val_loss: 0.0454\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.0221\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0347 - val_loss: 0.0267\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0347 - val_loss: 0.0161\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0165\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0137\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0134\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0127\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.0122\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0122\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0118\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0126\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0117\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0125\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0119\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0115\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0116\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0123\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0131\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0117\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0117\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0111\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0150\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0112\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0122\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0108\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0130\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0100\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0091\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0138\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0176\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0129\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0079\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0096\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0167\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0137\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0108\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0159\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0108\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0150\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0086\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0076\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0142\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0141\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0125\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0158\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0088\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0209\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0120\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0144\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0139\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0132\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0102\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0114\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0154\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0158\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0151\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0060\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0127\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0192\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0132\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0108\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0136\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0111\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0124\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0164\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0181\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0138\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0153\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0177\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0157\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0092\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0048\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0202\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0136\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0069\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0151\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0194\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0135\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0139\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0122\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0151\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0159\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0132\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0137\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0187\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0192\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0145\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0114\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0148\n",
      ">4: Score=0.06700804084539413\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 5s 72ms/step - loss: 0.1763 - val_loss: 0.0160\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0519 - val_loss: 0.0591\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0226\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0372 - val_loss: 0.0248\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0352 - val_loss: 0.0200\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0158\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0146\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0131\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0129\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0127\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0128\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0132\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0125\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0128\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0141\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0135\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0127\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0126\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0142\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0128\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0144\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0181\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0116\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0115\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0145\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0115\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0112\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0134\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0109\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0138\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0112\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0113\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0112\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0100\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0101\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0175\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0130\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0104\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0139\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0148\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0142\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0126\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0142\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0126\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0145\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0084\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0084\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0086\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0140\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0088\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0157\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0090\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0073\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0148\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0213\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0144\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0109\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0104\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0148\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0075\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0141\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0148\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0080\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0175\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0150\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0142\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0151\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0145\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0147\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0170\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0120\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0116\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0111\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0134\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0143\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0164\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0123\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0142\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0053\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0160\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0223\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0119\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0121\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0147\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0142\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0175\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0153\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0181\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0174\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0112\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0121\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0184\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0199\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0110\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0141\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0154\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0171\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0156\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0149\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0206\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0139\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0109\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0153\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0136\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0119\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0215\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0194\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0179\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0134\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0180\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0181\n",
      ">5: Score=0.07952901721000671\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 6s 78ms/step - loss: 0.1717 - val_loss: 0.0162\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0508 - val_loss: 0.0455\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0371 - val_loss: 0.0195\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0374 - val_loss: 0.0199\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0312 - val_loss: 0.0163\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0286 - val_loss: 0.0147\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0129\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0123\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0118\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0115\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0118\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0111\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0109\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0111\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0108\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0105\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0106\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0106\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0101\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0100\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0107\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0098\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0099\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0113\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0105\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0111\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0104\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0105\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0133\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0093\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0093\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0107\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0098\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0082\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0172\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0087\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0077\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0089\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0076\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0091\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0072\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0141\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0115\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0067\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0110\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0093\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0091\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0133\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0061\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0058\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0105\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0114\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0109\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0097\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0096\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0089\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0050\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0063\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0120\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0063\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0141\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0123\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0052\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0095\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0047\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0153\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0070\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0053\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0115\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0125\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0115\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0148\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0094\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0097\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0096\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0123\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0114\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0039\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0053\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0141\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0139\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0109\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0080\n",
      ">6: Score=0.07341945916414261\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 5s 74ms/step - loss: 0.1587 - val_loss: 0.0150\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0466 - val_loss: 0.0409\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0344 - val_loss: 0.0231\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0357 - val_loss: 0.0197\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0170\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0138\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0135\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0128\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0127\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0249 - val_loss: 0.0124\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0121\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0137\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0120\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0121\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0117\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0142\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0121\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0121\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0130\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0118\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0136\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0112\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0111\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0135\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0158\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0113\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0174\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0104\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0142\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0114\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0155\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0124\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0121\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0117\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0148\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0133\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0143\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0107\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0075\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0131\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0140\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0147\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0124\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0139\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0174\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0165\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0139\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0067\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0160\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0145\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0123\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0117\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0139\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0138\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0151\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0161\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0072\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0125\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0139\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0132\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0168\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0173\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0112\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0201\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0131\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0133\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0150\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0157\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0186\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0135\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0128\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0136\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0165\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0207\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0209\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0055\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0196\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0172\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0144\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0130\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0128\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0115\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0114\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0204\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0242\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0158\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0076\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0181\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0144\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0198\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0077\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0128\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0272\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0233\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0137\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0137\n",
      ">7: Score=0.08329405635595322\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 6s 77ms/step - loss: 0.1645 - val_loss: 0.0147\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0496 - val_loss: 0.0562\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0344 - val_loss: 0.0239\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0248\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0314 - val_loss: 0.0198\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0327 - val_loss: 0.0167\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0296 - val_loss: 0.0144\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0256 - val_loss: 0.0131\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0242 - val_loss: 0.0130\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0227 - val_loss: 0.0122\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0119\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0245 - val_loss: 0.0117\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0115\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0115\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0208 - val_loss: 0.0119\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0113\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0114\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0112\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0116\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0118\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0125\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0110\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0127\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0132\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0112\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0104\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0180 - val_loss: 0.0140\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0113\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0104\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0141\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0128\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0101\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0112\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0109\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0095\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0106\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0141\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0092\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0115\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0126\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0083\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0113\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0108\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0081\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0143\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0088\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0126\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0073\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0081\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0141\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0153\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0129\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0079\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0097\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0134\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0091\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0119\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0095\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0124\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0080\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0156\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0176\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0077\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0112\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0159\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0092\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0111\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0118\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0120\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0171\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0141\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0113\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0117\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0116\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0103\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0162\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0152\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0095\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0117\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0094\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0053\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0194\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0141\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0097\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0121\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0147\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0156\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0165\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0196\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0116\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0124\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0136\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0115\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0135\n",
      ">8: Score=0.06941094994544983\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 6s 72ms/step - loss: 0.1854 - val_loss: 0.0170\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0598 - val_loss: 0.0557\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0340 - val_loss: 0.0193\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0359 - val_loss: 0.0242\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0313 - val_loss: 0.0196\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0315 - val_loss: 0.0143\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0141\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0129\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0265 - val_loss: 0.0131\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0128\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0133\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0145\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0132\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0129\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0149\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0135\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0150\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0131\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0122\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0133\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.0122\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0196 - val_loss: 0.0118\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0124\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0117\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0124\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0122\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0115\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0111\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0120\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0113\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0196 - val_loss: 0.0132\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0145\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 0.0112\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0139\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0124\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0109\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0116\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0133\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0092\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0094\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0134\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0094\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0092\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0141\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0176\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0128\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0091\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0149\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0131\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0197\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0134\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0175\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0143\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0115\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0154\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0148\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0131\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0133\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0095\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0072\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0213\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0139\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.0135\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0155\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0148\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0116\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0077\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0131\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0110\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0132\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0091\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0170\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0126\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0154\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0153\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0119\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0104\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0141\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0110\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0132\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0147\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0126\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0136\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0122\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0097\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0139\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0141\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0107\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0187\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0160\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0127\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0147\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0048\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0059\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0128\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0175\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0105\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0155\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0133\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.0146\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 0.0171\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0223\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0086\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0101\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0161\n",
      ">9: Score=0.043163228780031204\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 6s 78ms/step - loss: 0.1856 - val_loss: 0.0192\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0608 - val_loss: 0.0572\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0374 - val_loss: 0.0230\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0378 - val_loss: 0.0221\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0350 - val_loss: 0.0193\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0318 - val_loss: 0.0150\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0288 - val_loss: 0.0169\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0130\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0125\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0257 - val_loss: 0.0121\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0121\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0116\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0114\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0112\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0110\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0111\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0106\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0121\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0113\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0115\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0120\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0127\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0142\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0102\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0107\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0101\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0103\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0115\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0105\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0104\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0098\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0104\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0091\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0097\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0091\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0086\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0092\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0081\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0083\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0079\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0126\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0092\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0096\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0090\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0081\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0077\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0083\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0096\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0076\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0075\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0125\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0079\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0114\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0084\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0126\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0066\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0059\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0129\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0133\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0119\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0102\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0067\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0058\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0131\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0087\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0165\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0097\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0103\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0166\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0090\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0174\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0170\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0134\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0112\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0114\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0138\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0113\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0105\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0126\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0073\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0040\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0177\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0166\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0159\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0103\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0121\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0125\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0086\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0118\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0137\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0110\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0063\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 0.0037\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0047\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0171\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0146\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0113\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0130\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0184\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0192\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0107\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0118\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0192\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0104\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0141\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0111\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      ">10: Score=0.06910419464111328\n",
      "[0.10362408310174942, 0.06366556137800217, 0.053350020200014114, 0.06700804084539413, 0.07952901721000671, 0.07341945916414261, 0.08329405635595322, 0.06941094994544983, 0.043163228780031204, 0.06910419464111328]\n",
      "Loss: Mean = 0.071, Std = 0.016\n"
     ]
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=batch_size, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=5)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = np.mean(scores), np.std(scores)\n",
    "    print(f'Loss: Mean = {m:.3f}, Std = {s:.3f}')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(repeats = 10):\n",
    "    # repetindo o experimento\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(X_train, y_train, X_test, y_test)\n",
    "        score = score\n",
    "        scores.append(score)\n",
    "        print(f'>{r+1}: Score={score}')\n",
    "    # resumindo os resultados\n",
    "    summarize_results(scores)\n",
    "\n",
    "# Rodando o experimento\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(units, dropout):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=units, return_sequences = True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units = units))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, batch_size):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    history = model.fit(X_train, y_train, epochs=150, batch_size=batch_size, validation_split = 0.2, shuffle=False, callbacks=[early_stop])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18/18 [==============================] - 5s 74ms/step - loss: 0.1663 - val_loss: 0.0149\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0543 - val_loss: 0.0429\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0369 - val_loss: 0.0202\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0358 - val_loss: 0.0241\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0293 - val_loss: 0.0158\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0306 - val_loss: 0.0148\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0127\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0124\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0122\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0125\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0135\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0119\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0121\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0120\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0119\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0118\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0117\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0123\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0126\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0140\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0110\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0112\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0090\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0147\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0138\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0094\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0099\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0127\n"
     ]
    }
   ],
   "source": [
    "model_lstm = create_model(neurons, dropout)\n",
    "history_lstm = fit_model(model_lstm, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: despesas_2013_2022\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: despesas_2013_2022\\assets\n"
     ]
    }
   ],
   "source": [
    "model_lstm.save('despesas_2013_2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga do modelo salvo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = tf.keras.models.load_model('despesas_2013_2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-processamento e predição da base de testes com a utilização do modelo carregado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_future(prediction, y_test):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    range_future = len(prediction)\n",
    "    plt.plot(np.arange(range_future), np.array(y_test), label='Dados reais')\n",
    "    plt.plot(np.arange(range_future), np.array(prediction),label='Predição')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Período')\n",
    "    plt.ylabel('Valor Arrecadado')\n",
    "    plt.title('Predição de Receitas - LSTM')\n",
    "    plt.savefig('../../src/static/images/despesas/figura[3].png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "y_test = scaler_y.inverse_transform(y_test)\n",
    "y_train = scaler_y.inverse_transform(y_train)\n",
    "\n",
    "prediction_lstm = prediction(model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_future(prediction_lstm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo do erro médio absoluto e raiz quadrática média:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(prediction_lstm, actual, model_name):\n",
    "    errors = prediction_lstm - actual\n",
    "    mse = np.square(errors).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.abs(errors).mean()\n",
    "    print(f'{model_name}:')\n",
    "    print(f'MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n",
      "MSE: 55817135773.11, RMSE: 236256.50, MAE: 201198.50\n"
     ]
    }
   ],
   "source": [
    "evaluate_prediction(prediction_lstm, y_test, 'LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-processamento dos dados e aplicação do modelo em toda a base de dados (treino + teste):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_future(prediction, y):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    range_future = len(prediction)\n",
    "    plt.plot(np.arange(range_future), np.array(y), label='Dados reais')\n",
    "    plt.plot(np.arange(range_future), np.array(prediction),label='Predição')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Período')\n",
    "    plt.ylabel('Valor Arrecadado')\n",
    "    plt.title('Predição de Receitas - LSTM')\n",
    "    plt.savefig('../../src/static/images/despesas/figura[4].png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydd3hb5dnG76MtD8l7xc7eIQkJNBDCSCAQVkpoKQXassooe5RS4GOvQBsoKaVASyFlFApllpFBIAVCAoQssqcTJ95DsmVtnfP9cc57dLSHJUuyn9915Yp9tF7LsnSe976f++EEQRBAEARBEARBEARBRESV6QUQBEEQBEEQBEFkO1Q4EQRBEARBEARBxIAKJ4IgCIIgCIIgiBhQ4UQQBEEQBEEQBBEDKpwIgiAIgiAIgiBiQIUTQRAEQRAEQRBEDKhwIgiCIAiCIAiCiAEVTgRBEARBEARBEDGgwokgCIIgCIIgCCIGVDgRBEHkGMOHD8ell14qf79q1SpwHIdVq1YlfF+LFy9GYWEhzjrrLDQ1NWHevHl47733UrbWSNTX14PjOCxZsiTtj5Ut3H///eA4LtPLIAiCIJKECieCIIgEWLJkCTiOk/8ZDAaMHTsW119/PVpaWjK9vIR55JFHcNddd8HlcmHIkCHYtWsXTjnllEwvKymUvxeO42AymXDSSSfho48+yvTSIvLoo4/2S6HaF1iRu2jRoqjXc7vdWLx4MaZNmwaTyYSioiJMmjQJV111FXbs2AEg9HcU6d+qVavkx+U4Dg8//HDYx/zFL34BjuNQUFCQ8p+bIAgiGE2mF0AQBJGLPPjggxgxYgScTie++uorPPvss/j444+xZcsW5OXl9etaTjzxRDgcDuh0uoRvu2bNGowaNQp33nknmpubUVpaCq1Wm4ZV9g+nnnoqLr74YgiCgAMHDuDZZ5/F/Pnz8cknn2DevHkZXdvdd9+NO+64I+DYo48+ivPOOw8LFizIzKJSyE9/+lN88sknuPDCC3HllVfC4/Fgx44d+PDDD3Hcccdh/PjxeOWVVwJu8/LLL2PFihUhxydMmACHwwEAMBgMeP3113H33XcHXKe3txfvv/8+DAZDen8wgiAICSqcCIIgkuCMM87A0UcfDQC44oorUFpaiieffBLvv/8+LrzwwrC36e3tRX5+fsrXolKpkj55HDVqlPx1VVVVqpaUMcaOHYtf/vKX8vc//elPMXHiRCxevDjjhZNGo4FGMzA/dr/77jt8+OGHsoKp5C9/+QssFgsABPxuAGDt2rVYsWJFyHFAVLoA4Mwzz8Q777yDTZs2YerUqfLl77//PtxuN04//XR89tlnqf2BCIIgwkBWPYIgiBRw8sknAwD2798PALj00ktRUFCAvXv34swzz0RhYSF+8YtfAAB4nsdTTz2FSZMmwWAwoLKyEldffTW6uroC7lMQBDz88MOora1FXl4e5syZg61bt4Y8dqQep2+++QZnnnkmiouLkZ+fjylTpmDx4sXy5Rs3bsTFF1+MESNGwGAwoKqqCpdffjk6OjpCHmPDhg0444wzYDKZUFBQgFNOOQVr166N67mxWCy49NJLYTabUVRUhEsuuUQ+kQ5mx44dOO+881BSUgKDwYCjjz4aH3zwQVyPE44JEyagrKwMe/fuDTjucrlw3333YfTo0dDr9airq8Ptt98Ol8sVch+vvvoqZsyYgby8PBQXF+PEE0/E8uXLA67zySef4IQTTkB+fr7cMxb8uwruceI4Dr29vfjnP/8pW9JY79qBAwdw7bXXYty4cTAajSgtLcXPfvYzuZhgeDwePPDAAxgzZgwMBgNKS0tx/PHHY8WKFUk/Z8nAnt9Zs2aFXKZWq1FaWpr0fc+cORMjRozAv/71r4Djr732Gk4//XSUlJQkfd8EQRCJMDC3vgiCIPoZduKoPEH0er2YN28ejj/+eCxatEi28F199dVYsmQJLrvsMtx4443Yv38//vKXv2DDhg1YvXq1bJW799578fDDD+PMM8/EmWeeifXr1+O0006D2+2OuZ4VK1bg7LPPRnV1NW666SZUVVVh+/bt+PDDD3HTTTcBAJYtW4b6+npcfvnlqKqqwtatW/G3v/0NW7duxdq1a+WT/K1bt+KEE06AyWTC7bffDq1Wi+effx6zZ8/G//73PxxzzDER1yEIAs455xx89dVX+M1vfoMJEybg3XffxSWXXBJy3a1bt2LWrFkYMmQI7rjjDuTn5+PNN9/EggUL8Pbbb+Pcc8+N87fhx2q1oqurK0BZ43keP/7xj/HVV1/hqquuwoQJE/DDDz/gT3/6E3bt2hXQc/TAAw/g/vvvx3HHHYcHH3wQOp0O33zzDT777DOcdtppAIBXXnkFl1xyCebNm4fHH38cdrsdzz77LI4//nhs2LABw4cPD7u2V155BVdccQVmzJiBq666CoBfAfzuu+/w9ddf44ILLkBtbS3q6+vx7LPPYvbs2di2bZv8Wrr//vuxcOFC+X66u7uxbt06rF+/HqeeemrCz1eyDBs2DIBYzMyaNSvlytqFF16IV199FY899hg4jkN7ezuWL1+OV155BUuXLk3pYxEEQUREIAiCIOLmpZdeEgAIn376qdDW1iY0NDQIb7zxhlBaWioYjUbh0KFDgiAIwiWXXCIAEO64446A23/55ZcCAOG1114LOL506dKA462trYJOpxPOOussged5+Xp33XWXAEC45JJL5GOff/65AED4/PPPBUEQBK/XK4wYMUIYNmyY0NXVFfA4yvvq7e0N+flef/11AYDwxRdfyMcWLFgg6HQ6Ye/evfKxxsZGobCwUDjxxBOjPl/vvfeeAED4wx/+IB/zer3CCSecIAAQXnrpJfn4KaecIkyePFlwOp0B6z3uuOOEMWPGRH0cQRAEAMKvf/1roa2tTWhtbRXWrVsnnH766QIA4Y9//KN8vVdeeUVQqVTCl19+GXD75557TgAgrF69WhAEQdi9e7egUqmEc889V/D5fAHXZc9jT0+PUFRUJFx55ZUBlzc3Nwtmszng+H333ScEf+zm5+cH/C4Zdrs95NiaNWsEAMLLL78sH5s6dapw1llnRXta+sz+/ftDnsNgeJ4XTjrpJAGAUFlZKVx44YXCM888Ixw4cCDqfV933XUhz0m4x92yZYsAQP6dPfPMM0JBQYHQ29srXHLJJUJ+fn7yPyBBEESckFWPIAgiCebOnYvy8nLU1dXhggsuQEFBAd59910MGTIk4HrXXHNNwPdvvfUWzGYzTj31VLS3t8v/jjrqKBQUFODzzz8HAHz66adwu9244YYbAuxdN998c8y1bdiwAfv378fNN9+MoqKigMuU96UMsXA6nWhvb8exxx4LAFi/fj0AwOfzYfny5ViwYAFGjhwpX7+6uhoXXXQRvvrqK3R3d0dcy8cffwyNRhPwPKjVatxwww0B1+vs7MRnn32G888/Hz09PfLz0tHRgXnz5mH37t04fPhwzJ/9H//4B8rLy1FRUYGjjz4aK1euxO23345bb71Vvs5bb72FCRMmYPz48QG/A2a3ZL+D9957DzzP495774VKFfhxyZ7HFStWwGKx4MILLwy4L7VajWOOOUa+r0QxGo3y1x6PBx0dHRg9ejSKiork3w0AFBUVYevWrdi9e3dSj5MqOI7DsmXL8PDDD6O4uBivv/46rrvuOgwbNgw///nPI1oz42XSpEmYMmUKXn/9dQDAv/71L5xzzjn9HsRCEMTgZlAXTl988QXmz5+PmpoacByXVCSsIAhYtGgRxo4dC71ejyFDhuCRRx5J/WIJgsgqnnnmGaxYsQKff/45tm3bhn379oWED2g0GtTW1gYc2717N6xWKyoqKlBeXh7wz2azobW1FYDY4wIAY8aMCbh9eXk5iouLo66N2QaPOOKIqNfr7OzETTfdhMrKShiNRpSXl2PEiBEARIsbALS1tcFut2PcuHEht58wYQJ4nkdDQ0PExzhw4ACqq6tD4qKD72/Pnj0QBAH33HNPyPNy3333AYD83ETjnHPOwYoVK/DRRx/JPUV2uz2g8Nm9eze2bt0a8jhjx44NeJy9e/dCpVJh4sSJER+PFSwnn3xyyP0tX748rjWHw+Fw4N5770VdXR30ej3KyspQXl4Oi8Ui/24AMd3RYrFg7NixmDx5Mn73u99h8+bNUe/b5/Ohubk54F889s9Y6PV6/N///R+2b9+OxsZGvP766zj22GPx5ptv4vrrr+/z/V900UV46623sGfPHnz99de46KKL+nyfBEEQiTCoe5x6e3sxdepUXH755fjJT36S1H3cdNNNWL58ORYtWoTJkyejs7MTnZ2dKV4pQRDZxowZM+RUvUjo9foQpYLneVRUVOC1114Le5vy8vKUrTEW559/Pr7++mv87ne/w5FHHomCggLwPI/TTz8dPM/32zoAyI932223RUy/Gz16dMz7qa2txdy5cwGIaWxlZWW4/vrrMWfOHPl9nud5TJ48GU8++WTY+6irq0t43a+88krYVMJke31uuOEGvPTSS7j55psxc+ZMmM1mcByHCy64IOB3c+KJJ2Lv3r14//33sXz5crzwwgv405/+hOeeew5XXHFF2PtuaGiQC2TG559/jtmzZye11nBUV1fjggsuwE9/+lNMmjQJb775JpYsWdKn3qcLL7wQd955J6688kqUlpbKPWYEQRD9xaAunM444wycccYZES93uVz4v//7P7z++uuwWCw44ogj8Pjjj8sfLtu3b8ezzz6LLVu2yLunwR9GBEEQSkaNGoVPP/0Us2bNCrBjBcOa7Xfv3h1gkWtrawtJ3wv3GACwZcsWuYgIpqurCytXrsQDDzyAe++9Vz4ebPkqLy9HXl4edu7cGXIfO3bsgEqlilpoDBs2DCtXroTNZgtQnYLvj/2MWq024pqT4eqrr8af/vQn3H333Tj33HPBcRxGjRqFTZs24ZRTTgmwLgYzatQo8DyPbdu24cgjj4x4HQCoqKhIat2RHv8///kPLrnkEjzxxBPyMafTGdbyVlJSgssuuwyXXXYZbDYbTjzxRNx///0RC6eqqqqQ1D1lzHcq0Wq1mDJlCnbv3o329vY+Rd4PHToUs2bNwqpVq3DNNdcM2Gh3giCyl0Ft1YvF9ddfjzVr1uCNN97A5s2b8bOf/Qynn366fGLx3//+FyNHjsSHH36IESNGYPjw4bjiiitIcSIIIiLnn38+fD4fHnrooZDLvF6vfGI8d+5caLVaPP300xAEQb7OU089FfMxpk+fjhEjRuCpp54KOdFm96VWqwO+j3T/arUap512Gt5///2AKOyWlhb861//wvHHHw+TyRRxLWeeeSa8Xi+effZZ+ZjP58PTTz8dcL2KigrMnj0bzz//PJqamkLup62tLeJjREOj0eC3v/0ttm/fjvfffx+A+Ds4fPgw/v73v4dc3+FwoLe3FwCwYMECqFQqPPjggyEKHHve5s2bB5PJhEcffRQejyfhdefn54cthtRqdcjv5umnn4bP5ws4FhwdX1BQgNGjR4eNVWcYDAbMnTs34F8s+2csdu/ejYMHD4Yct1gsWLNmDYqLi1Oipj788MO47777QnrkCIIg+gParonAwYMH8dJLL+HgwYOoqakBIFpIli5dipdeegmPPvoo9u3bhwMHDuCtt97Cyy+/DJ/Ph1tuuQXnnXceDeMjCCIsJ510Eq6++mosXLgQGzduxGmnnQatVovdu3fjrbfewuLFi3HeeeehvLwct912GxYuXIizzz4bZ555JjZs2IBPPvkEZWVlUR9DpVLh2Wefxfz583HkkUfisssuQ3V1NXbs2IGtW7di2bJlMJlMOPHEE/GHP/wBHo8HQ4YMwfLly+U5VEoefvhhrFixAscffzyuvfZaaDQaPP/883C5XPjDH/4QdS3z58/HrFmzcMcdd6C+vh4TJ07EO++8E9Cnw3jmmWdw/PHHY/LkybjyyisxcuRItLS0YM2aNTh06BA2bdqU2JMtcemll+Lee+/F448/jgULFuBXv/oV3nzzTfzmN7/B559/jlmzZsHn82HHjh148803sWzZMhx99NEYPXo0/u///g8PPfQQTjjhBPzkJz+BXq/Hd999h5qaGixcuBAmkwnPPvssfvWrX2H69Om44IILUF5ejoMHD+Kjjz7CrFmz8Je//CXi2o466ih8+umnePLJJ1FTU4MRI0bgmGOOwdlnn41XXnkFZrMZEydOxJo1a/Dpp5+GzEOaOHEiZs+ejaOOOgolJSVYt24d/vOf/6SkpyiYlStXwul0hhxfsGABduzYgYsuughnnHEGTjjhBJSUlODw4cP45z//icbGRjz11FNysd4XTjrpJJx00kl9vh+CIIikyGCiX1YBQHj33Xfl7z/88EMBgJCfnx/wT6PRCOeff74gCIJw5ZVXCgCEnTt3yrf7/vvvBQDCjh07+vtHIAiiH2Bx5N99913U68WKSP7b3/4mHHXUUYLRaBQKCwuFyZMnC7fffrvQ2NgoX8fn8wkPPPCAUF1dLRiNRmH27NnCli1bhGHDhkWNI2d89dVXwqmnniqoVCoBgDBlyhTh6aefli8/dOiQcO655wpFRUWC2WwWfvaznwmNjY0CAOG+++4LuK/169cL8+bNEwoKCoS8vDxhzpw5wtdffx37CRMEoaOjQ/jVr34lmEwmwWw2C7/61a+EDRs2hMSRC4Ig7N27V7j44ouFqqoqQavVCkOGDBHOPvts4T//+U/MxwEgXHfddWEvu//++wOeI7fbLTz++OPCpEmTBL1eLxQXFwtHHXWU8MADDwhWqzXgti+++KIwbdo0+XonnXSSsGLFioDrfP7558K8efMEs9ksGAwGYdSoUcKll14qrFu3Tr5OuDjyHTt2CCeeeKJgNBoDYua7urqEyy67TCgrKxMKCgqEefPmCTt27Aj53T/88MPCjBkzhKKiIsFoNArjx48XHnnkEcHtdsd8vuKFxYJH+vfKK68ILS0twmOPPSacdNJJQnV1taDRaITi4mLh5JNPjvq7izeOPBoUR04QRH/BCUKQF2CQwnEc3n33XSxYsAAA8O9//xu/+MUvsHXr1pBdsoKCAlRVVeG+++4LsWc4HA7k5eVh+fLl/Tp8kCAIIhI8z+OII47A22+/jQkTJmR6OQRBEASRk1CPUwSmTZsGn8+H1tZWjB49OuAfa26dNWsWvF6vHP0LALt27QLgb+wmCILINCqVCvPmzZNn4BAEQRAEkTiDusfJZrNhz5498vf79+/Hxo0bUVJSgrFjx+IXv/gFLr74YjzxxBOYNm0a2trasHLlSkyZMgVnnXUW5s6di+nTp+Pyyy/HU089BZ7ncd111+HUU0+V54EQBEFkkueffx5qtRpLly6NmiJKEARBEER0BrVVb9WqVZgzZ07I8UsuuQRLliyBx+PBww8/jJdffhmHDx9GWVkZjj32WDzwwAOYPHkyAKCxsRE33HADli9fjvz8fJxxxhl44oknUFJS0t8/DkEQRAiXXHIJ3njjDYwZMwbvvPMObeoQBEEQRJIM6sKJIAiCIAiCIAgiHqjHiSAIgiAIgiAIIgZUOBEEQRAEQRAEQcRg0IVD8DyPxsZGFBYWguO4TC+HIAiCIAiCIIgMIQgCenp6UFNTA5UquqY06AqnxsZG1NXVZXoZBEEQBEEQBEFkCQ0NDaitrY16nUFXOBUWFgIQnxyTyZTh1RAEQRAEQRAEkSm6u7tRV1cn1wjRGHSFE7PnmUwmKpwIgiAIgiAIgoirhYfCIQiCIAiCIAiCIGJAhRNBEARBEARBEEQMqHAiCIIgCIIgCIKIwaDrcYoHQRDg9Xrh8/kyvRQiQ6jVamg0GoqsJwiCIAiCIABQ4RSC2+1GU1MT7HZ7ppdCZJi8vDxUV1dDp9NleikEQRAEQRBEhqHCSQHP89i/fz/UajVqamqg0+lIcRiECIIAt9uNtrY27N+/H2PGjIk5EI0gCIIgCIIY2FDhpMDtdoPnedTV1SEvLy/TyyEyiNFohFarxYEDB+B2u2EwGDK9JIIgCIIgCCKD0DZ6GEhdIAB6HRAEQRAEQRB+6MyQIAiCIAiCIAgiBlQ4EQRBEARBEARBxIAKJyIulixZgqKiokwvIymGDx+Op556KtPLIAiCIAiCIHIYKpwGCJdeeik4jgPHcdBqtaisrMSpp56KF198ETzPZ3p5GeW7777DVVddlellEARBEARBEDkMFU4DiNNPPx1NTU2or6/HJ598gjlz5uCmm27C2WefDa/Xm+nlJYTb7U7ZfZWXl1NKIkEQBEEQBNEnqHCKgSAIsLu9GfknCEJCa9Xr9aiqqsKQIUMwffp03HXXXXj//ffxySefYMmSJfL1nnzySUyePBn5+fmoq6vDtddeC5vNFnBfS5YswdChQ5GXl4dzzz0XHR0dIY/37LPPYtSoUdDpdBg3bhxeeeWVgOft/vvvx9ChQ6HX61FTU4Mbb7wx4trvv/9+HHnkkXjhhRcwYsQIOf7bYrHgiiuuQHl5OUwmE04++WRs2rRJvt3evXtxzjnnoLKyEgUFBfjRj36ETz/9NOC+lVa9RNdFEARBEARBEADNcYqJw+PDxHuXZeSxtz04D3m6vv2KTj75ZEydOhXvvPMOrrjiCgBizPaf//xnjBgxAvv27cO1116L22+/HX/9618BAN988w1+/etfY+HChViwYAGWLl2K++67L+B+3333Xdx000146qmnMHfuXHz44Ye47LLLUFtbizlz5uDtt9/Gn/70J7zxxhuYNGkSmpubAwqecOzZswdvv/023nnnHajVagDAz372MxiNRnzyyScwm814/vnnccopp2DXrl0oKSmBzWbDmWeeiUceeQR6vR4vv/wy5s+fj507d2Lo0KEhj5HMugiCIAiCIAiCCqdBwPjx47F582b5+5tvvln+evjw4Xj44Yfxm9/8Ri6cFi9ejNNPPx233347AGDs2LH4+uuvsXTpUvl2ixYtwqWXXoprr70WAHDrrbdi7dq1WLRoEebMmYODBw+iqqoKc+fOhVarxdChQzFjxoyo63S73Xj55ZdRXl4OAPjqq6/w7bfforW1FXq9Xn7c9957D//5z39w1VVXYerUqZg6dap8Hw899BDeffddfPDBB7j++utDHiOZdREEQRAEQRAEFU4xMGrV2PbgvIw9dioQBAEcx8nff/rpp1i4cCF27NiB7u5ueL1eOJ1O2O125OXlYfv27Tj33HMD7mPmzJkBhdP27dtDAhdmzZqFxYsXAxCVoqeeegojR47E6aefjjPPPBPz58+HRhP5JTds2DC5aAKATZs2wWazobS0NOB6DocDe/fuBQDYbDbcf//9+Oijj9DU1ASv1wuHw4GDBw+GfYxk1kUQBEEQBJEL8LyATYcsmFBtgiFF55GEHzpbjAHHcX22y2Wa7du3Y8SIEQCA+vp6nH322bjmmmvwyCOPoKSkBF999RV+/etfw+12pyxEoa6uDjt37sSnn36KFStW4Nprr8Uf//hH/O9//4NWqw17m/z8/IDvbTYbqqursWrVqpDrsmj02267DStWrMCiRYswevRoGI1GnHfeeRHDJZJZF0EQBEEQRC7wyZZmXPev9bjyhBH4v7MmZno5A47crgiImHz22Wf44YcfcMsttwAAvv/+e/A8jyeeeAIqlZgN8uabbwbcZsKECfjmm28Cjq1duzbkOqtXr8Yll1wiH1u9ejUmTvT/kRqNRsyfPx/z58/Hddddh/Hjx+OHH37A9OnT41r79OnT0dzcDI1Gg+HDh4e9zurVq3HppZfKCpnNZkN9fX3U++3rugiCIAiCILKRwxY7AKCh05HhlQxMqHAaQLhcLjQ3N8Pn86GlpQVLly7FwoULcfbZZ+Piiy8GAIwePRoejwdPP/005s+fj9WrV+O5554LuJ8bb7wRs2bNwqJFi3DOOedg2bJlATY9APjd736H888/H9OmTcPcuXPx3//+F++8846caLdkyRL4fD4cc8wxyMvLw6uvvgqj0Yhhw4bF/fPMnTsXM2fOxIIFC/CHP/wBY8eORWNjIz766COce+65OProozFmzBi88847mD9/PjiOwz333BN1blUq1kUQBEEQBJGNeHxiIrPL68vwSgYmFEc+gFi6dCmqq6sxfPhwnH766fj888/x5z//Ge+//76cUjd16lQ8+eSTePzxx3HEEUfgtddew8KFCwPu59hjj8Xf//53LF68GFOnTsXy5ctx9913B1xnwYIFWLx4MRYtWoRJkybh+eefx0svvYTZs2cDEK10f//73zFr1ixMmTIFn376Kf773/+G9CtFg+M4fPzxxzjxxBNx2WWXYezYsbjgggtw4MABVFZWAhCj1YuLi3Hcccdh/vz5mDdvXlTlKBXrIgiCIAiCyEbcXnHz2OmJvIlMJA8nJDosKMfp7u6G2WyG1WqFyWQKuMzpdGL//v0Bc4SIwQu9HgiCIAiCyCX+uGwHnvl8L6YPLcI7187K9HJygmi1QTCkOBEEQRAEQRDEAIBZ9UhxSg9UOBEEQRAEQRDEAIBZ9ajHKT1Q4UQQBEEQBEEQAwCPj3qc0gkVTgRBEARBEAQxAPDKqXpUOKUDKpwIgiAIgiAIYgDAFCey6qUHKpwIgiAIgiAIYgDgZoUTWfXSAhVOBEEQBEEQBDEAYFY9t48Hzw+qiUP9AhVOBEEQBEEQBDEAYFY9gPqc0gEVTgRBEARBEAQxAHAHFE7U55RqqHAiEuLSSy/FggUL5O9nz56Nm2++Oe7br127FqWlpbjiiiuwfft2nHXWWalfJEEQBEEQxCBEqThRJHnqocJpgHDppZeC4zhwHAedTofRo0fjwQcfhNfrTevjvvPOO3jooYfivv4HH3yAxx9/HGVlZTjzzDNx9dVXp3F1BEEQBEEQgwfW4wSQ4pQONJleAJE6Tj/9dLz00ktwuVz4+OOPcd1110Gr1eLOO+8MuJ7b7YZOp0vJY5aUlCR0/UcffVT++rHHHkvJGgiCIAiCIAhSnNINKU6xEATA3ZuZf0JiaSh6vR5VVVUYNmwYrrnmGsydOxcffPCBbK975JFHUFNTg3HjxgEAGhoacP7556OoqAglJSU455xzUF9fL9+fz+fDrbfeiqKiIpSWluL222+HELSmYKuey+XC73//e9TV1UGv12P06NH4xz/+Id/fr3/9a4wYMQJGoxHjxo3D4sWLA+6P53k8+OCDqK2thV6vx5FHHomlS5cm9DwQBEEQBEEMRtykOKUVUpxi4bEDj9Zk5rHvagR0+Unf3Gg0oqOjAwCwcuVKmEwmrFixAgDg8Xgwb948zJw5E19++SU0Gg0efvhhnH766di8eTN0Oh2eeOIJLFmyBC+++CImTJiAJ554Au+++y5OPvnkiI958cUXY82aNfjzn/+MqVOnYv/+/WhvbwcgFkW1tbV46623UFpaiq+//hpXXXUVqqurcf755wMAFi9ejCeeeALPP/88pk2bhhdffBE//vGPsXXrVowZMybp54IgCIIgCGKg4yXFKa1Q4TQAEQQBK1euxLJly3DDDTegra0N+fn5eOGFF2SL3quvvgqe5/HCCy+A4zgAwEsvvYSioiKsWrUKp512Gp566inceeed+MlPfgIAeO6557Bs2bKIj7tr1y68+eabWLFiBebOnQsAGDlypHy5VqvFAw88IH8/YsQIrFmzBm+++aZcOC1atAi///3vccEFFwAAHn/8cXz++ed46qmn8Mwzz6TwWSIIgiAIghhYeChVL61Q4RQLbZ6o/GTqsRPgww8/REFBATweD3iex0UXXYT7778f1113HSZPnhzQ17Rp0ybs2bMHhYWFAffhdDqxd+9eWK1WNDU14ZhjjpEv02g0OProo0PseoyNGzdCrVbjpJNOirjGZ555Bi+++CIOHjwIh8MBt9uNI488EgDQ3d2NxsZGzJo1K+A2s2bNwqZNmxJ6LgiCIAiCIAYbHoVVjxSn1EOFUyw4rk92uf5kzpw5ePbZZ6HT6VBTUwONxv/rzc8P/BlsNhuOOuoovPbaayH3U15entTjG43GqJe/8cYbuO222/DEE09g5syZKCwsxB//+Ed88803ST0eQRAEQRAE4YfmOKUXCocYQOTn52P06NEYOnRoQNEUjunTp2P37t2oqKjA6NGjA/6ZzWaYzWZUV1cHFDVerxfff/99xPucPHkyeJ7H//73v7CXr169GscddxyuvfZaTJs2DaNHj8bevXvly00mE2pqarB69eqQ202cODGep4AgCIIgCGLQQj1O6YUKp0HKL37xC5SVleGcc87Bl19+if3792PVqlW48cYbcejQIQDATTfdhMceewzvvfceduzYgWuvvRYWiyXifQ4fPhyXXHIJLr/8crz33nvyfb755psAgDFjxmDdunVYtmwZdu3ahXvuuQffffddwH387ne/w+OPP45///vf2LlzJ+644w5s3LgRN910U9qei3hYsa0Fb3x7MKNrIAiCIAiCiIaHUvXSCln1Bil5eXn44osv8Pvf/x4/+clP0NPTgyFDhuCUU06ByWQCAPz2t79FU1MTLrnkEqhUKlx++eU499xzYbVaI97vs88+i7vuugvXXnstmpqaMHr0aNx1110AgKuvvhobNmzAz3/+c3AchwsvvBDXXnstPvnkE/n2N954I6xWK37729+itbUVEydOxAcffJDxRL1b39yIHqcXJ0+oQEWhIaNrIQiCIAiCCIebFKe0wgmROv0HKN3d3TCbzbBarXKBwHA6ndi/fz9GjBgBg4FOjvvK1VdfjfPPPx+nnHJKppeSFOz1MGzYcEx88DMAwNKbT8D4KlOMWxIEQRAEQfQ/I+/8CLx0Zn/76eNw7ezRmV1QDhCtNgiGrHpEyrFardi7dy90Oh0++OCDTC+nz7i9/h2bHqc3gyshCIIgCIIIj48X5KIJIMUpHZBVj0g5hw8fxrHHHguDwYBXX30108vpM0qPsI0KJ4IgCIIgshDlDCeAepzSARVORMqZOHEiuru7M72MlOFSvBF1Oz0ZXAlBEARBEER43MGFEylOKYesegQRA6VVz+YixYkgCIIgiOzD6wuMLSDFKfVQ4RSGQZaXQUSAvQ6ox4kgCIIgiGwn2KpHPU6phwonBVqtFgBgt9szvBIiG2CvAxfv/zOhHieCIAiCILIR5UYvQIpTOqAeJwVqtRpFRUVobW0FIM464jguw6si+htBEGC329Ha2oqioiIccPgVyB7qcSIIgiAIIgvx8oGOKVKcUg8VTkFUVVUBgFw8EYOXoqIiVFVVYeeuNvlYD/U4EQRBEASRhVCqXvqhwikIjuNQXV2NiooKeDykLgxWtFot1Go1gMAdG+pxIgiCIAgiGwm26pHilHqocIqAWq2WT5yJwQ3NcSIIgiAIItshxSn9UDgEQcRAOQehx0UqJEEQBEEQ2Qf1OKUfKpwIIgZOxY4NWfUIgiAIgshGPJSql3aocCKIGDg9ZNUjCIIgCCK7cUtWPZUUCE2KU+qhwokgYkDhEARBEARBZDten2jVK9CLEQYuDylOqYYKJ4KIgVLqdvt4kr4JgiAIgsg6WDhEoUELAHB5SXFKNVQ4EUQMgqVuUp0IgiAIgsg2mFVPVpy8PARBiHYTIkGocCKIGDiDpG7qcyIIgiAIItvwMKuewT9tiFSn1EKFE0HEgBQngiAIgiCyHW+Q4gQEjlQh+g4VTgQRA2dQTxPNciIIgiAIIttgPU55OrWcrEd92amFCieCiEHwbg0pTgRBEARBZBtuyaqn06ig16gBUCR5qqHCiSBiELxbQ4UTQRAEQRDZBrPqaVQqGLTiKT4pTqmFCieCiAELh9BIurfNSVY9giAIgiCyC2bV02k4UpzSBBVOBBED9qZTWqADQIoTQRAEQRDZB7PqadWkOKULKpwIIgbsTae8UA8AsLmocCIIgiAIIrvwKKx6pDilh4wWTl988QXmz5+PmpoacByH9957L+r133nnHZx66qkoLy+HyWTCzJkzsWzZsv5ZLDFoYW86ZQVi4dRNihNBEARBEFkG63HSajhSnNJERgun3t5eTJ06Fc8880xc1//iiy9w6qmn4uOPP8b333+POXPmYP78+diwYUOaV0oMZliPU3kBKU4EQRAEQWQnbACuTk2KU7rQxL5K+jjjjDNwxhlnxH39p556KuD7Rx99FO+//z7++9//Ytq0aSleHUGIsMKpTLLq9VA4BEEQBEEQWYabKU5qFfSkOKWFjBZOfYXnefT09KCkpCTidVwuF1wul/x9d3d3fyyNGEA4vYFWPRtZ9QiCIAiCyDI80vmKRk2peukip8MhFi1aBJvNhvPPPz/idRYuXAiz2Sz/q6ur68cVErmOIAhwy4UTpeoRBEEQBJGdeHm/VY96nNJDzhZO//rXv/DAAw/gzTffREVFRcTr3XnnnbBarfK/hoaGflwlkeu4vP6dmnKy6hEEQRAEkaUEWPVIcUoLOWnVe+ONN3DFFVfgrbfewty5c6NeV6/XQ6/X99PKiIEG628C/OEQPRQOQRAEQRBElqG06pHilB5yTnF6/fXXcdlll+H111/HWWedlenlEAMctlOjUXEw52kBiKl6vCSHEwRBEARBZAPMqkeKU/rIqOJks9mwZ88e+fv9+/dj48aNKCkpwdChQ3HnnXfi8OHDePnllwGI9rxLLrkEixcvxjHHHIPm5mYAgNFohNlszsjPQAxsmOKk16hgMoiFkyAAdo8PBfqcFGwJgiAIghiAsAG41OOUPjKqOK1btw7Tpk2To8RvvfVWTJs2Dffeey8AoKmpCQcPHpSv/7e//Q1erxfXXXcdqqur5X833XRTRtZPDHxYj5NBq4Zeo4JGxQGgPieCIAiCILILFmZFilP6yOiW+ezZsyEIkS1PS5YsCfh+1apV6V0QQQTBFCeDVg2O41Bo0KDL7hEjyUnkJAiCIAgiS2CKE/U4pY+c63EiiP5EtupJb0CFkl2vmyLJCYIgCILIIpRx5HqNVDiR4pRSqHAiiCiw4bcGSfJmfU02StYjCIIgCCKLUFr1DFrxvIUUp9RChRNBRCFUcRILJ+pxIgiCIAgim1Ba9dh5C/U4pRYqnAgiCq4gxYkVTjay6hEEQRAEkUWEiyMnxSm1UOFEEFHwh0ME9jj1UOFEEARBEEQWwQbgKuPISXFKLVQ4EUQUXIpUPcDf40RWPYIgCIIgsgm3T1KcNBwpTmmCCieCiALbqWGFk9zjROEQBEEQBEFkEXKPk4oUp3RBhRNBREEOh5BiPQvkcAgqnAiCIAiCyB68Pr9VjxSn9ECFE0FEQQ6HkBUnsceJwiEIgiAIgsgmPAqrnn8ALilOqYQKJ4KIQnAcuUm26lGPE0EQBEEQ2YEgCHD7/HOcmOLEzmOI1ECFE0FEwSlJ3CEDcElxIgiCIAgiS/BJUeQAoFWp5A1fl5eHIAiRboYth624/l/rcbDDnvY1DgSocCKIKLCmSj3FkRMEQRAEkaUwmx4QmKonCJCVqHC89s0BfLi5CW+ua0j7GgcCVDgRRBTkOU5BihOl6hEEQRAEkS0oiyOtYo4TEL3Pqdshns80dJHiFA9UOBFEFELDIWiOE0EQBEEQ2YVHUThpVBx0ahU4Tvw+Wp9Tt3Q+09BJhVM8UOFEEFGQFSfZqqeRjvMBb1IEQRAEQRCZwssS9dQcOE78x0apuKLMcrJJDppDXY70L3IAQIUTQUTBFTQAl1n1AAqIIAiCIAgiO/AoEvUY8cxyYucyrT2uuBL4LHY3vqvvjBo4MZChwokgosBS9diujUatglEqoigggiAIgiCIbMAdpnBibhlnHIoTADRaYqtOd7z9A3723Bp8u78z2aXmNFQ4EUQUghUnQNHnRLOcCIIgCILIApRWPUYiihMQn13vh8NWAECjdXBa+6hwIogoyHOcFOk0/oAIUpwIgiAIgsg84ax67NwlUo8TzwuwueMvnJwen1wwOdyDs8+bCieCiALz+7JdGwAokGY5UY8TQRAEQRDZQDirHjt3cUZQnOweH5StSodiRJI3dNrl6zvi6IcaiFDhRBBRcIax6pnIqkcQBEEQRBbhkcanaBRWvViKU/BolViKU32Hv7CKJ0hiIEKFE0FEwa84+f9UWLIeKU4EQRAEQWQDXl6UgnQJKE7B5zGxFKcDHb3y11Q4EQQRgCAIIQNwAX+PUzcVTgRBEARBZAHRUvUiKk6u4MIpluLkL5wcbiqcCIJQwIomIDAcokAv9Ti5qHAiCIIgCCLzMKteuFS9SOoQU5yqTAYAsWc51bf7FSnqcSIIIgDlDk3YOHIn9TgRBEEQBJF5mFVPo7TqMcXJG15xYhvAdSVG5OvE85xos5zqA6x6lKpHEIQC5glWq7gA6ZviyAmCIAiCyCZYHHnYHqcIRQ5TnAoNWtSV5AEAGiLY9VxeX0BRRT1OBEEEEBAM8fpFwF+PA1w2uXCicAiCIAhioLGtsRuf72jN9DKIBHGHserJPU4RwiFYj1OBXoPaYiOAyAERh7oc4BXR5WTVIwgiACZtF2p4YOdHQOtWYOcnKJTmOJHiRBAEQQw0rn51HS5b8h1aup2ZXgqRAB5fGKteDMWJtRwUGDSoLRYVp0gBEfXtvQHfUzgEQRABMMVpiMbqP7jlbTmOPDiNhiAIgiBynRarCwDQYXNneCVEInj5cFa96IqTbNULUJwiFE7SDCd2n6Q4EQQRANuhqVJ3+w/u+RRFnLjrQuEQBEEQxEDC7eXlWGvWM0PkBuGtejF6nBKw6rEZTuOqCqX7pMKJIAgF7E2hSqVQnHgPKhtXAKA4coIgCGJgobRfualwyimYVU+bgOIk9zjFY9WTFKcJVSYAVDgRBBEEe1Oo4CwBx4v2/ReA2OMkCELwzQiCIAgiJ+l1+zcE3REirInsxCsVupqAAbjxpeopFae2CLOcWI8TU5zIqkcQRAAsHKIMFvHAqJMBALqDX6IUVvh4YdDOMSAIgiAGHnal4kSFU5/psLnQYXP1y2P548iVA3Bj9Di5/HHkZqNW7uE+HDTLye3lZQvf+GqpcKJwCIIglLAdlzJ0iQfqjgWGHAVO4HGW+lsA1OdEEARBDBzsCsUp0tBUIj48Ph6nL/4S8576UlaD0ok7jFWPKU6umHOcNOA4LmJAxGGLGEVu1KoxrDQfAA3AJQgiCKf0oVHCd4oHCiqAI34KAFigXQMA6KZIcoIgCGKA0OuiHqdU0Wx1oq3HhXabq196oj1hrHoxe5xYHLmkNEUKiKiXgiGGleYhTyrG3D4ePn7wtStQ4UQQEXBJilMRLylOhVXApHMBcJiOHahGBwVEEARBEAMGO/U4pYxGhd2tP9QZbxirXqweJ2U4BICIARGsv2l4aT6MOrV8fDAGRFDhRBARYG8IZi9TnCoBUw0w7DgAwFnqtWTVAwDeB3jCp/AQBEEQuUMv9TiljCarf4BwfwQphLPq6bWRFSdBEPw9TkGKU0NnoOJ0QErUG1aWJ6tYwOAMiKDCiSAi4PLy4MCjQFk4AcARPwEAzFevkf3Bg5pXzgWenAg4LJleCUEQBNEHHAGK0+A7KU4ljVal4pT+55JZ9bSKwsagkXqcwhTBdrcPLBg4puLU4VecOI6DQSrIBmNABBVOBBEBp8eHYtighg8AJ/Y4AcDEBfBBhamqfRA69mV0jRlHECAc+BpwdALNmzO9GoIgCKIPUI9T6miy+BWn/iycNCpFqp5U4IR7fKY2qVUcjJKlL1I4BFOchkvBEEbZAkiFE0EQEk4P75/hlFcKqLXi1/ll2JV3FACgouGjzCwuW3BawfGiXbGncXeGF0MQBEH0BepxSh1NCsWpPyxtXsmqp4tTcepRzHDiOLHYqpMUp3abf5aT18fL1r3hZeLlxhi9UwMZKpwIIgJOjw8VnBQMwWx6EltLTwUADG9a2t/Lyip8tjb5a8vhnRlcCUEQBNFXAnqcfIMvMS2VNCoUp0hx4KmEKYThepycHh8EIfD3yRQnlqgHACajRu53YqrTYYsDXl6AXqNCZaEBAGCQAiKox4kgCBmXV6E4FQYWTgcr5sAlaFBm3wu0bOv/xWUJ3e2N8tdC5yC3LRIEQeQ4dhcpTqmiKUM9TkqrHlOceAHwBkWHs3CrQoO/cOI4DkOCIsnrWTBEaR5U0n2z+6XCiSAIGafHh3JYxW8KqgIu0xeU4H/8VPGbLW/388qyh+72JvlrXffBDK6EIAiC6CuUqpcaHG4fuuz+1N1MWfWY4gSEFm82Z6jiBIQGRBxQBEMwWCQ5hUMQBCHj9PIKq15FwGUFeg3+65spfrPlbUAYnJYGh6VZ/trsPDRonweCIIiBgCPAqjf4TopTRXO3M+D7/ugFCmvVUxRRwX1OwTOcGMEBEfvZDKcyReFE4RAEQQTj9PhQLlv1AhWnQoMGK/np4MEBXfuB3vb+X2AW4O5ukb828r2AvTODqyEIgiD6Qi+FQ6SEJktgKl1/KE6eMIUTx3GyAhW/4hRo1TugsOoxDFQ4EQQRjMvjQznHrHqBPU6FBi3sMKBTVSIesAxOmxqvCIcAAFCfE0EQRM5id5FVLxU0WoMVp37scVJzAccNGjYEN/D3KQ+/NWgDjgdb9eqjWfWocCIIguHy8qhA+FQ9tkPTxEnHLQf6c2lZg9oeqLQ5W/dkaCUEQRBEXwlQnGiOU9IEK06u/uxxUgee2usjqEP+wimyVc/HC3IUeYDiJBVjVDgRBCEjxpFbxG/CWPUA4JBQJh4YpIWTziVa83oE8Y22p4lmOREEQeQqdgqHSAnBilN/FBjhepwAwKANrzj1RLDq1ZX4Zznta7PB4xOg06hQYzbK12GKk5PCIQiCYHDuXuRzLvGbEKue+EZT7ysXDwxSq57RIxZOG/lRAABPGylOBEEQuUqvIo483NBUIj5YFHm1WZx71B/hEP4ep0Crnl4TXnFiceTBhZPZqJXPcb7aI7pKhpb4o8gBfzgEKU4EQcgUejsAALwmD9AXBF4meYL3eUvFA12DU3Ey+SwAgD36CQAAtaU+c4shCIIg+oSDFKeU0CQNvx0hJdH1R48Ts+rFqzjZIqTqAf4+p9VS4TRcYdMT75MVY4PvNUKFE0FEwCQVTr78ypDL2A7NIWHwKk6814Mi9AAAXFVHAwDyexsyuaQBCc8LuPXfG/GHpTsyvRSCIAYwgiBQj1OKaJQUp5HlYuGUqVQ9wK84BfdZsVS9Qn24wkm05a3dJ7pKhimCIQAKhyAIIghBEFDEi8EQQkFo4aTTqKDXqNCgLJz4wfUh0ykNv+UFDqbRxwIACrydgMuWyWUNOPa12/DOhsN4/ot9EGhOFkEQacLl5cEr3mJIcUoOm8sr9w+xJLp+mePkDW/Vi6U4BafqAf7CiV1HOcMJoHAIgiCCcPt4lEuJelxhaOEEiH1OTUIpBE4N+FxAb2t/LjHjWNoaxf+5QgypGYJOQbIzdu3P4KoGHg2d4s6ljxcG5YcUQRD9g7K/CfArGERisEQ9k0GDsgI9gP6KIw9v1Yvc4xTbqscItupROARBEAE4PbycqKcKStRjFBq08EENd550+SDrc7J1iopTt6oIdcVGHBTEAlOgWU4ppUEaQgj4rRUEQRCpxh50EkyKU3KwRL1qs1FWe/qlx4mPZNWL0eMUxarHGB5k1TNQOARBEEqUw29VpkiFk/hmY8+vFQ8Msj4nR1czAMCuLcGQYiPqpcLJ3kzJeqmEzdAAgB4XFU4EQaQHZX8TQIVTsjDFqbrI4J+h5E1vgSEIgkJxCrbqhSpOgiBEnOMEBBZOWjUnpwMyjBFmQw0GqHAiiDA4Pf7ht1wExYnt0vQYqsUDgyxRztMtWhM9hhLoNWp0aIcAABwtNMsplTCrHkCKE0EQ6SNEcSKrXlIoFSc5tjvNljZWNAGAVhNBcVL0WTk8PvikhrbwipPfmldXkgdNkIrlD4cYfK8RKpwIIgwurw/lbPhtQUXY67Bdmi5djXhgkClOgq0NAOAzikOAnYVDxeOd1OOUSgKseqQ4EQSRJuwu8eReF8HaRcQHU5xqzIZ+i+32KsKptKrgOPJQ1YttwnEckCcVQUqUs5yCbXoB90mKE0EQQGCPEwoiKU5iEk2HdnD2OKkc4nwHVYGYLOgrHgEA0PcMrgIyIoIA/Pcm4LkTAFvywSEBVj1SnAiCSBPMqlecJ362kVUvOZqY4lTkV5xcabbqebwKxSlkAG6o4tSj6G/iuMDrM5jqNCwoGAJAvylp2QgVTgQRBpfbiVJOnFGEiOEQ4m5Ms0pSpAaZ4qR3ifMdtGaxt0lfPgoAUOBsBrzujK0rE7yy9gAu/NtaWB0e/8FNbwDfLwGaNwPL70nqfq0OD7oVxRIpTgRBpAu7VDgVGXUARKsejUBIHDbDSVScpNjuNBcYzFbJcYBaFVQ4RVGcTGGiyBlsBtXoioKQyygcgiCIAHw9LQAAL9SAsSTsdVjh1ASpcLIeAvjB8yaS5xELJ2ORWDiVVtahV9BDBX5QFZGCIGDxp7uxZl8HVm4XXzfobgQ++b3/SpvfAOpXJ3zfSrUJAGxOT4RrEgRB9I1eyapXJClOggB4eSqcEkEQBDRZ/IqT3yaX3iJUHn6rUoUoSOEUp2iJeozbThuH358+HudOGxJymRxHToUTQRAAAKlwsqiKAFX4PxNWODX6igCVFuA9QE9TPy0wswiCADMvpg4Wloo9XnUleTgoSEXkIJrldKDDjnabCwCws7lHPNv44EbAZQWGHAVMv1i84ke/BXxi4fPh5ka8+FXs5+hQV1DhRIoTQRBpwi5b9XTyMbLrJYbV4ZFVmGpFj5OPFwICHFKNN0KiHoCA4o0RbYYTY0RZPq6ZPQp5utDr+C2IPPhBVlxT4UTINFocITvcgxVOGmZrVYdXmwB/j1O3WwDMUiT5IOlz6rJ7UAKxcDKXiYXT0NI8HBBEW6OvY2/G1tbfrDvQJX+9s6UH2PAKsGcFoNYDC54F5j4gqpZt24FvnoPby+PWNzfhwQ+3YU9rT9T7VibqARRHThBE+mCpesX5fvsWFU6J0SipTSX5Ohi0atmqB6Q3kpxZ9YIT9QCl4qSw6sWhOEWjv36ubIQKJwKAuBty7l9XY95TX4Tscg9G1L2i4tStLo14HaY49Tg9QJGYKDdYLGqtHZ3I50SVRWcSVabKQgMOgc1yGjyR5OvqO+WvrU37gKV3id+cfDdQPg7IKwFOfUA8tuox1O/fLZ+M7Gy2Rb1vlqjHLOsUR04QRLpghVOhQSv3yVAkeWI0Sf1NbO6RTq0Cc86l09YmW/XUoaf14RUn0f0QTXGKhkHjT+IbbAERVDgRAIBuhwct3S7Y3T4s/nTwnPRGQmMXFSebNp7CyQsUDxMPDpLCydIuWhLd0AL6QgCASsWhO09U3jxt+zK2tv7GrzgJuNXxNODuAeqOAWZe57/Skb8EamcAbhuMn98nH94dU3ESC6eR5WJzLln1CIJIF73S+4tRq5YtX6Q4JYZyhhMAcBznHxbrTt9zKVv1VKFWvbCKk7QJV5ik4qRScfL9DraACCqcCABAl92fgvb2+kMxLUQDHZ1DnFFk05VFvA4rnGwur0JxGhxWPVuHWDj1qIsARSOq2zQcAKC21vf/ojJAZ68be1pF1egKwyqcoN4Cn9oAnPNXQKWYjaFSAWc9AXAq1DV+guNUWwAAu1tiKU7i7uWEahMAUpwIgkgfTHHK16uhk5QLUpwSQ57hVGSQj4Wbo5Rqoln1wilObBOuMEnFCVAGRAyu1wgVTgQAwKKIUeYF4InluzK4msyjd4qFk0MXTXESfeA9Ti9QNFw8OEgUJ6e1GQBg1wb2gGlKRwIA8nsPAfzAfzP9XlKbji+z4TbuFQDAhrE3AmWjQ69cPQX40ZUAgIc0L0EHT1TFSRAE2TY7oVpU9ajHiSCIdMEUpzydBjrJikWKU2I0BSlOgD9IIVNWvXCKk3+OU+Q48lj0x8+VjVDhRAAArHaxcCrJ14HjgE+2NGPzIUtmF5VBjC5xuKvTUB7xOqyp0uZUKE6DJBzC2y1aGd2GwMKpsHI4PIIaGsEN9DRmYmn9yroDYn/T71WvwSA48Q0/Hh/q50e8vjDnTrTDjFGqJlyh/hj723vlD7xg2mwuOD08VBwwrlIsnEhxIggiXTDLVb5eLZ9sU+GUGI1hFCd9P8xyYp8jmjBWPaY4KX+XtjhS9WIxWGc5UeFEAPBb9SZWm3DukWJm/x+X7czkkjJKnrsDAOA2Ri6cTEZpurqPh71AmnPQfRjwDfyTW6FXVOSEvMDnp7bUhEOCZG/sHPiR5OvqRcVppEfsC3zS8zPsaO2NeP1mtwGPuC8CANygeRcGXy8OdIS/PkvUqzYbUSTFA1OPE0EQ6SJQcSKrXjKEU5xYkIIzjUUo63HSRUnVc4ZJ1Uu2xwlQFE4UDtF/fPHFF5g/fz5qamrAcRzee++9mLdZtWoVpk+fDr1ej9GjR2PJkiVpX+dgwCIpTuY8LW45dSy0ag5f7m7H13vbM7yyDCAIyPeIhZMnhuLEBgXWOwrE+GnBB3Qf6pdlZhK1XXxdqAoCn5+6EqMcST7QZzk5PT78cMgKFXjkuUQF7qBQgZ3NPREHHW5v6sa7/PFo40ph5NwYwx2K2OfEbHq1xcbAfjqCIIg0IPc46TT+HidSnOKG5wU0y4WTX3FivUDpLDDccaTquVKsOBm1FA7R7/T29mLq1Kl45pln4rr+/v37cdZZZ2HOnDnYuHEjbr75ZlxxxRVYtmxZmlc68GE9TsV5WtSV5OHCGaL17I/LdqZ12nVW4uiCRhCfD29+RdSrjpLSzva22wdVJLneLVrUdKbKgONDS/JwQBqC620f2LOcfjhshdvHY0y+ExzvhcCp0M4VocvuQZs0EDeY7U09ADhYjHUAgGFcC3ZFKJxYol5dSV6gLZQgCCIN9EoDcI06tV9xosIpbjp63XD7eHAcUGVWhkNIPUZpDIfw9zhFTtVTKk7dLI68D4qTPxyCCqd+44wzzsDDDz+Mc889N67rP/fccxgxYgSeeOIJTJgwAddffz3OO+88/OlPf0rzSgc+FsmqV2QULUHXnzwaRq0aGw5a8On21kwurf/pEYMPuoQCaHWGqFcdVZ4PANjbZhs0fU6CICDfI1rUjMWBhZPZqEWLuhoA4GjZ0+9r60++k+Y3zakSiySuoAp1pWL63a4I85m2NXYDALzm4QCAYaqWiAERzKpXV5wn7wq6fXxaP3wJghi82F2KVD0WKECFU9ywGU7lBfoA5Ue26qWxwJDjyONVnFwp6HHqh58rG8mpHqc1a9Zg7ty5AcfmzZuHNWvWRLyNy+VCd3d3wD8iFGbVY9azikIDLps1HACwaNlO+PhBpDrZxOG3bYJZfsOJhKw4tfUOmllOVocHJRD/jgpLqwMu4zgO9gLxeRAGeI/T91J/09El0sBo8xCMlUIcdraEL4a2N4nPm6FiFABgKNca0arHht/WlRiRr/N/uJHqRBBEOmCKU4BVj3qc4qbRItn0iowBxw0ZtuoxxcnLC/BK12OFk6kvhVM//FzZSE4VTs3NzaisDNzhrqysRHd3NxwOR9jbLFy4EGazWf5XV1fXH0vNOZhVz2z0R1NefeIomAwa7GzpwQebDmdqaf2PVDi1CkXxF06ttkEzy6m1x4VSzgog1KoHAELxcACAoecAMEBtnjwvyINvJ+RJRZJpCMZWiYXTrubQwsnu9mK/FARRWjcegGjV29dukz/MlPgLpzyoVRzypQ8p6nMiCCLV+HhBnseTR1a9pGCKU4050KnSH+EQ0ax6yvMYl5eHIAj+HqcUxJE7aI7TwOLOO++E1WqV/zU0NGR6SVmJVbLqFUvpXYAYFPGb2eLO+J9XDmzbVQCSVa8VxbI3ORKjKsTCaV+7Dbx5cChOrVYHSiAVBvmh4RnGCnGWk85rA+yd/bm0fmNvmw1WhwdGrRpVnPQzmmvl2PAdYRSnHc09EASgvFAPU80YAMAwrhUen4ADUj8Tw+vj5d3LuuI8AEFzwwiCIFKIssE/X6+hwikJwiXqAf4ep7TOcZJ+T5ooihNbg8vLwyu5iPoWDkFx5FlPVVUVWlpaAo61tLTAZDLBaDSGvY1er4fJZAr4R4TSFWTVY1z4I1FF2d/eO3h8rDaxp6tNMEOvia441RUboVVzcHp4tGkk9WWA9zh1drRCy0mvhfyykMury0rQJEjznQZost53kk3vyLoiqHskNdY0BOMkxWl3Sw/4IHsrs+lNqDYBxSMAAGWcFflwYHdQodVkdcLHC9BpVKgo1APwf8CR4kQQRKqxS+8rKk480fan6g2Sz/0UEG6GE9A/BQYrhHRhCieVipOPu7y8vPnGcUBeDFdNNFg4hGuwnBtK5FThNHPmTKxcuTLg2IoVKzBz5swMrWjgIIdDBBVOZqMWbJ5at2TnG/DYJMVJKIqpOGnUKgwvlQIiPKXiwZ4mwBs+VW0g0NspPj8OVQGg0YdcLkaSS0Vk577+XFq/wQbfHj28GLCywqkGw0vzoFOrYHf7cNgSaB/2F06FgLEIMBYDAOq4tpA+J2bTqy0yQiX9AVKyHkEQ6aJX6lPJ02nAcZysOHl8A9NunQ4iK06swEifeueOYtUDApP15GAInUb+fEkGg4biyPsdm82GjRs3YuPGjQDEuPGNGzfi4EHR6nTnnXfi4osvlq//m9/8Bvv27cPtt9+OHTt24K9//SvefPNN3HLLLZlY/oDBxwvolk7GihRWPUDcqWCDXq2DpXDqYeEQxTF7nAB/n9MOqw7Q5gEQAOvAneXktEqFk6447OV1xXk4wIuFkzBQCycWDDG8RBx6DADmWmjUKtm+uTOoz0mMIheHTAOQVadhXAt2tQYWToekRL3akjz5GM1yIggiXfiH34qfeRQOkThN0mZZdbDi1A8hCh5v5FQ9ANArkvV6WBR5H2x6AIVDZIR169Zh2rRpmDZtGgDg1ltvxbRp03DvvfcCAJqamuQiCgBGjBiBjz76CCtWrMDUqVPxxBNP4IUXXsC8efMysv6BgrIgUoZDBB8bNIUTS9WDWW7qjMaoCklxau8Filif08C16/m62wAAHn1p2Mtri/2znDxtA2+WU2u3Ewc77eA4YFptgdwTB9MQAMC4SqlwUtjveF6QFSe5cCoRC6ehXEuIVU8Ohij271wyxamHCieCIFKMPPxWep+hOPLE8PECWnpEp0lNkOIkqz1ptD16+cipegFr8Phk10JhHwunwdrj1LdnrY/Mnj076nDVJUuWhL3Nhg0b0riqwQez6RXoNWH/6AZr4RSPVQ9QRpJLyXpt2wd0n5NgFwsnIUwwBCDurnUZagEf4GnfB13Ya+UuLE1vfJUJJk8nIPgAlQYoEItFlqynVJwOdtphd/ug06gwokwstJWK0z/be+H18XJjr3L4LYOsegRBpAu7O0hxonCIhGjrccHHC9CoOJQXBlrYmXMlnX3isax6/iG8vLz51pfht4C/cBo0/e8SOdXjRKQHFkUe3N/EGFSFk9sOuERloFUojhkOAQy+WU4aRzsAQFUQvnACAI9JfB40lvr+WFK/wgbfHj2s2G/TK6wGVOJrZTyLJFeoSExtGldZ6E89khSnEepWuL08DiqS9Rq6/MNvGcxWwWwWBEEQqUJWnHSBihMVTvHRKEWRV5oMUAf1DfVHbHdMq55iWK0cRW5IPooc8FsQnRRHTgw2IgVDMAZij9O+Nhs+2NQYqnhKapND0KEHxrgUp5HlooLQ1uOCI1+0aw1Uq54gCNC7xMJBZ66IeD1NmRhJrne1A67wA15zle8PsP6mYn8vm2TTAyAPwd3bZpNna4TY9ABZcRqpFhW83Yo+J7/i5Ld8FOqpx4kgiPQg9zjpg3ucBpeakCxNbPht0AwnoH8UJ0+UAbgAoFcoTuwzpLCPihMrxgabVY8KJwIWFkVuDG+qKpIKJ3a9gcDv396MG1/fIJ8Ey7D+JsEMgJMbKqNRaNCi0iRK802clCY3QBWnHpcXRYI4/DavuDri9crKKtEpiErcQErW63V5sbVRLIJ+NLwE6G4ULzD7C6chRUbk69Tw+ATsbxcH3m5TJuoxJMWpgm+DBl65z8np8aFV8sqHU5zIqkcQRKohxalvsOG31UWho3Fkm1xa48hjWPWUilOqrHoUDkEMViwRZjgxBqJVr75D3NHf19YbeIFi+C2AuBQnABhZJhYJ+1kk+QDtcWrtdqGUE4sAnSmy4jS0JA/1QpX4zQAqnDY2WODjBdSYDagpMvqtegrFieO4kD4nlqg3Qak4FVQBGgPU8KGG65AVp0OSTa9Arwn4m2QT3ikcgiCIVNMr9Tixk2E9FU4JwQaW14RRnPojRMEdM1UvdI5TX1P1qMeJGLTEsuqxwmmgzHHieQGdveLP3NztDLxQGn7bKhSB48IPkwsHS9bb4igSD/S2Ah5H5BvkKK3dTpRBVJwQIRwCAGpLjNgvF04DJ1kvIIYcCGvVA8ReJkDsc7LaPfJMpwk1isJJpQKKhwMQAyLYLCd5hlOxERzn3z0kxYkgiHRhdzHFKSgcguLI40JWnMIUTnpt+nuBYln1mOLk8vhgc0lx5CkKhyCrHjHokMMhIlj1Bpri1GV3wydN2WYD62Sk4bdtghl6jSrgxDUaLCBiWycH6KWT4wFo12vt8StO0QqnuuI81PNi4SR0DJzC6YfDFgDA9KFF4gF5hlNQ4aRQnJhNr7bYCFNwM64iWW9vmw0+XsChMIl6APU4EQSRPphVL4/FkatJcUqERjb8NoxVrz8KDE+sAbhhFKc+x5Hr/BHngwkqnIhBZ9Vrt7nlr5utQapQD4sij2/4LUNO1mu3K2Y5DbzCqd3agyJOsjdGKZyqzQYcgFg4edv29MfS+gWmVFaxOR3WUKse4Fecdrb0yMEQATY9hiJZz+Xl0dBpD5uoBygUJyqcCIJIMSyOnClOTLmgOU7xwYbfBs9wAvyW//SGQ0S36hnCpOr1tXCicAhi0NIlW/UGh+LUbnPJX0dSnFpRFNfwW8aoCrFwOtDRC95cJx7squ/TOrORnk6xsOShAozFEa+nUavQqhWLCW4A9Th1Sx84JqMG8HnkMBGYawOux3qcDnbasf6gaO8LWzhJitMEfQcAMVkvXKIeoBiAS1Y9giBSTC9TnILCITxk1YsJzwvyeUWFSR9yOduEdWXQqqcPO8cpdXHkPB95JutAgwonQi6IWHpeMAMtjrytx184hfY4+VP14g2GAIBqkwFGrZik1mOsEQ8OQMXJZRWfH6euWOzRiUKXQSwgNY42wNUT9bq5ApuhZDJogZ4mAAKg0gJ5ZQHXKyvQozRfB0EAPt0uPmcToyhOw1Vib92ulh65xylEcZKtegPj75AgiOzBLp1M5+uDepxIcYpJj9MLVjeEc+4wq57bx8ttAqlGLpw0ERQnbbg5TqnpcQIGlzJJhRMR06rHjlsGSOGkVJwsdo8/SrP+K6BlKwCgQaiIa/gtQ6Xi5HlO/kjygZes5+sRT/C9htKY19XkFaFdkIqFAaI6dTvEDxyzUauw6dWELSJZnxNrCA5bOEmKU7lHLML2tNrQ0ClZ9YJ7nKQPOaeHp11ggiBSij9VLyiOnN5rYmJxiK6dPJ067HmD0vafLruel1n1VBF6nDShc5z6Gg6h/LkGk12PCicibque28sPiCbANkXhBEiqU08L8NZlgMCjadg52CsMSUhxAvx9Tvt9kvowABUn9LYDAIQghSUcJoPWH0k+AAIi3F5e/nAoNGgUwRC1Ya/PBuEC4gdUbXGo9x1FQwFOBS3vQDms+P5Al6zsBl8/X/Eh10t9TgRBpBD/HCcpjpzCIeKmS9p8Lo5wDqVXqEDpOodyx0rV04bOceprj5NaxckF9kA4N4wXKpwGOV6fP2ElkuJUoNdALe1iDAS7XnuPO+D7pq4e4O1fixHi5ROwaep9ABDX8FslrHDabi8SDwzAHietQyyc1IWRZzgxTEYNDgiS+jYAIsmZTQ+QdurCzHBSwhQnQBx8qwq3E6jRASax8BrKteCg1N9Umq8LKJQA8QORFfPU50QQRCqxR+hxosIpNl0xRrqoVJxcPKVLmYll1QtQnFIUDgEAhjT/XNkIFU6DnG7FCZg5Qo8Tx3EwSX9gA6FwClacSr9dBNR/CegKgJ+/gl5BbO5MJFUP8M9y+rbbDIADHF3yXKiBgM3lRSFvAQDozZUxr28yaLGfZ4pT7lv15KGBeg00alWgVS8MSsUpbDAEo2Q4AGCUpk0+VBtk02OwZl5K1iMIIpUM1h6nXpcX39V3QhCS7z2KNQsTUCo+6Xk+5cIpklVPevxuh0dWp/pq1QP8ARFyy8MgIKnCae/evbjhhhswd+5czJ07FzfeeCP27s39HeXBCPuDL9RrIkq8wMBK1muXwiHKCnSYo9qAcbv/Ll7w4z8DZWPg9IpvAIYIOzeRkBWndh+EkpHiQalnaiDQ2u1EKcRoba0pHsVJYdUbAIpTt6Q4ybt0Ma16BfLXUQsnqc9pSl6nfKgunK1P8dhUOBEEkUoipeoN9B6na15bj589twZr9nYkfR/+PvHwVj3AH6SQ9h6nGIqTchxLvi4FhVOaf65sJOHCadmyZZg4cSK+/fZbTJkyBVOmTME333yDSZMmYcWKFelYI5FGmDfXHGWnBFAUTvYBUDhJitPsSgf+pP2reHDGVcARPwXg3xFK1Ko3oiwfHCcWl+7S8eLB1m2pWXQa+Nc3BzFz4UrsaO6O6/rxDr9lmAxa7JcLp9xXnFgwhDzE1npI/D+CVa/QoMXYygJwHDB9aOTodpasN07XLh8KDoZgyMl6ZNUjCCKFyHOcmOI0COY4bWqw4ItdotK/p82W9P34e5yiKU7p7QWKt8eJnf8U6DXh7eMJYuiH4b7ZRsLl5h133IFbbrkFjz32WMjx3//+9zj11FNTtjgi/VgdsSVmYOBEkvO8gI5eN3Tw4DbLYyjierFPPx4jT3tYvo4rScXJoFWjttiIhk4H2oyjUAsALdlbOL2/8TCarE58tqMV46uiKCISLd1ODOOs4jdxFE5mZY9Tbxvg7AYMsR8nW5GjyI1McWoU/zeHL5wA4PlfHY1GiyOg3ymE4uEAgFq0yIeCo8gZ8iwnUpwIgkgRbi8vD1DN0w6eHqfn/ud3Qlj6sCksW/WMkRWnfrPqqaOn6nVIilMqbHpA4CynwULCitP27dvx61//OuT45Zdfjm3bsvckkQiPJUYaDINJ0LkeSd5ld8PHC7hV8xaqerfDIuTjIePtgMY/tI69ASTa4wQokvXUw8UDrdlr1TvUJcZes4GrsWjrcaEsEcXJqIUNebCqisQDOW7X61bOcPK6xDARQA53CMeIsnzMGh0jgVCy6pW4D8uHgoffMtjcDVKcCIIIpqHTjn9+XZ+wqqHsT2EnwkqrXl/6f7KV/e29WLq1Wf6+L5vCsUa6AOlXZmSrXgzFSe5vSkEwBAAYNINPcUq4cCovL8fGjRtDjm/cuBEVFbH7HojsQrbqRQiGYJiNAyMcgvl7z9J8BwC4x3MZfrAFqiAu6Q0g0ThywF84bfZIJ9Ot2wE++95QPD4eTVaxcDoYZ+Gk7HFCfnxx5ABwWCWFJ+R4JDmz6olR5JLapDEAeSV9u2PJqqd3dSIf0gynCIpTIQ3BJQgiAouW78R9H2zFh5ubErodm+GkU6vkgolZ9QQB8KZpaGsm+dsX+yAIACcJNH1RnFiqXrQN6Exb9fRBDpqUK06DKBwi4WfuyiuvxFVXXYV9+/bhuOOOAwCsXr0ajz/+OG699daUL5BIL9Y40mAAf2HVnfOFkwsq8KiC2Aj6PT8W7TY3XF6fPLjOKRdOiStObAjuum4ToDECXgfQuR8oG52inyA1NFud8qTzeAunLmsXjJzUWBqn4gQAB1CFidiW831OsuJk1CqiyGv8n7zJYjADxhLA0YljiqzYiRIMiRAOQYoTQRCR6OwV35/r23sTuh3rb8rT+z/zdIoTbbeXjxoelWu09jjx9nqxR/XcI4fgnQ2H+01xSlfhFMuqF3w+k4oocsAfDjGYFKeEn7l77rkHhYWFeOKJJ3DnnXcCAGpqanD//ffjxhtvTPkCifTCrHexrHoDJVWv3eZCBbqghReCSoMuTSngBVq7XXJDvhwOkWCPE+BXnPa2O4GK8UDjBtGul2WFk9Ke12hxwuOL/cHotojWNK/aAI0uP+ZjsF6gvT42yym3CycWR24yaP2KU4RgiIQpGQEc7sRzZ5XAN+6kiL8L6nEiCCISzHLXaHEkdLteFxt+6z8l1CnegzwDLFlvyep6uL08pg8twikTKqXCyR37hhHwz3HKXKqeJ4ZVL/h8JlWF02AMh0j4zJDjONxyyy04dOgQrFYrrFYrDh06hJtuuglcX3deiX4nfqvewCic2npcGMKJ6WWcqQblJrEAaO52yteRwyH60OPU0GWHt2yCeDALAyIauvyFk48XQj9o+dAPSm+PVDgZSuNSWZhVb6dHsvDmvFVPEUfOEvUiRJEnjNTnpLMekK0PATR8B7RuJ8WJIIiIsJPXw4kWTkxxUrz3aNQqsNC1gRQQ0eP04JW1BwAAvzlplKwS9eXcxhpXql76QhR4XoCPj6/HiZE6q156LYjZSJ+018LCQhQWRkmLIrIeSxw7JcAAKpxsLtRy0qDRomGoMhsAAE1Wf+GUbBw5IM6GMhk0EASgI19SmbIwIIIFQzAC7HrL7wb+MALYtVw+5PHx8HaLqW+qgtg2PcD/mtknK045XjhFsuqlAqnPCV37Qy87/D3wj1OBJWfDpBPPZGiOE0EQwbCT10ZrYoWT3cVmOAV+5jG73kCKJH/j2wb0OL0YVZ6PuRMq5c+pZHucPD5edgBE73FKnzLjUWx0xkrVY7Bh6n1lMIZDxFVyTps2LW41af369X1aENG/WB2xd0qAgRNH3t7jRq2kOMFch2qXWDg1Kz5okh2AC4iK7KiKAmw4aMF+9QhUAlk5BDc4Se9Ahx0njAHgtALf/h3wOoF//wI4/2Vg3Blo6LSjSB5+WxnXY+Tp1FCrONTz0vXtHYDDAhiLUveD9CPdSquelRVOKbLqSYoTOoMKJ0EAlt0NQADs7aj0io9LhRNBEMGwTb9mqxM8L8Q9p8fuCRx+y9CpVXB6+AEzBNft5fGPr8T32KtPHAWViuuz4sQKLo7znyeFI53hEMymBySgOKWqx2kQhkPEdWa4YMECnHPOOTjnnHMwb9487N27F3q9HrNnz8bs2bNhMBiwd+9ezJs3L93rJVJMV5zhEGw+Qc4XTjYXhsiK09AIilPyVj3Ab9f7wSOdVHfuB9yJNeummwZJcao0iTHsciG19T2xaAIH+NzAv38F7PgIe9t6UQpxhhMXRzAEIBaRJoMGvTDCmyfZ9XJYdWJWPZNR41ecUmXVi6Q47fgQOPi1/G2VfTcAf78VQRAEg312eXyCPOg0HuyuwOG3DJ2kJgwUq957Gw+juduJSpMe50wT3QJMcXJ5+aSKGtYbZTJooY5SqKbTquf1KRWnOHucUmTVG4w9TnE9c/fdd5/89RVXXIEbb7wRDz30UMh1GhoaUrs6Iu1Y5B6nGFY9titj90AQhJztZ2u3ufyKU1Edqu1McQpj1UtCcQL8hdMWq05Mn+ttA9p2AEOO6sPKU8shqcdp1qgyvLPhsN+qt+l18f+T7xaVsq3vAG9eDGHiQsUMp9hR5AyTUYsuuweOwmEotLcCHfuy6nlIBFasFBqUVr0UK07WQ4DXDWh04v8r7hWPa/MBTy9KenYAqCLFiSCIEJQnr4ctDlSYDHHdrtcdXnHSD6AhuDwv4G9fiAFFl88aIafoFug1UKs4+HgBFrsHVebENky74uhvAtKbPscUQRWHiMVbusIh/D9X7r9G4iXhM8O33noLF198ccjxX/7yl3j77bdTsiiif/D6ePlkMNYfPduVcfv4nJ4QrQyHEBUnMfZZqTgxP3fyipMYOLG3zQZUTBQPZlFAhNPjQ0u3uBt5nDSc9WCnXUy9O7gG4FTAkb8AfvJ3YPLPAN6LU7bcgVNUkg03TsUJ8AdE9OQNEw/kcLIeU5zMGo9oOwRS1+NUWCXG1ws8YJU2oNb9Q3y+8iuAOWKCqdmyHQCFQxAEEYggCAGKSaPFGeXagURWnPxDcHOdlTtasafVhkKDBhcdM1Q+znFcn3q4u6QIeHOMPnFm1XOl0aoXLRlXo1ZBoyiqUm7VG0SKU8KFk9FoxOrVq0OOr169GgZDfLsbRHagfJOIlaqXL/WrBN8ul+B5AZ29ToXiNBTV5lDFydVHq95ISXHa19YLgRVOrdlTOLHEpTydGlNrzQCAgx12CJveEK8wcjZgqgbUGuDc54EpF0ANH4apxFS9hAonKZK8y1AnHshRqx7PC7BJyVNmr/T60eYBxuLUPADHAcXDxa879wOOLuB/j4vfz7kLGCbOzDN2bAUgkOJEEEQAbh8P5ZzapgQCIiIpTiySfCAoTm+tEzekLjpmqOgaUFAkB0QkHkluibNPvC+WNpfXh3ve24KV21vCXu7xRh9+y1CqTqlK1Uv3YN9sJOFn7uabb8Y111yD9evXY8aMGQCAb775Bi+++CLuueeelC+QSB/sD75Qr4Emxh8c25Xp7HXD6vDIvUG5hMXhQTFvhZ7zQOBU4ExDUK0W/9hbe5zw+nho1CpFj1NyVr1aaXip3e2Do2Q88gCgZUsqfoSUwBL16orz5NlVNpcb/MY3oAaAqRf5r6xSAwv+ig9+aMGPhc/FYwlY9VhB3qaTLG05Gkne4/JCkE5KClzSh5dpSN+H3yopGQG0bRf7nPZ9LhZP5ROAab8CeA/AqaF2dqISXWhxlSTU/E0QxMAm2AmSSCS5PUwcOaBQnHK8cOJ5Ad/WdwIATp9UFXJ5X8KvWLEVaxZmXwbgrtnbgVfWHsD6g104ZUJoOJOXjz78VrkGViSn3Ko3iMIhEn7m7rjjDowcORKLFy/Gq6++CgCYMGECXnrpJZx//vkpXyCRPuT+phg7JQxl4ZSLtCuiyLnCGkCtRWmBBhoVBy8voM3mQrXZCGcfrXoGrRol+Tp09rrRbBiFkUBWWfVYEERdiREGrRpVJgOG9myA2noA0BUC488KuL7F6cNNjl+jUVOAK0d1QT302Lgfi1n1mtSSpS1HFSdm09NrVNDZmsSD5hT1NzFYn9Pez4HdUhT8aQ+Lyp9aA5SNBdq2Y5KqHi18CXrd3pCdU4IgBifBJ+SJDMG1R1Cc2Il4rseR72zpgcXuQb5OjSOGmEMuZ+FYlmSsetJ5VKyArb6EQ7TbxOIsUmS62xvbqgcEK04piiMfhOEQSW2pn3/++Vi9ejU6OzvR2dmJ1atXU9GUg8S7U8LI9Ujy9h7lDCfROqZWcag0BSbrsQ+gZMMhAMgWwAOqOgAcYG8HbK1J318qYYpTbbGoNg0tycNP1V+KF05aAOjyAq6/t60XAlT4Z/5lUF/2EaDLj/ux2GumAdIun6MLsHf27QfIAKwXUJzhJA2/TVUwBIMl6+38SFSYRp0MjJnrv7x6CgBgsvpAwJoIgiBCC6cEepzcA7vHae0+sSf16OElYYsL5ozo7oPiVBQjYKsv4RCsj4rNEgzG44vPqqfcDE5ZjxMVTsRgwhLnTgmjKMcLpzZbYDAEoyqoz6mv4RAAUC2FThzq5YCSkeLBLJnn1CAl6jFL4cgiFc5UfyNeeORFIdff12YTr1cef8HEMElvzh1uLVBYLR4MnlWUA7APrEKDJvUznBhMcQLEgI7THg68vEosnKaoDwKgWU4EQfgJPnFNqMfJFaHHSUqe8+S44sQKp2NGloS9vKgPQ3DZbYrzYylOyfcCsbExNpcXvLKRTSJeq54uDT1OLBzClcOhYYmScOHk8/mwaNEizJgxA1VVVSgpKQn4R+QOTJaOFQzBMPehgTIbaAtQnEILpyarEx4fD5/0xsQmYidDTZF0nxYHUMmS9bKjcDokW/VEZWk2/w0KOQc6tNXA0Jkh19/XLs6gGllWkPBjMcWp2+kBSkaJB3PQrifPcDJoge5G8WCqrXolisJp2q+AykmBl1dNBgBM4OoBkOJEEIQf1mPCTojbbe64T9JlxSm4x0md+4oTzwv4dr/ocjh2ZGnY6/QpVU+ehRlfj1Mytkf2GIIAOaRISbxWvQDFieY4JU3ChdMDDzyAJ598Ej//+c9htVpx66234ic/+QlUKhXuv//+NCyRSBfWBK16fZGzs4F2m9uvOJnr5ONVJqY4OQI+aPRJhkMAQE2RIua88gjxYJYk6/mteuIap3d9AgD4XH9K2LCDvihO5oDCSSoMcjAgojvAqscUpxQNv2UUDQUKawBjCTDn/0IvlwqnGqEFJvSS4kQkzd++2It/f3cw08sgUgjrnak06eWQB+WYjWjIipN+4M1x2tXagy67B3k6NSaH6W8C/FHiyfQ4yc6dGBvQfQlR6Or1ryvchlm8Vj32+1SmJPeVwRgOkfCZ4WuvvYa///3v+O1vfwuNRoMLL7wQL7zwAu69916sXbs2HWsk0kS8TY2MvuzKZAOBw2/9ipMcSd7tCmjcTEWP02GLQzHLKfOKU6/Liw7JL11XkgdYD6O8bQ0A4N/uWWFvs7dNUpzKk1CcDKzY9gKluas49TiZ4qQRh9QCqVec1FrgN18C130DFIYmJyGvBDCLr9sJ3EGa5UQkxf72Xjz68Q7c837m34+I1ME2/Yw6tX/jLs6AiIGcqrd2r2jTO2pYccTCoi/nNrJVL845Tk5v4gVGp8LlE27j2l84xU7VA1LX36S8T4fHB0EItREORBI+M2xubsbkyeLOZ0FBAaxWKwDg7LPPxkcffZTa1RFpJVmrXq4WTm3dzqhWPaXipNeowPUhatqvODn8lqu2HQCf2V0ZpjaZjVqxqNn8b3AQ8A0/Hut6zCEfkF4fjwMdYuE0KpkeJ2mOU4BVLxcVJ4d4YlGi8wJOi3gwVcNvleSXAQUVkS+XVKdJqnrYXLn5d0hklo0NXQDEk2FvDluwiEDkMRoadeDGXRz4U/UGnlXvmxg2PUDRv51EG4Lfqhf9PEqvSV6ZUbZHhFecEkvVS5VND/D3OAG5n74YLwkXTrW1tWhqEuN4R40aheXLxdjc7777Dnq9PrWrI9JKoql6uV44uXvaYOSkNyCz32ZVrehxSkUwhPI+m61O8OZhgMYIeJ0ZD0Y4pAyGEARAGnr7X5wEQQj9oD3U5YDHJ8CgVaFGCrxIBKY4WR2eQMUpx3amWDjEEJWUCKgrBAzhbR9pRUrWm6g6QD1ORFJsarDKX+fyCTERiEOhOA2RNu7iTdZjhVN+SDiEeIqYqyfEgiAoCqfIPfis6En03Mbh9snPTXF+jFQ9nb/HKVFlplNh1YuuOMXX41SQwjEWBoUzZ7AMwU24cDr33HOxcuVKAMANN9yAe+65B2PGjMHFF1+Myy+/POULJNJHXKl6B9YAr54HfHRbzseR622ixcqTVwlo/EV+lVQQtHQ7+zz8llFpMoDjxJ2gdocXqBgvXpDhQbjyDKfiPKBxPdC+E9AYsa34ZACQ1SXGvnaxv2l4aX5Sw1ZNir44oXi4eNBpFWPJcwhm1auCaPtIuU0vXqRkvUlcPfU4EUmx+ZBF/jqXLVhEIMxmrtf4rXrxzHISBAG9zKoXKY48R18nu1tt6Ox1w6hVY/KQoojXk4OvEjy3YWqTRsWFBGsEo9yMTaQQFQQhUHEK4zSQC6cY7QVMcSpMoeKkUatki+BgCYhI+Nl77LHH5K9//vOfY+jQoVizZg3GjBmD+fPnp3RxRHqxOKJIzC1bgZUPAruWyodKR14LIDcLJ54XUOBoArSAoAiGAICKQr1c5DArW18VJ61ahYpCPVq6XWiyOFFRMQlo3CAGRExa0Kf77gsN0s9XV2IENv9TPDjhbJT2lgEtLXJhxdjXxmx6ifc3AX7FiReAXkGPgsIaoKdRtOvl5U4KJ7PqlfOS1TPVUeTxIln1RnOH8Z7dHuPKBBGIx8dja2O3/D0pTgMHR5gep8Y4IsmdHl42AERSnHK1cPLPbyoOiOIOxpzn3+DjeSHuTUL/5rMuprVfqcw43L64zzFsLi+8igjycE4DL7PqxVg3e8zCFPY4sfv1+LyDJiCiz8/ezJkzMXNmaIQxkf0o/+hluuqBzxcCm/8NQAA4tdi07nWi3CH2puRi4WRxeFANcQCtumRYwGVatQrlBXq09rhQLykufQmGYFSbjWLhZHVgKutzynBAhN+qlwfs2CweHHMahh4Uo8kPBhVOe/uQqAeIyp1OrYLbx6Pb4UFB6SixcOrcC9T9KMmfov9hVr1iLyuc0tDfFA/mWjg1Zhi8VuR37wZwZGbWQeQku1p6Ana7c/WEmAhFDofQqlAjWcXjUZx6FfHWRm2kHqfcPCGW5zeNiL5JxxQnXgB6XN64+7797Q6xr8+UGY9PSCggQpmoB4S36rkTTNVLZY8TIL5uepxeUpyUfPDBB3Hf4Y9//OOkF0P0H14fL+9cyDGaXywCVj0G8NIf5sQFwMl3A8vvBnYtRVHPLgDDYXV4IAhCn8IT+hsxUU886VUXDw25vNpsEAsnaWZRXxUnQJzltLFB8pnXSMl6GY4kb+hUKE4sHa5oGIbaIhVOfVOcOI6DyahBu82NbqcHNSUjgfovcy4gghVOZrdYfCt75PoVjkOnaRxqOr9FSc+OzKyByFk2H7IGfE+F08DBbzNXWvWcMT+r7S5WcKlDlJZcVpwEQcA3+2IHQwCivdGoVcPh8cFq98RdOCWaTGzQiMqMM4FhsV1BgRVR48hjbPhWmMQWBdaDnSpY/9Zg6XGKq3BasGBBwPccx4U0t7E/TF+O7kwMNpSqkdmoBTr3AZ89JB4YOQc45V5gyHTx+8pJwK6lyO/aCWA4PD4BDo8vZMp4NtPe4/LPcCoKLZyqzAZsOmSVFae+DL9lVJsVyXpHSopT537A3QvoklNw+koDU5zMOv88oqI6DHWIv8sDHeGteskqToBo12u3uXM6klz8sBJQZJF61ILsnv2JrWgi0Pktqnp3ZWwNg51upwdvfteAMydXyyepuYCyvwkgq95Awq84qeWkWIfHB4vdEzW4wO6Rht/qQz/zZMUpBwunPa02dPS6YdCqMKW2KOb1zUatWDgl4KjxtzvEF7Bl0KnR40rM0tYZVDixTTwl8caR/+KYYag0GTBnfJTk1iRgSmUiBWEuE5cfied5+d/y5ctx5JFH4pNPPoHFYoHFYsEnn3yC6dOnY+nSpbHvjMgKWBNkoUEDjVoFbH1XvGDEScDF7/mLJkCO09a0b4dG2pHKNbteW4QZTgxW5NS3i4VDX4bfMvw+cydQUA7klwMQgNbMKAVWh0ferarTWAHBB6i0QEEVhpaIilNDp13eFOl2etBucwEARpQlXzgVKkNFWCR5576k7y8TdDs8OEH1A/I6t4kJiWPnZWwtjjLx73GIa0/G1jDYeef7Q3j4o+14+rPdmV5KQigT9YDcPCEmwsNsUnqtGgatGmUForoQq89JHn4bZiNUVpxysMBmNr2jhkXvb2Iw1YgVQ/Hgn+EUp+KUxCwnS0jhFCWOXBX958zXa3DOkUPk3uNUoR9kQ3ATPju8+eabsXjxYsybNw8mkwkmkwnz5s3Dk08+iRtvvDEdayTSgCV49sCWd8T/j/hp6JUrxBM1rnUbigziH0iuFU4BipM5vOIEAM3dYnxrSqx6wT5zNgi3NTN9Tiz4oaxAB6NdHCkAUw2gUqG22AiOA3rdPnRKA3KZ2lRRqEdhH95oTVIjarcykrxjX85EkguCgG6nF9eqJcvyUZeK85YyhK/iCADAMM9+gM+9E5qBQPDfSC7g9Piwq6UHgH+HmAqngYPDLf4u2e+2poh9/kSPJI80/BZQWvVy471ayVoWQz4iuk2PkUxqcFdvgoqT5GRxJqI4ST1OzG0Z3aqXmfYJo1QQDpYep4QLp71796KoqCjkuNlsRn19fQqWRPQHcjCEUQe07RRjslUaYEKYZMTS0YBaB7htGGcQY6St9twqnHosbSjkpAKmKNRmFez5TUk4hDy9XfrgqhRPeNGSmT4nlhg4pDgPsDaIByX1Ta9Ro9okPgcHpAJrb2vfgiEYciS50wOwSHKX1T9INstxeHyYKuzETPU2CCotcNz1GV2PunwsnIIWeXDknHI3UGAnCPEOGM0GtjV1w8sLKCvQiXPckJtKAhEepmIwVYPN3YsVEMEUp/wwgQG5OgBX7G8SFadjR8VXOLFeb0sC5zaJ9jjJvUBJKE5V0udzX+Y4pQtWrFPhFIEf/ehHuPXWW9HS0iIfa2lpwe9+9zvMmDEjpYsj0kfADCemNo06OXxEtFoDlItziI7QioECuaY48V0HAQB2bQmgDe1JYG9KjFQqTq09Tnh9PFCZWcWJJerVFRv9hZMi5KBOYdcD/DOcRiYZDMEwy7OcvOJznyepNZaGPt1vf9Ht8OJazfviN1MvyFwwhERBngE7BEk1bd6c0bUMVtjA0GarEz4+N3bjNzdYAABTaotyuumfCA9TMfyKU3yFU3yKU26dEO9t60W7zQ29RoUptfENKjcnoThZHSxVL0HFKYFeIKZuMzt9T5geJzmOPFOF0yALh0j4WX7xxRfR1NSEoUOHYvTo0Rg9ejSGDh2Kw4cP4x//+Ec61kikAZbUUmTUAluj2PQYUp/TOIgFSKKD4jKNpkc8SXfkh5+/U2UOLpz6/gZUVqCHVs2BF4CWHhdQPkG8oD0zvSny8NuSPH/Rogg5YG/MB6WAiL7OcGIwP7Xc1MoUP2tuFE7OQ5swV70BPnDgjr8l08tBoV6DbbwYqS80UeGUCdjOqpcX0NId3QqVLbBEvSm1ZvkEiwqngYNfcQqy6lljWfUkxSlaj1OOvU6U/U36OIOemGqUkFUvwR4n1judSC8Q2+QeVip+PofrcXLHGQ6RLgzawVU4JRyLNnr0aGzevBkrVqzAjh1ik/uECRMwd+7cnIqnHuywN4fx3AGgfReg1gPjzox8A6lwGsHXAwgvF2czxl4xQc5bGF4tqAxWnFKQqqdScag0GXCoy4EmiwNDiqvEC3pbxd6UGI2cqYZZ9WqLjcBuZtULUzh1BhZOfbfqiW8z8geSuU4cBpwjipNp3dMAgFXqWTiF9WhlkAKDBluF4QAAvmkT+v5KJRJFeeJz2OLIiWS9TVKi3tTaIny9VzyxzDULFhEZ9po0pENxyrHXCSucYsWQK5EVp4Ssem7ptvEpTnL6XAIKHlOchpWKn8PhFKdMW/UMcjhEbr1OkiWpPGmO43DaaafhtNNOS/V6iH6C7WIcbVslHhhzKmAwRb6BFGxQ694PIPeseoVOMQxBFSZRDxD/8EvydfKbVCqseoDoMz/U5RB3/WrLxYO8F3B0Afnxv6mnggbZqpfnn+GksJ0NlXa0DnTa4eMF7Jei2UeVpUhxYq8Z9jvIBcWpYy+K6z8CALxfcD5OyfByAPHDd5tUOKH5h4yuZbCi9PIf7nLgR8Mzt5Z46HF6sE+aUTel1iz3cOaakkBEhtm/5B6nOAsnOVUvTBy5PgeVSUEQ8I0UDBFr8K0Ss2S3SyRVjxVZxfnxpuolbtVjxRnb2HR6eLi9fEBSoMebYaveIOtxSqpw6u3txf/+9z8cPHgQbnfgi4yS9XID0WonYELnCvHAET+JfgMp2KDUdQgGuHKqcOJ5AaXeFkAF6MqHR7xelckgF06pCIcAgGrJLtFkcQAaHWAsFoum3tZ+LZwEQfAPvy02Kqx6/kJSGUneaHHIb85Divu2mx4QDgH4izXLwT7db7+w+ilwAo/PfEeivWBcplcDQNy4OqwbAZ/AQW1vA3qagcKqTC9rUGEPUpyynR8OWyEIwJAiI0oL9Dk9n4cIj3KOE+C36rV0iz22mggn1UxxGihWvX3tvWjrcUGvUWFqXVHct0u0x0kQBLllId4eJ2MSljZWOLEeZEDcCCmV4uYBwMNn1qqXzM+VyyRcOG3YsAFnnnkm7HY7ent7UVJSgvb2duTl5aGiooIKpxzBYndjCrcPJsdhQJsHjD09+g0KKoC8Mqjs7RjDHYbVMaJ/FpoCrA4PatAGAMgrj7zuarMB25q6AaRQcWLJesxnXlApFk62FqBiQkoeIx46e91weHzgOKBG7wA8Uoyy2d/zxQqn5m6n/DwML82DWtW3N2N/HLnkzWZ9VUz1yla6G4GNrwMAnvGeg/IUz77oC1pDAfbZazCGOww0babCqZ9RniAwC2w2w/qbptaJjfLshNiTYxYsIjJy4SRZ7sryxQLZ7ePR0uPCkAh20l53HHOccqhwYja9aUOLEvocTzRVr9vplYNhWNEVC3mOU5wFhiAIch9VWYEOBXoNbC4vepzewMIpS8IhaI5TBG655RbMnz8fXV1dMBqNWLt2LQ4cOICjjjoKixYtSscaiTRgsXtwtnqt+M3Y0wFdjD4WjpNT4carDuaU4tRuc6GWEwsnbenwiNdTBkSkIhwCCDPLKV+y69naUnL/8dIgndxVFhqg7230r0WRMFiSr0O+Tg1BAL7YJa6vr8EQgCJVL9fCIb7+C8B7cNg8Hd8L4+RerWygQK/BVkEMiKBkvf4n1xSnzVJ/05TaIgD+E2JXDp0QE9FhNilWLKhUnPyZFs2uZ3dJilMYq542B+PIv5Nteok5Olg4RLz928ymZ5QGDseDIcFBsXa3Ty5ai/N0KGSbkEF9Th5vdvQ4JdK7BQA7m3vQaHHkTDIpI+FneePGjfjtb38LlUoFtVoNl8uFuro6/OEPf8Bdd92VjjUSacBqd+Js9Rrxm1g2PYZk1xvPNeRU4dTZ2Q4zJ/b3KFPkglHOctKnSHGqZrM02PT2gkrxf1tLhFukB3+injFsoh4gWsCGSg2oq3aKhVNfgyEAhVVPGQ4BAL1tgCdLTzp7O4DvXwIAfFl1MQD0aQhwqikw+JP1qHDqfwLCIaTewWxmU4M/UQ/IzRNiIjqsb8ao+OzyD8GNUjjFoTjlUoG97oA4a/JHw+PvbwL8G3zxJgYzC128iXpA4gUGewydRoU8nVounIKH4HozbNUzJJEWKAgCfvyXr3DcY5/F7MPLNhIunLRaLVRSGlhFRQUOHhT7FMxmMxoasnwHmZAZZt+KGq4TvLYAGH1qfDeSkvXGcwdzagCuvVUMtOhWmQB9ZAWlyuxXX1Jl1fP3ODGrXoX4fz8XTv5EvfDBEIyhJeJzwHbRR/YxGALwh0P0uLzgeUHs89JJ95utdr3vXgA8dqB6KjbpjgLg/zmyAVFxGi5+QwER/U5AOITFAUHI3h3TDpsLhy0OcBwweUigVS+XLFhEZARBkF+TeoVbwh8QETmS3F84hUnVy7FeuJZuJw51OaDigCOHFiV02yIpGU+p8kRDHukSZ38TkHg4RFevP+6c4zj/Z2mQ4uTOtFUviXAIh8cnF+Ql+fE/h9lAws/ytGnT8N133wEATjrpJNx777147bXXcPPNN+OII45I+QKJ1OPx8TjF95X49ZgzAK0hxi0kKhRWPXv8yTOZxtt5AABg0UbvAwlQnFIUDsGmt3f0ukVfMyucevvbqhdm+G2YhMGhigZUIDWKE9slEwSxeALH+VWnbA2I2P+F+P/RvxbXDGSXVc+gQT0vvZ6th8Qnl+g3WEM9IJ4EdfRm7/sh628aWZYvq6a5dkJMREepCCkVpyFxJOv1Rokj1+dYL9y6elFtGl9lQoE+sffrQoMGbKJOPI4a1gtVlJDiJCkzcRYYflVLJ68RUPQLS2TaqpdMOESHzR/EFe61l80k/Cw/+uijqK6uBgA88sgjKC4uxjXXXIO2tjY8//zzKV8gkXq6e504S/0NAEAz5bz4b1g+HgKnQinXA62zPat3WQOQCgWbsSbq1QJ7nFLzh1yUp5XfLJutzoxZ9WTFqSTPX6yEVZyCC6e+K04GrVr+APbb9aTHzsY+J0HwqzhDpssDB7NJcSrUa9CKYvEbnxuwd2R2QYMInhfkHWOm3BzO4oCITUH9TQAojnyAoTxhVX52yVbxqD1O0gDcMIUGe33zAuDNgeJp3QGxv+no4cUJ31al8is61jgiyS1BRU08sALDlXThFNQvLJHxOU66xGPWWYJxab4u52bAJvwsH3300ZgzZw4A0aq3dOlSdHd34/vvv8eRRx6Z6vURacC55wuUc1ZYkQ/16JPjv6EuD0KxmEo3BgcCGqSzGV2PeHLuLhgS9XpViiG4hhQpThzHyapTo9UB5DOrXv8qToekHqfaYqPCqhfa78V6nAAxxSfetKBYRA6IyEKrnuUA4LICKi1QNk4u9thuXzZQoNfAAw16NdIJQndjZhc0iFD2J4wsE/9esjkggilOrL8JyN3BpkR4mIKhUXEBJ8+sxyna6zOa4qScFZQLr5Xvpf6mo4YlXjgBiUWSdyWlOCVq1ROLC2ZlY66H7qAeJw/PrHppKEDcvTGvkoxVr5MVhTlm0wOSKJz279+P3bt3hxzfvXs36uvrU7EmIs3odrwHAPhCPVOcLZQAXJVoxxyXQwEReQ5x+K1gihwMAYg7biw6O1WKExDU55SBHieeF2TFSRx+y6x6YQonheKUCrWJ4Q+ICIokt2Sh4sTUporxgEYnF3umFBWRqaBAep1atFJKIxVO/YayAXpUhfg3kq2KkyAIIYl6gN+qly0WrFzqmc1G/MNvAz+3hgSPwwgD2wANqzgpirBsVyftbi+2NopjNI5OMBiCwYqgeCLJLXKPU+KFU7wFRmdQcVYYoccpbVa9j28HFtYCB9dGvVqiaYEA0GkLLApziYSf5UsvvRRff/11yPFvvvkGl156aSrWRKQT3gfzgaUAgG/zZyd8c05K1puQQ5HkRS6xcFKXDot53V8fPxLHjy7DhGpTyh6fKU5NVoe/cLK3A3z/KHZtNhfcPh5qFYfqPMHfXxVGcRpSZJR93qNS0N/EYAWp/Jph/VVxWPX63RLKCqeqqQD8CUbZZNVj/v1OdZl4oIcKp/6CnWjqNSpxIwLZqzg1Wp1ot7mhUXGYVON/T8umtLR/fl2PqQ8ux3830Ws4WdgJa3DhVC0VTlaHBzaXN+R2gL9fL5zipFGrwMb4ZXvhtKnBCh8voNpsiDizKhaJKE6JDr8FEp/jxIozWXGSC6cgxSkdVr2dS4FvnwcE3t/zG4Fkepw6ewdR4bRhwwbMmjUr5Pixxx6LjRs3pmJNRDo5tA46VxesQh4Omo5K/PYsIILLncKp3CeqO4ay2EN7b5o7Bq9ecUyARaGvsA+vRqsTyCsDwIlvRv3Ul8KiyKvNBmhsYhEJbb6YbheETqOSC71UJOoxTMFWvTgVp65eN0784+d4+MNtKVtLTJqkeO+qyQCQlVY9tpY2TppVQopTv8FODvJ0agwpFv9WsnUI7uYGCwBgbGVhwEm1NovCIVjBtFFaK5E4zD4aPH+wQOGiaApT3PsU/Xrh4siB/iuynR4f7v9gK9bsTe5z8XupvylZmx6giCSPQ3HyW/UST9WLW3HqDUzu84dDROpxSpFVz94J/PdG//eWA1Gv3her3qAonDiOQ09PT8hxq9UKny83el4GNbtEtel//FSY8pPYlZEiyUdzh2G1ZefJghLB1YMiiK/XwqqRGVkDG4LbZHEAag2QJ53s2lr75fH9iXp5gFUKhiiqAyI0ZLJeiGkJxrlGg+2UyW/4zCbYfRjwhd8JBcSZHA2dDizf1o9hGkxxqp4Cl9cfmZpVVj29uJYWQbKkdDfJl7V2O3HyolX404pdmVjagIcpTkatGrVFgfH92cYmqb9pap054Hi2xJH3urxywdSVQ0mt2YZT8ZoMpibKa1SZDhkp2UzXTzO/PtvRiiVf1+OJ5TuTuv26PvY3AQkqTsyql8Dngj8cIr7nkhVwJfnMqhd+jpMn1XHkn9wuthNw0msixganQedX0uJ1iDCrXmkOFk4Jb6GeeOKJWLhwIV5//XWo1eKT6vP5sHDhQhx//PEpXyCRYnYvBwB85puW0OA2maJhcHBGGOGA0L4HQGgyWzbR07IfJgBWIQ8lpWUZWUN1sM+8oFK06tlaAKQuwv/7A1247a1N4AUBJoMWJqMGJoNW/sAUgyGkk+kwiXqMP5w3BdfNGY0jhpgjXidRQppaCyoBlQbgvUBPU9h+KwA4JBV9iVgA+oS9E+iWAisqJ8kfUBwnJtllC6zHqZFn4RCH5cs+2NSIfe29WLqlGbecOjYTyxvQsF1Vo0JxytYhuOH6m4DsCYdYd6ALXqmxPZ5dfiI8THEyhil+hhQZsaO5J2yfE9sEUKu4iCM4dBo1AG/ai2yW/JfMMFSeF7BeKpyOHpZcfxPg7yWKLxyChRskEw6RnOIU4tyQSKlVb9v7wA9vAZwKmHs/sOKemJZ6VhDygvieotfE7hFnIxxyMRwi4TOBxx9/HCeeeCLGjRuHE044AQDw5Zdforu7G5999lnKF0ikEEsD0LIFPFT4Hz8Fv0pmB12lQot+BIY7t0HbsQ3A7FSvMqX0NO+DCUATV47xcfwxpwOmOMk7fgXlQCtSPstp2dZm7G+PnIAzqqLAv3MUpr+JUWjQprRoAhSpeuwDSaUGTENEC4D1UMTCiTXdJ2IBSIS1+zrw0Ifb8OA5k3DUsBKgWbLpFQ8HDGZ0t9kAiJYXlSp7IlNZj1ODr0g80ONXnD7bISqZmT4pHqiwfhKjTi33UnQ7vehxeuTm7XTx/sbD2HDQgnvOngh1jNcjzwv44XBooh6QPXHkSltWZxbPwsp2HG4pHCLMZ1xNlFlOvS5/f1OkSGidZP9K92ultccl/8/zQkLvt7tbbeh2epGnU2NCdWHSa0hMcUrGqpfYHCe5x4kVThEVJzYeoY+fUbY24MNbxK+PvwWYtEAqnA4BPA+owhdmShuw0x1f4cQKz0GhOE2cOBGbN2/GX/7yF2zatAlGoxEXX3wxrr/+epSUJF/pE/2ApDbtN0xAl9MEcwJ/8Era88dguHMb8i3JSer9iau9HgDQoYk+/DadMMWpx+mFzeVFQZpmObETup9Or8XZU6rR7fSg2+FBt9MLjgMuOmYo8AkrnPpXKTSFmz9RNFQqnBoAzAx7O9Y7Eq+1IVHe39iIrY3deGf9YalwYsEQU6T1Zl8wBOC3bBx0SyfEklWvx+nBt/tFr3+mT4oHKuykJ0+rQb5eg6I8LSx2Dw5bHBhflb7XiSAIuP+Dreiye3Dy+AqcOLY86vUPWxzocXqhVXMYWxl4MpktqXpr9vkLJwtZ9ZKGKRiGMIpTdZRIcjlRL0J/E9B/6mRrt6iIeXkBHb1ulBfq474tm990ZF0RNH1QXYqM4jlRrNei18fLxUsyc5yYpS3W/KLOoDlOpgipel7JqqeJUNjEhSAAH90i9l5XHgGc9HvRqsepxVmBthbAVB32plq1ChoVBy8vwOHxwYzY74P+cIj4f8/ZQlLek5qaGjz66KOpXguRbqTC6Xv9DABIzqoHoNs0BugAinpCY+mzDb5LbGq06sL/wfcHBXoNCg0a9Di9aLI4MCZfOuFJcY8T+/AcVZGPOeMrwl+JzU1iqXb9hClYcQIUAREHI96Ofdi7fTx8vBBzlz1R2nrED2tZqZODIaYErDebgiEAv+K0z20GtBDnTrls+Gp3j2x9yobEtIEIO9lkJ6lDioxi4dTlwPiq1KVxBtPc7ZQb0ne19MQsnHa3ir2do8oLQiw82dDj1OP0YIukiAH+ZnsicVgxH27+4JAoihN7LefpIysE/fVaYYoTALR0OxMqnL6vZza95PubAMAcp1XPorjclMBng15hafP4hKgKkcPtk4M7iuUeJ7YB6Q0ovFhRq+1LqNUP/wG2/1e00C94FtBIz7+pRtzctByMWDgBYlHY4/LGraZ12MTfd0kCVsdsIaln+csvv8Qvf/lLHHfccTh8WPTWv/LKK/jqq69SujgihXgcwL7/AQC+wHQAic0fUOIomQAAqLDvSc3a0ohK6ldx5NdkdB3+IbhOsb8HSHnhJPdeRJtBxYqUKFa9dOAPh1BYDOQhuJH904cUvSPp6HNqkz6s5cJJEQwBKKLIsygYAlDMcfIZIOik9MOeJqzc4X9Nub3psTcOdvyKk79wAtIfELFNmlEDADubQwOagtnZLNpMx1SGWpdYIZXJ4vq7+k74eCFgOLaP7+fRAwMEp6LvLpiaKLOcog2/ZfRX4dTS7Qz7dTx8f1AsnKb3tXBiqXqxCiepyDcZNAkpXMrP5lgFBrOyadWcvFHGNvB8krLD6HOqXncT8PFt4tcn/V7+/AMQ9+gQtpEUz+e0x8fLbo5cVJwSLpzefvttzJs3D0ajEevXr4fLJZ54WK1WUqGymf1fAl4HYBqCja4hAACzMTmrnrdMLJxKvC2A0xrj2pklv6ceAOAu7F+FJRj/EFyHonBKrVXPGatw4n3+2Or+turJ4RDhFKfwb8i9Lm/ALnQ6+pzYLmeT1Ql7bw/QLoVnsChyp/8DMptQWmt8BeIuIG85jFU7/YUTS1oiUotDOtlkJ6n+gIj+K5x2tcQunHZL1xlXGTpWIBvCIVh/06kTxfdDQYivt4QIRbbqRelxarI4wQcVpnYXi9aPYtXrp1Q9peLUnEDh1NbjwoEOOziu74UT20wOjvsOxmJPLthAq+bkuViuOAunojydrCzl6dSy64JtQvp4AezXqk3Wqvf104DTAlQfKfY2KYnDGQIkFknOfjYV5y9Wc4mEn+WHH34Yzz33HP7+979Dq/X/wLNmzcL69etTujgihUgx5D/kH4tDFvFNqUoKLUiUPHMZGlkMcks/ztdJFN6HEkc9AMBXNj6jS6lRznIqkCw2KQ6HcETZdQQgFmq8R/QsF/avdTEkjhzwF28RdrKCd/BTrTjxvIB2m+LDevcGQPCJcfHS88PWm209TmoVh3zp9+zJF/v3Dh3ci3ab2z+wMsvDIZqtTnxX3xl6QfuemAMXM4ndHfh3xhSnQ2lWnLY3KwsnW8hJcDA7pcIpuL8JyA6rHutvOmFMmbyTTpHkyRHtvb+yUA8VJ74ftPe6Ai5jilN+hhUnh9sXEHjQ0u2Kcu1A2PymcZWFfX6fVs5xiharLc9wSvCkn+O4uGc5dfVKUeSKHiqO4xSR5OLlyj7FpK16LZLTYsZVgDroZ2KKU4zCSR7u6479Oa1MC0y1/b4/SPhZ3rlzJ0488cSQ42azGRaLJRVrIlKNIEDYvQwA8KcD4hDYG08e3afp2jt46Y+pZUtKlpgWuuqhFdxwClroyoZndCkBs5zSHA4RPD1ehik7phpxnlQ/4rfjKK167A25QdxuDiJ4Bz/VhZPF4QlQZWwHNohfVE2RZ1xlq1UP8Nv1nAbx9XTggGidnTFC3NTw8ULWWp8++aEJc5/8H3723Br8cEihWrfuAP52EvDPHwNd0YcuZopgS2xtBhQnh8cXdeiujxewp1W06oUtnDI8ANdid2Or9PPMHFkqN793UbJeUrBeGL029JROo1ah0iR+/jRaApUcO0vVizJqQSepWOl8rbT2BK6rJYytMBLr6vs+v4nBwiG8vCBvkITDYg+MCU8Ef0BE9OfTrzgFfvbIQ3Clz6aAwilZq1671HZRFmZ8RRyWeiAxxckfDJF7iXpAEoVTVVUV9uwJ7W356quvMHJk4gNGn3nmGQwfPhwGgwHHHHMMvv3226jXf+qppzBu3DgYjUbU1dXhlltugdOZmB92sOFu2gLOeghOQYuv+Um4b/5E3HrauKTvz2zUYocgnfS2ZrHi1LYDALBXqEFlUahdpT+pNit85vlScIO9E/ClzprikN6II1r12BtfP/c3Af7Cw+bywsve6E2iZRReh/hcBHEoaDZOrA+aRGnrCdzV5FgUuWTTA7LXqgf4AyJ69WLh1N0sFhqnT/InSGZbsp7by+OB/27FNa+th006aVvLktUcFuCNiwC3DYAAdGRn+AzboMiTFac8AOntcbK5vKjvEP8eqqVNmJ1R7HoHO+1weXkYtCrUleSFXM7iyDOVqvfN/k4IAjCqPB8VJoMcVEQBEckRq791WKn4GvjP94Env71yql4UxakfrHqtQe/FLT0JFE5sftPwvhdOBq1K/nmj9TmxHqdkArbineXECqfg4iI4oVa5+ZeUVc9lA3okC3/Z6NDLY1jqGfEqacAgLJyuvPJK3HTTTfjmm2/AcRwaGxvx2muv4bbbbsM111yT0H39+9//xq233or77rsP69evx9SpUzFv3jy0toZvmv/Xv/6FO+64A/fddx+2b9+Of/zjH/j3v/+Nu+66K9EfY9Bgc3nxzhsvAgDWCpPwhwuPxWWzRvTpPkXFSfxjElq2hlze1ev2nxxnEqlw2iXUYkhRcrbEVMF6nBqtDiCvRJrILQC97Sl7DNnnHqtwijAzKZ0oU+lkS4bW4FffrKE2gGDrU6p7nIJ3OQst28UvqqfKx/ypetmoOEnRtDrR+qm1NwMATsvSwulQlx0/e34NXlpdD0C01gDApkMWsf/u7SuAzr3+G1gPh95JFuAItupJilNbjyttg5p3NInqTKVJj2NHlgKI3ufEwiNGVxSEtcJk2qrH+ptmjhJ/FrZzT1a95Ij13n/dHPGE+NW1B7Fim9/p4N8EiLwx1B8zv1olax5L526OU3FyenzY2igq1n0ZfMvgOE5O1osWSd7VB8VJH+csJ2bVC36MwqBZTuxcS63ikps12CEJIXllgDFM8am06kWxLxp18SlpgKJwSnIkTqZJuHC64447cNFFF+GUU06BzWbDiSeeiCuuuAJXX301brjhhoTu68knn8SVV16Jyy67DBMnTsRzzz2HvLw8vPjii2Gv//XXX2PWrFm46KKLMHz4cJx22mm48MILY6pUg5V2mwsX/G0NRlpWAwBqjzkXP57a93Q5s1GL7cIw8ZvmHwJUk62NVhz32Ge46Y2NfX6cvuJuFtWw3fwQWfHJFHKqnsUBgVMB+WXiBb2pS9aTT+hiWfX6ORgCEFO82A59vAER6bbqKT+sVeBR6ZRO2gMUJ2bVyz7FialgFo148lnFdWJqrVlWJADA5cuOZL3PdrTgrD9/hU0NFpiNWrxw8dG45+yJAKTC6fNHgD0rAI0BqDtGvBELMsky7EG7+8V5WvnrcMllqWCbVDhNrDbJ1rtohdPuKP1NQObDIZjKOHOk+D5YHMfJKhGZWMFAJ4wpx5UniBumt/9nk5xaly2pemw9o8pFZ0iwAhWJTQ0WeHwCygv1smW2r8QzBFfucUpCcTImrDgFPkZwv7C7r4l6rHAqGxP+cna+4HWIM54ikJRVr2AQFE4+nw9ffvklrrvuOnR2dmLLli1Yu3Yt2tra8NBDDyX0wG63G99//z3mzp3rX4xKhblz52LNmjVhb3Pcccfh+++/lwulffv24eOPP8aZZ54Z8XFcLhe6u7sD/g0WbnpjAw4dPoyjVKLlZfSsn6bkfg1aFQ6qa2EV8sB57ACzOAF4euUeODw+8WQow/DNooLQqBuO/Cge7v6ABXE4Pbwo8xdIdr0URpL7G4Qj/FmzGU4ZsOoBiUeSB/dwOOJoOk2ENikYYlxlIYZzzTAKTkBjBEr9doUeZ3aGQwB+q16nWlScqrguzBlfAY7jMq4oKHn924O4fMk6WB0eTK0148MbjsfciZWYXCsO7z3Csgr48gnxyj9+GhgtfSZ0Z6fi5Ayy6nEcl/Zkve2scKoxYVyVeHIZLZI8WjAE4I8j9/iEmCETqabD5sIOae3HjhRVApZORla95HDGsmkDuG3eOEyqMaHL7sGtb24Ezwtyql60z8f+tOpNGSK+J3T2uuGKY5wCiyE/elhxzGGy8cICH6xRXotWR+Bg2kQwJNjjFPwYhfIQXNbjJP79Bs9qi5t2yRJdGsamB4jznAokF4Mlct+p/HMlEA4xKBQntVqN0047DV1dXdDpdJg4cSJmzJiBgoLE+0fa29vh8/lQWVkZcLyyshLNzc1hb3PRRRfhwQcfxPHHHw+tVotRo0Zh9uzZUa16CxcuhNlslv/V1WXmpLG/sbu9WLuvEyeqNkMNHqiYmDKLFsdxMBn1WMdLfVIHxEJ3T2sPlm0Tf3esfyFj8D5oLeJOis0U4Q2hHzFo1SiVTg4arQ5/n1MaCqeYVr0MFU7KeS3+g9JuVjjFSbLqMWuCM8VFAFOcZowowURO/EDwlk8EVP7njxV5WWnVk052DvuKAABlsOLksaLVQq84Mc40L63eDwC4cEYd3vzNTLnnxmzU4pTiNizSPideceb1wJTzxfASIHsVpzAhLP5ZTvawt+krLBhiYrVZLob2tfVG7FHa3SIGQ4yLoTgB/a86fbPfn4JWWiDOcKFwiL7BNpXChUMw9Bo1/nzhNBi1aqze04EXvtoXl+KklYa0pnPmF7NNj6kslF+brXEk632fwmAIRlyKU2/6FSdWXIQWToGjPdh7gC7Zwon1kkZSnIDAIKcIJNLj1DHYepyOOOII7Nu3Lx1ricmqVavw6KOP4q9//SvWr1+Pd955Bx999FFUtevOO++E1WqV/zU0RG9wGyhsPmSFjxdwlkFSg8bOS+n9m41afMcKp4Ni4fTsqn2yBbZHmmydMbrqofa54BS0UJUMz9w6FPhnOTlTnqzH84KsLkQOh5AUpwz0OAGKWU4BkeThh+s5PT45vGF0hbgxE89OViIwxWloSR5mGMXnpssUGJoih0NkoVWPpep9vNcDt6CGihNwRKFYbGaL4uT0+LC3TRwufPPcsdAr58zYO/G493Hkcy4cKJoBzH1APJ7lhZM8AFfRF5JOxcnr42WFZmKNCUOKjMjXqeH28TjQ0RtyfY+Px752KVGvKkLhpM5c4RTc3wRAEQ6RfOH0xa42PPrx9owFXmQSpzeO4ecQrXD3zRctsn9cthM/HBb7g/KjznHqh1Q9qUiqNOlRaRKL6VhDcHle8CtOw/ve38SQe5yiWvWS73GSY7tjFBhyAEWwVc/IFKfAwkmTdKIeU5yiFU6xk/USmuMkFU6lg8GqB4hznG677TZ8+OGHaGpqStoGV1ZWBrVajZaWwBPHlpYWVFVVhb3NPffcg1/96le44oorMHnyZJx77rl49NFHsXDhQvB8+D9qvV4Pk8kU8G8wsP5gF9Tw4XhsFA+MSX3h9C0vzUY6uAaHu+x4f6PfWhM82brfUSTq1RRnNlGPUSMn6zlSPsvJqbA1hJ3j5LAALunvMwM9ToDf7hawkxfhDblRUpvydWpUSVG6zjisG4nQKn0wV5gMmKoRwykadIEfHnIceRYqToWS4rTxcA9aIe64qmyi4psthdPO5h74eAGl+TpUFAZNiP/otyjzNOIgX45Fhb/3R+SbpNdnthZOYXoJ5VlOaSic9rf3wuXlkadTY1hJHjiOkwuinc22kOvXt/fC4xNQoNfIYxCCURZOnn5+jbD5TSzkAlCGQyRv1Vv4yQ787Yt9WL0ndYE7uULMURQKfv6jOpxxRBU8PgEHpKTGPH1me5yY4lRRaJDf72MNwd3XboPF7oFBq8KkmtSd18WjOLHLkknV08dZYERSnExB4RB9suoJAtAh9fbGpThFnuXEWgTi6UWO9LPlCgk/02eeeSY2bdqEH//4x6itrUVxcTGKi4tRVFSE4uL45VKdToejjjoKK1eulI/xPI+VK1di5syZYW9jt9uhCopbVEu7IRlVN7KQ9QcsmMbtRj7fIyal1P4opfdvNmrxgzASXpUesHfg3eWfw8sLmDmyVE5xUg6063daxf6mXUItajKcqMcIHIKbWsVJ2f8Tbnq8XJgYSwBdfkoeM1FMYa164cMh2AnokGKjfycrTYpTeYEeI32inWwbCz2BuNPPLKfZPMcJAJrZQGqpL8jf/J/ZcAg2q2dijSmwB8HrBnZ+DAC42XMdvm4U/O/hJmk4s8sKuCL38WSKcMNGWWN6OobgsmCI8VWFcmoWs+CFiyRnx8ZUFkTs+1CpOLmZvD8Vp9ZuJ/a02sBx/v4mwH8C1ZdwCKZQpDMWPltxhnlNRoLjOCz8yeSAEJmoilM/vJewHqcKkx4VUuEUawju91IM+dTaouT7e8LAZjlZohTxkfqP4iHeOU6WCI8RHA7RJ6tedyPg6QVUGqB4eOTrxRFJHq8FEch9q17C/pPPP/88ZQ9+66234pJLLsHRRx+NGTNm4KmnnkJvby8uu+wyAMDFF1+MIUOGYOHChQCA+fPn48knn8S0adNwzDHHYM+ePbjnnnswf/58uYAixCJyY0MXfq2WBnqOnpvygadmoxYeaNBqOgI1lu/RuvUzACfjujmjsf319bDYPehxeuTBe/1O204AwG6+FpOKQueYZIJq5RDcmtT2OLGTOb1GFT6SNMM2PcC/UxY2HMLRCbh75aKOnfzUFufBkEDMaSK0SR/M1WoLCr2d8Akc1jmq8UvpcmWfXmFWznHyF3MtYIVTEwD/7mM6+xLiYVuTaAWaGLwj3LgB8Doh5JVhs3ssvL1uHLY4UFucB+gLAb1ZLJy6G4Hy5GfOpQN7GMUpnUNwtymCIRhjWLJemIAIdmxsRXibHkOnVsHj8/WrKsnUpglVpgCbU1Ef5zh5fbx8MttkSU+yYTbD3hvDbpqFoShPhz/9/Ehc+Pe1EITo72/yzC9vejannR6fXKRUKhSnWFa97U3i63yKFDKTKthrsTuC4uT0+OTnO5kep3isei6vT56xVZwfvsepJ2gAblJWPdbfVDwcUEf5WeJQnAxxbnAKgpDzVr2EzgY8Hg8efPBBPPfccxgzJoqsFyc///nP0dbWhnvvvRfNzc048sgjsXTpUjkw4uDBgwEK09133w2O43D33Xfj8OHDKC8vx/z58/HII4/0eS0DiYZOBzpsTszTrxMPjD095Y/B5Oz6/CmosXyPqcIOTKk9F7NGl6LQoIHF7pGjnDNCm6g47RaG4NQsUZyqAxSn1BZOMXcc5SjyDBZO4RQng9l/kmxpACpE+ycbfjukyCgXAam06jncPvRIhVFF7y4AwD6hBjs7/Y/BCjyjVp3SHc1UoVScOFMNYIM8yFBOwsp04SSHGgQVTge+AgBww47DeKMJWw53Y1ODVSycALHPqc0qKmhZVjg55R4npVVPXHdztxNeHw9NCl8vymAIxrgokeS7WqL3NzG0GhXg7t/CicWQH6fobwL8O88WuxuCICSckNZl98j9tY3Wwac4xUxUDcOxI0vxxM+mYt2BLhxZVxTxeulO1WO9rDqNCiajJu4ep3qpv29EWWqt+OzcxuIIr36yAl2j4uSAnkRgxW20wokVkmoVFzJ8vTDCANykPqPi6W8C/IVTlB6neMMhup1eeKUkz1y16iX0W9dqtdi8eXPsKybA9ddfj+uvvz7sZatWrQr4XqPR4L777sN9992X0jUMNNYf7MLJqg0YyTWJJ6VjTkv5Y7A3l82qSTgOwAxuJ/JnjwLHcdJOuCNzVj3eB6F9Nziw4beZneHEYLvSWw9bcchbiVoghVa9WMEQ0k5RBgsnOVUveCfPXAu0WsU3ZalwOqyw6rEm2FRa9diHtUGrgrFDnPe1TRiG+vZe8LwAlYrL6mAIwN/jBAAl1cOB3ZD7grKhx8nHC/Ku8KSaoF3hA1+L/w+bham6Imw53I3Nhyw4a4pk0zPViJsfWdbnJAgC7FISmXKToqJQD62ag8cnoKXHlbL3HEEQ/IWTQnEaK0WS13f0wunxBfS27JKjyKOfUOoyoEqGC4YA/CdQHp8Am8ubcIplR6/f1hXv8NSBhFN2HCTmvPnJ9Fr8ZHr0ntd0v5fINr1CPTiOk10qsX6P9e2scEqt9ZyFQ0TqcbIoZjglE4HuHxQb+fPM3wMU+hjs80hWnLxsjlMShZM8wylG8jDri3Z1i/3SxqKQq/jDIaK/TtjPlq9Tx9WTl40k/Ez/8pe/xD/+8Y90rIVIERsOduFqzYfiN0dfBhhSH4jBToKf21cCn8ChTtWG02rFNwK/lJyhmRxd9eC8TjgFLZpVlSgr0Me+TT8wtbYIRw0rRq/bhxs/kKxzTgvgjW/YXzRiR5Fng1WP7ZQFFdRsTQobAOtxqi02yjt08cz1iBfWjFxeqAcnzSHbLgyHw+NDi3QZK5yyMYocCFScRo6Udgwlq16mB5wC4km9w+ODQasKPLnxeYGD34hfDzsOU2uLAAAbGyz+62Rpsp7bx4ONPVIWTioVJw/ZTqVdr63HhY5eN1RcYLR4eYEexXla8AKwp9UfEOH0+OSd+EhR5Iz+fo00WR2o77BDxQE/GhGYgmbUqWVLWLTekkh02PzqQLqGEGcrPC/IxW88PU6Jwl4n6SqwWUgPK5iYVS/aEFyPj0eD9HeW8sKJKU4RXod9SdQD4pvjFO0xQuc49aHHKdYMJ4YuH8gTh1VHsuvFUxACuT/8FkiicPJ6vXj22Wdx9NFH4+qrr8att94a8I/IPL1712CGaid8Ki1wzG/S8hjym4vPIDfUqxrWAvD3stgypTgpEvUqzfnhe34ygFrF4dlfTEelSY8N7YCXCb4pSNaLWTjJVr3MJOoB/p2ykJ08poKx4g7+HqchRUb5DTkdilNFoQFo/gEA0FEgWsL2S/HZzKoXbJXIFkaU5cOoVWP60CJU1IwQD0rhEHJfQh9Oine39ODXS77D5iSHWTOlZHyVSQ6MAQC0/AC4e0Q1vHISpko2oS2HxREKAADTEPH/LBuCq3wNBqu76ZjlxPqbRpTlB5wUcxwnz3NS2vX2ttnAC+JueHlwimEQ/a1KMrVp8hBz2JRKeZZTEgER7Tb/SXajxTGowqKUBU06dvDTbdVTKk4AAhSnSL/Hhk47fLwAo1YtW/tSRVGMVD1ZcUoyMCgeSxubExVuQCzbmLa5vPDxAjzSe2afepxiWfWAmJHkic6nytXht0AShdOWLVswffp0FBYWYteuXdiwYUPAPyKzONw+nGr5NwDAOeE8f0JVijEr3jS2aSeJX0j2m+AdkX5HkaiXLTY9RoXJgOd/dTS0ag3aBEkJTEGfkz8iOcKfNCtKMtnjZIhg1Qt6Q3Z7eTmKtrY4T45vTWU4BPuwrsv3AZ1iHKu7XHwd75MsID2yVS87FaeyAj2+uH0O/nn5DL9C09MMCEJKepw+2NSIlTta8ea65GbfsUS9kKjg+tXi/8NmAio1RlcUIE+nRq/bh71tknpiZoVTdilO7GRHq+ZCrDHpmOXkD4aQrI4H1gDfvQAIAsaxSHJF4STb9CoKY9qIdOq+F9eJwJSxqRH6afoSEKFUnFxePinVKldRnoAbNEmoDjHwF9jpSdXzR5EHFk4Ojy9in/R+6T16eFl+Una5aJiN/vMXeSNHgd+ql6ziFDscwq84hX72KIM8bE5v8lY9j8O/oRotipxhDnWGKGHDl2NtcHb+P3vnHSbJVV79U9XVOU6e2dmcd5W1klYBJZAQQQIRTDAgWeQghC0DJnxgG2PAiWiwjIwMNgZkCwQiiSABQqC80irsanOcnTzT0zlV1ffHvbequru6uzpNp/t7Hj3T29PTU9PqrrrvPec9L7XVdmqiHtDiVD1O4zmw50lcLZBQCM/lf9603xM0fKCHTrsSePqn2iDcllv1qOJ0QFmpRYC3E2evCuHvX3U6Zu8JYkxYwK49+3Du+Ll1PWfZcIhcGqDzfbQmzxZgGg4BFEWdkp1GopoM+hxVDdazCrtYn26jFw7/CgyNjAMHjmgX5Ugbz3BiaKqCRDdI5DSQWGiImhBPk9d7KVnbBohZGhwAQ3/TxQCIEnv6eBCPHlnA7hNhoqS0qVUvUWZejq44NbBwMoZrqCrw/bcDkZPA0DZsHiHqsTFZTw+GqNww71xmxYkVRANec4WgnkhyY48TQAIiCtPIuhV27nfYxIaGkjCarUyy2HEWQ+522BBwSYikcpiJpPI2aRnsHL2+wTY9IH9TOJLMFr2P9CjyGhUnyYriVDqu2ykRW2s6pyCSymobH1UXTguHAahE+fcOVX68lqxXXnGqPJ+KqmklzgOdQEM+Zaqq4uc//zle+9rXNuLpOHUgPfpViIKK3d6LIdBG+2awqs8Dmyhg0OfERVdcS+6c2QMkFrTCqWWpeqxwUscx3iaJeoX8yXmr4AqRQc93//5J03SsatAKJzOrBlObJDfgGSj+/jKhK06FPU75iT1aol6fG4IgWJ60Xg3MqrdJJfObMHoG1tKLsFY4JVmPU3ta9fKQHPrFLzLRkDhylmJYKpa3HCTUgESR5wVDKApwXA+GYLBUr93MFsisegb7ZjvAdlM9JhsUTHFq5BDcvOIzMkGKJgCYeFxTnFixBBiiyCv0NwHLb9XT5tJ4zRecbJHIFo3VMBfN/5leCojQRlGUchvUyXJb9QBgNFh+CK6uODV+1IhkE7W0vLDJuS9cRg2yAtvcTJftcSqvahk3IZlVz16tVY/1Nw1uBKyodtp1ut4eJ6Y4te+GZCXq+qQdOXIEn/jEJ7B69Wq86lWvQirVOyertiQ6jU2TPwYAHN3ytqb+qtGgC3e9+yLc/d6L4e4f05sLTzzSWqueImsnBDL8tv0UJ8bG9RsAAAF5Ee/8r8exVIe9pGyPk2bTW2ntBNkk2E5eMlsQgcz6rqKTgJzVhoiyHfxqButZhV2sxzPHyB0jp2m7l7ri1N5WvSL8VHWKTjak8Z+93rUox7PRNOZixaEGmN0LJBcBuxcYO0u7m81i2X2CFFua4pQKk/lebUKyzAbFygqKU7V9N4lMTnsvbh8LACcf07956iltTtNEOKn9P9o/Y71wsjd5QVwIsziZKQiAvhBdqMWqV6Q4ddZa5OhcHG/5xiP448G5qn+27KZZA2h6qh4tjoYNMx9HKgzBbWgUuaqSDR0DekBEcRFfqaiphLYRWMb6yFStUsWFcZZTzVa9avqbgIqznKwO9u1JxSmdTuN//ud/8MIXvhBbtmzBZz7zGdx6662YmZnBT37yk2YcI8ci6iP/DruaxRPKJoyfcWXTf985q/uwqp/u+Ky+iHw99sfWWvUWjwK5FNJw4IQ63NaFk0hnOa11xXF0PoG//clzNT9XuQWd1szZwmAIID8FLs+u5x0GbA5AVYDIhCFRzwNM78GFv7gWH5TubGiPE1Oc+jLUCta/DuuGSOF0fCGBrKxohX87W/Xy0OxtEw1Z7LAd0VqU4+eoUrJ+yJdvH2U2vVUX5A1cZMl6z09FyELQGQAcdFFEkwLbAW34raNYhWSKU2E4QSKTw8fufgbn/N2v8OiRhfwfOvYQ8Ou/BdIxFLJvKgpVJXbMIb8TOPm4/s3JpxD02LUEsv3TMcTTOZxYIJ+dahSn5Yoj1y1O5gvOeqx6c7THKW/IeAfx82en8PsDc/jOo6UHjJYiVSkYqE6WK47cGPIwUmEILgvwWdcIxen+vwM+O671RgN64WQWEME2AGqdQaRZ9cr0AlVK7vMb+oVrturNWYwiZxRY6gsxWvXKbRL1lOL0xBNP4L3vfS9GR0fxxS9+Eddffz1OnDgBURRxzTXXIBBofOQ1pwrSMaiP/QcA4BvKdTidLkSWDdqvgOMPaTJ3SxQnatM7rK6AAlFbzLQlPjLo+bIV5MSXF8dcJSltQWdy8WQnuhZGkQOkl4XNHsqzf4miXtQtndSa6093TgH/9Qp4w/vxGtvvG9zjRE7eviRNbQutwYjfBbfdBllRcWIh0VlWPcBQOE02JByCLchqsertKRUMcYwFQ1ySd/fKPjcGvA5kZRV7JyNEGTUUgu1COaveWNANQSA7rvPUbrbnVATXfeVBfOeR4wgnsvjNPhoEo6rAQ18Dvvly4MHPA09+u+j5mE1vGxsePPGE/s2Fw0BqSRtyu386qoUvDPqc5RuvFQV49HZcmCRDiJfPqqfPvzGjrnAIuhhjttBOs+qxYrGWRMGKM/zqpJnDtDM5RUtZG/YbFafSQ3BTWVlTFOtWnBaPAX/4EpBNAAd+qd0dKjPLKVxvjxOztJVTnCokzwWMihOLI5eqdJNUrTjR9UNywXSjh4U4yYqqDeU1Q0vV6wXFaefOnXA6nXj44Yfx2GOP4ZZbbsHIyEgzj41TDbv+C2J6CYeUMUyOXLH8g8WY4nTqSYQkUjBF0y1QnOiu0fMK6ZFYEWznwon0pPhzZBe6niSosopTmNrRgq0LhmDo3uyCotqwmzURTmC1MI1XP/NeLap9CGFkMtUvKsyQFRXzsTQEKHDEqI2xbw1EUcjrc+o8qx5L1jvVkDhydmGvZQMkL9SAoapFwRAMQRA0u97TJwvsem0UEJHM0uG3Jp8zhyRqfRonF5P4zz8cwfVf/QMOzepWw4nFJEmzuvtdwC8+Cqh08XTkgaLny3sN5SxwiqbWSvScNrkbW+iQ231TUS1db0u5YAhFBu65GfjZB/HW2c9CgLJsqXrhZPMUJ5aqd8Y4eQ+dWuosxYmda1gMdTXoilOTepw022/jI95ZjLzdJuQVIqNlhuAym17AJdVcvGj84YuAQs9vrOcH5RWnBfr+DNYZDlF+jhNVtUqoMvpMxKxWpEhiFf//VdWgOFksnFxB8h9gGkluPCeW2+Rc0GyInRveYvmVftGLXoRvfOMb+NSnPoV77723p+YktD1yFnj4awCA2+WX46w1g8t/DH1rSY+FksNo9FkArVWcDigr0e91NGUgYMOgipMjRXzt4UQGikn8qRXK9jjR1wRDm2t67kaiBYeUiSTPzh/Ddxx/D3dqBhjaClUQIQkK3LnFhhzDfDwNRQVGhTAEOQMINiBAFC9jn5Nu1es0xelUQ+w17MJe1JNmAaaW5AVDzB8CYtOAzQmM7yj6GRZTvZspr204y0nb3S9xXmF9ebd890n87Y/3ICMruGrbMP7u+tMBAOn5Y8Ad1wBP30ned+feSH7w2IOkqDGQFwwx/RyQS5EErE1XkQecehKbDLOcWDDEpuESNj05C3z/bcBT/wMAcKgZ9CG2LIpTKitr76dSihNbJFaruiQyOc1CecZKUqh32hBctkCvpWisOMOvTpoZR84UpWG/Ky9WnPU7TZsMwT1K+/7WDfnqiyJfmshXeucPajfZe7RwM/PZiSUcno1DFGofvKuFKJSz6sXLbzKwmYhGxanIqldujR6fBdJLAASgf73FI4e++Wpi17PbBG1eX7l+5IVYDxVOv/jFL/Dcc89hy5YteM973oOxsTF84AMfAICG5+hzquS5u4GlE1gUQrhbfgHOXdO3/McgCJrqNDBPLCUtGYA7Q4oEEgzRnol6Gl7S42RLEPuOotZebJZc0CkKMLuP3B7aVttxNpBKkeTKiUfxhdQnsFKYQ65vA3DDPVA85HUKZecbcgwztOF4uydMf/c4YCMXInYxPNyJihOb2Wa06jUgHAKorl8xltZDDbaNGRbxzKa38jzAXvzZZH1ORcl6baQ4JTKlFScAGO8jPRfHFxJwSCL+9hWn4fYbzsMZ40FcKO7B5+beD0zuJumWN/wQePnnAYcfSC0B089qzyMrKp6fJIXQ9rEAMEH7m1buAFbQ0QWnntKCN/ZPR7GfWvVY2l4e2RRw51vItUK0k55CAANCZFkKJ7YAlURBs3IXog3ArVJ1YWqTUxK1onGyzPDU5SCVlfHhu3bjV3umLT2eFU612BSb3uPUxBARZpkuHNbMFKdpkwKYzdlbN1Bnf9MfvgTIGT1Ux1A4Bd3kvVioOH35PqJKvfLscYzV6GapFA6RlRVE0+Q8U6pw0gO4DD1ORqvexC7gc2vIzDczmLoWWgXYq/g72AYnc7EYEAShYpBTKisjTgvGniicAGDVqlX45Cc/iSNHjuC///u/MTs7C0mS8MpXvhIf+9jHsGvXrmYdJ6ccT3wTAHBH9sVIw4FzSgwYbDrUfuOfIelPy644KTIwtx8AiSJva5seANBwCCEdRZ+DnExq8bgDhotn4QDEpePEvy3aq9tZahLMAlEUSU4LJ/Hgr7BamMFxdRjijT8G/CNQ/SS2vV+dNx1IWC2z1B6yzUkb9UNrtO+xwunoXFw7xo5RnPzFilNdceR5hZP1z/LzVCkZDbgw4DMsiErY9BjMqndolhatbdjjxF4Tsx4nQC8UNw778KP3XYIbL14LQRCwfvJn+Lb9M+hDBMromcA7fwusu4wU7GuozfnI77XnOTYfRzIrw2UXyXuSBUOMnwesOJvcnnwKm6hVby6Wwa5jRJHdPFJg1cskgO++Adj/c0ByAW/4DtC3DgAwKCwtS6qecaBnqY1WrXCq8hzI+skGfU4tVMDYO9MKHjo0j/99/KS20K4EW6Ans3LV6aHNTtWrdd5XTlbwnm8/UfY10BL1CgsnGvIxG0sXnfM1xame/qboFLDrW+T2y/6ZfI3PAskwAGOqnl447TkVwS/3TEMQgPddaTFQwQRm1cvKKnImnz32/heF0pt2eq9wTrPq2Y1WvUP3EUXpN58Fciafg2r7mxgFo0MKcVWY5cT+NkkUOue6akLNptirr74a3/nOd3Dq1Cm8//3vx89//nOcf/75jTw2jhXkHNldAPBT+QIM+Z1Y2apABKo4OSafgA0yMrLS0AjpiiweBeQ0soITJ9Th9g6GAIhf2EYuGOtdZHZRrYWT1uNUuKCjChwGN2mqSith3uwi77ghuOKkOogPej4NMUQUB4HuCI4Kiw15P81SxWm9nUb/9hkKJ5qsd3g2rqksHZeql16CG+RvbIRVDzBRCMug2/RKDb69BGYM+PRz17Mnl9rSqlduAC4AvO0F6/Dtt+3Ej29+QV6og/8Xfw5JUPBD+WJMXH93/iDqtS8gX4/qhRN7DbeOBoj9hRVOK88Dxs4mtxcOw6PEsZomm8boLvUmY6JeKgJ8+zXA4d+QCPg3/R+w+cXaps0glpZFcaqUEgbohVMiIyNdhS1sjqoWAz4HHJKIQVqst9KuxxQDq8Wb8XxYba8r+5w2u8dJUWG60C/Fc6ci+PmzU/jK/QdKnrf1RL18BXrA64Ao6P2oRhoyw+mPXyHW15UXAFtfXqQ6mYVD/OtvSLFx7ZkrsHG49qLNeI1OmXz2jLH9zPpWCCuooukSqXq0AERiDth7T/ETaDOcqiycKiTrsfdgqcRApg73eR0d7VSr+5PW19eH97///XjyySfx2GOPVf4BTmOZ2wfkksjYvDiijuLc1aHWvSGHtwOuIIRsHKeJRMpdVtWJBkNMOVaTRL02jiIHQOyNdAGzxkVsNrUGRCRLLei0/qbmDUOuBubNLlqID58G2D1Iukbwp5mPQ+rXixkxSAqCYWGxIcl6THFaJZDgCYTWat9jPU5TkRTYRmfHWPVceoR3MEf+trriyHO1KU7PTRh6cxjh40T9FCUSRV4C1uf01Mlwm4ZDlFecnJINL9g0qC+OYrPAnW+BIKfxB9sF+Ivse3GicCzV2kvJ12N/JBth0IMhto0FyNwrtkM8vgPw9OuF1+TuvOjxFUGXXuirKlGajv+R9Ea95W6icgHasORBYWlZ4sjZjLpQmc+S3yWBrROrOQ+yRL0Bav1hFu1WFk6sf8UsXMAM4wy/ajfPSm6a1cPenwB/+DIAvXACqrPrnaKR8FlZ1TYCCmG26ULFSbKJmn2vcAjukTmyybi+VsUpPgc8fge5ffmHyXWYzaGkBYUeDkH+X+ybiuJnz0wBAN7/wtrVJkBX8ABzSxsrtvvKWNn0XuGcuVUvYRh78Ph/Fj8BsyUOVPm3VJjlxCyEpd7D7G8b6GCbHtCAwsnIueee28in41iBqk1H7JugQsQ5q1vQ38QQRWDVhQCAFziIZW5ZZzmxKHKBNPq38wwnDVo4rbSTfoZa7SXML11k12CF03Dr+5sAQxpQ4YLCOwB8YDe+ee5dOK6O5BW9THEaQWMUJ2YPGVFo/4FBcQp5HHlJTXabkHeha3tosRHM0sKprh4ng+JURSS5qeLE1KaxswFH6abqs2mf09MnlvTCKTFPenTaALZBERBSwCNfJ4EXpZCzwP/9GVHMBjbiW6MfhQpRi9vXGDuLzK1KR4CppwEUBEPQczz61gFeGvzDVKdTT+al6OWpTZO7SV+Z5AZuvAdYvVP/nqFwWo5UPStDQ0VR0L5fTfHAZjgxW6g2y6mFyXqsmImlcxVfX0VRNYUKqL5waniPk5wFfvBO4FefAOYOaD1OQHUbMcZB0LtLjNqYjrLht8XR1GZDcKOprJbEV7Pi9NC/Evv6inOAjTRohSkvdIMiVJCq95X7yf0vO2PU0oy0cgiCfk0xU2bCFeadAYU9TmSHz5GnOBmClI49qDtPGLUqToYQJzOYErdvqjiuHDAO9uWFE6eV0IjaRzNk8XduKwsnQPPrXyCSQIJlVZxokbAnSxZcHVE40YCIMYkUTjVb9UrNcWJD/dpGcSoRRw4AvmEcpRuTK/sMF0Xa4zTSKKsevfD2Z+hgVUOPE5CflhRwle7JaEtokenP1K84GV9rq1a9rKxg3xQLNTAk6mnzm8z7mxisz2n3yTDg7tOjt6PtoTqxBfFZ8z8Bfv4h4LYXAI/ebp5g9atPkkWLwwe84Tvo7ydFz0ThcFbRpr8u1K53aJYGPYz48216jBXnkK+nnspbyOUFQzz/U/J101V6XxSDjkIYwPKEQxh7nMqhzXKqIiBiXiucyGKMNe23UnFKGBbElVSnaDqX9/ap1nXQ8FS9yaeBLJVFl07AJgpgp8Bq3iunwvrrX6pw0hSnAqseoBdORsXpKFWbBn0OrXioisQC+bwCwGVUbQL0Xh9aUAQMPU4HZ6L46TPkWnHzlVUWGiVg12kzS+pCvPKAXbM5TpLR1pekipODng+eMKhOuQxpawCq73FiqXqxadPNrK30/PP8lLnCaLTqdTK8cOp0aOH0cGoNJFHQ5li0jJWkz22LehTAclv1SOG0K0UW2m1v1QM0xWlECAOo3apn2iCsKFpYRrsoTno4hPnfyRaVef1peT1O9S/yZiJpSMjBmypWnID8puOOsekxaF+QL03+tlrVhJysIGdoyrb6OT40G0NGVuB3Svm9lkdp4cT6eUpw+ngQokAWvTPR9LLa9awEj7AFcShDbDvIJoCffZD0EUUm9QfuvlMbEYFX3QYMbdHOR0WKE6Db9Y78HumcrD1m7aBHT9QbNxZOZ5Ovk0/lFUubjL0XrHDaem3x7zMoTssRDsGKh0pzd/prUJyYVW/QW6A4FRaoy4jRUlypcCo8F1avODV4AO7xh/Tb0WkIgqCpGdXYOk8ZFSc2m60A1uNUaNUD9CG4M4bC6fAc2VCoNQocD/8bkIkBI2cAW16q388sayY9Tv96/0GoKvDi7SP59uM6KDfLadHCgF1/3hwnZtUzUZwueDv5+tR3SUgMQIomVSY9j+z8ahVPP/k5AFg6WfRtFo7DEkEL6UmrnqqqOH78OFKp9rBN9Dy5jBZh+7S6DtvGAq2fW0Q9sIPqPAQoy2fVMyTq7VfG4ZDEzvhw0sKpH+TCUm84RN6uY/gYWdjZHFqKVqthO2WlFhMnF8nJPW/RTWO2G9XjNBNNY0wg709ILm2eFmP9kFFxan2gRlXQ18qTJhH3taoJhU3LVq16Wm/OigBEtgManQIWDgEQgFU7S/8wAK9TwtoB8vofnImRqHig6YXTiYUEzvnUL/HZn+8t+zi2QeGjQ6ux+iLyHjp0H/C1C4Fnv08scj++hXz/0g8C264DoG8GFClOALCOFk7HH8KJuQgUFfA6bBjyOgyKkyF8yRAQsd4na7vNmvq0cBiYeY7Mitr04uLfR5XuwWWKI2dzacpZ9Yzfr6pwKlCcWCLbqVb2OBnOU5U2wwrPhdWHQzR4AO6Jh/XbMbJBoA/BraJwMlglj8zFi2ZU5WRFK3qH/cWKk9kQXKY4sXNEVaSWgEf+ndy+/EO62gQAg6xwOgQoirbBl84p+NFucu655UWNUZsAQ4iCyfWMfVbK2dn0XmFDqp7Rqsd6nE57NZmxmV4i5ybAkKi3If81sIIgGOx6xX1OW0dJYXloNmaupvWiVU9VVWzcuBEnTpj7GznLzMxzgJxB0ubHCXUY564OtfqIqDogwI4cBhHJ8243FZqop9hIot6KoEtfuLUzdNEeUsgOUb3hEHmFM+tvGmiPRD2gzBwnEK8/s3fkqYVUcRoQokinEnX9flVVMRtNG4IhVhddPIy7mTXZQVoJfa3cKVI41dr4X+i9N7VWmvAcLZy2jxl2Zll/0+jpgDtU8TnWsiHE8/FlS9bbfTKMSCqH3+2bLfs4pji5M3RHd8efAe96gBQyqTBw11uBO15KErs2Xg1c+THtZzXFyaxwGjkDcIWATAzzB0jI0tpBL4TFI8R2Y3OQ149hCIhwzDyNP79qE1597rjuOHj+Z+Tr2kvIYwsxKk7LMccpyXqcyn+e+koMHi0H63lhaXrMoj3VUque/nlhAQOlKCycFqvsc9XO/Y1QnFQVOG4onKJEua4lkpwpTqyoL1Sd5mIZqCpgEwXTTU6zIbhHmOI0VEPh9Nh/kAJiaBuw9br874XWkM+YnAaWTsDnlLREO1UFXrR1GKc30M3jKjPvyEo/ILsuZXKKlqZpt9HrmKrqipN3ENhxE7nNAjFq7W9ilAmIGAu6EHBJyCkqDs0UpuB0x/BboMrCSRRFbNq0CfPzjRlEyakTatPbZ9sIQGhtMATDZtcWb2PC/PJZ9WgvT8S3HgrEzuhvArQFjD9HTnS1z3EysWtowRDt0d8EGMMhit8Xs7E0MrICmyhodhsAgLsPWZDCT4lYGyhZilg6h2RWNhROa4oek9fj5G6PgtMytNBwJclOca02rMILutUeJ6Y4mQZDlIghL4TtJh+bT+hWkqXmFk7sPFVJWdPSKzP0GugdAoa2AG//NXD5XxGFJxsnCu9rbif9SxSmOE2GU1AKbYGiqL0+wpEHANACcoIME8fomYBUYGdiqtPkU7j5hZvw+dedrW8WlbPpAQU9Ts0fGWGl4R3Qex+qKR7minqcdKWi6HVeJthAcqB6xanaIbgsGMjZiMJp4TCZZ8RgipOtusIplZW1/y8v2ER6+wr7nGZoMMSQz2m6yWk2BPfIPNk4W1eL4nToN+TrzneSz5sR0abPOZw/AEEQNNUJAN7fQLUJMMw7MgmH0AMUSm8yGIdIM/ubpjilI8SKB5A+0XPeTIrCU7vImrHWGU6MMpHkgiBgK900M+tzWrCgpnUCVWu7n/vc5/ChD30Izz77bOUHc5oLLZwey6wFAGwdqy/tpWFQe80KYX75rHqzpHCadq4lv7tTCieqOHkyZKZQLZPjc7KiLZDzCieWpDPUHv1NgF6ILCUzebuyAHCS9nWMBlyQjLYDQcCibYDcpBfyWpmlu5cbpOIZTgyjDaRjZjgxqFXPkSAFZq1qQqHNwqzQLURV1fw0OMbh35KvVgsnmpZ1ZC6+bD1O7DxVqR+FWWscKUPhBJANoys/BrztV8DO9wBv/j5ZtBgYDbhgEwVkZEULKMmD2vVCM4+Qfw54zW16DENARB6xWd1uteVl5n8IPW63kIGQLd4ZbjT6LrrFcAiL50FFUbEQz1ecRgIuCALZNJhv0RDcZFb/vFQqnAqL9UJLW8Xf1UjFydjfBGiKE7PqWe2ZZMEcHocNl20i77XCwmlaC4Yo7m8CisMhVFXFkdkaFSdVBaaeIbfHd5g/Roskp31OtHC6fPMQzqZjEmriyf8Bnvx23l3s/5XZHCcrM89soqANwS0qnJhNT3IDdjdRnba/ktz3+B3a31e74lQ+WW+7VjgV9zlpVr0KGyjtTtWF0w033IBHH30UZ511FtxuN/r7+/P+4ywjtHB6PLMWglCj77cZBIyF0zIpTrOkv+moSD7UHREMAWg9To4UWchXe9EE8k++eT1OtJhsJ8VpJODCSMCJrKzi1jt35+0Is/4ms8HFSxLZtbTVWTixZuQNdrrwNVGc3A6btmvt77geJ/LZsydnISFXe49TQdOylQ2QiXASS8ks7DYBm4YNvTbzB8j8pvWXW/rd7Dx2dG75rHrsPBXPyGUXh4lMDiIU2NN0cUI/vxordwAv/RzpHyhAsonaLvrJMgERq+O7ISFHFSeTRD2GISAij/33AqpCYs4Ng6XzcHiRs5EC1ZtdNH9MAwlrc5wqKE50QWX1PBhOZrV5a+xn7TYRQ7SIapVdz6gkhCsU46xY91KbddXhEDk2ALeBhRMdK1LU42TxfMJseitCbpxNWwh2nwxDNcQHMsXJrL8J0BWnpWQWqayMxURWswyv6a9yrROZIFZaUSqdMFsQSX7O6j647CJuvXpzdb/LSHwe+NH7gB/dTG5TWI+TqVXPoirDrk3s/aLFkTObnnHj5ry3kq/P3KUn7VY7w4lRYZYTS9bbazK7S1OcfJ1dOFW9KvjiF7/YhMPgVE02qX0AnlbWY1W/p3FxpPUSJHOUxoR5HFguxYnufhzKkd2tTiucbLkEPEhhMVF9g6/xIq3NHFIUrZhsJ8XJbhPxtTedizd+/RHc+9wUvvDr/fjLF28BoPd+rDT5fxexDwJpQEo0pnBaJZAeIO0iUMC6QS8ml1Kdpzh5BgHRDkHJYghLSMq1fQ6KrXqVN0CYTW/TsF8fmnngV+Tr6osAl7UeAc2qt5CA4hsju3tNV5yMPSlZTb0oJJmR0YcoBJUuID2DVf2e8ZAbE+EkJsJJ7FhTYK0e3g64++FKLuBM4TDWhy4g0dCA+S65ISACybDeP1bJpkfJuvohxRPwZhfKPq5eVFXVrXpl7EeAXvwsWCwe5qlyF3Tb8wa1joXcmImmcWopiTNWLn/SrLHpv5L9kxVOawa82DMZqT4coqGKE1UqT7ueqJbRKUBVtdc2bVFxmjAUTtvHApBEAXOxDCbCSW3UxEwFxSngluCURKRzCqYjKa2XbUXQVX0IFlObBrcUW14ZBZHk//TaM/HJ67bnWfaqZvpZALRYnH0e8BLV3UqPU6UEyoDbjlNLKS3KXmI9TiyK3NjbuPoisg6YNYTf1Fo4sUhyE6seAINVL19xkhW1a+Y4VV043Xjjjc04Dk61TD0LKDkkHf2YTPXjhcYY2lZDC6cVwhx2LZfiRKMxn0+Qi2THWPUcPiKp55IYFJZwPOtCKitXVQQbU5U0r3j4KJBL0kS9tY0/7jrYsaYfn3n1Gfjg/+3GV+4/iI3DPrzy7HFtF36lieIUd5CC2J6Yqet3M6veqMnwWyOXbx7Cw4fncVY9Fo1WIIpk7tXSCYwJ83g+N1z5Z0woVJyspOppwRBGm96BX5KvZsluJVgRcsFuE5DJKZgWBjAGAPEZkiIqNeeCa7lwysoYFehOqru/6tCV8T43cLREJLkoQl59MWz7foKLxD3YIB8GlCwpzsw+wywgInycJPmtvxxIx4BD95Pvb3152WPJuYeA+El4c81VnOIZWYu2r6w4VRcOUdjfxBgLuLAbbaI4VSgCWeG0dtCDPZORGhSnBqXqxee0OG5sewVw70dIKms6WnWPE1OcxkMuuOw2bBsL4JmJJTx1IqwXTpriZP5ZEwQBo0EXjs0nMB1J4/gCTdSrJYp8iraWGANWCimIJBdFob6iCQCmn9Nvzz5PwlpgsOoVFE45WTFE91tTnBiaVS8ZJl+NipMgENXp5x+iP7wCcNa4ZmQqdvQUGZZsy3+NNo/4IAjkWjsXS2vn0qVkVivyKv1t7U5NnzRZlvH9738fn/70p/HpT38ad999N2S5+Q2mHAPUpnfCtQWAgA21pMw0C82qt7A8Vj05p+1IPx0jMvGKkLn833YIgj7LSSQLslonx+cHQ5ABxBjc3DaJekZeu2Ml3nUZacb90F1P46kTYW0xaWbViztJ4eRK1lc4zURTcCGNgEwXiyZWPQB41+Ub8MzfXIPLNg/V9ftaAu0LGhEWa57jxN5Tfm3QYuWF7MEZ0n/ArBrIJIAjZKBrNYWTZBOxii6ujsRdgI0urKKTZX6qPox/X6k+p6ysICurGBRoOlihTc8CerKeeTrk3BCJa7/UvheB+d3kzpXnlY4NNgREACBFk5wmhdbw9rLHknOTvkG/3NzCiVmPnJJYUSnQwiGsKk4FM5wYYyEWSd6aWU5GxcmqVW81tZ8tJbNVhVpogSX1Kk5MbRraRvqU2fDU2HTtVj06jJj1CBn7nJjiNGIy/JZh7HM6Us8Mpymq3I6UKZyYVS8yAWQa1Pc3Yyyc9mk3nVrhlP96Gs89lYq2wsTXoh6ngh5LnPV6wE4Hyw/WqDYBZJSBzUnswCYWao9DHymxz6A6sV7EgEvKj07vQKo++oMHD2Lbtm244YYb8IMf/AA/+MEP8OY3vxmnnXYaDh061Ixj5JhBC6fnQD4AG4baT3EaW65wiOgkoMpQRTuOZVjh1CGKE6AFRKx1kgvDQrVxtGaFE/Mxl/JztwEffslWvGjrMDI5Be/8r8e1kyzbkTSSdpFFqjtdv+K0kiXqOQPFFxcDXmf7FZyW0AYGLyArqzUli7Fd7CG6GxxN5yo+Dws8YHN0cOQBsogPribJc1WgRZIvJJYlIKJQcTKDfc4G6cw1LRiiCrRZTmaKE4ADbhL4cA72QzhO0wjHTfqbGIUBEUabXoUZLYqHHH+gyYVTOGFtBx3IHzxqZSBx4Qwnhj4Et0WKUxVznLS+nQFy3lNU6ymWgGHjrN4Zjqy/aTXtb/LT+XbRKTjowFbrhRN53dl1+CytcNIjycsNv2WwwmkmktJmONVUOE0zxemM0o/x9BMVGSDznBpBoeJEKTXHiSmoQbc9PyDJhMIZg1ocOetxKhxD4AoCZ7yW3C5XQFZCFLU1HhaPmT7ErM9J/6yW/v/dKVRdON1yyy3YsGEDTpw4gV27dmHXrl04fvw41q1bh1tuuaUZx8gxgxZOf0wS2XRjG1r1hhFGYjmGJVObXtY7BhUiBn2O9un3sgLduV7pIIVDtR53bcfRbIZTGwVDFGITBXzxDWdj84gPM9G0lp5k1p+WcpPXyJsuP2enEvkznNZUPwCwE6CK76hAdh5riSRnO6FsUaOqQCxTXj3WmprZApnZ9Da/uOrXmS0iSSR58wMiYoZ5c6VsiayXZIgqwzUVTuVmOQF4NjuGOTUAJ9L6LCazYAiGMSBCzgL7f07+XcGmBwAqPf6gErZw5LUTTrKUsMq2J2blU1Vr9lDW41RcOLV2lpPRqlcpqZF9f9DnNAREVFM4NSgcgilOqy8iX32j5GtsGg66KLd6LmGKE1P+zl5FLPTPTCwhR59jOlI+HAIARgN6yMfhOaICVV04paPAwhH6hGUKJ6AoIKIuFFlPtgXyFKdSVr07HyN9Q1uYal+GkopTsoTiBAAv/jRw9aeAF9xa8fnLMnIa+cpmQxXABuEa+5wWtZEEHdY3bELVhdPvfvc7/OM//mNegt7AwAA+97nP4Xe/+11DD45TgnQMmCMfwt9GyaKirRQnzyAU0QFRULVBnE2FFk4xFznRd5TaBGiF0wobOclUa9Urrzi1TzCEGX6XHd+48XytWVQQ9IutkZyH7H76s3N1/T5SONH3ZIn+po4nwBQnsvNYW+FE3lNBt13rb6hku9UujF4HWfmyYIgqbHoMtjjKjyQvUTjlMiQMpQ6sWPXY8NtRGy2carHqGRQnY8IY4+h8Ag8r9DOrygAEYPzc0k9oDIjY9zMgtQR4BoBVOysfDC2c+tSw9T+gBqxGkQMkvY3NqLFyHpylu9iFPWkrWm3Vq6LHiRWIQbddi6C2eg2QFdV8FEW1ZBK63dNUcbJu1VNVVdsYYBsF6wd98DklJLMyDszEICuqFvYwUiIcgnxPt+odpYVT1T1O03sAqESJ91YIc9ECIg6WfswP3wd8ZYeu7JRi4YjeZwyQhEL6M2bhEJNLSXz7EaLgvP+Fla10pXucWKqeScq1Kwhc8gFtjlvNXP5hQBCBPT8Ejj5Y9G02Gsc4y2leSwvsQcXJ6XQiGi3OZ4/FYnA4Orvhq2OYehpQFWS9o5hFH/q9Ds0b3haIIhQfWbz50/WloFliicRiLkjkRM981R2DlyzAhkViY6h6AGJh4aTIwBxL1GtfxYmxqt+D2968A05JxBnjQTil4gWA7CVFsUuJk42DGpkpVJy6EYNVD6htlpMeOGLTZm+VUwAURdXetwNeB1E8l44DkkuL2a6GNXmR5GWseukY8LULgX+/rK7iKc+qV+LzxzYoRkR6/au0CDOBLSTjGdm0QDsyF8fDiqE3aXBz+TRCFhABAL/9HPm65aV5g3dLIdDCL6QuVXhkfVgdfstgyXtWigddccpfjI3Sa8B0ZPmH4KqqmmfBqtSztGQonNjfbjWO3bjwriscYuIJQMmR0AD2fqLnEcSmqgqHWIhnkKaPY7ZdURRwJk033H0ijPl4GooKiEJ56xYrnJ6ZWEIyK8MmClr/o2WmaaKeFXsa6/0ppTgtTQBPfZsESLAQllKw/qaR04AAtbbRpFu3SY/Tl+87iExOwc51/XjBxsrnlkBBD5SjUo9TIxk9A9jxZ+T2vR8haw4D26jitH86pimMC8yq105r1Rqp+pN27bXX4p3vfCceeeQRqKoKVVXx8MMP493vfjde8YpXNOMYOYVQm95cgMilbRUMwaB2vQF5ruYGdctQxWlaICebTlWcBhEGAIRr7XFiVr3wMSCXIg2c/esadpjN5IJ1/Xjwr16I773zQtPv29wBxFSqREVrK8YzOQUL8YxeOHWr4kTfTwMCWeDXUjixhY9LsmmWkHKKUySl96SEPA7dprf2UsBR5UIHdPgraCS5v4zitPu7wMIhsjgKm/vtrRBNV+5xYoqTFg7hrV5xctltGKS2MrNZTkfn43jIWDiZDb4thKlOM3vI1wox5AzRT3adB9SwqfrVKMJVKE6AXmAtxi1Y9ei5crBgMTbid0IUgKysYi5uMmy4iaRzCox1klLG5qqqan7hVMXfDuT3yLhMNpwswwYmr96p22p9THEyhENYuJaz/qYhvzNvE4z1OT11IqwFQwz4nLCJpW28rHA6Nk/6m1b2ufNi5y3BosjLJeoxCiLJi9j7Y/02G05dCtbfNHya3uNJLfSFc5yOzcfxf48Tm94Hr9kCwYK1uVBxKhtH3gyu/DjZ1Jl6Bnjyv/O+tbLPDa/DhkxOwdF5ohQuGB0JHU7VhdOXv/xlbNiwARdddBFcLhdcLhcuueQSbNy4EV/60peacYycQmjhdMhOBrO1VX8TRewjhdP4cgzBpYXTsRw5UXRMoh6DXqD6FHLCq1ZxSmYKPO7MVz242dLOc7sw5HfC4zAPZHDZbZhW6Q5ajelqLIFrtTbDqUsLJyfZ7fODLDbqU5xErQm5nOLEAk38ToksbOqw6QH5keSLErWVFCpOigI8cpv+b0PzdTWkc3Lea1QqBY29JgN1pOoBpfucEpkcpiNpHFJXQGFF2UqT+U2FsIAIALB7gfVXWDoOG7ViDQgRLS68GTDlKGRRcarGrlZKcZJsotY7s9wBEUYViKkApVTMeEbWNhxqseqx3+WQDKMoaqGwvwkgYw0AojixOU4WziXGGU5GzjYWTjSKvJxND9CH4DJqS9SzEAzBMEaSm20m7PmhfvvEo+Wfa9qgODHnB+1zYql6rPD90q8PIKeouHzzEM5fa63gKZwxWGzVa6LiBBDF/fKPkNv3/Z0egw6iMG7RAiLIBh67RvSk4hQKhfCjH/0I+/btw1133YW77roL+/btw913341gcPkHzfUkE7sAAE/l1gJos/4miricyXq0cDqYDgEwnwPU1tCG1KHUEYhQLNs0GEmDrQqAPuSujYMhqsWdVzjVpjixXc5VYpcrTk5ywfIJZAFTi+Kbb9UjF+hySV/aYEOfg/TZsISuTVdX/buB/EjykzL9/15YOB38tT53BtD7+qqkcGOnkuLUx6xtNYRDAKWT9VhqWJ/HAfHKjwHrLge2X1/5CVlABABsfBFgt3b+k/zUqifEkUk3r7hgRUPI4kycamY5lUrVA3Sb2OQyB0Sw94ndJmjHVepvYZsRdpsAl12seo6V6SiKalFkvQhYbVD8fYYeJxt5fivnEuMMJyOscNo/HdXe6+WCIYDi4bgs5toyiqwrsSMWCqf+daR3JxMrvs5EJvUCEyCz07Jl3lta4bRdvxbTa7MxHOLAdBR3P0XU9A++2Hr6aKHiVGzVa7LiBAAXvINs0CbmgAf+Ke9b+iBc0ue0oPU49WDhxNi0aROuu+46XHfdddi4sY5MeE51JMPEmgLggVgbBkMw8gqnJipOqqpNsH42QT6oHWfVG9gISG7Y5STWCNN1zHGiH2emOHVAf5NVXHYR06hPcZqNphFATFNiNC9/t0EVJy9SEKFY2iUuhHnvnXabYZZT6c8xW8D2eRzAod+QfonBzXVZRVkT+ME03ZCLTpHkOMbDXyNfnfT7TS6cyAaFihBLoau1cCqhODFLy9pBL3DeTcCN91iz2zCrHmDZpgcADl8/sipdEEfqS6ssx2K1PU4WVZdUVtYsloVznADdeTC5zAERxrAeNouHJQsWYrTpCYJQg+LE3AZ19DfN7AHSETK3afg0/X6mOEWrm+NUOMOJMRJwYTTggqIC9z9PVP9yUeQA2bgxWjzXV9uWsHCYDPGV3MDAhsqPl5y6E2G+ICDi+Z8AUIl91jtEhlNP7jZ/nnQMWKRJfiOnFylOLk1xUvCFX++HqgLXnDaCM1ZaFx+KUvUkgRSKKbqx02zFCSDDb6/5LLn9yG15FsdtVHF6vkBx6obCydKgkltvtR5d+PnPf77mg+FYgH5Q1dBqPDUnAVDa0qrHmiHHhXmEm6k4pZaADPlgPqsNv+2wwkm0ETl/4nGcJhzFyUR1SXgswcldpDi1d6JeNbjtNhyo06qXFwzhHQIcbdgb2AhcAe2mD8m6UvWIVY8qTmWsepri5HXUbdNjsEjyfVEnINrJQiU6RSbXz+wFDv+G7A5f+THg3r/S3/dVEisonEr9nclMDn4k4QD9fr2FU4HidITFLVe7q+7pBza/hATCbHmJ5R+TJAnT8GMEYSjRaWC0OQpsNal6xsdVKh7YQkwSBS3AxMhogLzOy604aedjh144lSrG2f1M1a1WcTJNVK0WpqKsOj9/WDpTnNJL8AjktbZUOC2ZW/UA4KxVQUw9l8LDh+cBAMNlht8yRvwu7fWoWnFi/U0j263b1gc3kaJn/gCwzhBs89wPydft1wPH/kBSLE8+SvrCCmG2Ye8wsbSJ9HWNTACpiFboHp6JYfeJMAQBuPXq6mbdBQve85IoAqkwAGoxXI7CCQA2XQVsugY48AvgFx8H3vS/AIyKU48WTk8++aSlJ7PS0MapE9rflBg8C5kpBU5JbM9CIUjUsDFhHiebqThRm57s6kMi5YJDEjvTQzt6BjDxOLaLx/BsjYqTy2GjiXp016eLFCen3YaZugunlD78tlv7mwCya2pzAHKGFE61KE6GcAgrVr0F2sze75b0YIgabXoMLZJ8Pkki1sPHiV0vtAp4+N/Ig7ZeS+ZE3ftXJLFKkavu6yu0EpdUnDKy3t/k8NUUegEA49SCWKQ41Rq3DAB/emdNxzKPEEYQhhxt3tgI9npa7XFiC6tKAQlGm57Z2kNXnJa5cDIUM6EKhZBRcQKsq22MVKFNuxbM+psA0vgvuYBcSuu/tXIumSgYfmvkrFUh/OK5aa2nrpLiBAAjQRf2TZPFd9U9TlowhAWbHmNgEzmHGSPJYzOkWAKA7a8A5AwpnEr1ObGBu2zekTtEUgqjk8Dcfrjt6wHooTSvOGuFpdlNRornOAl6f5PDD0jLuA665u+BQ/eR4unAr4BNV2t/z0Q4iaVk1hBH3oHrswIsFU6/+c1vmn0cHKvQwmnSSxbF6wa9ZVNpWga16vUJMSRiEQCjDXvqRCYHt91GLpa0cEp5VgBhspvbkQX82JkAgNOEo9WHQxh3HRePkkQ9yQX0rW3wQbYOt92GqTp7nPKG33ZrfxPDGQASc/AJtRVO2lBluw1+Z2Wr3gIN3tguHgXiM6SwWH1x9cdtIC+SPDROC6cJ4uF/mhYKF74XCK0lVpxcksxOGazOOh6hf9egz4m5WLp0j1NWxiDq628CLFr1lolFgViD1HjzCqdqB19atauxOUCFM5wYbAjuZIlhw81CV5wkbaBvJcWJFU662mZRcco0sHAqnP0lCER1Ch9DMLcAwGkxVS9/hpMR1ufEsFQ40cc4bDVsEmsFjIVEPYZZJPneewCowPgOYvFedQG5/+RjpF2gcM0xzfqqDNbHoS2kcJp9Hq7hTdrdNlHAn1+12frxUYzhEHabQNY9yxFFbsbgJmDnu4GH/hW496PA+isQcNkxHnJjIpzEruOL2nWoGwqnOoyxnJZwigRD7BPIh3tDO9r0AMAVRFIkO6sqLW4awfefOIntn/wFXvQvv8MXf70fc6dIv9eSgxRmZifrjmCUFE7bxWNYSma12QdWyCucmEVgcFNHJepVwmUX607VmzEOv+1mxQnQAiL8SNQYR26w6lWhOJ0ef4Tcsf6Kunc8jZHkqhZJfgp44j/J5sDYWaSZXRSBIbrwqMGuF6O7vixUJpGRTZvgUxkZg0Ltw28ZLBxiIZ5BwhBTfYQ2zFdt1auDsBACAKix+gZLl0JW1KoVJ6t2tbkSiXqMVoVDJA09p7riZF4EMlsoWwQzxcnyHKdcncNvwyeAyElAsAErzyv+Pu1zCuSIta7SuSSdkzEbJf9fzNJtzxgP5tUYIxaseuz/45oBT/WbxNUk6jHMIsn3/Ih83f5K8nXFOeQ1i05qm7d5GBP1GFqf0/N5he5rz11ZU1qgyy5Coq+HJBYk6nmWuXACgMs+RAq2+QOaEreNDsL940FyfnFKIjyOzl+XWFKcCnn88cfxv//7vzh+/DgymfwP+A9+8IOGHBjHhPg82XUF8FhmFYAwNrZjMAQlYh+GO30Ugtn8lRp5/BjZUTk8F8cXf30ALukhvFsCdkdZf1OHRZEzhrdDFUQMYQlDWMRSMlt2MKCRlHGOE2uQH+qe/iaA/G16OMSU+S5fBXpLcaKFk1Bvj5N+kSunODF1YEOY2lnq7G8CyGdZEkkkecw1DD9AZjWxWSoXvld/DwxvJ/2fM3uBbddV9XuYVW9FyIWnSM4MlpLZIiUjkZENM5xqV5yCbjv8TgnRdA6nwklsHPYjmspqhcDawdosgLWwJAYBGRCapDhFU1kt1TloOVXPmuJUaoYTg10LpiMpyIq6bM6MvB6nCkVgpF6rXkbf4KgJpjaNnWXe80n7nHzZOQArKgbNTC+R97BTEk2VBb/Ljo1DPhyYIUPMC1PzzGB9TdVa2RCfB6I0idNYwFSCptySeYhpIBUBjj5I7mOFk8NL5kJN7iZ9TqFV+s+rav7wW4Y2y2kf+jx2iAIpeG65SlefqkEQBPhdEhYTWWLTA/QZTsutOAHEjji0lSSq0vPJ1tEAfr13Bg8eJIV3v9fcVttpVP1p+973voeLL74Ye/fuxd13341sNovnnnsO999/P48jbzaTtNesfwOenSdvvrZVnADEXGS3SorXphCYPmeaXCiuOW0El28ewrhAdjKeCJOTa1v2e1nB4YFAd7pOE49VZdfLs2swxamLosgB0mszq4bIP3IpfWetCvIKp25XnFzkXFyr4sTSutx2m6VwiPl4Bv2IoD9MewoaUDhJNhGr+0kRMScMkDt3f4/s8vpGgNNepT+Y7ebWkKzHCsKg264lCJotdBPZxhROgK46sSG4bMDnoM9R1LvQTJZEssASE81J1WPnMR+b72UBY19QucG8+gwn88Jp2O+CTRSQU1StKF0OdMVJMqTqWbTqecnXVFbJmwdVilSuYPh5tbCxAYX9TQz/GADAl6WKU4VNmAmDTa/UApkNwhWE0jZLIy8/cwyfffUZ+NjLqtwMnKbnor512kaSJXwjxGqsKsT6+/xPyO2xs/Pt7yuZXa9gEG50klyfBBswaAh8MChOAz4n/v0t5+Hbb99Zl0uGuQG0z9ZyRpGbwX4vPY6tY2yWE1Hqu8GmB9RQOH3mM5/BF77wBfz4xz+Gw+HAl770JTz//PN43eteh9WruzTet12g/U0YPxeHZsmOzYZq4zmXkaSbnHRdicYVTnFqq3nR1hF8660X4CWryL9dg2sw4HXgqm0jDftdyw7tc9ouHKtqlpOpVa+LgiEAsjBIw4EFlW4UVNnnpKoqZo3hED2iOPnqVJyceVa9MopTPIPLxKchQCW2mMBYDQddDEvWOyHTC3KaWuXOfzsJwWAMbydfaxiCyxQnv8teNgUtlWlMjxNQ3OfEEvWqTg2rk6hECidbcr4pz8/OY1bVJkBXXTKygnimdPGgh0OYL75toqD10CynXS9hUJyq7XHyOyXNfmVFddI2zaQaCqfYLPD8T8lts2Q4AKBDkj0Zct7M5MoXc6dKDL81wgqnAa9DH9paBpfdhjdesLr6TdFagiEAUtENGPqcmE3vtOvzH8f6nAoDIphNb2AjYDc4YNg1OXwcyMRx9fYRXLCuvgKHbfQs+/DbUrDfS49j62gg79s9WzgdOnQIL3/5ywEADocD8XgcgiDgL/7iL/D1r3+94QfIMTD5NAAgMXAGFhNZCAKwfrB9FaeMlyyePMlGKk5k8ealDev2GJHiP/gnL8ITn7gap493sOpJT/DbxeoCIpJMHbChKxP1AGL9AFBzn9NSMougvAi3kIEqiEBwVeUf6mToLKfaU/UM4RDaHKcyceTxDC610YXKxvrS9IywoIRDacPn2uYAdtyU/0CmsM4dyJ/1ZAF2TvE7JU3tMFPXEhkZAw3ocQKKh+DWlahXBzFaOEnJ5ihOTLnr81ovnDwOm7aDvhgvXTzM0e+VS1EdY31OyxgQwTYdPIZUvSWLqXpklhMNiKiQKggYhp9Xqzjl0sCdbwJiU0D/emDjVeaP8xHXiCdNnB2VziV64VTaMn/pxkFIooAzmn2trqW/icHseiceAY48QG5ve0X+Y1aeT74WDsI1Dr414unXN1zm9ld/TCb4neS9IhVa9azMf2sGnvzCae2AR7t2Az1cOPX19SEaJdGQ4+PjePZZ8uYMh8NIJBKNPTpOPrFpAMAEyIdvPOSuXaJfBmTa0O3PTDfsOeNa4WQjCyS2gO6GhfCorjhVMwSX+dz7MhNdmagHkAWFyy4aIsmrU5yMwRBCYJwM7utmtB6n+qx6eXHkyZypdSqTUxBN5zTbbFX9BBVgTdPPxQwbRGe8DvAVKD7BVcReo2SB+UNV/Q6mpPlcUlnFKdlIq16h4kQT9WppEq+HuEQWWPZUcxSnaoffAuSzbiUgYr5Cqh6gJ+udWkbFyWyOU6UBuAGDIheqIiDC+Dm1jKoCP/4AKQqcQeBP/7f0TDuqOLlSVHGqoF6Xm+HEWDvoxR8+8kLc9pYd1o+5FmpVnAA9IOKJbwGqTJ6jcIBu31rzQbhmwRCMgkG49cLml7WP4pRv1ZNsIjaP6DbJni2cLrvsMvzqV2TA4Z/8yZ/gAx/4AN7xjnfgjW98I170ohc1/AA5BuLk5HUsRU5KG9o4GAKAHkmebdxuJiucfE6JJGypCtmBrnMh0xbQwmm9OIV4xHoPD9t1DMbognFwc1cl6jFcdptBcTpV1c/ORtO9McOJoaXqNWIALrk4Z2TFtDmcLY6HWFHha5xdlkWSP7Po0FQ0XPju4gcKgqHPaU9Vv4P1OFWy6iUzMgZAFacG9TgVKU7LbNVLOMjnyZFeAJTq3yeVYIVPNVY9wFpIwlyFHidAV5ymlpZPcUoYek6tznEyDvDtqyKSXA8GqmIp94cvAbu/S3pwXvdNXV0xgypOTlY4VdiEKTfDychIwAVnLfZCq+TSwBwtTqqJImewSHJmDd5+ffFjBMHQ52Sw67Hzz7BZ4cQCIqq3FJvB+iEdtjbpcWJKF1O+AGw1hHp05IxNEyyn6j377LM4/fTT8a//+q9IpciH4+Mf/zjsdjv++Mc/4jWveQ3+3//7f007UA5ISgyAA1EnABUb2zgYAgBsIVI4DcgzNaWgmcHCIbxOSY8BDYyTSOJOxzuAJfswgtkZ2Of3AjjT0o+xwskfpYXTcHcl6jHcdhumMrUqTqneSdQDABcpMvxCEtFa4sjZTrbdBq9DgiCQj3AklS2aGcMmwg8LYXJHAwsnFs19ZDEN5e13QszG83aQVVXF1357CG67DW8d3gpMPF71okTvcapCcarXqlegOB2l4RDLmagHAEk7DYdQZSAVbrjFJ1yD4gQY5xmZF06qqmo9TmUVp1ALFCdm1TMoTukcCXso/OxEDMEkDKtzrADDBofVIuT5nwG//hty+6X/AGx4YfnH0zhye3oBduSQlUuHdQDlZzgtK7P7ACVHQnLoBm5VDBQUk2aFEwCsOh/Y91O9z0nO6mrScihOrkKrHosjb1U4RL5VDwC2jul9Tn29VjideeaZOP/88/H2t78db3jDGwAAoijiIx/5SNMOjmMglwHS5KL93JIDQLrtFSdnPwkLcSNNPkgN+DBrVj2HBMzQwqmWE2ObMu/bguDiDAKL1nfNtYtnkloiQ90Z0uKy22q26s320gwnQA+HqKHHSVZUTaVy2W0QRQF+p4RIKodIMofhgoCqxXgGTmTgB7Vq11lUGDFGkk+GzilakD1xbBH/9AuyCHnNizchCFSdrBfTFCdJs0yZFU7ZdAIBgSoXDVKcpiMpzMfSWvG53IqTZHcirHoREuJAbKbxhRN9Ha0Ov2Xo84xKxXjnkFPIIr6c/aeVPU5uuw0+pwSbKEBWVIQTWYwG8wucwh4nwDjHykI4hHEURSWmngW+/3YAKglXueAdlX/G3Q+IEqDkMIglZHKl0+lUVbUUDrEsaDa9M2vbsDXa8kZOLz1UW1Oc6CDcuQPEuufwm1+HG644FVr1WhhHDhRZ9QBgWxcqTpa36X/3u9/htNNOw1/+5V9ibGwMN954I37/+98389g4RhK0f0Cw4WlqR2/nRD0A8Pl8mFPpbkMDZjnJiqpdKLxOG7BEZlp1U6EQ7SNqUX/UevMou1A70vSN0Q22RRPyrXrVhUMsJrK9pTg5SeO1D4mqrXppQ3IWmw/DCgqzgIj5eAZDTG2SXFoUeiMwRpIfo3Y2I9966Jh2e1eS7I5XWzhpVj2nbtUzW7B7smQXVREddf+Ng14nHJIIRQUePkwWGcN+pxZ6s1w4JBFzKv1b4o0PiGB2s2DVihN5/EKJcIi5OLHp+Z1SkYpjRLfqLWeqHk16ddhI2EOJYjyVlbVNjfzCiSlO1q16znIDcBWZLOi/+wYgGwfWXQ685HPW/hhR1BTkYWGx7BynpWRWsymy171lTNNgiFpsegDp+QqMk9tsdpMZK87OH4RrDIYwK9iY4rR4FMjWX8wXF05h8rWNrHrG+Vv9XmuzKdsdy4XTpZdeijvuuAOTk5P4yle+gqNHj+Lyyy/H5s2b8Q//8A+YmqpuB5hTJXFSOKmeAZwIk4tGO89wAkgf0qRKPkjy4om6ny+e0eOQ86x6XaQ4ZQaJvL8iaa1wysqKZp+wp1iizkBTjq3VuOyiXjhFqiucwolsTypOfqF6xYk1nAO6BYh56c0iyRcTGQwjTP7hG26IJdcIiyRnAQqMmWgK9z6rvw9+Nh0iNxYO56dcVcCqVc+dIRsTsnug7r9RFAVNPXvwIDm3L3eiHkB6I+ZBN7eaMARXt+pVpzj1e8urLnoUefmCjCkf09E0ZKW8zaxRsJRTDy1mgiUUJPYeEwXas0upxqqXNMxbA0DOiw/8M/Cjm4FvXQd86Szg08PAv54HLJ0gEdmv+1Z14Tha4RQuG0fObKeDPkfZYnZZqCcYgnHujWQO0zlvLv0YNggXIKqT2eBbI94hogapCjB/sPZjo7DzlVMSiU2Q9WS1WnFKLmo9kwM+J9YPeiEK0DbBOp2qt7e8Xi9uuukm3HTTTTh48CD+8z//E1/96lfxiU98Ai95yUtwzz33NOM4OVRxSjv7oarEA97usqffZcekOoAzcBSZhROoV7xP0P4mSRTIiaILCyeMnQUAWJk7Sk6EFS5wxiGJYpKqkl2qOLntNhxihVNsmuykWgzBiCaSWCFQRa6LFMqSGK16VSpOmoJpEyHSmTIsIMIspnshnmlKMARj7aAX2DerDYllfO/RE8jKKob9TsxE0/jZURX/6AlCSC2R+SsWFk2yomqzgoyFk9nf6c8tADZAbdDnazzkxpG5OB48SJSedcts0wOI4jSrKU5zDX9+ptyFarTqlVJd9OG35XewB31OSHQI7pv+42G47DZIogi7TYBkE3HOqhDe+oJ1VR1bJZJ0g4/Z50IlhuAaE/WMw2KtJAoyjLZAAMAv/x/w7F3FDxQlYlt79e3VL6rpENxhIVz2XHLKYjBE01FVQ+FUo+IEAFf8FfmvEisvIKl6Jx/TiyE2V64QFmJz/CFg5vn6CjsAV24dxuWbh/DGC1blD4V3h+p63pph7y1VIUUcPY7/fvtOzMfSGG21Etkg6vIFbNy4ER/72MewZs0afPSjH8VPf/rTRh0XpxB6UYvaQgBIol6pydztgkMSMS0MAgCyC8frLpyMM5wEQejKwsk9tA4R1YOAkCANpBVO/My6KAiAEO/uwsllt2EOQSgQSTN7fE6Ly62EGD0FSVAgi3bY/I0ZztrW0HCIQA1x5MbhtwzdqlesOC0YrXrNKJxYQITBqpeVFXznEWLV/ejLtuLvf/o85mJpREc3IZB63PKihJ1TABJHXmpgqaKo8CtLgA0N+3wxxenEAtmpb4niJImYZ3bqWOMVJ6aahGq06pVSXazMcALIENzNI37smYxolkgjP959Ci89Y1SLLW8EhX1H7G8pnOUUMelvMj6+qnAI9lmdp3P8zn4zsO5SskkUWk2Kn1qTVv26Va/cuUTrb2rga1kTkQkSdCJKyzPPcNUFwGO3k4AI1ntbziI4tIUUTg3ocxr0OfGtt9I+KxY44Qq2LlXX7gLsHiCbIHY9WjiNh9ytDwxpIDUXTg888ADuuOMOfP/734coinjd616Ht73tbY08No4RuiheoBe5du9vYixIw4ACqKzIqYO8KHJVBcLU/hfsHgWhz+fEHnUNLhT2Qp16GkKFwimVIRcynx0Q2I6Td7DZh9kS3HYbZNiQcg7Ak54lvnKLhZMnTnrs0t5xeLohgbESdYRDpAyJegzmpY+Y9DgtxDPY1KC0OTNYQXHUUDj9as80piIpDHgdeNkZY3jwwDy+v+skDqqrcC4eB2at9Tkxm55DEuGUbCWteqmcjCGQv1H0N+ZvZAERjHXLnKgHAA6brak9TtoA3CoLpz6PHa8WH8DbJx8A5r9dNEPHquIEAN+86Xw8enQBWVlBTlaRU1TkZAVf+PUBLMQzmFpKNbZwyuSrQKVmOZkFQwB1Kk7sOnvhe+pTW4zQSPJhhKGoQE5WINmKz6FtFwwxuAWQlqGnRhuE+xRJ8gPKJ9tqyXqNCYjQaHUUOcPdTwqnxCLQ4kNpFlWtIE6dOoXPfOYz2Lx5M6644gocPHgQX/7yl3Hq1CncfvvtuPDCC5t1nBxq1ZvMkb6mdo8iZ0TsZJEhNCAcIm/4bXKRNLoCQHC87uduF/o8duxRSA9OdmJ3hUfru5ujUgKACkBo/YmzSTAFJO6ghWEVARGBFHn/5QLdU2SXhc48cgsZ5LLWhykDpEgADLvY0GNvzSxsi4kMhrQep2YoTjQcYiEBhfap/NdDRwEAb7xgNZySDVdsISrQH6NUDbIYEMEUNGZFLFU4JTJ6FLmtQX9j4Q5sKxQnuyRgHs0pnLKyoil6oSrnOG2Y+CE+77gN23N7gEf+vej7c9rw28oF2XDAhWvPXIFXnbMSf3LeKrzxgtV4y0VrsYr2W8zFqvt8VKJU4VT4nipZOHmr6XEyhENkEkCC2pEbeU306z1OQOkhuBNa4dRiO9bJx8nXRhWOldAG4dKiKbiqvFWuwZHkGq0efsvwsEjyYoW3W7BcOL30pS/FmjVr8JWvfAWvetWrsHfvXjz44IO46aab4PV2hvrR0dCL2olOGX5LibnoHIh4dc38ps9lsOppO2ueQcDePRKw227DPoF47pVTT1d8vF44xcgdnn7AtrzJXMsFW4hE7NUXTqEssVAIvRAMAWiKEwDYstGqftRsNgwrLMysevOx5lr1xkNuPZI8ksL+6SgePrwAUQD+dCcphC/bNARRAP4Qqa5wYucUFn7BFrFJQ+IZQIffCqTxWvA1yKpXoDit6V/+66jTJurJpw226jHFRBB0q6clnv5frHnQ0Fuy7+fEYWDAygynSgzRoms2mq75OcwwznECUHIIrrHHyQhT55aS2YqBFiljOESEDgV3+ABXqPY/oBCmOAlkYV5KwW6LGU5LE8Ajt5Hb669cnt9pHIQLlO5vYrDCaeEwGdTbKFih0qoZTgyTSPJuw3LhZLfbcdddd+HkyZP4h3/4B2zZsqWZx8UphA6/PZjorMIp6Sb9JM7EFGnmrwOWqufr0kQ9ABAEARNOMjPCPvts0YKhELa7OWyji2NPd9r0AN06tiTRhavFWU6ZnIJhhWw8SAM9ojjZ7MjZyM6vlI1V9aNpE6seW9yZWfUWE80tnAojyZnadPX2Ec0WFPTYce7qPuxX6Plg8SjZga8As+qxVDO/S9IC84wKQTIrYxCNtSMaF5hjQZe1WTwNpplx5EvUmhZ022ETLfbjPnc3cPe7IEDF93JXIKk6yNgJFvNMsZqqV44hPym6mHrVKJJa35G1cIjiHifyb1U1V3iNpDIGdXiJWddXNjbZslBxKlk4tUE4xM8/DGRipJA58/XL93tXna/fLpWox/CPknERqgzMH2rcMWiKU6sLp+IhuN2G5cLpnnvuwStf+UrYbC2OmexVqFVvKueDwyZiZV9nqCyydwSyKkBUc3XvaMbShp08VjiFVtV7iG1H2LsOaVWCLRMBwsfLPpapAyM2GkPapcEQgK44hW00bt2i4rSUzGIFyOfHOdAjihOAnERUp2oLp2Rhwzl0q16h4qSqKhbj2aam6gF6JPkzE0u4exexXd540dq8x1yxZQjzCCIihgCowFxlK0zUMPwWgDbsF9AX/gDZoGBWvUb1EI4GXWD1xHIPvmU4JBFzTbLqsUQ8yza9539KBrSqCtSz34yPy2/HgwoN+Nj387yHsjlOA3XMhWFqVSMVJ0VRdRWoQjiEpji58l8fu03U3oOV7Hp5QRTsmhhosHWdKk6DWIIIxXSWU1ZWMB1tceG098fA8z8hoRDXfYnMoFoujIpTpcJJEBo+CBeAocep1Va94llO3UYPdEl3CfSitqAGsG7Qa9qc2Y54XE5Mg83eqa/PKZ5n1aMFRbD7Cief14MDKt05nypv12OF04BAFSdvd85wAvSF/IJIT8wWFaelZEaLIhe7sNAuhewgqrQ9V13hlCrYMQcM4RAFO+DxjIyMLBt6nBofDgHo/T9ff+Aw4hkZG4d9uGhD/nv9ii3kd++VV5A7ZiovSiIFhROgz90xKk4Jg1UP3sb8jXabqIUStKK/CSCR85rilE0AmeIhw7WyGK8iUe/Ar4D/vZH0iZz5egiv+DICbid+pZxLvr/vZ3kP16167aU4pQxzjphVr1Q4RCSZy/u+kRCdY1VuCG5WVpCjVj6XZGueC8M7BECATVAxgAiyJj1OU0spqCopxFsyJiUVAX72YXL74lvIANrlZMU5gEj/P1qJGNcKpwb2OTGFh1v1mk5nrL45mlVvHgFsGO6cnjK/y45TKt2hrTNZLy9Vr0utegDxuD+nrCX/YAlBJUhqhVP3K05sIT8n0BOzxSG44XgaY2yGUxe+X0oh24ni5MhVtxhmO+ZOqbJVbyGWQRBxOAS6YGxW4UQVmXm6GH/LhWuKxjGctiKAIb8Te2X6/3hmT8XnjaXye5wAmEaSp9Ip9INuTjTwb2R2vVYk6gGAQ7IhASfSAlVuGtjnxKxpFWc4HXsI+N6bACULbL8eeOXXANGGPo8D98vnQoUAnNqlfd4zOUX7f2MlVa8UzVCcEhm9cGI9gsEKPU5mhRPrcyo1ABjIn+HndtiACLsmNnhzyCZp15VSs5z0KHKXNvttWbn/74DoKaBvHXD5h5f/9zs8wPVfA178ab0oKkczkvWSXHFaLnjh1AnkMkCa2ETm1UDH9DcBZCd3UqUfpDoLJ9NwiC5cCPd5HdijUkvZZHnFiRVO/SqzEXV/4TTDFEyLVr3k4hScQg4yRMC/olmH13YoVHFyKLUpTsaem1JWvQVjf5Mr1LT4X6Mi43XY8Opzi+1IgiDg8s1DulprYVFS2OMEmKeg5WILEAUVSoNTK1997jjWD3px1bbmWBwrYbcJAARERPqZauAQXLborxhF/uu/AeQ0sOVlwGv+Qwu3CXnsmEMQ4f4zyeP23wtAt6+JQvVpfUaY4jTbQMUpaeg5YgVEqESqXqk5ToBxllNpxYltcAAoGAjfhJRZ2uc0VGKW06mlFkaRn3wcePR2cvu6L7YuLOrM1wEXv9/aY5uRrNc2ceS8x4nTDtD+JhkiIvB0TBQ5QAqnUyq11NRp1UvQHqd8xan7rFd9Hjueo5HkFRUneqEOqlRx8nSvVY/1OE2xQjwxRzYVKpBdILbORdtA1yYOmqE6iOLkrFZxYnHkkn55KGXVW4xntKZx+EdrPNLKsEhyAHj1uSvzFCIjV24Zxj4WEGEhWa8wjhwwFE6GRasamwYAxMRgQ99Db7hgNe7/4BVY36LNMAf9f7wksj6nxilOWo9TOcXp1FPAiYdJX8q1XwBs+mNZwfWs7xJyB7XrMWtdv9eZr24c+g3wm88C2ZSl42OK01wDFaeiuUrQi6BoKoecQa0przgxlaqy4uSyi80fCE+Hho8IYfPCqVXBEHIW+PEHAKjAmW8A1l+xvL+/VpgqNX+A/A2VUBTgwS+SIbulSIbJ11YrTtyqx2kLDMNvVYjYPhZo8QFZJ+CyY5IVTvUqTjRVzy8pen9LVxZODjyv0vS3yMmyJyB28QwqYXJHDyhOc7JX95PTBW05VJo2teRoza5+q1DpLCeXUptVzyxVL56R8xZ/8/FM0/ubAGJpY4l3b7modMDHCzYN4pBAzwlLJ4B0+Sj2wjhyQP9bl5K6uibSHtOo1OJFSYNx0sJpUQiROxoYEBHWwiHKKE6Pfp183X59UeF96SZi8f7UgbXkjsO/A9Ixbe5SXn9TYoH0SP3uc8AD/2Tp+JjiFM/ISGSKY/ZrIZEpLpyMRXnEoNjqceTFhXifpjhVLpzcdhuJ4FuiG5PNKJxo6MswzBWniVYNv33oq8D0s2Sxfs3fL+/vrofgShIbr+RILHklDv4K+PVfA/fcUvoxWhw5t+o1G144dQJUcZpT/XBIIta1qJG4FvIUpwb1OA0qcwBUwOZsWMJVOxHyOBCDB1MStZWVCYhgVj2f3P1WPbeDnK5SOUXbAbVi15Oo0hl3jjXt2NoRgc5ycldZOKVNUvWM4Qms2ACI4tTsRD2ARJJ/660X4Ntv24nNI/6Sjwu67di4eiWm1RC5o4IVRrPqmSlOBnVNoOfgeJcVTg6tcKKKU6yRhRO16nlLKE7xOeCZu8jtne8q+vaNF6/FTZesxQF1HEeVEWLnO/wbzFPFKS+K/A9f0uzs+MOXLAWDeB027T0+F23MENykic1Vsona58eoIJVTnJhKV86qlxd7nlgAcqR4aXiqHqAVtcNCGOkyPU7jyzn8dvEo8NvPkdvX/H1nrQWMyXpWZs6xNcDc/tKKarsMwNUUJ27V47QSg+K0ZcTfMYl6AAuHaIxVjxVOAzK1kzR6XkWbwGwaB0UyCLdcn1MyQy5ivhw9SXXSxaNKWLN1Kivru9MWCidHggyGTHl7q3CCmylOlecZGTFL1bPbRH0AsUGJWWjyDCcj567uwyUbK7+/r9gyjH0KVZ0qBESYpuqZFE5SipyDk44W9w80GAcdLzLfhEhyTXEq1eO061ukGFpxDrDy/KJvC4KAT167HW+9ZD1+TdP1Dj/4f8XDbyOn9KGn/RtIyMRP/pzYm8ogCIKhz8mava8SZoUTYEzWI69JJqdoj609HMIw/JbNcPION6fPkClOJa16LVCcHv43UiyuvRQ4643L93sbRTUBEay4UmVi7yskmyKpmEDre5yY4pSJWrMhdiCdswLvZWjhNI9AR9n0ABYOQQun2HRdk7LZHKdghhZOXRotzRYaerJeecXJjhxcMosj717FyUUXI8msDASY4lQ5ktybJIVT1teEndg2RnSRc4VXrd+qB+iWImOy3kLMqDg1z6pXDVds0QMictPlC6eoSaqeXjjpi1YHLZxSju7qIWSK07zajB4nGkduFuAg54DHvkFuX/CukhtggiDgE9dug337tQCA4Mn7cddjRwEYZjj97h+BXApYtRO44UeA3Qscfwh46tsVj1FP1muQ4mRi1QN0BYn1zRk/Q2b9euzxzqUjwH1/Z+rWYIWX027TNyWbFZZkUJwKCydVVTGxuMyFk6IAe35Ebl90c2duoNZSOBXeZjC1SbABrmD9x1YPriAA+v+jSwMieOHUCVCbyLwawLax0jaVdsTnkjCPANKgF4fIqZqfiylO/jRVGbowUQ/QFac9WVocLBwp+dhUVkYfi0kWbCTZrEvRFafqrHqBNOmDUruwH64crHDyqEmoqmr551g4hFPKvzywBV5e4ZQw9ji1Rw/Z9rEAJp1rAQDRY+XDVWJp8rcYFaeQyRwnZ5r49TOu7iycZlS6IddQqx55/UxT9Z7/CVnse4eA019d9nkEQcANr3sdkjY/BoQofHNPAaBWvflDwK7/Ig+86m/IZtqVHyP//uUnKv49Q6xwalCynlY4OfL7lgoj7tlXv0uCzSS+u8/jwEvFR/D3MzcDv/9n4I9fKXqM3uMkNj9llg7BHTIpnJaSWcTp370iuEyF04lHyLnfGQA2XLk8v7PRDG8jXyvZSnMZYtFjmKnoWhR5qPVFpGgo3ro0IIIXTp2ANvzWj+0rWrybUCVkQSLglMJm79Ru19MG4CZZ4dSdC2G20DicCZE7yrxmyYyMQbbj7xlY3mnpywyzv6QyBquehVlO/Tmyi27rUoWyFDY3OVf4kERWrqJwMrHqAXqTu9Gql5eq1yaFkyAICK0hEdb2uT2kcb4EmuJUIY7cnSFzwLLu7rLCkjhyYFahhVMjrXpJNgDXRHF65N/J1x1/ZslaJkgOuLa/FABwtW0XAJBBq7/5e2Jf2vRiYM3F5ME7302GkKbCwC8/XvZ5tSG4DUrWSxiLGQPBgpS8cv1NkLPY9vQ/4N8cX4IHtG9p+rmih+V9TplVr2mKE40jRxgZw5BfANh9klx/1g54iiyKVaGqwLPfB8InKj/2ubvJ160vb9oIhKajJesdLG9pWzhEQiQYZiq61t/UJlbiLg+I6N5VVheRjZCL2TyC2NphihOb/6In69VeOLGmdCftWelWxSngtkMQoPeGRadKxm6ncnJPDL8F9LCCVE42KE4VFMxMHAEa1e4aXN3Mw2s7bLTHyS8kTIdWlqK0VY/NcipQnNqscAKAjWdehITqhC+3AEw+ZfoYVVUrWPX0v9ObJQsApcsKJ6YqTsuscGqMVS+VlbX3UVHhNPk0cPyPJIL8vLdafk5hCymcXud/GltH/XhhaIostAHghZ/QH2iTgOu+BEAAnr6TxJSXYLDBilOKKi+eIsUpv8dJS9QrtOlFp4BvvQJDz5K5RL9UaO+XSchJni2wmYl6gPbZdgo5CAX2qyeOkX+fu7rOUIK9Pwbueivw3TeU3eyAogB77yG3t19f3+9sJcFVNFkvWz5ZjylMNlogmln1tBlObRJewwq4Sla9n30YuO9TDZ0ftxzwwqkDSC0Rq5HgHSg+0bY5TkmE3SZgEqxwsrCbZEJOVpCmFgFHjBVO3akg2EQBQbcd8whAsTkBqCUtacmMXBW8uQAAYPlJREFUjH6wwqm7bESFsL6BrKwiF6RF0HyFKFe6oIiobviC3f36FCJ5QgCI4mTW0F2KlEmqHmC06um7n5FYHP0CHbDbRoXTOevH8FvlLACAsufHpo9JZmXIClmgVQqH8OXCAAC1yzYnWDjElEI35JKLDWnoZjY9SRTyhgsDAB6latO2VwCBKgZSb7wKEO3oTx7DvW8ew/Cj/0juP/21wNiZ+Y8d3wFc8E5y+6e3lkwia7TilCyh1mrhEKzHyUxxOvoH4LZLgeN/hOrw4V2ZP8dfZN5NvhefKbI95StOTbbqSU7ERVJcS4n84noXK5zW1LloP/AL8nX6WeDI70o/rhtseoD1ZD1m5dv8YvJ16TiQiuQ/RosibxPFiRVw5ax6chZ47Hbg9/8CKHLpx7UhvHDqABTq0w4OdF4qmCAI8LvsmKgzWS+eZh8sFWKkyReJNqDf4wAgIONhljTz1y2VlTHYM4qTvhhJhTaRG5GTZWf1KItk+O2EOqjZZXoFm8ugOFVTONHHsp4yBrPqMcUpJyuwp4iFTRWl9tntBFESfqWS3Xp5z09MHxOjBaAoAB6DxYgpa6msgnROBlQVfjlMvtkmARiNgvU4zeY8pEcSaMjurxYM4bGT4ayM+Lwhgvzd1T2pKwCsu5Tc/tUnyWwbUdJ7mgp54f8jyvTCYbI4M6HRipPZHCeguG+uqHA68SjwretIgTS8HXjnb3G/sBNxuJHz01CbAtUpaVSGWeEUaN41MWIn13BHUp+dJysqnjxOCqcd9RROqpqvDD58W+nHdoNNj2ElIIIpTmsu0Z0WhQpku0SRM6xY9aKTgKqQmYwdtnbhhVMH4EiTD8XwaGcWCnnJejVa9eJ0QOGILQ6hmfMq2gR2oY276C5+idctmZXR3yOFkzGsIGkLkOhdIL9xtoDU/DEAwCl10LyfoJuhc5yqVZzSpXqc6OvHepyWklkMgs0PG26r/jqbKOBZz4XIqjbYF/YBc8URvkw58zmlvMW93ylp/dVLySyQWoIdZKErdmnhlFUEqGyUQQP6nPTCqSAYYte3SALe2FnAqguqf+ItLyNf9/2MfD33RmBgg/ljXQHgpVSVevALwFPfKXqIFkfeIMWJqUCegl6fUuEQ2jlpz49Ir9b6K4C3/xrC4CbttUuyTaK5/MWy9rskRXckNHEzMe4g7w9nSn9/7JuKIp6R4XNKZeerVWTuANkcZIPN999Lgj8K6RabHsNS4UTVqOFthkCJgp43zarXLooTm+VUpnBia5rAira6dlih5Uf71a9+FWvXroXL5cLOnTvx6KOPln18OBzG+973PoyNjcHpdGLz5s342c9+tkxH2wJyabgVYoVZvbozezT8LgmzbCBlorbdTBYMsd7B5hUNA/ZlHLa3zLCAiIiDFk6R4jhagBROA8yq5+mu/otCBEHQ+5yysm5zmC1dOGUWiOI0Iw7CKdXRuNyJUMXJKeSQyVif5VTaqpcfR74Q1/ubhDYsKLzBATykbCf/2Fts12PKWWEctCgKmiV6KZHVComI6obL7WniES8/DsNmhMrOHw3oc1rSEvUMr60xgnznu2tL/9r8Ev225AYu/3D5x2+7Djjz9aSP5IfvIT0VBisiS9Wbi6WrSp4shZ6qV2DVKxUOwV4fpiBsfyXgIAPu2WsX8W3IfwyFfU6H1QWQgfCOpm6exe3FhdMTVG06Z3XINB3QMofuJ1/XXAxsvBqACjz69eLHdYtNj1EpWS+b1PufhreT/4Bia18nKk5ahH7ntVy0tHC68847ceutt+Kv//qvsWvXLpx11lm45pprMDNjfuLOZDK4+uqrcfToUdx1113Yt28fbr/9doyPd6/ykI2Sk1ROFbFpdYcqTk47oipdcKSWanoOFgyx1k5PEF2ekMZ2Gxds9EJoMscDIANw9XCI7i6cAN0Ck8rKwOBmcudcceM0Q1kkPXVhqX36b5YNh0+7KSciZR6YT8lwCFd+OAQpnOjnmaUcthGjARfuVaiq8XyxXY+dU4z9TYy8PqcYuR7NqcH6UsPaEJaqBwCyh55rGmLVY4qKQXHa/3OyAeQZAE4rH0FektAqYJT2M1347srvO0EArr8NuPwj5N+P/jvwX6/UYsoH/eT4UllFez/UQ6KEWls6HIK+95jiMLRN/xl6DZhzr81/DIUVTkMqLWSavHOfcJL3hzutvz92NSoY4jC16W14IXDhe8jtJ/+nuJenm2x6QOVkvdl9AFTymfEOGQqtgmQ9Vjh52qRwYgVcuXAIrS+v89bvLS2cPv/5z+Md73gHbrrpJmzfvh233XYbPB4P7rjjDtPH33HHHVhYWMAPf/hDXHLJJVi7di0uv/xynHXWWct85MvHyQmy8FtEACv7vS0+mtrwuSREwAon6ws4I6zHabWN9FR0c38ToO82zoiscCrd49QrqXqAviBJZRWDzaF04cT64SKu9lvYNx3RhjjIXBW5is9dsoTiVGjVW0xkMAx6YWxDxWk06MKv5B1QIQATTxR9hvREveLCKa8nJc5STQNFvSudjsOm/z+W3WxQef2KE7Pq5SlOh39Lvp75+vrcAq/4MimELqugNjFEEbjyo8Abvgs4/MCxPwBfvxyY2AWPQ4KXFsNzsfqH4CYzJax6tAhiSlyeVS8d1UOT2EIa+mt3yr6W3FHU40R+1wAdt9DsnfuUk2zMeTN64cQS9erqb8plgKMPktsbriTF0+AWIBMFnjQMMe42mx5QOVlPs+ltJ5sAFRWndrHqsXAIC4VTB7ZctKxwymQyeOKJJ3DVVVfpByOKuOqqq/DQQw+Z/sw999yDiy66CO973/swMjKC008/HZ/5zGcgy6UTOdLpNCKRSN5/ncSpCWI1SthD+U22HYTfJSHSIMVpXKCFUxObYNuBPi+50Orzr4oVJ1VV8616PaQ4JbMyMEQVpzKFkz1GFssJVxXpXV1EQiCfOyVp/XPHdrILrY2FVr15o+LURol6jJGAC7MI4aj7NHLH8z/N+34pqx5QoDjRwmlODRYtiDsdQRC04innblyPEysM8qLIp54lX1ecU9+TrziHFEKOKm2TW18GvON+YGATsQnd8RJg950N7XPSh9KWSNVLZqGqqq44ue36+cs3kpeKxuzax0V6rYtM5G08anHvOfr/q8mbiWk32ZhjhdNsNI3jCwkIAnD26lDtT3zyMSATI1bzkTNIgXAhDQ559N/1xLVus+kBlZP1mLLElKahLQAE8hk1Dndutzjyqqx6nbeWa1nhNDc3B1mWMTKSf8EdGRnB1NSU6c8cPnwYd911F2RZxs9+9jN84hOfwL/8y7/g05/+dMnf89nPfhbBYFD7b9WqzrJ4zU6T6G1tN7ADCbjsiDLFSU6XjIYtB+txGmW2hK636pEL7XGZnoBMFKesrEJW1J5SnJxGqx5TnBaPADmTRY8iw5Uk55Ksr7cLJzVpbcNIVVUt9r+0VY8qTvH2nOHEGA2SBfEf7BeSO57P73MqpzgFDIWTGiMpYnNqsOsUJ0Dvc8o46TWmEeEQ8YJwCEXRh7iOnF7389fM0GbgHfeRkAk5DfzwPdjqJsX/XAOS9RI0xKjQ0snO57KiIpbOaapt0G3XF8zsfKb9DHntpjMuwEcVc0MQDlOcghm6XmryAjRDCydflmxe7qL9TVtG/PWNSWE2vfVX6FbDM98AuELA4lESFAF0n02PUc45UfjecHiBvrX0ewa7nmbVaxfFyUo4ROemI7c8HKIaFEXB8PAwvv71r2PHjh14/etfj49//OO47bbS0ZUf/ehHsbS0pP134kRtc4RaRXSenBRt/vazwljF75IQhRsKqGKWrl71Y6l6w8ry2BJaDdttPJIJkTuSC0BBg38yK8OJDHwCLUQ9nVtcW8VN7WPJrEwW684giTSdP1j84NgMbGoOOVWEEGi/hf1ykBSJvVe1+JlLG9L3Cq16QXdhOETWoDi13/lpJEDsYPfmziN3HP1D3oW8XOFkVJzkqMGq12WKE2AonFyNU5xYLw87j2HpOLFe2RzA4Ka6n78uXEHg9f8DjJ8HqDIuF3YBaIzixCLCCwtsl92mpYIuJbP5Vj3WuzS8Le9n+oyBEloQjt7nxNQtf5rGgzfZ8pR1k894IDcPqKrW33ROvf1NLBjCqCI5PMCOG8nth/+tO216DK1wMlOcDFY9RqFdT1V1ZaftFKfF0sOMuVWvegYHB2Gz2TA9PZ13//T0NEZHzfsRxsbGsHnzZths+klp27ZtmJqaQiZj7k92Op0IBAJ5/3UKqqoiGyGvjzfUuQs/v0uCChFpsXa7HrPqaX7uHlGcJpJ2vcm/YJZT2mDTU0U7WRB0OS6j4iQI5e169MQ8hX74Pd2VhmaVFPvMWSyc2GIMKFac/AbFSVVVLMTTGEKYfNPXfj1kY0HS37Ur1gd15DQS98x2r6EXTj5neaueEjWEQ3Sj4kSteikHXew0oMcpbJjjBEC36Q1tBWxtMBZAFIl1D8A56ccBNEZxSpZQnAD9tQgnsvlznLRgiHzFiRWdi4mMqSrBPqveFFOcmntNzHnIGsSppoDUUmP6m5KLwKknye31Bfa7899BZosd/T3w+De6z6bHYP9vC5P1UhHdoj9seG+MsMKJKk6ZOCDT9W+79TjJaSBrkuiaSejFHg+HsI7D4cCOHTtw3333afcpioL77rsPF110kenPXHLJJTh48CAURd8V3b9/P8bGxuBwOEx/ppOZiabhzoYBAMHBzht+y2ALroRAwy1qCIiIp3NwIgO/TCXpHlGcwsmcviNTkKxnnOEkeIdqi/ftMPJS9QDDTqxZ4UTU5VPqQH6vRQ+RoopTuSHBeY+nO+aSKMBuy788MDuOrKhIZOT8VL02VJxGqeKUyMjIbKTzfwyx5HqPU4VUPRrPHRb6INk6yqRhCaY4JR3Vh0MoivluMkvV0z5307RwaqVNr5BNLwYAbIg9DicyDVKczHucAH2W00I8gyjdCAy47fqCuciqR167xUTW9Dyn/a5E82c4AYDN5cMplSzMM5PP4ekJ8tmvq3A68gBxDAxuKV5Ah1aROHkAuPej5Gu32fQAvSgqTNZjBbV/Rb6SpCXrUcWJ2fREuxZl33IcPn0ml5ldL3JKf5wrtGyH1ShaehW49dZbcfvtt+Nb3/oW9u7di/e85z2Ix+O46aabAAA33HADPvrRj2qPf8973oOFhQV84AMfwP79+/HTn/4Un/nMZ/C+972vVX9CU9lzKqL1r9gD7bcwsQpbmMS0wilc9XPE0zJWsGAIu7d9JOkmoRdOWahBQ3OwgWRWxqDW39T9Nj2gIFUPIBdcwDyS3FA49dzwW0raRj5zouXCyTxOmdwnQqKzWiKpLFKxJXgEuthsw8LJ7bBpcc9TK64mdx66n+zQQlexA+UKp0RWi+eOSqEmH3FrYJHkMZY8GZs27xks4MB0FGf97S/xwf/bXVRAhRMFVr2pZ8jX0TYqnEZOB/wrYFfS2CnubZDiZD7HCdDfU8cX9B34oJg0VxWgBwSF8xQno1VPgRdJ2LP0GtDknXuHJOI5ZS0AYHrfI8jkFPR7HVg7UIear9n0Xmj+fRZNrtCCottsekDpZL3CYAiG0apntOl5+ttn81QQygdEsBTJwHj7HHMVtLRwev3rX49//ud/xic/+UmcffbZeOqpp3DvvfdqgRHHjx/H5OSk9vhVq1bhF7/4BR577DGceeaZuOWWW/CBD3wAH/nIR1r1JzSVPZN64dTJw001iw+qsw0ZiadzGBdoDGpoVUd+2KrB2Eyc9VK1sSAgIpkxJup1fzAEoC/ok0WKk8kQXKrQTaiD2hyVXiMj0cIpY7FwyplHkQMkgY2FJkRTOYhxYiOW7b722eksYDRIVKfj9nWkqTqXAg7+GoDBqmcWR25QnGxJ0vOTsLeJDabBOGh6YkIKkU0pqEC4ci/w3U9OIJrO4a4nTuJTP9mjDZBVVbXYqtcOwRCFCAKwiRTUV4pPNV1xYsNuT9DCyeOwwT5/gHzTN1q0GdiXpzjRwil8XCv8kxkZY2wz0RUEnP66j78cDpuI59S15HcfJ31h567uqz3tV1XN+5uMrNqppzB2o00PIO9DNpPQmKyn9TcVFE4DG4mak6Ex9u02/JbhNvQ5FaIl6nWeTQ9og3CIm2++GceOHUM6ncYjjzyCnTt3at/77W9/i29+85t5j7/ooovw8MMPI5VK4dChQ/jYxz6W1/PUTeyZjKC/CxbGPidZmITriCSPZ3JYwQqnDkxhqRaX3aZFH8fZTnCktFWvk98f1cAW9EVWvfkDgFwwwJIWTqfUQW3R0mtkJLKYErMxS49nSl5hFDmDqTORZBZ2WlAo3vZTmxgsIGIqkga2Xkvu3EuG4WpWvTI9TqlEDLYsXag6urVwIp+prKwCfWvIneGjFX/ud/v1EIlv/vEovvbbQwCIkpejClSfx0FsootHyAPbqXACNLveFQ0onLKyQl5DFM9xAvRinClO+cEQW4sfT9W6SCoL2d1Pw39UYI4UW+mcrI/nWAbrutOgOHnmSSFcl01v4TApBEU7sOYS88cIAnDpB8nts9/UfTY9BiuOjJZzTXHanv9Ymz2/0NKiyNvs/KTNcjJTnDo3ihxog8KJU5q9kxEMCHSnuINn9LDFVlimQw9rCoeQdcWpy/ubGMzmEnHQhWmB4pQ3/LaDFclqcBcqTsHVgOQmzbHhY/kPpnaACXVA6y/oNbLUqidlq7XqmV8amHo8E00jQPsNhTa06TFYn9N0JKX3S+z/BZDLaIrTSGI/cM/7gc+tAf79MmDXfyNoJ6+DLUnOOWnVDsXe3B39VuGkfVsZWQFCtHBaPFbmJ4CZaArPnSLnnpuv3AgA+Kdf7MP/Pn5Cs+k5JZEoxNN0Aegfaz9L8frLoYp2rBOn4Ysd1VSzWigXrALo6tuxeZPCaWhb8eNpoaWqtNeuICAimZH1zcRlSCZzSCKeVdYBAEYzR+FEpr7CicWQr9oJOH2lH7ftWuAv9gAv/rvaf1e7Y5asV0pxMt43s6f9osgZlqx6vHDiNJBEJoeJuTACAvVDd3DUNFtsLcgk5arWcIiVRqteD6A1B0uscCpQnDKKocepNwontiBJsx4nUQQGycKtMCBCNShOvRoOkaWLfcmy4lS6xwkAAjSS/Nh8QpvhZAu2b3ANs+pNLqWAlReQCPv0EnDoPlyU/A3ucvwNzvjJtcCu/yK9l5O7gXtuxtbv7sRHpO9gXZosXmYRhNtZbOnrBrQ48pwChFaTOws3IQr4/X5yLj5jPIgPXrMF7758AwDgoz94Bj/YRTZ4tP6mdgyGYDj9UFZfDAB4AZ7U5ivVAutvEgVo0eNGmILEFKeAyzjDaUvR4yWbqPUHLxojyef2QVVVpHKK3ve7DDv3DknEJPqxqPohQcE220mcubKOJNdDtHDacEXlxwbH2yONsVkUJuvFZulYAMH0vZEXEKFFkYeafZTVoSlO3KrHWSb2TUURUukusSh1ZPIIg538l+qx6qVzWIHlsyW0A2zhMSPSoigykTcTIZmVDVbO3iicWNM1W6QAMG2cRjoGge7E9XKqnmwnO7lSrjqrXsnCycV2zeNa4SS04fBbxohRcRJFMvgUAL77Rvy9/EWcJ+6HKkrAaa8G3vJD4OpPAaHVsKUW8W7pJ/ii7csAgHk1YGq/6gbyCqc+a4rTAweITe/yzcQi/Fcv2YLXnLsSsqLiC78m/YbFiXqnNfjIG4Nts8GuV0dAhLG/yazvh9k/Y8ZEvRIznBhaSFBBJDkbfr6chRNJ2RTwDLXrXd03XfI8URE5RxL1gNLBEL1EYbIeU5761pj3jzL73vQevTBpN6uecZZTIdyqx2kGeyejBhvWgD5RuwPxOGywiQIiau3hELF0DuMC9dT3SOHEFh6nVKo2ZmJ5RWfSaNXrkR4ntpPLQgwAGJL1DAERVG1aUj3I2HxdOX/HCqxwslssnNJlwiEAfRPk6HwcQ2jfKHLGqNbjRIdEb38l/Y6KaTWEL2Rfg8i7nwT+5D9J4/klHwBueQrK67+LB5QztOc5pQ7Uvkhsc1iqXtpo1SujOMmKigdof9PlW8h5RxAEfO41Z+DKLfp5qGiG0+gZaEs2XwMA2CnuxfyCia3IIokyiXoAipI9Rxxpfed9qLjHCTAERMSzeUNw2flP30xcBsWJWjr30ICIna6TZR5dgVO7yDrAFQLGzq772DqewmQ9s8G3Rtgsp7l9+sDqtg2HKPhMqaph+C0vnDgNZM/kUtf0rwiCAJ9TQgQsjrx6xSmZSmNMoB/AHrHqsd3G+bRNPwkZIslTmd4rnMwVJ5MhuAXBEDUnP3U4soNY9Ry5uKXHa1a9kuEQep/GMFWc0MaKE7PqTS1RJWH9FcCrvo7oK+7AJekv40vya+AdKLh4izaI216GW6RP4sr0v+DnI+/CP+be0MWKE/m7rCpOz04sYTGRhd8l4ZxVIe1+u03EV990Ls6m940EXICi6E3u7WjVA4CBjZiyjcEp5CAcfaDmp9EUpxLvk0LVez3oudw/VtJmFTIbgrtwGKkEsfutEJcvMIkpk89SxWmDfKj2J2NpeuuvAMTu/FxVRWGyXrn+JoD09tq9pLd3ggxwbrsep1LhEKkwQAN3EFixrIfUKHjh1KbsnYx2lQ3L75IQVVmPU/WFkyezALsgQxVsJLq1B9DjaDO6F9gQEJHM5PQ48g7ugasGtqBP5fQh2NqCYm6/bmXMC4boTZseAKi0cHLKDbLq0ddycimlWfU6oXCaj6eRlRWyQDnr9Vhc81LkIMFtt5Ucahty23FEHcP3nK/FEXWsa1VLpiRkjYpTcqHk0GSWpveCjYNFr53HIeGbN52PD754Mz7wok0knS8TA2xOEqPcjggCnvdfCAAInLi/5qdJZXSrnhmFATVrZFqcllCbAP0aEE5kyefMGQRUBfLsQQhQMAa6KF2Gwomp/SySPBTZX5xkahWtv6kL48VrxZisV0lxEkXd3sdmP7Wb4lQqHIKtYTwDgKOOGWAthBdObYiiqF2TqMfwu+wGxak6q14mp2BIIdPsVf8KwNadTdqF6LuNWV3SZmk0AOR0DG6BzEvpNcUpZVSc+teTPsBMTFfkeDAEAEBxBgAATjmR1x9XCqY4OStY9QBgSGh/q16/xwG7TYCqkiRARoRFkZvMcGIwa9XUErH5lVISOp28HidXQF+AlVCdWOHE+psKCXkcuPmFm7B+yKfb9Ia3tvV5++TACwAAK2Z/b+lzYkaiUuFUcB4ayxwlN8oUTuwaMBVJkaKf2vXU2ecxiAgcQg4QRKJaNRn2PjmqjiAOFwQ5lW+PtkoqApx8jNxezwsnDWOyXiXFyex77dbjVGqOk2bT68xgCIAXTm3J8YUEEhkZw7busOoBgN9Zu+JkTNQTesSmBwADPnLRnIumdcXJYNUTk8TfnhWdbTuAtNFoc5yMPU42O9BPUr00ux4tME+pAwj2aBQ5AAh0KKYNMpBNVny81XAIEQoGtB6n9lWARVHAsJ/Z9VLa/SyKvFzhxNQ11h/VrVY9p7FwAsr2OS0lsnjyOFkIXVaicMpDC4Zo0/4mSmzsQiRVBwKZGd1aWCWVrHqFs+QGk1QpMJnhxDhndQgA8P1dJ0mxTwsncX6fHkXuG12WxDmmTKoQMeneRO6cerr6Jzr6IKDK5JzNrKEcvXA6/DuS/ClKwMCm0o8fLghbaVfFqdCqx+ZRdmgwBMALp7Zk7yQpmNa56YW+C9QEv8vQ41RlOIRx+G0vFU4rQqTQnAgn9d0Zg1XPniKvSdLeR3YjewC2oM/rcQKK+5zortaEOljUlN1LCA4vZJW+Nyx87pIVepxYodGPKGyCCgVi2yvizK43HdELJ5ZsxkYlmMHeN0tJok51rVWPFU4yLZzK9Dk9eHAOigpsHvFp56eyTJNBqe2aqMfoCwbwR4Ue44Ff1vQcxlQ9M3wOCaLhNB2M0R4hkxlOjGvPXIGNwz6EE1l84/dHtMW1feGA3vO7TAtQhyFiPTNI+9Umd1f/RCxNb/3lDTiqLoIV0MzaNrARkMps+hUqTu3a45QKk15HRocn6gG8cGpL9tDCaaWDNtC129DAGvC7pPxUPUUu/wMG4j04/BYAxunCZGopBYVZ9QyKk52eYNOONjthNhFWOOUpToAhWS9fcZrocauew25DDHSBW6JnxUilAbhMhWH9TRlnf9s3d2vJenmKk3WrHsPtaF+rWT0wJcGK4vS7/cQyfdkmi5t5U8+Qr6NtGgxBGfI78RvlbPKPA7+q6TnYZo6nxPtEFAXtPeVHAq7kNP3lJnN6KDZRwK1Xk02h//j9YUQDRFl3hg8YronLXzj51+0gNyZrUJyO/I58XccLpzwCK0ngA6OcTQ8o7n9qN8WJWfVUhRRPDG7V4zSDE3RAXrek6gFkZzcKQyOghUUcg0SR99bwW4CkUkmigJyiYkGiCxXDEFxHhhROGVfnF9ZWcWuKk5L/DcOMEygyEDkFgM5w6mHFyWET9c+dhd5CPY68vFWPJerlPO2vho8URpLDmlWvqHDqUsXJTgundK5AcQofz3ucqqp6f9MWC//fUxG9+GrXRD3KkM+F3ypnkX8cf9h89kwFkhWGRwN6z9ImgZ7H/SsqDi59yWmjOH08gHhGxrcOkPeyJ3IUqwRSxC7XEFG7TcTV20dw0foBjG3dSe6cejpfTahEzGCFXHtp4w+ykxHF/CK6VDAEwzesFyeSG7BbUICXE8lBItaB/M9ThCtOnCbAbCTeXJjc0SVWvQzsyApUeq6izymezi3roL92wSYKms1oQqHFUeSUdqFyZ8jJKOvsPcUpnS1j1YtNA0oOMkTMoK+3FSdJ1HsLLVj19B6n8uEQTHFSve0bDMEYDToBlFCcnJWteoxu7XFiSkKWWfVCa8nXAqvevukopiNpuOwizl9r4ZzDFsj+Fe1nIypg0O/ASXUYB9Vx0n/DUt+qQJ/jVHpZxd5Tm0S6eCzT38QQRQF/+WKyoP7KE0kodi9ENYuLRPr6LqML4/YbzsN333khpJFtJCkxHSHJiVZhNr3RM7rCSdNwjCpTJcVJEHQLbLt+vswCIpZ4jxOnCUTobqgrS99sbd5DYAXWS5AU6Q5ENYVTKmuwJaxu9KG1NcyudzQTACAAchpIkNfCTd8fchcoklbRFKfCwmlgEwCB+MNPPQkAWLANQoGIoKd3wyEcklijVa98HDkbfisF2jcYgmGqOKWrV5y6dQCuozAcos9g1TMkzP1uH1GbLlpvcRhwh9j0AGDAS4rr++WzyR012PXYZ6eUVQ/Qk/U2M8WpTKKekSs2D+G8NX1I51SckkihtEVs4QLUZteHsFbT58RteuUxKk5let80WHHVbjY9hqdglpOiaG4QbtXjNJRoKgcHsrBn6UKnC2b0sAVKQqw+ICIdW4BfoIlgHbxLUQvjfWTRezKS0+fl0B0bX44UTqq7898fVmFKSE5R9R1ygMyDCNGi+uCvAQCTIEptT1v1JBGxqhSn8oWT3ymRVGSqONlDzY9BrhfW4zRtYtXzlSmcCpXKblectMKJKRiZWF4iVqUY8iK0RL32L5wckoiQx673OR38VdWx5KzHqaxVj56LtKLHYuEkCAI+dA1ZVD8aK3j9W7UAHaPWxmr6nA7zwqksrFiyOYH+dZUfz+x87bq5zgo6FngRnwGU7LJF6DcLXji1IdFUFn2gRZMoAa5QS4+nEbDCKarNcrKuOAk0vjJqC3bswLRaWdlH/t6Ti8miSHK/HAYAqO160mwCxkVJqsiuR3frDt4HgARDAMUL4F7CaexxsqQ4lY8jF0UBPoekFU6doDiNBfWQFZUuhvUep9LvjUBROER3Fk5OFg7BNiLsLn1RQ21Y8XQOjx0li5/Lt1i0Z3ZIoh5jyOfEE8pmqBCA+CwQn6vq5yvNcQLMrHoWVAXKzvUDuHTTIPYrBYVSqwKTRs8kX60qTotHiYopSsCai5t2WB3N6gtJ8XTOm62F7pz+GuDcG4BLP9j8Y6sFZtVjGzAsUc8/1tZz3SrBC6c2JJrKGYIhBkjTYIfDmsqraVRnSFHyYVuyt/8irdGsLBNJ7ldI8Sl2QQ+cVZySqCWvs0W+xiDtc6IN6cdy5KQd6uE5TnmKk4XPHEsrdEkicPJx4GsXA3t/kveYgNveEcNvGcMBYsNK5xQtWrymVL1eseoBerIe7XN66NA8srKK1f0erB2wsHmlKMA07cEZbe8ZToxBnxMZ2JFmPaPRU1X9vG7VK1M4eRwIII4R0IVkmUQ9Mz50zRYcUPXCKSM4W9ffMnY2+Tq525o6x/qbxs8DnL6mHVZH4woA73sYuPbz1h//iq8A69o0aMNT0ONE02472aYH8MKp7VBVFbF0rqsS9QB9gRJWqh+C64iTQiHi6lxpt1aYVW9iMaHvLFIFLqSGAQA2f+8UToIgaAM7ixWnfNvLcZmctAsHT/YSdpuICAxjACqQpzg9dzcw8xxw97uAhcPaY/wuCUMIk38w+2gb47Lb0OfJH2YbY4qTs5o48u4snOyFceRAfp8T8m16gpWZcYtHgGwckFz6cOo2Z8hPCuyYg24GRCar+vlKc5wAYtXbKNBd98A44ApW9TvOXBnC6MaztX9HnSOtm+E3sh0QbKTnNmrhtdJsepc197g47YMWDkE3CrREPV44cRpIMitDVlT0gy5yusSGxWwvtRRO7gTZ+Uu6e09xGjcoTmpgBblz6SSgquhXWYN+++/6NxK2MClp1aOcUgcgCuUXx91Ofo9TZate2tjjFCeLZWRiwA/eCchEpQm47JpVrxMKJ8AQEEGT9axY9XotVS8jmytOqqrit3R+k+X+JhYMMbS1Yyw5gz5SOC3aaM9olYpTIkPeU+UK7DUDHmzW+puqU5sYN770MqRU8t6MOVt4TbS79b+hUp+TqvLBt72IuyAcYsmwadDB8MKpzWAX9EGRLnK6pHBiitNcjixgqgmH8KWmAAApb2d/2GphLERer1RW0S+SSxNQU0uwC2SR6/D3VuHkKpWsx6x6lJPqIAJuO0SxRTuybUB+ql414RCiXjgBwMnHgAf+CQAw6MwhwMJaOsCqB0CL9WcBEVasej6nBJvhvdNbVj0atBI+hqPzCZxYSMJuE3DRBotBNKy/qQMS9RhMcZoR6C551YoTHRNR5n1y5ZZh3Hx6jv5C6/1NRjaPhTDvJoWtNhi9VVjtc5p9ngQDSG5g5fnNPy5Oe+ApVJxYEmRnz+PkhVObwS7oY1KM3NElVj3W47SksB6nsPWfTZPCKevrvcLJKdkwTC/oUwKb5TSBbJTsAMdUF1ze3vKL64pTQY+TOwT49B3YyR4ffgvQAbhqFeEQOYNVL0YLp7P+lHx94J+A4w9jBT03ZUUn4Aw0/JibAUvWm2SKk4U4ckEQEDB8v1uteo7CcAhAt+otHsPhWfL/e/OIH16r6q2WqNcZ/U0AMOgjvZCTSm09TkkLipMoCliZpfOxLMxwKsXYxnMAAKvX1/4cDYEl601VUJyYTW/1hYDkbO4xcdqHwjlO2gynzl7L8cKpzWAznIZtTHHqjv4Vj8MGmyjo/RZVhEP0Z6cBAGqPRZEzWJ/TiRyVvaOTyCyS3dB5NdC1O+GlcJZSnABtEG7WEUQc7p6e4QSQMA1NcbISDsEUJ8lg1dv5LuCsNwKqAvzgHTjXS+7PuIZa119RJSOGSHJFUbUh4+XiyAEgRN8/oqAXGN1G2XCIpRNYjKcBAAO+Kha8U7Rw6kDF6XiW9h3V2uNUqcCefZ7+wtoUJwAQL70VOO+tsO14S83P0RDGLCpO3KbXmzDFKcEKJ27V4zQB3apHFacuma4tCAL8LgkRtvtttccpm0JIoTJvh8u7tcL6nI6kvCTKVVWgTJIegkUEtObuXsFtLxEOAWgBEXEXUZ56XnGS9HAItYJVT1VVQ+EEvXDyDQMv/UeymA4fx0uP/QMAwNO/omnH3WiYVW9qKYV4JqeFgAXK9DgBem+mxyFZC0XoQJxmhVNgnDT+yxlkFship89qyEpqCVg6Tm53SBQ5oPc4HU5TFdVK4IGBZKayVQ/JsP68NfY4ASDBDNd+AQi0+DPIEhOXTuTN/MpDzgFHHyS3eTBEb2Gc45TLADGyCd7pa7neWnF1ACztaQC0sOgSqx5AbDF6HLnFwommsCRVBxw9lB5nRFOcwhntQilMkR2+RaG6VKZuwFUqHALQhm0uOok62csznID8cAi1glUvK6tQaEHhykUAlb6+nkESe/ua/wAEGwRqtxA6pL8J0K16U5G0tjllt+kJjaVgARHdatMDDKl6RqueTdKHjdNZTn1W1VvW3xRYqS+cOgBmiT6Q9JM7IjVa9coVTkxtCoyTz1Sn4woCfXRQaynVaXI3kF4ij2UR5pzegH3+MzGa0KmS4b4d3rvPC6c2g/U4hVSWqtc9xULAZdcVJ6vhEDT3f0IdhLfC7nC3kj/LiSxm7NPkIrUkhlp1WC2jZKoeAJz5OuDqv8N94+8FwBUnu0236gkVrHpshhMAuDLz9EYIkOiCedUFwOUf1n+gQxL1gHyrnmbTc1ZWkbTCqYvtsKZWPUDrc5Ki5BxsuXBiNr0OUpsAoN/rgCAAkwpd7KXCQDZp6WdVVdWsemXTF4/8nnwd3l7HkbYZrM+pVOF0hPY3rb3U2lBXTvfgCgECLTNY0mZgRcdYvEvBC6c2g+2GBpQwuaPDK3MjNSlOYb1w8jl786Srz3JKak2VzvABAEDMFmrVYbUMLVUvY1I42d3AJbfgKMiivtd7nCRRQIx95jIxMpi0BKwQFQTAnpwjdxaqSpd+EFi1k9zuX9/ow20aY9SqtxDPYC5GenbKRZEzgm7SA9WtUeRAiThyQOtzcseIwtjvtbgJMU0XSB3U3wQAkk1Ev8eBCDxQJNoXaFF1ysiKrtaWeq8oMrDrW+T2Ga+t82jbCNbnVCogghVO3KbXe4giKZ4AvXDqgl51Xji1GdFUFg5k4Vbi5I4uKpyI4uQl/0hFLE0bVzXFacB6olOXMR4iC1+iOJHCSVDJIicmhVp1WC1Ds+oV7pAbCCeoctvjipMgCEjbyGdOgEqGkpYgzYbfSjYICVo4FSreNgn40zuBV34V2PFnzTjkphDy2LUC4dAseQ3KJeoxmOLk6mbFyTAAVzWek6ni5E8Ru3SoasWpswongAVECEi5qZpqsc/JuIlTUp088EvioHD3A9uvr+9A2wmmOJ18HMim8r+XTQHHHya31/FgiJ6EBUTwwonTLCKpHPpAexFESa/WuwC/y66n6ilZSzYIeZE0GU+oQ71bOFHFaSmZRdo7lve9hNQ5PQSNwkXDIUwVJ8pSkhZOPd7jBACq5ERGpYu5Mna9pHGGE4siN7MKu/uAc94MODsnBl8QBK3P6eA0Ob9WUzj1guIEkD43jdBaAEB/hhQP/V4LhZMiAzN7ye3RzokiZ7CAiLiDvu8tJuuxz47dJpQO63nsG+TrOW8C7K66jrOtGDuH9K2EjwG3vQA4+gf9eycfA3IpYuutJwyD07mwPifNqtfZiXoAL5zajlg6hwGBLm48Ax3vBTUScEuIwwWFve0s2PXURUOPk6M3CyefU9IWcLNi/kI26ei9wknrccqVLpw0xYkXTnBKNsMQ3NIBEfrwW0MUeRf1WLLC6cAMSSz1OSu/N8aC5HUbrCaKu8MwBmSYzXIalkkSlqXP0sJhIJckg047yMrJYJHkYYk6PSzOckpkDJ8dMxaOAAd/TW7vuKmuY2w7vAPA674FeIeB+QPAN18G3HMLSRA02vS6aC3DqQI2yylG5nFyxYnTcKKprF44ddGiBWA9BQJS1DpkKSCCTpqetw3BJvbuiZdFkp9S+/PuTzv7zR7e1WhWvTKKUziZAQAE3b3d4wQQKxZL1iv3mWMDhUnhRAYsF/U4dTAjwfzCKWBBcbrmtFF89tVn4MMv6d7dcqNCYjbLaVidhx05a4oT21Ue2d6RQQBsCO6sNmy8OqteSWXyif8EoAIbXggMbKj3MNuPLS8Fbn4UOPdG8u9d3wK+egHw9J3k39ym17t4CtYovHDiNJpoKod+GBSnLoItVJIi63OqoDgpCmx0x2/RMdrMQ2t7mF3vSCZfYco4u+s9YgUWDc0W+mYwxSnY4z1OALFiaaEsZQsnsvhzSiIQZz1O3dNjORogasJslIVDVC6cHJKIN16wGiv7PE09tlZiEwVtUyqvcPINQ5XcEAUVY8K8tVS96c7tbwJ0xWmKJevRcRiVYJ8d0/6mXBp48tvk9vlvr/sY2xZ3H/CKLwN/9lNgYCOZ2ROm87z44NvexV1QOHGrHqfRRFM5DAjUTtNFixZAHzYZgyEgohyxaYhKBrIqIOnsnp3vWmCK0+GYg9hgKLKr9xQnZi1KmsWRA5AVVUun5FY9OsupCque22EDYlRx8nbP545FkjN8FgqnXoEFRGSNVj1BQM5Pdoc3SnPWAjI6OBgC0C2ZJ3IhcofFcIiyVr09PwIS82TBuOmaRhxme7P2BcC7/wBc9mFAtJPZTaHVrT4qTqsonOXWBYoTv3K0GcSqR5WYLrPqBWi0b1QrnMLlf4AO2pxCP1yu7u0xsMJKqjidXEqRSPL5g1hSPbA7u6jJ2CK64mReOEVoMATAFSeAWLGizKpXZrOCpRS6pC7tcQrmf1asxJH3Cg5JRDIrI12QVJnwrkRw8QA2OxesPRFTnDosipzBFKfDaTqctspwCFOrHguF2PFnJJWyF7C7gBd+HNj5bsDRvWotxwIeQ+HkDHTF4GeuOLUZsXQOA5pVr7sUJ7ZQiVjotwAALLFEvd4NhmAwxWliUY8kn1cDXT2YsxQuic5xKlE4hWnh5HNKpROueoh8q56VcAhRL5x8XVQ4BQoLp94+pxgpNQQ36ibnmnXSXOUnSSzo1rYOG37LYIrTgaSf3BGbKjv7jJGn1hqZfg448TBJyD33hoYea0fgHSCz9Ti9i9Gq1wU2PYAXTm1HJJXDmEB39wIrWnswDYZZ9RYVi0NwDcNvvT06/JahDcENJzWpex69WTixxUm6RI9TOMGCIbiiAFgPh0jTxV/AlgGyCXJnFylOhVY9rjjpaLOcCobgLtjJ+IPVwmzlJ5l+jnwNrQZcwYYe33LBFKcDSQ9UCICS0zcRysCsem57QTHO1Kat1wL+3u7T5fQoxnCILrDpAbxwaivSORmZnIIVwjy5o0veZAy2w7sg0wVMpcKJWvVO9fDwWwZTnGajaeR8pKCeV4PFO5w9gDbHqYLixPubCNYVJ7JoHmKpnpIbcHTOrKZKFBVOPX5OMeIsoTjNSGSxP6pOV34SLRii8+Y3MQa8DvidErKqBNlDNw0sRJKzVL2883E6qqfKnf+2Rh8qh9MZGBWnIFecOA2GNLSrGBeoLaLLCqcAVQAW5Mr9FgDIlHWQ4be+Hl/k9HsdWsEwPXYlwtIgfiGflzeDpVfQ4shLFE5LfIZTHk7Jahw5eT37QTc0fENdNXvFIYla3DTArXpGmKW1sHCaBAkHGcpNVX6Sqc7ubwLIoORtK0gPRtRufQhuUkvVM5yPn74TyMSAwc3A2ksbfqwcTkdgDIcIdMeatvdWXW1MNJVDCDF4BBKX2y1+UAZbqGg9TlVZ9Xp7kSMIgqY6HXFswYdX34m7lUt7VHGq0ONErXohPsMJAFOcrIRDkNezTw2TO7rIpscwqk7cqqfDepyyBVa9ozIZd+DLLQKZePknmWYznDqzv4mxfYwUTjMC3SmvQnHysF5cVQUeu4PcPu+tXbUBweFUhYcrTpwmEkvlMM5set5hkkzTRdhtItx2GyKwOACXWvUmuFUPADBOZ8lMhBOGHc7eK5zc9vJznJhVL8gVJwCkfyWqWrfqhbTCqXuiyBmjeYUTP6cwWOFUmKo3lXEjwt47bCaPGXIOmHme3O7QKHLGdqo4Hc/QPq0qFCctjvzULmDmOWJ3PeuNTTlODqcjsHsAG01F7hIXFS+c2ohoKosVzKYXWtXag2kSfpekX4jLKU6pJSBNvj+hDsLX4+EQQH6yXtmBi11OJaseG34b4uEQAMiGhT7HqbJVLyiHyR1dNkcOAEYMkeR8jpNOyXCIeAYnVKo8Lh4r/QTzBwA5TXri+tY16zCXBaY47U3Q/j4Ls5z0cAh6Pj7xKPm64UrAHWr0IXI4nYMgAGNnkk2E4e2tPpqGwK8cbUQklevaYAiG3yUhGrdQOFGbXkwMIAkXV5xgmOUUTuo7nD1o1XNX6nHi4RB5OKTqFCe/vEju8HWv4iQIgK/HRxwYKRVHvpjI4IQ6jNNwDAiXKZxYot7wdkDs7P3YzSN+2G0CjmVCgANApLJVL1U4x2nyafJ19MzmHCSH00nccA/p9+uSzbjOPsN1GXmKU7A7FaeA225QnMpY9ahNb9ZGFm+9Hg4B5CtOycIdzh6ChWTkFLWoJwPgceSFOCSj4lSmcKI9Tr4cLZy6sMeJFU4+hwRR5H0njPKFkwXFaYr2N3VwMATDIYnYOOzHFGhTuwXFiZ2PtY0s9nqM8cKJw4HD01UbcbxwaiOiqVzXJuox/C67Ho1cTnGiiXrTArloe/jucN4sJ6YO9GbhpP/NZqoTU5yCPBwCgPVwCDbHyZulc+S6sHBiVj1u08tHL5z0z5OqqlhMZPXCqazixKLIO79wAohdb0qlTe0WepwSTHGy24BcBpil/V6jnRvNzuFwzOGFUxsRSxvCIbq0cAoYe5yycdJUbAa9SE+ASLu9PgAX0BWnqaUUYmnyuvViqp5TErWQKrNkPT7HKR+nTUSUJVlm44BibnFkxbgr072F0441fThzZRCv3dGd59daMetxSmTIXMHjKt0pnnoGUMwDWbQo8m4pnFYEMK1SxSm9VDFRMGWc4zT7PKBkAVeoa50jHE4vwwunNiLfqtedF/Y8xQko3ay+eBQAcFThVj3GSMAFSRSQU1RNVelFxUkQBLgk8nenTZL1+BynfIhVr/JnTuuby9DNmy6yVjB8Tgn33PwC/OWLt7T6UNoKVjhlZVW7b5FaXneL26E6A2Qz6+Cvin84PgfE6Jynke5o/t4+FkAMHiRAw0QqqE55KadTrL/pDB5DzuF0IbxwaiMSiQRGhDD5R3B1S4+lWQTcEnKQkBHpBSkVNn/gwlEAwKEc2fXm4RCATRQwGsyPqHf1YOEE6H1OhYqTqqq64sStegBI4ZSFhKxAX48SfU6prAwJOTgy1ELbhYoTxxyzOPLFOPkcOTwBCDtuJHc+9K/FP8z6efrWAU5/U49zuWDJepMK63MqHxCRyBgcAFq/F+9v4nC6EV44tRG2ONm1y4mu/KFhXUSADp1MijTq1aznQlU1xWl/hg5g5IUTAN2ux3DZe/MjXCpZL5bOQVbIrjlXnAhMTUiKbH5a6cKpH/R7gg1wd+c5iFOMWTgEU5z6PA5g57vJe+LIA3piHIMl6nVBMAQj6LFjZZ/bcp9TXs+pVjjx/iYOpxvpzVVXm+KKTwAAku6xrpX4A7QpOyHQRZxZQERiHshEoULACYUrTkZYQASjdxUn8nezNCsGm+HklMSefW0KsdNFcVIon2aZyioYFJjaNNjxsdIc61QsnIIrgdNeRb7x0Ffzf1gLhuiuQmH7WMCQrGdRcbILPFGPw+ly+JWxjfCliOKU9q1o8ZE0Dz9VnKJsEWfWb0HVJsU3hjSIvcjDF8EAgJUGxcluE2C39eZHWBuCWxCfzGc4FcMUp4RYfpZTOicbCidu0+sl9HAIfSNiMU4Kp34vtXhe9D7y9dm78mcbsWCILlKcABYQYU1xYpZhX/IUuabZHMDg5mYfIofDaQG9uepqU/wZUjjJ/vEWH0nzCLiJchRRyyhOC0cAANkA6fPyOmx85grFqDj1sqKi9TiVUJx4f5MOUxMSKLNZAaI4DYB+jxdOPYWZ4rRQGLIyfi6w+mJAyQGP3k7uM0Zvd0miHoNEkldWnBRF1ax6vsU95M7hbYCNb95wON0IL5zaiL7sDLnRpYl6gK44LSlsroxJ4UQVp6SPFk7cpqcxHtLT0XoxUY/BYtjTuYLCKUmH33LFScNJF8WxciovSI8TV5x6E7NUvbDRqsdgqtPjd5CI7rn9JHrbGQBC3RVoZFSclDKKU8pwDnLPs34vbtPjcLoVviJtIwblGUAAbH3ddQEywsIhFpQyAzlp4RT3kAKSB0PorDQoTr04w4nB4sgLFaeHD5Mo7SGfc9mPqV1hakIcpa16OVlBTlExINHPYxdGkXNKY97jRBSnPq+hcNryUpKet3gEeOo7eoreyGld15c7HnIj5iAbCHJ4ouQus/EcJM0w2yIvnDicboUrTm1CTlYwqpIZTo6BNS0+mubhp+EQCzkWR26mOBGr3pKLWBY9fPitxlhIjyPvZcXJ5ShO1Xt+KoLvPHIcAPCmnd27+VAtDht5rbQhuCabFaxXbMgYDsHpGczjyJniZFBvRRtw4XvJ7Ye/pgchdJlNDyDz4oIj5FpsS8yUHBzN+puckgiBBWXwRD0Op2vhhVObEEtlMU6H37oHu7dwCrjJRTisVA6HWHCSwsnr4IoTwynZMOwnakpP9zgxxYn2Fqiqik/9eA8UFXjJaaO4eCNf+DPYolgrnEwUJ1aADoIVTlxx6iX0cAiTVD1vQb/gOW8CXCFg4TCw67/JfV0WDMFYsXI1ZFWAqMpAfNb0MUxxWmGPAxGSjNutrweHw+GFU9sQD8/ALZALlb2ve3ucvA4bRAGIokSPUzalJTbNSWMAuFWvEBYQ0cuKk9tBTl1swf+L56bwx0PzcEgiPv7yba08tLbDbiMWqiUrhZPIwyF6Ed2qV5yql9fjBAAOL3DeTeR2mp6/uyyKnLFtRT9mESL/iJgHRDDF6QyJqN3oX981g4A5HE4xvHBqE9Lz5KQ7hxAgdW9/hiAI8LvspVP1wscBqIDDj3mVXHx4OEQ+bAgu73EiC/5UVsanf7oXAPDOS9djVb+n3I/2HGxRrAWymKi8LBVMs+r5eOHUS5TrceovLJwA4IJ3AiI7LwskRa4L2b5CT9ZTSxROCao4bRePkTu4TY/D6Wp44dQm5BZI4TQrdv+Cxe+SEGGN6oWFE+1vQt9axDPkIs4Lp3y44qQXjamsjP/4/WGcXExiNODCe6/c0OIjaz9Yqt6CQjcrosUJYURxUtHP48h7ksJUvVRW1pSUkNckoTKwAjj9NeT2wAbA0Z2bFRuHfZjFAAAgPH3c9DHsddqq0msXL5w4nK6GF05tgho+CQBYkLq/tyDgsiOiliqcjpKv/WsRp9PYfTwcIo/z1pCI3M0jvWsHYf1dR+YT+OpvDgEAPvqyrfDwfrgiWDjEMzLtnZx6lszfMZDOyQgiDgnUqsULp56iUHFi/U2SKMBfauPqsg8B/RuAHTctyzG2ArtNRNpNrskLU8dMH5OiitMGhRVOZy3LsXE4nNbAVxltghg9AQAIO8ZafCTNx++SMF9qGCcrnPrWIhYnhRNXnPK5evsIHvnYi7SQiF6EFU4P7CcN2+et6cMrzlrRykNqW9ii+JA8BHhDQCoMzDwHrDhHe0wqq+gznJzBrrYLc4rRCicaDrFA+5tCHgeEUjHjg5uAW3Yty/G1EltoHJgGUvMnTL+fyMhwIoPxHNn85IoTh9PdcMWpTXDEiH867hpt8ZE0n4DbjqimOEUAVR+6iAWDVS/NFCdeOBUyEnCVXtD0AC67fuoSBOCvrzutp1+PcrBFcU4B1PEd5M6JJ/Iek8rKGGQ2Pd7f1HNoqXpUcQqz/iYzm16P4RtcBQAQTCyuALHqbRWOQ4QCeAYBf/dfwzmcXoYXTm2CK0EKp6SnNxQnrcdJlckEeoamOK1DPE0sEFxx4hRi7O963Y5VOGNlsIVH096wwgkA5DGqMk3kKwWprIIBgUeR9yqFc5yMilOvMzS+DgDgTs+Yfj+VlfVgiLEzu24QMIfDyYcXTm2CNzUFAEh7x1t8JM0n4LIjCSdkgS5+WZ+TquZZ9Zji5Onh9DiOOUyF9DslfOglW1p8NO0NUxMAID1CC6eTj+c9JpWVdaseH37bcxTGkYdpj5Npol6PsWoNCZwZUOa1iHYjiYyM7QJP1ONwegVeOLUDuTR82XkAgOzvhcJJAiAgJfrIHaxwik0DuSQgiEBotSEcgitOnHwu2zyEt1y4Bl9787kY9PF+nHKwOU4AkBw+m9yY258XzJLMyhgQmFWPK069RuEA3IU4ser1casevNSqFxCS2He8OJI8aVScRs9czkPjcDgtgBdO7QCdNp5UHbD7Blp8MM0n4CYX44RI45FZQATrbwquBGx2xNI8HIJjjstuw99dfzou3cT7cSohCIK2ME47B4DQagAqcOop7TGprIwhMMWJv6a9BlOcWBw5S9UrGn7bizj9SArEWn7i2KGib6fSGWwTaFQ5L5w4nK6HF07tQJik9Uyogwi4u/9C5XeRQiguFAzBNfQ3AeDhEBxOg8iLmzYJiEjnFF1x4oVTz8EKa1lRISsqL5wKSLqICjt76mjR9zyx4/AIaWRFJ5lpxeFwuhpeOLUDSyTG9JQ6oBUV3YzfRRSnKAzJekBefxMAHg7B4TSISoVTfo8TL5x6DWOASCanYDHBrHq8cAIABEhoU2y2eAjuYGwfAGDRtxkQeT8uh9Pt8MKpHaCF04Q6CF8PFE4BWjgtKaxwCpOvi3oUuaqqWo+Tlw/A5XDqgikKWdlYOOnJeqmsjAHwHqdepbBwCmuKE+9xAgD3AOlzQmQSB2eied8bTewHACyFti33YXE4nBbAC6d2YIlY9Yji1P0XKqaqhRU3uaPQqte/DomMrI134lY9Dqc+8uKmx84iASzRU0CENLvnDcDlilPPIYmClqKdlmUeR16Au38lAGBEWMB//P5I3vfGUwcBAPE+XjhxOL0AL5zaAc2qN9gTVj0WDjEv08KpMBzCEEUuCvkzezgcTvXkWfUcXmB4O/kGtevJ6Th8QorcxwunnsMYIEIUJzYAlxdOAIDACgDAqLCIHzw5gdloWvvWqiwJjEj2n9aSQ+NwOMtLWxROX/3qV7F27Vq4XC7s3LkTjz76qKWf+973vgdBEHD99dc39wCbjMoUJ/RKjxP5GxdyLnJHaokMwY3TAYN96/REPYcEgQ8U5HDqojBuGuPnkq+0cLKnyTiEnOgAnP5lPz5O62HvkURG1s6/3KpHoYXTRuciNsqH8ciPbwd++w/AXW9Fn7IIWRUgD3HFicPpBVq+Sr/zzjtx66234rbbbsPOnTvxxS9+Eddccw327duH4eHSXvujR4/igx/8IC699NJlPNomoKqa4nRSHdT6f7oZVjhFjOEQzKbnCgHuEBILxDbEgyE4nPqxGxUnABg/D9j1X1rh5EyRwintGIDENyp6EockAmlgOkKUR1FAT1yPLOEn4RAbcofwM+fHgP0g/1F2qxvg9Phac2wcDmdZabni9PnPfx7veMc7cNNNN2H79u247bbb4PF4cMcdd5T8GVmW8aY3vQl/+7d/i/Xr1y/j0TaBxDyEXAqKKmBeGIBTavn/kqbjlGxwSqIhVW8pr78JgLbj6eHBEBxO3ThthYUTC4h4ElAUuDK0cHJ1/xw5jjnMzjkdITa0kMcBUeRFNABgcDPgJRu5YfjxuLIZh8ZfCbzor/Fh6cO4MfMRbinncHqElq7SM5kMnnjiCVx11VXafaIo4qqrrsJDDz1U8uc+9alPYXh4GG9729sq/o50Oo1IJJL3X1tBbXqzCMLpcveMLS3gtiOimhROWhQ5n+HE4TQKrcdJJhH/GNoK2D1AJgrMH4AnswAAyPHCqWfRCyeiOHGbngGnD/jzZ4APH8H3r/o9Xpv5G7xj6a1QLvkL3Js7D1F44HbwwonD6QVaWjjNzc1BlmWMjIzk3T8yMoKpqSnTn3nwwQfxjW98A7fffrul3/HZz34WwWBQ+2/VqlV1H3dDyQuG6J0Lld8lIQI6ADcdyQuGAJDX48ThcOqDLYqzORpVaZOAsbPJ7Ykn4M0tAgBybh4M0auwHie9cOLBEHnYXYCnH68/fxX8LgmH5+K4//kZpLJExeWKE4fTG3SULywajeItb3kLbr/9dgwODlr6mY9+9KNYWlrS/jtx4kSTj7JKwuR4Jnpk+C0j4LIjaqo4EaseH37L4TQOtihOs3AIQA+IOPk4fLRwUjzWzquc7oMV11NLtHDiiXqm+JwS/vSC1QCAf3/gkBa44uGKE4fTE7R0VTo4OAibzYbp6em8+6enpzE6Olr0+EOHDuHo0aO47rrrtPsUhZy0JEnCvn37sGHDhryfcTqdcDqdTTj6BtFjUeQMv0vCkbxwiHzFSbfq8YsRh1MvjsJwCMDQ5/QE/DJJ0lN5FHnPYmeKE43a5la90vzZJWvxjQeP4LGji9p9Lq44cTg9QUsVJ4fDgR07duC+++7T7lMUBffddx8uuuiiosdv3boVzzzzDJ566intv1e84hW48sor8dRTT7WfDc8KS0xxGoTP2TsXqoDboDjlkkXhEAt0cj2b+cThcGqnbOE0/SyGFTIKQPDxwqlXYe+RmQhXnCoxFnTj2jPHtH8LAnoi2InD4bRBHPmtt96KG2+8Eeeddx4uuOACfPGLX0Q8HsdNN90EALjhhhswPj6Oz372s3C5XDj99NPzfj4UCgFA0f0dg6Y4DSDQQ4pTwCUhBrd+h5IDRDsQGAcAHJqJAQDWDXpbcXgcTldhL0zVA4DQajLsNj6L7TgAABB9pUdAcLobtvCf0RQnXjiV4+2XrscPnzoFAPDYbT0T7MTh9DotX6m//vWvx+zsLD75yU9iamoKZ599Nu69914tMOL48eMQxS7eyTFY9c7rqcLJDhk2pEUPnEqC3BlaDYjE7nBolhROG4f5bAwOp16chal6ANkmH98B7L8XEkhBZQuMmP04pwdgfXCyQgJE+nnhVJbTx4O4aP0AHjo8zxP1OJweoi1W6jfffDNuvvlm0+/99re/Lfuz3/zmNxt/QMtFNgXEiUVmQh3AlT2WqgcASdGnF060vykrKzg2T+7bMMQLJw6nXkyteoBWODHsfq449SqOAqtZiPc4VeSdl6/HQ4fnMex3tfpQOBzOMtEWhVPPEpkAAKQFF8Lw9VQ4BOtdiotehNidtHA6Nh9HTlHhddgwFuQXJA6nXhxmVj1AT9YDIKsCnAHe49SrFBZO/bzHqSJXbhnG7Tech9X9nlYfCofDWSZ6Z6XejtBgiAVpGIDQc3OcACAGwwWHBkMcpP1NG4Z93DfO4TQAfQCumv+NFXrhtAA/+p18sdyrsOKaEeJWPUtcvZ3bWzmcXqKLm4c6ANrfNC2SXV5fLylOtEiMqIbCiSpOh2bjAICN3KbH4TSEklY9Tz9yIZpkiSBsIt+o6FXsXHHicDicivDCqZXQwmkKZOhkL1n1mLoWziucihUnDodTP5pVT1aKvpccOhsAsKibZjk9iFFxEgQgyEdBcDgcThG8cGol2SRgc+CkMgAAvRVH7iZ/66Js6GHqWwPAUDhxxYnDaQi64iQXfS86uhMAcMpWPHSc0zsY5xAFXHauPnI4HI4JvHBqJVf/LfDxadwuXwcAPdbjRP7W+Ryd5eQdApx+qKrKo8g5nAZTMhwCwPT6V+P9mZtxh/PNy31YnDbCGA7BbXocDodjDi+cWowqCFgg8wZ7yqrH1LWwQgsn2t80uZRCIiNDEgWsGeBJRRxOI9DDIUyseooNP1YuRtret9yHxWkjjFY9HkXO4XA45vDCqcWkcwqyNOnK5+ydwsnrkCAIwD51Jblj5QUAdJvemgEP7Db+9uRwGkHJcAgA6Sy5z2XnQzx7mTzFiSfqcTgcjim9s1JvUyKpLADSjOt19M7/DlEU4HNK+G3qHBz70wewZsN2AHrhxG16HE7j0MMh1KLvpbKk78ll5xsVvYw9T3HihROHw+GYwa+ULSaaygEgapPYY824LJJ8wbUasJHbvL+Jw2k85RSnVI4VTlxx6mXye5y4VY/D4XDM4IVTi4nRwinQQ8EQDNbTFaGvAcAT9TicZlAuVS9FrXpOiRdOvYyxcOKKE4fD4ZjDC6cWwxSnXgqGYATonJAotSsCXHHicJpBuXAItnnjdvDCqZdx8lQ9DofDqQgvnFoMKxp6KRiCwZL1IkmycAsnMpiLZQBwxYnDaSTl4sj3T0cBAOsGvct6TJz2wpiq18dT9TgcDscUXji1mJ5WnFz5ihNTm8aCLnh7sJDkcJpFuR6nPZMRAMD2scCyHhOnvTBa9fq4VY/D4XBM4YVTi2Gper00/Jah9ziR14An6nE4zaGU4pSVFRyYJp87Xjj1NsZUvT5u1eNwOBxTeOHUYmLpHlactB4n8hocmo0D4DY9DqfRlOpxOjwbR0ZW4HNKWNnnbsWhcdoErjhxOBxOZXjh1GJ0q14PK05JrjhxOM2ELYqzsgpV1Wc57aU2va2j/p4bh8DJJz9Vr/euRxwOh2MFXji1mKhm1etBxcmVrzjxKHIOpzkYF8VG1YkVTtu4Ta/nYXZOv1PKs+1xOBwOR6f3VuttRi+HQzCVLZLKIpWVcWIxAYArThxOozEmpmVyijazaQ8vnDiUTSM+nLUyiHNW97X6UDgcDqdt6b3VepvRy4VTwE3+5mgqhyNzcagqEHTbMejj/noOp5EUFk4MpjhtX8ELp17HKdnwo5tf0OrD4HA4nLaG6/EtJsrCIZy95ynXFKdk1mDT80IQeK8Fh9NIRFGARHuYmFVvJprCXCwDUQC2jPhbeXgcDofD4XQEvHBqMb3d46QrTjwYgsNpLoWznPZOksG3awe9cDtsLTsuDofD4XA6BV44tRhm1fP1YOHEFKdoOocDM2QRxwsnDqc5FBdOvL+Jw+FwOJxq4IVTi2GKU6CH48gBYPeJJQC8cOJwmoU2BFfOL5z44FsOh8PhcKzBC6cWkpUVpLJkEdOLVj2X3abtgk+EkwB4FDmH0ywKFac9p5jixPubOBwOh8OxAi+cWkiM2vQAwOfsvcIJyFfaHJKIlX2eFh4Nh9O9GAunVFbG4bk4AGD7WLCVh8XhcDgcTsfAC6cWwvqbPA4bpB4dOBgwKG3rB72wiTxRj8NpBkar3oHpGGRFRZ/HjpGAs8VHxuFwOBxOZ9Cbq/U2IUL7m3pVbQIAv1tXnDbw/iYOp2kYFSdjMASP/+dwOBwOxxq8cGohvTz8lmFUnDby/iYOp2loilNOwR6eqMfhcDgcTtXwwqmF6DOcei9Rj2HsceKJehxO89AUJ5kXThwOh8Ph1AIvnFoIV5zy/3ZeOHE4zYMVTums0arHE/U4HA6Hw7EKL5xaSCxNCqdenOHECNAeJ0EA1g16W3w0HE73wqx6R+fjiKZysNsEbBrmhROHw+FwOFbhhVML0a16Paw40WCMVX0euOy2Fh8Nh9O9MMXp6ZNk2PSGIZ92H4fD4XA4nMrwq2YLYVa9Xk7V6/c5AACbR7hNj8NpJqxI2n0yDADYzvubOBwOh8Opit5dsbcBO9b04caL1uD8df2tPpSW8fIzxnBoJo5Xnzve6kPhcLoaJy2c2IYND4bgcDgcDqc6eOHUQl582ihefNpoqw+jpYQ8Dnzyuu2tPgwOp+uxFwzZ5oUTh8PhcDjVwa16HA6H0wM4igonHgzB4XA4HE418MKJw+FwegBjEMRIwIkBn7OFR8PhcDgcTufBCycOh8PpAYyFE7fpcTgcDodTPbxw4nA4nB6AF04cDofD4dQHL5w4HA6nBzD2OPHCicPhcDic6uGFE4fD4fQAToPitJ0HQ3A4HA6HUzW8cOJwOJwegMWRu+wi1g3ygdMcDofD4VQLL5w4HA6nB3A7bACALSN+2EShxUfD4XA4HE7nwQfgcjgcTg9w+eYhXHfWCrz6nPFWHwqHw+FwOB0JL5w4HA6nBwh5HPjKG89p9WFwOBwOh9OxcKseh8PhcDgcDofD4VSAF04cDofD4XA4HA6HUwFeOHE4HA6Hw+FwOBxOBXjhxOFwOBwOh8PhcDgV4IUTh8PhcDgcDofD4VSAF04cDofD4XA4HA6HUwFeOHE4HA6Hw+FwOBxOBXjhxOFwOBwOh8PhcDgV4IUTh8PhcDgcDofD4VSAF04cDofD4XA4HA6HUwFeOHE4HA6Hw+FwOBxOBXjhxOFwOBwOh8PhcDgV4IUTh8PhcDgcDofD4VSAF04cDofD4XA4HA6HUwFeOHE4HA6Hw+FwOBxOBXjhxOFwOBwOh8PhcDgV4IUTh8PhcDgcDofD4VSAF04cDofD4XA4HA6HUwGp1Qew3KiqCgCIRCItPhIOh8PhcDgcDofTSlhNwGqEcvRc4RSNRgEAq1atavGRcDgcDofD4XA4nHYgGo0iGAyWfYygWimvughFUf5/e3cf09T1hwH8KZSWAiIvBhAdykAUFAjKJIhmMZKhMTqnk2k6gc3NyCCKL6jbgi4aRSW4xJfh5hY0mQ41oEOmM8ibwSBUkPkCQ+aYGhXJ5hAmCtie3x+/eLMOtcgct63PJ2lCzz33+L19AvabWw64desWBgwYAIVCIXc5aGtrwyuvvIIbN27A2dlZ7nLoBWGu1om5Wi9ma52Yq/VittZJjlyFEGhvb4e3tzdsbJ79W0wv3R0nGxsbDB06VO4yenB2duY3vhVirtaJuVovZmudmKv1YrbWqb9zNXWn6TFuDkFERERERGQCGyciIiIiIiIT2DjJTK1WY926dVCr1XKXQi8Qc7VOzNV6MVvrxFytF7O1Tuae60u3OQQREREREdHz4h0nIiIiIiIiE9g4ERERERERmcDGiYiIiIiIyAQ2TkRERERERCawcZLRrl27MHz4cNjb2yMiIgJVVVVyl0TPIT09Ha+99hoGDBgADw8PzJo1Cw0NDUZzHj58iKSkJLi7u8PJyQlz5szBnTt3ZKqY+mLz5s1QKBRISUmRxpir5bp58ybeffdduLu7Q6PRIDg4GOfOnZOOCyGwdu1aDB48GBqNBtHR0WhsbJSxYjJFr9cjLS0Nvr6+0Gg08PPzw4YNG/D3va+Yq2U4ffo0ZsyYAW9vbygUChw9etToeG9yvHv3LrRaLZydneHi4oKFCxfir7/+6seroH96Vq7d3d1YvXo1goOD4ejoCG9vb8TFxeHWrVtGa5hLrmycZHLw4EEsX74c69atQ01NDUJDQxETE4OWlha5S6NeKisrQ1JSEs6ePYvCwkJ0d3fjjTfewP3796U5y5Ytw7Fjx3D48GGUlZXh1q1bmD17toxV0/PQ6XT48ssvERISYjTOXC3Tn3/+iaioKNjZ2eHEiROoq6tDZmYmXF1dpTlbt27F9u3bsXv3blRWVsLR0RExMTF4+PChjJXTs2zZsgVZWVnYuXMn6uvrsWXLFmzduhU7duyQ5jBXy3D//n2EhoZi165dTzzemxy1Wi0uX76MwsJCFBQU4PTp01i0aFF/XQI9wbNy7ejoQE1NDdLS0lBTU4O8vDw0NDRg5syZRvPMJldBshg/frxISkqSnuv1euHt7S3S09NlrIr+jZaWFgFAlJWVCSGEaG1tFXZ2duLw4cPSnPr6egFAVFRUyFUm9VJ7e7sYMWKEKCwsFK+//rpYunSpEIK5WrLVq1eLiRMnPvW4wWAQXl5eIiMjQxprbW0VarVafPfdd/1RIvXB9OnTxfvvv280Nnv2bKHVaoUQzNVSARBHjhyRnvcmx7q6OgFA6HQ6ac6JEyeEQqEQN2/e7Lfa6en+meuTVFVVCQDi2rVrQgjzypV3nGTQ1dWF6upqREdHS2M2NjaIjo5GRUWFjJXRv3Hv3j0AgJubGwCguroa3d3dRjmPGjUKPj4+zNkCJCUlYfr06Ub5AczVkuXn5yM8PBxz586Fh4cHwsLCsGfPHul4U1MTmpubjbIdOHAgIiIimK0ZmzBhAoqKinDlyhUAwE8//YTy8nJMmzYNAHO1Fr3JsaKiAi4uLggPD5fmREdHw8bGBpWVlf1eM/XNvXv3oFAo4OLiAsC8clX2679GAIDff/8der0enp6eRuOenp74+eefZaqK/g2DwYCUlBRERUVhzJgxAIDm5maoVCrpG/8xT09PNDc3y1Al9VZOTg5qamqg0+l6HGOuluvXX39FVlYWli9fjk8++QQ6nQ5LliyBSqVCfHy8lN+TfjYzW/O1Zs0atLW1YdSoUbC1tYVer8fGjRuh1WoBgLlaid7k2NzcDA8PD6PjSqUSbm5uzNpCPHz4EKtXr8b8+fPh7OwMwLxyZeNE9AIkJSXh0qVLKC8vl7sU+pdu3LiBpUuXorCwEPb29nKXQy+QwWBAeHg4Nm3aBAAICwvDpUuXsHv3bsTHx8tcHfXVoUOHsH//fhw4cACjR49GbW0tUlJS4O3tzVyJLEh3dzdiY2MhhEBWVpbc5TwRP6ong0GDBsHW1rbHLlx37tyBl5eXTFVRXyUnJ6OgoAAlJSUYOnSoNO7l5YWuri60trYazWfO5q26uhotLS0YO3YslEollEolysrKsH37diiVSnh6ejJXCzV48GAEBQUZjQUGBuL69esAIOXHn82WJTU1FWvWrMG8efMQHByMBQsWYNmyZUhPTwfAXK1Fb3L08vLqscnWo0ePcPfuXWZt5h43TdeuXUNhYaF0twkwr1zZOMlApVJh3LhxKCoqksYMBgOKiooQGRkpY2X0PIQQSE5OxpEjR1BcXAxfX1+j4+PGjYOdnZ1Rzg0NDbh+/TpzNmNTpkzBxYsXUVtbKz3Cw8Oh1Wqlr5mrZYqKiurxJwOuXLmCYcOGAQB8fX3h5eVllG1bWxsqKyuZrRnr6OiAjY3x2xlbW1sYDAYAzNVa9CbHyMhItLa2orq6WppTXFwMg8GAiIiIfq+Zeudx09TY2IhTp07B3d3d6LhZ5dqvW1GQJCcnR6jVarF3715RV1cnFi1aJFxcXERzc7PcpVEvJSYmioEDB4rS0lJx+/Zt6dHR0SHNWbx4sfDx8RHFxcXi3LlzIjIyUkRGRspYNfXF33fVE4K5WqqqqiqhVCrFxo0bRWNjo9i/f79wcHAQ3377rTRn8+bNwsXFRXz//ffiwoUL4s033xS+vr7iwYMHMlZOzxIfHy+GDBkiCgoKRFNTk8jLyxODBg0Sq1atkuYwV8vQ3t4uzp8/L86fPy8AiG3btonz589Lu6v1JsepU6eKsLAwUVlZKcrLy8WIESPE/Pnz5bokEs/OtaurS8ycOVMMHTpU1NbWGr2f6uzslNYwl1zZOMlox44dwsfHR6hUKjF+/Hhx9uxZuUui5wDgiY/s7GxpzoMHD8RHH30kXF1dhYODg3jrrbfE7du35Sua+uSfjRNztVzHjh0TY8aMEWq1WowaNUp89dVXRscNBoNIS0sTnp6eQq1WiylTpoiGhgaZqqXeaGtrE0uXLhU+Pj7C3t5evPrqq+LTTz81etPFXC1DSUnJE/9fjY+PF0L0Lsc//vhDzJ8/Xzg5OQlnZ2fx3nvvifb2dhmuhh57Vq5NTU1PfT9VUlIirWEuuSqE+Nuf1iYiIiIiIqIe+DtOREREREREJrBxIiIiIiIiMoGNExERERERkQlsnIiIiIiIiExg40RERERERGQCGyciIiIiIiIT2DgRERERERGZwMaJiIheKnfu3MH69etx9+5duUshIiILwsaJiIheGo8ePUJsbCzs7e3h5ubWpzVKS0uhUCjQ2tr6YosjIiKzxsaJiIjMUkJCAhQKBRQKBVQqFfz9/bF+/Xo8evSoz2umpqYiNDQUq1ateoGVEhHRy0ApdwFERERPM3XqVGRnZ6OzsxPHjx9HUlIS7Ozs8PHHHz/XOnq9HgqFAp9//vl/VCkREVk73nEiIiKzpVar4eXlhWHDhiExMRHR0dHIz89HZ2cnVq5ciSFDhsDR0REREREoLS2Vztu7dy9cXFyQn5+PoKAgqNVqXL9+HQkJCZg1a5Y0r7OzE0uWLIGHhwfs7e0xceJE6HQ6oxqOHz+OgIAAaDQaTJ48Gb/99luPOnNzczF69Gio1WoMHz4cmZmZ/9ErQkREcmHjREREFkOj0aCrqwvJycmoqKhATk4OLly4gLlz52Lq1KlobGyU5nZ0dGDLli34+uuvcfnyZXh4ePRYb9WqVcjNzcW+fftQU1MDf39/xMTESBtH3LhxA7Nnz8aMGTNQW1uLDz74AGvWrDFao7q6GrGxsZg3bx4uXryIzz77DGlpadi7d+9/+loQEVH/YuNERERmTwiBU6dO4eTJkwgJCUF2djYOHz6MSZMmwc/PDytXrsTEiRORnZ0tndPd3Y0vvvgCEyZMwMiRI+Hg4GC05v3795GVlYWMjAxMmzYNQUFB2LNnDzQaDb755hsAQFZWFvz8/JCZmYmRI0dCq9UiISHBaJ1t27ZhypQpSEtLQ0BAABISEpCcnIyMjIz//HUhIqL+w8aJiIjMVkFBAZycnGBvb49p06bhnXfewdtvvw29Xo+AgAA4OTlJj7KyMly9elU6V6VSISQk5KlrX716Fd3d3YiKipLG7OzsMH78eNTX1wMA6uvrERERYXReZGSk0fP6+nqjNQAgKioKjY2N0Ov1fb52IiIyL9wcgoiIzNbkyZORlZUFlUoFb29vKJVKHDx4ELa2tqiuroatra3RfCcnJ+lrjUYDhULR3yUTEZGVYuNERERmy9HREf7+/kZjYWFh0Ov1aGlpwaRJk/q8tp+fH1QqFc6cOYNhw4YB+P/H+3Q6HVJSUgAAgYGByM/PNzrv7NmzRs8DAwNx5swZo7EzZ84gICCgR2NHRESWix/VIyIiixIQEACtVou4uDjk5eWhqakJVVVVSE9Pxw8//NDrdRwdHZGYmIjU1FT8+OOPqKurw4cffoiOjg4sXLgQALB48WI0NjYiNTUVDQ0NOHDgQI9NH1asWIGioiJs2LABV65cwb59+7Bz506sXLnyRV42ERHJjI0TERFZnOzsbMTFxWHFihUYOXIkZs2aBZ1OBx8fn+daZ/PmzZgzZw4WLFiAsWPH4pdffsHJkyfh6uoKAPDx8UFubi6OHj2K0NBQ7N69G5s2bTJaY+zYsTh06BBycnIwZswYrF27FuvXr++xiQQREVk2hRBCyF0EERERERGROeMdJyIiIiIiIhPYOBEREREREZnAxomIiIiIiMgENk5EREREREQmsHEiIiIiIiIygY0TERERERGRCWyciIiIiIiITGDjREREREREZAIbJyIiIiIiIhPYOBEREREREZnAxomIiIiIiMiE/wEAbaz4DXZOJAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df_despesas_agrupado.drop(['valor_pago'], axis=1)\n",
    "y = df_despesas_agrupado.loc[:, ['valor_pago']]\n",
    "\n",
    "y_norm = output_scaler.transform(y)\n",
    "X_norm = input_scaler.transform(X)\n",
    "\n",
    "X = X_norm.reshape((X_norm.shape[0], 1, X_norm.shape[1]))\n",
    "y = y_norm.reshape((y_norm.shape[0], 1))\n",
    "\n",
    "y = scaler_y.inverse_transform(y)\n",
    "\n",
    "prediction_lstm = prediction(model_lstm)\n",
    "\n",
    "plot_future(prediction_lstm, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo do erro médio percentual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro médio percentual: -8.95%\n"
     ]
    }
   ],
   "source": [
    "real = y.flatten()\n",
    "previsto = prediction_lstm.flatten()\n",
    "\n",
    "tabela = pd.DataFrame([real, previsto]).T\n",
    "tabela = tabela.rename(columns={0: 'Real', 1: 'Previsto'})\n",
    "tabela['Diferenca'] = 1 - (tabela['Real'] / tabela['Previsto'])\n",
    "media_tabela = tabela['Diferenca'].mean() * 100\n",
    "print(f'Erro médio percentual: {media_tabela:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribuição de erros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(data=tabela, x='Diferenca', kde=True).set_title('Distribuição dos erros percentuais').get_figure().savefig('../../src/static/images/despesas/figura[5].png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relizando previsões com os dados e modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['valor_pago', 'populacao', 'variacao_anual',\n",
       "       'aceleracao_variacao_anual', 'ideb_5ano', 'ideb_9ano', 'idhm',\n",
       "       'pct_desp_recp_saude_mun', 'desp_tot_saude_pc_mun',\n",
       "       'desp_recp_saude_pc_mun', 'desp_tot_saude_pc_mun_def',\n",
       "       'desp_recp_saude_pc_mun_def', 'SMA(12)_pago', 'SMA(6)_pago',\n",
       "       'SMA(3)_pago', 'SMA(2)_pago', 'lag(12)_pago', 'lag(6)_pago',\n",
       "       'lag(4)_pago', 'lag(3)_pago', 'lag(2)_pago', 'lag(1)_pago',\n",
       "       'ano_mes_ordinal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao = df_despesas_agrupado\n",
    "\n",
    "previsao.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 32 features, but MinMaxScaler is expecting 22 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\allys\\repos\\neural_network_studies\\notebooks\\v3\\rede_neural_dados_nuvem.ipynb Cell 109\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/allys/repos/neural_network_studies/notebooks/v3/rede_neural_dados_nuvem.ipynb#Y220sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Transforme a linha em um array e normalize\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/allys/repos/neural_network_studies/notebooks/v3/rede_neural_dados_nuvem.ipynb#Y220sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m row \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(row\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/allys/repos/neural_network_studies/notebooks/v3/rede_neural_dados_nuvem.ipynb#Y220sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m row_norm \u001b[39m=\u001b[39m input_scaler\u001b[39m.\u001b[39;49mtransform(row)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/allys/repos/neural_network_studies/notebooks/v3/rede_neural_dados_nuvem.ipynb#Y220sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Preveja usando o modelo LSTM\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/allys/repos/neural_network_studies/notebooks/v3/rede_neural_dados_nuvem.ipynb#Y220sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m to_prev \u001b[39m=\u001b[39m row_norm\u001b[39m.\u001b[39mreshape((row_norm\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, row_norm\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:514\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \n\u001b[0;32m    502\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[39m    Transformed data.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    512\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 514\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    515\u001b[0m     X,\n\u001b[0;32m    516\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[0;32m    517\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    518\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    519\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    520\u001b[0m )\n\u001b[0;32m    522\u001b[0m X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[0;32m    523\u001b[0m X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_\n",
      "File \u001b[1;32mc:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    627\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 32 features, but MinMaxScaler is expecting 22 features as input."
     ]
    }
   ],
   "source": [
    "periodo = 8  # escolha o período de previsão à frente será executado\n",
    "\n",
    "for i in range(periodo):\n",
    "    # Crie uma nova linha de dados vazia\n",
    "    row = pd.DataFrame(columns=previsao.columns)\n",
    "\n",
    "    # Calcule as médias e valores de atraso\n",
    "    row.loc[0, 'SMA(12)'] = previsao['valor_pago'].iloc[-12:].mean()\n",
    "    row.loc[0, 'SMA(6)'] = previsao['valor_pago'].iloc[-6:].mean()\n",
    "    row.loc[0, 'SMA(3)'] = previsao['valor_pago'].iloc[-3:].mean()\n",
    "    row.loc[0, 'SMA(2)'] = previsao['valor_pago'].iloc[-2:].mean()\n",
    "    row.loc[0, 'lag(12)'] = previsao['valor_pago'].iloc[-12]\n",
    "    row.loc[0, 'lag(6)'] = previsao['valor_pago'].iloc[-6]\n",
    "    row.loc[0, 'lag(4)'] = previsao['valor_pago'].iloc[-4]\n",
    "    row.loc[0, 'lag(3)'] = previsao['valor_pago'].iloc[-3]\n",
    "    row.loc[0, 'lag(2)'] = previsao['valor_pago'].iloc[-2]\n",
    "    row.loc[0, 'lag(1)'] = previsao['valor_pago'].iloc[-1]\n",
    "    row.loc[0, 'populacao'] = previsao['populacao'].iloc[-1]\n",
    "    row.loc[0, 'variacao_anual'] = previsao['variacao_anual'].iloc[-1]\n",
    "    row.loc[0, 'aceleracao_variacao_anual'] = previsao['aceleracao_variacao_anual'].iloc[-1]\n",
    "    row.loc[0, 'ideb_5ano'] = previsao['ideb_5ano'].iloc[-1]\n",
    "    row.loc[0, 'ideb_9ano'] = previsao['ideb_9ano'].iloc[-1]\n",
    "    row.loc[0, 'idhm'] = previsao['idhm'].iloc[-1]\n",
    "    row.loc[0, 'pct_desp_recp_saude_mun'] = previsao['pct_desp_recp_saude_mun'].iloc[-1]\n",
    "    row.loc[0, 'desp_tot_saude_pc_mun'] = previsao['desp_tot_saude_pc_mun'].iloc[-1]\n",
    "    row.loc[0, 'desp_recp_saude_pc_mun'] = previsao['desp_recp_saude_pc_mun'].iloc[-1]\n",
    "    row.loc[0, 'desp_tot_saude_pc_mun_def'] = previsao['desp_tot_saude_pc_mun_def'].iloc[-1]\n",
    "    row.loc[0, 'desp_recp_saude_pc_mun_def'] = previsao['desp_recp_saude_pc_mun_def'].iloc[-1]\n",
    "\n",
    "    # Incremente a data\n",
    "    row.loc[0, 'ano_mes_ordinal'] = previsao['ano_mes_ordinal'].iloc[-1]+1\n",
    "    \n",
    "    # Excluindo a coluna de valor arrecadado\n",
    "    row = row.drop(columns={'valor_pago'})\n",
    "    \n",
    "    # Transforme a linha em um array e normalize\n",
    "    row = np.array(row.iloc[-1]).reshape(1, -1)\n",
    "    row_norm = input_scaler.transform(row)\n",
    "\n",
    "    # Preveja usando o modelo LSTM\n",
    "    to_prev = row_norm.reshape((row_norm.shape[0], 1, row_norm.shape[1]))\n",
    "    prev = model_lstm.predict(to_prev)\n",
    "    prev = scaler_y.inverse_transform(prev)\n",
    "\n",
    "    # Crie um DataFrame com a previsão e adicione ao DataFrame principal\n",
    "    row_ = pd.DataFrame(row, columns = ['populacao', 'variacao_anual',\n",
    "       'aceleracao_variacao_anual', 'ideb_5ano', 'ideb_9ano', 'idhm',\n",
    "       'pct_desp_recp_saude_mun', 'desp_tot_saude_pc_mun',\n",
    "       'desp_recp_saude_pc_mun', 'desp_tot_saude_pc_mun_def',\n",
    "       'desp_recp_saude_pc_mun_def', 'SMA(12)_pago', 'SMA(6)_pago',\n",
    "       'SMA(3)_pago', 'SMA(2)_pago', 'lag(12)_pago', 'lag(6)_pago',\n",
    "       'lag(4)_pago', 'lag(3)_pago', 'lag(2)_pago', 'lag(1)_pago',\n",
    "       'ano_mes_ordinal'])\n",
    "    row_.loc[0, 'valor_pago'] = prev[0]\n",
    "    previsao = pd.concat([previsao, row_], ignore_index=True)\n",
    "\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
