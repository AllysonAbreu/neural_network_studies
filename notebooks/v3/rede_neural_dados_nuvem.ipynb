{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexão com o DB local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "driver = os.environ[\"Driver\"]\n",
    "server = os.environ[\"Server\"]\n",
    "database = os.environ[\"Database\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_conexao = (\n",
    "    f\"Driver={driver};\"\n",
    "    f\"Server={server};\"\n",
    "    f\"Database={database};\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_banco(query, dados_conexao):\n",
    "    engine = create_engine(f'mssql+pyodbc:///?odbc_connect={dados_conexao}')\n",
    "    return pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_fato</th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>2911694.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_fato  valor_fixado  valor_empenhado  valor_liquidado  valor_pago  \\\n",
       "0 2013-12-31     2911694.0           5120.0           5120.0         0.0   \n",
       "1 2013-12-31      107000.0           6950.0           6950.0         0.0   \n",
       "2 2013-12-31      107000.0            800.0            800.0         0.0   \n",
       "3 2013-12-31      107000.0            400.0            400.0         0.0   \n",
       "4 2013-12-31      107000.0            600.0            600.0         0.0   \n",
       "\n",
       "    saldo  \n",
       "0  5120.0  \n",
       "1  6950.0  \n",
       "2   800.0  \n",
       "3   400.0  \n",
       "4   600.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas = query_banco(\"SELECT * FROM Fato_Despesa\", dados_conexao)\n",
    "df_despesas.drop(columns=['id','uid_fato_despesa','credor_despesa', 'fonte_recurso', 'orgao_interno', 'orgao_vinculado', 'cod_elemento', 'cod_subelemento', 'cod_funcao', 'cod_subfuncao', 'cod_natureza'], inplace=True)\n",
    "df_despesas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>porcentagem_variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>porcentagem_aceleracao_variacao_anual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>51273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992</td>\n",
       "      <td>51530</td>\n",
       "      <td>257</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>51965</td>\n",
       "      <td>435</td>\n",
       "      <td>0,84</td>\n",
       "      <td>178</td>\n",
       "      <td>69,26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994</td>\n",
       "      <td>52279</td>\n",
       "      <td>314</td>\n",
       "      <td>0,6</td>\n",
       "      <td>-121</td>\n",
       "      <td>-27,82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>52586</td>\n",
       "      <td>307</td>\n",
       "      <td>0,59</td>\n",
       "      <td>-7</td>\n",
       "      <td>-2,23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>51396</td>\n",
       "      <td>-1190</td>\n",
       "      <td>-2,26</td>\n",
       "      <td>-1497</td>\n",
       "      <td>-487,62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997</td>\n",
       "      <td>51575</td>\n",
       "      <td>179</td>\n",
       "      <td>0,35</td>\n",
       "      <td>1369</td>\n",
       "      <td>-115,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998</td>\n",
       "      <td>51726</td>\n",
       "      <td>151</td>\n",
       "      <td>0,29</td>\n",
       "      <td>-28</td>\n",
       "      <td>-15,64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999</td>\n",
       "      <td>51878</td>\n",
       "      <td>152</td>\n",
       "      <td>0,29</td>\n",
       "      <td>1</td>\n",
       "      <td>0,66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000</td>\n",
       "      <td>54715</td>\n",
       "      <td>2837</td>\n",
       "      <td>5,47</td>\n",
       "      <td>2685</td>\n",
       "      <td>1766,45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001</td>\n",
       "      <td>55132</td>\n",
       "      <td>417</td>\n",
       "      <td>0,76</td>\n",
       "      <td>-2420</td>\n",
       "      <td>-85,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002</td>\n",
       "      <td>55439</td>\n",
       "      <td>307</td>\n",
       "      <td>0,56</td>\n",
       "      <td>-110</td>\n",
       "      <td>-26,38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2003</td>\n",
       "      <td>55775</td>\n",
       "      <td>336</td>\n",
       "      <td>0,61</td>\n",
       "      <td>29</td>\n",
       "      <td>9,45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004</td>\n",
       "      <td>56481</td>\n",
       "      <td>706</td>\n",
       "      <td>1,27</td>\n",
       "      <td>370</td>\n",
       "      <td>110,12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2005</td>\n",
       "      <td>56871</td>\n",
       "      <td>390</td>\n",
       "      <td>0,69</td>\n",
       "      <td>-316</td>\n",
       "      <td>-44,76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2006</td>\n",
       "      <td>57259</td>\n",
       "      <td>388</td>\n",
       "      <td>0,68</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0,51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2007</td>\n",
       "      <td>56051</td>\n",
       "      <td>-1208</td>\n",
       "      <td>-2,11</td>\n",
       "      <td>-1596</td>\n",
       "      <td>-411,34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008</td>\n",
       "      <td>57627</td>\n",
       "      <td>1576</td>\n",
       "      <td>2,81</td>\n",
       "      <td>2784</td>\n",
       "      <td>-230,46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2009</td>\n",
       "      <td>57875</td>\n",
       "      <td>248</td>\n",
       "      <td>0,43</td>\n",
       "      <td>-1328</td>\n",
       "      <td>-84,26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2010</td>\n",
       "      <td>58446</td>\n",
       "      <td>571</td>\n",
       "      <td>0,99</td>\n",
       "      <td>323</td>\n",
       "      <td>130,24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011</td>\n",
       "      <td>58794</td>\n",
       "      <td>348</td>\n",
       "      <td>0,6</td>\n",
       "      <td>-223</td>\n",
       "      <td>-39,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012</td>\n",
       "      <td>59130</td>\n",
       "      <td>336</td>\n",
       "      <td>0,57</td>\n",
       "      <td>-12</td>\n",
       "      <td>-3,45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>2,51</td>\n",
       "      <td>1146</td>\n",
       "      <td>341,07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014</td>\n",
       "      <td>61030</td>\n",
       "      <td>418</td>\n",
       "      <td>0,69</td>\n",
       "      <td>-1064</td>\n",
       "      <td>-71,79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015</td>\n",
       "      <td>61431</td>\n",
       "      <td>401</td>\n",
       "      <td>0,66</td>\n",
       "      <td>-17</td>\n",
       "      <td>-4,07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016</td>\n",
       "      <td>61816</td>\n",
       "      <td>385</td>\n",
       "      <td>0,63</td>\n",
       "      <td>-16</td>\n",
       "      <td>-3,99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>62187</td>\n",
       "      <td>371</td>\n",
       "      <td>0,6</td>\n",
       "      <td>-14</td>\n",
       "      <td>-3,64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>61776</td>\n",
       "      <td>-411</td>\n",
       "      <td>-0,66</td>\n",
       "      <td>-782</td>\n",
       "      <td>-210,78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019</td>\n",
       "      <td>61993</td>\n",
       "      <td>217</td>\n",
       "      <td>0,35</td>\n",
       "      <td>628</td>\n",
       "      <td>-152,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020</td>\n",
       "      <td>62289</td>\n",
       "      <td>296</td>\n",
       "      <td>0,48</td>\n",
       "      <td>79</td>\n",
       "      <td>36,41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021</td>\n",
       "      <td>62576</td>\n",
       "      <td>287</td>\n",
       "      <td>0,46</td>\n",
       "      <td>-9</td>\n",
       "      <td>-3,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>1,05</td>\n",
       "      <td>376</td>\n",
       "      <td>56,71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ano  populacao variacao_anual porcentagem_variacao_anual  \\\n",
       "0   1991      51273              0                          0   \n",
       "1   1992      51530            257                        0,5   \n",
       "2   1993      51965            435                       0,84   \n",
       "3   1994      52279            314                        0,6   \n",
       "4   1995      52586            307                       0,59   \n",
       "5   1996      51396          -1190                      -2,26   \n",
       "6   1997      51575            179                       0,35   \n",
       "7   1998      51726            151                       0,29   \n",
       "8   1999      51878            152                       0,29   \n",
       "9   2000      54715           2837                       5,47   \n",
       "10  2001      55132            417                       0,76   \n",
       "11  2002      55439            307                       0,56   \n",
       "12  2003      55775            336                       0,61   \n",
       "13  2004      56481            706                       1,27   \n",
       "14  2005      56871            390                       0,69   \n",
       "15  2006      57259            388                       0,68   \n",
       "16  2007      56051          -1208                      -2,11   \n",
       "17  2008      57627           1576                       2,81   \n",
       "18  2009      57875            248                       0,43   \n",
       "19  2010      58446            571                       0,99   \n",
       "20  2011      58794            348                        0,6   \n",
       "21  2012      59130            336                       0,57   \n",
       "22  2013      60612           1482                       2,51   \n",
       "23  2014      61030            418                       0,69   \n",
       "24  2015      61431            401                       0,66   \n",
       "25  2016      61816            385                       0,63   \n",
       "26  2017      62187            371                        0,6   \n",
       "27  2018      61776           -411                      -0,66   \n",
       "28  2019      61993            217                       0,35   \n",
       "29  2020      62289            296                       0,48   \n",
       "30  2021      62576            287                       0,46   \n",
       "31  2022      63239            663                       1,05   \n",
       "\n",
       "   aceleracao_variacao_anual porcentagem_aceleracao_variacao_anual  \n",
       "0                          0                                     0  \n",
       "1                          0                                     0  \n",
       "2                        178                                 69,26  \n",
       "3                       -121                                -27,82  \n",
       "4                         -7                                 -2,23  \n",
       "5                      -1497                               -487,62  \n",
       "6                       1369                               -115,04  \n",
       "7                        -28                                -15,64  \n",
       "8                          1                                  0,66  \n",
       "9                       2685                               1766,45  \n",
       "10                     -2420                                 -85,3  \n",
       "11                      -110                                -26,38  \n",
       "12                        29                                  9,45  \n",
       "13                       370                                110,12  \n",
       "14                      -316                                -44,76  \n",
       "15                        -2                                 -0,51  \n",
       "16                     -1596                               -411,34  \n",
       "17                      2784                               -230,46  \n",
       "18                     -1328                                -84,26  \n",
       "19                       323                                130,24  \n",
       "20                      -223                                -39,05  \n",
       "21                       -12                                 -3,45  \n",
       "22                      1146                                341,07  \n",
       "23                     -1064                                -71,79  \n",
       "24                       -17                                 -4,07  \n",
       "25                       -16                                 -3,99  \n",
       "26                       -14                                 -3,64  \n",
       "27                      -782                               -210,78  \n",
       "28                       628                                -152,8  \n",
       "29                        79                                 36,41  \n",
       "30                        -9                                 -3,04  \n",
       "31                       376                                 56,71  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_populacao = query_banco(\"SELECT * FROM Dim_Populacao\", dados_conexao)\n",
    "df_populacao.drop(columns=['id'], inplace=True)\n",
    "df_populacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>4,1</td>\n",
       "      <td>2,8</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>4,1</td>\n",
       "      <td>2,8</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>4,4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>4,4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>4,8</td>\n",
       "      <td>3,5</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>4,8</td>\n",
       "      <td>3,5</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>5,3</td>\n",
       "      <td>4,1</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>5,3</td>\n",
       "      <td>4,1</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>5,1</td>\n",
       "      <td>4,9</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano ideb_5ano ideb_9ano   idhm\n",
       "0  2013       4,1       2,8  0,679\n",
       "1  2014       4,1       2,8  0,679\n",
       "2  2015       4,4         3  0,679\n",
       "3  2016       4,4         3  0,679\n",
       "4  2017       4,8       3,5  0,679\n",
       "5  2018       4,8       3,5  0,679\n",
       "6  2019       5,3       4,1  0,679\n",
       "7  2020       5,3       4,1  0,679\n",
       "8  2021       5,1       4,9  0,679"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idhm = query_banco(\"SELECT ano, ideb_5ano, ideb_9ano, idhm FROM Dim_IDHM\", dados_conexao)\n",
    "df_idhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun_def</th>\n",
       "      <th>desp_recp_saude_pc_mun_def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>16,56</td>\n",
       "      <td>464,3</td>\n",
       "      <td>114,1</td>\n",
       "      <td>744,7674653</td>\n",
       "      <td>183,0238376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>23,4</td>\n",
       "      <td>448,73</td>\n",
       "      <td>186,19</td>\n",
       "      <td>676,4489043</td>\n",
       "      <td>280,676624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>22,48</td>\n",
       "      <td>468,65</td>\n",
       "      <td>190,19</td>\n",
       "      <td>638,3468516</td>\n",
       "      <td>259,057266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>21,23</td>\n",
       "      <td>439,37</td>\n",
       "      <td>202,37</td>\n",
       "      <td>563,0595289</td>\n",
       "      <td>259,3403211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>18,6</td>\n",
       "      <td>468,37</td>\n",
       "      <td>178,28</td>\n",
       "      <td>583,0388706</td>\n",
       "      <td>221,9274716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>18,26</td>\n",
       "      <td>705,23</td>\n",
       "      <td>190,43</td>\n",
       "      <td>846,1933549</td>\n",
       "      <td>228,4936837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>16,13</td>\n",
       "      <td>559,08</td>\n",
       "      <td>187,04</td>\n",
       "      <td>643,1360678</td>\n",
       "      <td>215,1609253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>16,23</td>\n",
       "      <td>668,07</td>\n",
       "      <td>187,35</td>\n",
       "      <td>735,277842</td>\n",
       "      <td>206,19741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>19,02</td>\n",
       "      <td>790,59</td>\n",
       "      <td>272,68</td>\n",
       "      <td>790,59</td>\n",
       "      <td>272,68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano pct_desp_recp_saude_mun desp_tot_saude_pc_mun desp_recp_saude_pc_mun  \\\n",
       "0  2013                   16,56                 464,3                  114,1   \n",
       "1  2014                    23,4                448,73                 186,19   \n",
       "2  2015                   22,48                468,65                 190,19   \n",
       "3  2016                   21,23                439,37                 202,37   \n",
       "4  2017                    18,6                468,37                 178,28   \n",
       "5  2018                   18,26                705,23                 190,43   \n",
       "6  2019                   16,13                559,08                 187,04   \n",
       "7  2020                   16,23                668,07                 187,35   \n",
       "8  2021                   19,02                790,59                 272,68   \n",
       "\n",
       "  desp_tot_saude_pc_mun_def desp_recp_saude_pc_mun_def  \n",
       "0               744,7674653                183,0238376  \n",
       "1               676,4489043                 280,676624  \n",
       "2               638,3468516                 259,057266  \n",
       "3               563,0595289                259,3403211  \n",
       "4               583,0388706                221,9274716  \n",
       "5               846,1933549                228,4936837  \n",
       "6               643,1360678                215,1609253  \n",
       "7                735,277842                  206,19741  \n",
       "8                    790,59                     272,68  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_saude = query_banco(\"SELECT ano, pct_desp_recp_saude_mun, desp_tot_saude_pc_mun,desp_recp_saude_pc_mun, desp_tot_saude_pc_mun_def, desp_recp_saude_pc_mun_def FROM Dim_Saude\", dados_conexao)\n",
    "df_saude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserindo colunas que tratam do tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_colunas_tempo(df, coluna_data):\n",
    "    df[coluna_data] = pd.to_datetime(df[coluna_data])\n",
    "    df['ano_mes'] = df[coluna_data].dt.strftime('%Y-%m')\n",
    "    df['ano'] = df[coluna_data].dt.strftime('%Y')\n",
    "    return df\n",
    "\n",
    "def transforma_data_em_ordinal(df, coluna_referencia):\n",
    "    df['ano_mes_ordinal'] = pd.to_datetime(df[coluna_referencia])\n",
    "    df['ano_mes_ordinal'] = df['ano_mes_ordinal'].map(dt.datetime.toordinal)\n",
    "    return df\n",
    "\n",
    "def transforma_coluna_em_datetime(df, coluna):\n",
    "    df[coluna] = pd.to_datetime(df[coluna], format='%Y')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação de IQR - Interquartile Range\n",
    "def remove_outliers(df, coluna):\n",
    "    Q1 = df[coluna].quantile(0.25)\n",
    "    print(f'Q1: {Q1}')\n",
    "    Q3 = df[coluna].quantile(0.75)\n",
    "    print(f'Q3: {Q3}')\n",
    "    IQR = Q3 - Q1\n",
    "    print(f'IQR: {IQR}')\n",
    "    print(f'Limite inferior: {Q1 - 1.5 * IQR}')\n",
    "    print(f'Limite superior: {Q3 + 1.5 * IQR}')\n",
    "    df = df[(df[coluna] >= Q1 - 1.5*IQR) & (df[coluna] <= Q3 + 1.5*IQR)]\n",
    "    print(f'Quantidade de registros sem outliers: {df.shape[0]}')\n",
    "    return df\n",
    "\n",
    "# Gráfico de dispersão\n",
    "def box_plot(df, coluna_referencia, coluna_visao):\n",
    "    print(f'Quantidade de registros: {df.shape[0]}')\n",
    "    df.boxplot(by=coluna_referencia, column=coluna_visao, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series_data(df, coluna_referencia):\n",
    "    train_size = int(len(df) * 0.8)\n",
    "    train_dataset, test_dataset = df.iloc[:train_size], df.iloc[train_size:]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(train_dataset[coluna_referencia])\n",
    "    plt.plot(test_dataset[coluna_referencia])\n",
    "    plt.xlabel('Período')\n",
    "    plt.ylabel('Valor Arrecadado')\n",
    "    plt.legend(['Treino', 'Teste'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('../../src/static/images/dados_treinamento.png')\n",
    "    print('Dimension of train data: ', train_dataset.shape)\n",
    "    print('Dimension of test data: ', test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversão de tipos de dados nas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_tipo_dados(df, colunas, tipo):\n",
    "    for coluna in colunas:\n",
    "        df[coluna] = df[coluna].astype(tipo)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise exploratória dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Despesas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86841 entries, 0 to 86840\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   data_fato        86841 non-null  datetime64[ns]\n",
      " 1   valor_fixado     86841 non-null  float64       \n",
      " 2   valor_empenhado  86841 non-null  float64       \n",
      " 3   valor_liquidado  86841 non-null  float64       \n",
      " 4   valor_pago       86841 non-null  float64       \n",
      " 5   saldo            86841 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_despesas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_fato</th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86841</td>\n",
       "      <td>86841.00</td>\n",
       "      <td>86841.00</td>\n",
       "      <td>86841.00</td>\n",
       "      <td>86841.00</td>\n",
       "      <td>86841.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018-03-12 20:45:52.451031040</td>\n",
       "      <td>336082.00</td>\n",
       "      <td>14906.00</td>\n",
       "      <td>14448.91</td>\n",
       "      <td>13163.63</td>\n",
       "      <td>1500.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2013-01-02 00:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-396163.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2015-08-20 00:00:00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>240.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018-03-26 00:00:00</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>990.86</td>\n",
       "      <td>880.00</td>\n",
       "      <td>613.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020-10-15 00:00:00</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>5244.05</td>\n",
       "      <td>4995.00</td>\n",
       "      <td>3800.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022-12-30 00:00:00</td>\n",
       "      <td>14400000.00</td>\n",
       "      <td>2795000.00</td>\n",
       "      <td>2795000.00</td>\n",
       "      <td>2795000.00</td>\n",
       "      <td>1639155.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1010914.22</td>\n",
       "      <td>71460.78</td>\n",
       "      <td>70443.38</td>\n",
       "      <td>67964.15</td>\n",
       "      <td>19966.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           data_fato  valor_fixado  valor_empenhado  \\\n",
       "count                          86841      86841.00         86841.00   \n",
       "mean   2018-03-12 20:45:52.451031040     336082.00         14906.00   \n",
       "min              2013-01-02 00:00:00          0.00             0.00   \n",
       "25%              2015-08-20 00:00:00       1000.00           250.00   \n",
       "50%              2018-03-26 00:00:00      50000.00           990.86   \n",
       "75%              2020-10-15 00:00:00     200000.00          5244.05   \n",
       "max              2022-12-30 00:00:00   14400000.00       2795000.00   \n",
       "std                              NaN    1010914.22         71460.78   \n",
       "\n",
       "       valor_liquidado  valor_pago       saldo  \n",
       "count         86841.00    86841.00    86841.00  \n",
       "mean          14448.91    13163.63     1500.68  \n",
       "min               0.00        0.00  -396163.17  \n",
       "25%             240.00      150.00        0.00  \n",
       "50%             880.00      613.00        0.00  \n",
       "75%            4995.00     3800.00        0.00  \n",
       "max         2795000.00  2795000.00  1639155.73  \n",
       "std           70443.38    67964.15    19966.49  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_fato</th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>2911694.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_fato  valor_fixado  valor_empenhado  valor_liquidado  valor_pago  \\\n",
       "0 2013-12-31     2911694.0           5120.0           5120.0         0.0   \n",
       "1 2013-12-31      107000.0           6950.0           6950.0         0.0   \n",
       "2 2013-12-31      107000.0            800.0            800.0         0.0   \n",
       "3 2013-12-31      107000.0            400.0            400.0         0.0   \n",
       "4 2013-12-31      107000.0            600.0            600.0         0.0   \n",
       "\n",
       "    saldo  ano_mes   ano  \n",
       "0  5120.0  2013-12  2013  \n",
       "1  6950.0  2013-12  2013  \n",
       "2   800.0  2013-12  2013  \n",
       "3   400.0  2013-12  2013  \n",
       "4   600.0  2013-12  2013  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas_com_outliers = cria_colunas_tempo(df_despesas,'data_fato')\n",
    "df_despesas_com_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de registros: 86841\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "box_plot(df_despesas_com_outliers, 'ano', 'valor_pago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 150.0\n",
      "Q3: 3800.0\n",
      "IQR: 3650.0\n",
      "Limite inferior: -5325.0\n",
      "Limite superior: 9275.0\n",
      "Quantidade de registros sem outliers: 72498\n"
     ]
    }
   ],
   "source": [
    "df_despesas_sem_outliers = remove_outliers(df_despesas_com_outliers, 'valor_pago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de registros: 72498\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "box_plot(df_despesas_sem_outliers, 'ano', 'valor_pago')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## População"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                 Non-Null Count  Dtype \n",
      "---  ------                                 --------------  ----- \n",
      " 0   ano                                    32 non-null     int64 \n",
      " 1   populacao                              32 non-null     int64 \n",
      " 2   variacao_anual                         32 non-null     object\n",
      " 3   porcentagem_variacao_anual             32 non-null     object\n",
      " 4   aceleracao_variacao_anual              32 non-null     object\n",
      " 5   porcentagem_aceleracao_variacao_anual  32 non-null     object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_populacao.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>populacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>57024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1991.0</td>\n",
       "      <td>51273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>52509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>57065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>61130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>63239.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ano  populacao\n",
       "count    32.0       32.0\n",
       "mean   2006.0    57024.0\n",
       "std       9.0     4073.0\n",
       "min    1991.0    51273.0\n",
       "25%    1999.0    52509.0\n",
       "50%    2006.0    57065.0\n",
       "75%    2014.0    61130.0\n",
       "max    2022.0    63239.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_populacao.describe().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_populacao_dados_copy = df_populacao.copy()\n",
    "df_populacao_dados_convertidos = df_populacao_dados_copy\n",
    "df_populacao_dados_convertidos['ano'] = df_populacao_dados_convertidos['ano'].astype(object)\n",
    "df_populacao_dados_convertidos = transforma_coluna_em_datetime(df_populacao, 'ano')\n",
    "df_populacao_dados_convertidos = cria_colunas_tempo(df_populacao, 'ano')\n",
    "df_populacao_dados_convertidos['porcentagem_variacao_anual'] = df_populacao_dados_convertidos['porcentagem_variacao_anual'].str.replace(',','.').astype(float)\n",
    "df_populacao_dados_convertidos['porcentagem_aceleracao_variacao_anual'] = df_populacao_dados_convertidos['porcentagem_aceleracao_variacao_anual'].str.replace(',','.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   ano                                    32 non-null     object \n",
      " 1   populacao                              32 non-null     int64  \n",
      " 2   variacao_anual                         32 non-null     object \n",
      " 3   porcentagem_variacao_anual             32 non-null     float64\n",
      " 4   aceleracao_variacao_anual              32 non-null     object \n",
      " 5   porcentagem_aceleracao_variacao_anual  32 non-null     float64\n",
      " 6   ano_mes                                32 non-null     object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_populacao_dados_convertidos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   ano                                    32 non-null     object \n",
      " 1   populacao                              32 non-null     int64  \n",
      " 2   variacao_anual                         32 non-null     int64  \n",
      " 3   porcentagem_variacao_anual             32 non-null     float64\n",
      " 4   aceleracao_variacao_anual              32 non-null     int64  \n",
      " 5   porcentagem_aceleracao_variacao_anual  32 non-null     float64\n",
      " 6   ano_mes                                32 non-null     object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_populacao_dados_convertidos = converte_tipo_dados(df_populacao_dados_convertidos, ['variacao_anual', 'aceleracao_variacao_anual'], 'int64')\n",
    "df_populacao_dados_convertidos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>porcentagem_variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>porcentagem_aceleracao_variacao_anual</th>\n",
       "      <th>ano_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>51273</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1991-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992</td>\n",
       "      <td>51530</td>\n",
       "      <td>257</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1992-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>51965</td>\n",
       "      <td>435</td>\n",
       "      <td>0.84</td>\n",
       "      <td>178</td>\n",
       "      <td>69.26</td>\n",
       "      <td>1993-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994</td>\n",
       "      <td>52279</td>\n",
       "      <td>314</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-121</td>\n",
       "      <td>-27.82</td>\n",
       "      <td>1994-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>52586</td>\n",
       "      <td>307</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-7</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>1995-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>51396</td>\n",
       "      <td>-1190</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-1497</td>\n",
       "      <td>-487.62</td>\n",
       "      <td>1996-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997</td>\n",
       "      <td>51575</td>\n",
       "      <td>179</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1369</td>\n",
       "      <td>-115.04</td>\n",
       "      <td>1997-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998</td>\n",
       "      <td>51726</td>\n",
       "      <td>151</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-28</td>\n",
       "      <td>-15.64</td>\n",
       "      <td>1998-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999</td>\n",
       "      <td>51878</td>\n",
       "      <td>152</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1999-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000</td>\n",
       "      <td>54715</td>\n",
       "      <td>2837</td>\n",
       "      <td>5.47</td>\n",
       "      <td>2685</td>\n",
       "      <td>1766.45</td>\n",
       "      <td>2000-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001</td>\n",
       "      <td>55132</td>\n",
       "      <td>417</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-2420</td>\n",
       "      <td>-85.30</td>\n",
       "      <td>2001-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002</td>\n",
       "      <td>55439</td>\n",
       "      <td>307</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-110</td>\n",
       "      <td>-26.38</td>\n",
       "      <td>2002-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2003</td>\n",
       "      <td>55775</td>\n",
       "      <td>336</td>\n",
       "      <td>0.61</td>\n",
       "      <td>29</td>\n",
       "      <td>9.45</td>\n",
       "      <td>2003-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004</td>\n",
       "      <td>56481</td>\n",
       "      <td>706</td>\n",
       "      <td>1.27</td>\n",
       "      <td>370</td>\n",
       "      <td>110.12</td>\n",
       "      <td>2004-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2005</td>\n",
       "      <td>56871</td>\n",
       "      <td>390</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-316</td>\n",
       "      <td>-44.76</td>\n",
       "      <td>2005-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2006</td>\n",
       "      <td>57259</td>\n",
       "      <td>388</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>2006-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2007</td>\n",
       "      <td>56051</td>\n",
       "      <td>-1208</td>\n",
       "      <td>-2.11</td>\n",
       "      <td>-1596</td>\n",
       "      <td>-411.34</td>\n",
       "      <td>2007-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008</td>\n",
       "      <td>57627</td>\n",
       "      <td>1576</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2784</td>\n",
       "      <td>-230.46</td>\n",
       "      <td>2008-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2009</td>\n",
       "      <td>57875</td>\n",
       "      <td>248</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-1328</td>\n",
       "      <td>-84.26</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2010</td>\n",
       "      <td>58446</td>\n",
       "      <td>571</td>\n",
       "      <td>0.99</td>\n",
       "      <td>323</td>\n",
       "      <td>130.24</td>\n",
       "      <td>2010-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011</td>\n",
       "      <td>58794</td>\n",
       "      <td>348</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-223</td>\n",
       "      <td>-39.05</td>\n",
       "      <td>2011-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012</td>\n",
       "      <td>59130</td>\n",
       "      <td>336</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-12</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>2012-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1146</td>\n",
       "      <td>341.07</td>\n",
       "      <td>2013-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014</td>\n",
       "      <td>61030</td>\n",
       "      <td>418</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-1064</td>\n",
       "      <td>-71.79</td>\n",
       "      <td>2014-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015</td>\n",
       "      <td>61431</td>\n",
       "      <td>401</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-17</td>\n",
       "      <td>-4.07</td>\n",
       "      <td>2015-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016</td>\n",
       "      <td>61816</td>\n",
       "      <td>385</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-16</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>2016-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>62187</td>\n",
       "      <td>371</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-14</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>2017-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>61776</td>\n",
       "      <td>-411</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-782</td>\n",
       "      <td>-210.78</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019</td>\n",
       "      <td>61993</td>\n",
       "      <td>217</td>\n",
       "      <td>0.35</td>\n",
       "      <td>628</td>\n",
       "      <td>-152.80</td>\n",
       "      <td>2019-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020</td>\n",
       "      <td>62289</td>\n",
       "      <td>296</td>\n",
       "      <td>0.48</td>\n",
       "      <td>79</td>\n",
       "      <td>36.41</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021</td>\n",
       "      <td>62576</td>\n",
       "      <td>287</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-9</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>2021-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>1.05</td>\n",
       "      <td>376</td>\n",
       "      <td>56.71</td>\n",
       "      <td>2022-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ano  populacao  variacao_anual  porcentagem_variacao_anual  \\\n",
       "0   1991      51273               0                        0.00   \n",
       "1   1992      51530             257                        0.50   \n",
       "2   1993      51965             435                        0.84   \n",
       "3   1994      52279             314                        0.60   \n",
       "4   1995      52586             307                        0.59   \n",
       "5   1996      51396           -1190                       -2.26   \n",
       "6   1997      51575             179                        0.35   \n",
       "7   1998      51726             151                        0.29   \n",
       "8   1999      51878             152                        0.29   \n",
       "9   2000      54715            2837                        5.47   \n",
       "10  2001      55132             417                        0.76   \n",
       "11  2002      55439             307                        0.56   \n",
       "12  2003      55775             336                        0.61   \n",
       "13  2004      56481             706                        1.27   \n",
       "14  2005      56871             390                        0.69   \n",
       "15  2006      57259             388                        0.68   \n",
       "16  2007      56051           -1208                       -2.11   \n",
       "17  2008      57627            1576                        2.81   \n",
       "18  2009      57875             248                        0.43   \n",
       "19  2010      58446             571                        0.99   \n",
       "20  2011      58794             348                        0.60   \n",
       "21  2012      59130             336                        0.57   \n",
       "22  2013      60612            1482                        2.51   \n",
       "23  2014      61030             418                        0.69   \n",
       "24  2015      61431             401                        0.66   \n",
       "25  2016      61816             385                        0.63   \n",
       "26  2017      62187             371                        0.60   \n",
       "27  2018      61776            -411                       -0.66   \n",
       "28  2019      61993             217                        0.35   \n",
       "29  2020      62289             296                        0.48   \n",
       "30  2021      62576             287                        0.46   \n",
       "31  2022      63239             663                        1.05   \n",
       "\n",
       "    aceleracao_variacao_anual  porcentagem_aceleracao_variacao_anual  ano_mes  \n",
       "0                           0                                   0.00  1991-01  \n",
       "1                           0                                   0.00  1992-01  \n",
       "2                         178                                  69.26  1993-01  \n",
       "3                        -121                                 -27.82  1994-01  \n",
       "4                          -7                                  -2.23  1995-01  \n",
       "5                       -1497                                -487.62  1996-01  \n",
       "6                        1369                                -115.04  1997-01  \n",
       "7                         -28                                 -15.64  1998-01  \n",
       "8                           1                                   0.66  1999-01  \n",
       "9                        2685                                1766.45  2000-01  \n",
       "10                      -2420                                 -85.30  2001-01  \n",
       "11                       -110                                 -26.38  2002-01  \n",
       "12                         29                                   9.45  2003-01  \n",
       "13                        370                                 110.12  2004-01  \n",
       "14                       -316                                 -44.76  2005-01  \n",
       "15                         -2                                  -0.51  2006-01  \n",
       "16                      -1596                                -411.34  2007-01  \n",
       "17                       2784                                -230.46  2008-01  \n",
       "18                      -1328                                 -84.26  2009-01  \n",
       "19                        323                                 130.24  2010-01  \n",
       "20                       -223                                 -39.05  2011-01  \n",
       "21                        -12                                  -3.45  2012-01  \n",
       "22                       1146                                 341.07  2013-01  \n",
       "23                      -1064                                 -71.79  2014-01  \n",
       "24                        -17                                  -4.07  2015-01  \n",
       "25                        -16                                  -3.99  2016-01  \n",
       "26                        -14                                  -3.64  2017-01  \n",
       "27                       -782                                -210.78  2018-01  \n",
       "28                        628                                -152.80  2019-01  \n",
       "29                         79                                  36.41  2020-01  \n",
       "30                         -9                                  -3.04  2021-01  \n",
       "31                        376                                  56.71  2022-01  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_populacao_dados_convertidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ano        9 non-null      int64 \n",
      " 1   ideb_5ano  9 non-null      object\n",
      " 2   ideb_9ano  9 non-null      object\n",
      " 3   idhm       9 non-null      object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 420.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_idhm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>4,1</td>\n",
       "      <td>2,8</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4,1</td>\n",
       "      <td>2,8</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4,4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4,4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4,8</td>\n",
       "      <td>3,5</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4,8</td>\n",
       "      <td>3,5</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>5,3</td>\n",
       "      <td>4,1</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5,3</td>\n",
       "      <td>4,1</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>5,1</td>\n",
       "      <td>4,9</td>\n",
       "      <td>0,679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ano ideb_5ano ideb_9ano   idhm\n",
       "0 2013-01-01       4,1       2,8  0,679\n",
       "1 2014-01-01       4,1       2,8  0,679\n",
       "2 2015-01-01       4,4         3  0,679\n",
       "3 2016-01-01       4,4         3  0,679\n",
       "4 2017-01-01       4,8       3,5  0,679\n",
       "5 2018-01-01       4,8       3,5  0,679\n",
       "6 2019-01-01       5,3       4,1  0,679\n",
       "7 2020-01-01       5,3       4,1  0,679\n",
       "8 2021-01-01       5,1       4,9  0,679"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforma_coluna_em_datetime(df_idhm, 'ano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idhm_dados_copy = df_idhm.copy()\n",
    "df_idhm_dados_convertidos = df_idhm_dados_copy\n",
    "df_idhm_dados_convertidos['ideb_5ano'] = df_idhm['ideb_5ano'].str.replace(',','.').astype(float)\n",
    "df_idhm_dados_convertidos['ideb_9ano'] = df_idhm['ideb_9ano'].str.replace(',','.').astype(float)\n",
    "df_idhm_dados_convertidos['idhm'] = df_idhm['idhm'].str.replace(',','.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimar valores para o ano de 2022 usando a média das variações anuais\n",
    "variacao_anual_ideb_5ano = df_idhm_dados_convertidos.groupby('ano')['ideb_5ano'].last().pct_change().mean()\n",
    "variacao_anual_ideb_9ano = df_idhm_dados_convertidos.groupby('ano')['ideb_9ano'].last().pct_change().mean()\n",
    "valor_2022_ideb_5ano = df_idhm_dados_convertidos['ideb_5ano'].values[-1]\n",
    "valor_2022_ideb_9ano = df_idhm_dados_convertidos['ideb_9ano'].values[-1]\n",
    "valor_2022_ideb_5ano_estimado = valor_2022_ideb_5ano * (1 + variacao_anual_ideb_5ano)\n",
    "valor_2022_ideb_9ano = valor_2022_ideb_9ano * (1 + variacao_anual_ideb_9ano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ano  ideb_5ano  ideb_9ano   idhm\n",
       "0 2013-01-01   4.100000   2.800000  0.679\n",
       "1 2014-01-01   4.100000   2.800000  0.679\n",
       "2 2015-01-01   4.400000   3.000000  0.679\n",
       "3 2016-01-01   4.400000   3.000000  0.679\n",
       "4 2017-01-01   4.800000   3.500000  0.679\n",
       "5 2018-01-01   4.800000   3.500000  0.679\n",
       "6 2019-01-01   5.300000   4.100000  0.679\n",
       "7 2020-01-01   5.300000   4.100000  0.679\n",
       "8 2021-01-01   5.100000   4.900000  0.679\n",
       "9 2022-01-01   5.246951   5.270346  0.679"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar um novo DataFrame com as linhas para 2021 e 2022\n",
    "novas_linhas = pd.DataFrame({'ano': [2022], 'ideb_5ano': [valor_2022_ideb_5ano_estimado], 'ideb_9ano': [valor_2022_ideb_9ano], 'idhm': [df_idhm_dados_convertidos['idhm'].values[-1]]})\n",
    "novas_linhas = transforma_coluna_em_datetime(novas_linhas, 'ano')\n",
    "\n",
    "# Concatenar as novas linhas ao DataFrame original\n",
    "df_idhm_convertido = pd.concat([df_idhm_dados_convertidos, novas_linhas], ignore_index=True)\n",
    "df_idhm_convertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idhm_convertido = cria_colunas_tempo(df_idhm_convertido, 'ano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ano        10 non-null     object \n",
      " 1   ideb_5ano  10 non-null     float64\n",
      " 2   ideb_9ano  10 non-null     float64\n",
      " 3   idhm       10 non-null     float64\n",
      " 4   ano_mes    10 non-null     object \n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 532.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_idhm_convertido.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "      <th>ano_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2013-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2014-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2015-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2016-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2017-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2019-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2021-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2022-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano  ideb_5ano  ideb_9ano   idhm  ano_mes\n",
       "0  2013   4.100000   2.800000  0.679  2013-01\n",
       "1  2014   4.100000   2.800000  0.679  2014-01\n",
       "2  2015   4.400000   3.000000  0.679  2015-01\n",
       "3  2016   4.400000   3.000000  0.679  2016-01\n",
       "4  2017   4.800000   3.500000  0.679  2017-01\n",
       "5  2018   4.800000   3.500000  0.679  2018-01\n",
       "6  2019   5.300000   4.100000  0.679  2019-01\n",
       "7  2020   5.300000   4.100000  0.679  2020-01\n",
       "8  2021   5.100000   4.900000  0.679  2021-01\n",
       "9  2022   5.246951   5.270346  0.679  2022-01"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idhm_convertido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saúde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 6 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   ano                         9 non-null      object\n",
      " 1   pct_desp_recp_saude_mun     9 non-null      object\n",
      " 2   desp_tot_saude_pc_mun       9 non-null      object\n",
      " 3   desp_recp_saude_pc_mun      9 non-null      object\n",
      " 4   desp_tot_saude_pc_mun_def   9 non-null      object\n",
      " 5   desp_recp_saude_pc_mun_def  9 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 564.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_saude.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun_def</th>\n",
       "      <th>desp_recp_saude_pc_mun_def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>16,56</td>\n",
       "      <td>464,3</td>\n",
       "      <td>114,1</td>\n",
       "      <td>744,7674653</td>\n",
       "      <td>183,0238376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>23,4</td>\n",
       "      <td>448,73</td>\n",
       "      <td>186,19</td>\n",
       "      <td>676,4489043</td>\n",
       "      <td>280,676624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>22,48</td>\n",
       "      <td>468,65</td>\n",
       "      <td>190,19</td>\n",
       "      <td>638,3468516</td>\n",
       "      <td>259,057266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>21,23</td>\n",
       "      <td>439,37</td>\n",
       "      <td>202,37</td>\n",
       "      <td>563,0595289</td>\n",
       "      <td>259,3403211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>18,6</td>\n",
       "      <td>468,37</td>\n",
       "      <td>178,28</td>\n",
       "      <td>583,0388706</td>\n",
       "      <td>221,9274716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>18,26</td>\n",
       "      <td>705,23</td>\n",
       "      <td>190,43</td>\n",
       "      <td>846,1933549</td>\n",
       "      <td>228,4936837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>16,13</td>\n",
       "      <td>559,08</td>\n",
       "      <td>187,04</td>\n",
       "      <td>643,1360678</td>\n",
       "      <td>215,1609253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>16,23</td>\n",
       "      <td>668,07</td>\n",
       "      <td>187,35</td>\n",
       "      <td>735,277842</td>\n",
       "      <td>206,19741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>19,02</td>\n",
       "      <td>790,59</td>\n",
       "      <td>272,68</td>\n",
       "      <td>790,59</td>\n",
       "      <td>272,68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ano pct_desp_recp_saude_mun desp_tot_saude_pc_mun  \\\n",
       "0 2013-01-01                   16,56                 464,3   \n",
       "1 2014-01-01                    23,4                448,73   \n",
       "2 2015-01-01                   22,48                468,65   \n",
       "3 2016-01-01                   21,23                439,37   \n",
       "4 2017-01-01                    18,6                468,37   \n",
       "5 2018-01-01                   18,26                705,23   \n",
       "6 2019-01-01                   16,13                559,08   \n",
       "7 2020-01-01                   16,23                668,07   \n",
       "8 2021-01-01                   19,02                790,59   \n",
       "\n",
       "  desp_recp_saude_pc_mun desp_tot_saude_pc_mun_def desp_recp_saude_pc_mun_def  \n",
       "0                  114,1               744,7674653                183,0238376  \n",
       "1                 186,19               676,4489043                 280,676624  \n",
       "2                 190,19               638,3468516                 259,057266  \n",
       "3                 202,37               563,0595289                259,3403211  \n",
       "4                 178,28               583,0388706                221,9274716  \n",
       "5                 190,43               846,1933549                228,4936837  \n",
       "6                 187,04               643,1360678                215,1609253  \n",
       "7                 187,35                735,277842                  206,19741  \n",
       "8                 272,68                    790,59                     272,68  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforma_coluna_em_datetime(df_saude, 'ano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saude_dados_copy = df_saude.copy()\n",
    "df_saude_dados_convertido = df_saude_dados_copy\n",
    "df_saude_dados_convertido['pct_desp_recp_saude_mun'] = df_saude['pct_desp_recp_saude_mun'].str.replace(',','.').astype(float)\n",
    "df_saude_dados_convertido['desp_tot_saude_pc_mun'] = df_saude['desp_tot_saude_pc_mun'].str.replace(',','.').astype(float)\n",
    "df_saude_dados_convertido['desp_recp_saude_pc_mun'] = df_saude['desp_recp_saude_pc_mun'].str.replace(',','.').astype(float)\n",
    "df_saude_dados_convertido['desp_tot_saude_pc_mun_def'] = df_saude['desp_tot_saude_pc_mun_def'].str.replace(',','.').astype(float)\n",
    "df_saude_dados_convertido['desp_recp_saude_pc_mun_def'] = df_saude['desp_recp_saude_pc_mun_def'].str.replace(',','.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 6 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   ano                         9 non-null      datetime64[ns]\n",
      " 1   pct_desp_recp_saude_mun     9 non-null      float64       \n",
      " 2   desp_tot_saude_pc_mun       9 non-null      float64       \n",
      " 3   desp_recp_saude_pc_mun      9 non-null      float64       \n",
      " 4   desp_tot_saude_pc_mun_def   9 non-null      float64       \n",
      " 5   desp_recp_saude_pc_mun_def  9 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 564.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df_saude_dados_convertido.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimar valores para o ano de 2022 usando a média das variações anuais\n",
    "variacao_anual_pct_desp_recp_saude_mun = df_saude_dados_convertido.groupby('ano')['pct_desp_recp_saude_mun'].last().pct_change().mean()\n",
    "variacao_anual_desp_tot_saude_pc_mun = df_saude_dados_convertido.groupby('ano')['desp_tot_saude_pc_mun'].last().pct_change().mean()\n",
    "variacao_anual_desp_recp_saude_pc_mun = df_saude_dados_convertido.groupby('ano')['desp_recp_saude_pc_mun'].last().pct_change().mean()\n",
    "variacao_anual_desp_tot_saude_pc_mun_def = df_saude_dados_convertido.groupby('ano')['desp_tot_saude_pc_mun_def'].last().pct_change().mean()\n",
    "variacao_anual_desp_recp_saude_pc_mun_def = df_saude_dados_convertido.groupby('ano')['desp_recp_saude_pc_mun_def'].last().pct_change().mean()\n",
    "\n",
    "valor_2022_pct_desp_recp_saude_mun = df_saude_dados_convertido['pct_desp_recp_saude_mun'].values[-1]\n",
    "valor_2022_desp_tot_saude_pc_mun = df_saude_dados_convertido['desp_tot_saude_pc_mun'].values[-1]\n",
    "valor_2022_desp_recp_saude_pc_mun = df_saude_dados_convertido['desp_recp_saude_pc_mun'].values[-1]\n",
    "valor_2022_desp_tot_saude_pc_mun_def = df_saude_dados_convertido['desp_tot_saude_pc_mun_def'].values[-1]\n",
    "valor_2022_desp_recp_saude_pc_mun_def = df_saude_dados_convertido['desp_recp_saude_pc_mun_def'].values[-1]\n",
    "\n",
    "valor_2022_pct_desp_recp_saude_mun_estimado = valor_2022_pct_desp_recp_saude_mun * (1 + variacao_anual_pct_desp_recp_saude_mun)\n",
    "valor_2022_desp_tot_saude_pc_mun_estimado = valor_2022_desp_tot_saude_pc_mun * (1 + variacao_anual_desp_tot_saude_pc_mun)\n",
    "valor_2022_desp_recp_saude_pc_muno_estimado = valor_2022_desp_recp_saude_pc_mun * (1 + variacao_anual_desp_recp_saude_pc_mun)\n",
    "valor_2022_desp_tot_saude_pc_mun_def_estimado = valor_2022_desp_tot_saude_pc_mun_def * (1 + variacao_anual_desp_tot_saude_pc_mun_def)\n",
    "valor_2022_desp_recp_saude_pc_mun_def_estimado = valor_2022_desp_recp_saude_pc_mun_def * (1 + variacao_anual_desp_recp_saude_pc_mun_def)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun_def</th>\n",
       "      <th>desp_recp_saude_pc_mun_def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>448.730000</td>\n",
       "      <td>186.190000</td>\n",
       "      <td>676.448904</td>\n",
       "      <td>280.676624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>22.480000</td>\n",
       "      <td>468.650000</td>\n",
       "      <td>190.190000</td>\n",
       "      <td>638.346852</td>\n",
       "      <td>259.057266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>21.230000</td>\n",
       "      <td>439.370000</td>\n",
       "      <td>202.370000</td>\n",
       "      <td>563.059529</td>\n",
       "      <td>259.340321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>468.370000</td>\n",
       "      <td>178.280000</td>\n",
       "      <td>583.038871</td>\n",
       "      <td>221.927472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>705.230000</td>\n",
       "      <td>190.430000</td>\n",
       "      <td>846.193355</td>\n",
       "      <td>228.493684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>16.130000</td>\n",
       "      <td>559.080000</td>\n",
       "      <td>187.040000</td>\n",
       "      <td>643.136068</td>\n",
       "      <td>215.160925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>16.230000</td>\n",
       "      <td>668.070000</td>\n",
       "      <td>187.350000</td>\n",
       "      <td>735.277842</td>\n",
       "      <td>206.197410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>19.020000</td>\n",
       "      <td>790.590000</td>\n",
       "      <td>272.680000</td>\n",
       "      <td>790.590000</td>\n",
       "      <td>272.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ano  pct_desp_recp_saude_mun  desp_tot_saude_pc_mun  \\\n",
       "0 2013-01-01                16.560000             464.300000   \n",
       "1 2014-01-01                23.400000             448.730000   \n",
       "2 2015-01-01                22.480000             468.650000   \n",
       "3 2016-01-01                21.230000             439.370000   \n",
       "4 2017-01-01                18.600000             468.370000   \n",
       "5 2018-01-01                18.260000             705.230000   \n",
       "6 2019-01-01                16.130000             559.080000   \n",
       "7 2020-01-01                16.230000             668.070000   \n",
       "8 2021-01-01                19.020000             790.590000   \n",
       "9 2022-01-01                19.584458             858.896682   \n",
       "\n",
       "   desp_recp_saude_pc_mun  desp_tot_saude_pc_mun_def  \\\n",
       "0              114.100000                 744.767465   \n",
       "1              186.190000                 676.448904   \n",
       "2              190.190000                 638.346852   \n",
       "3              202.370000                 563.059529   \n",
       "4              178.280000                 583.038871   \n",
       "5              190.430000                 846.193355   \n",
       "6              187.040000                 643.136068   \n",
       "7              187.350000                 735.277842   \n",
       "8              272.680000                 790.590000   \n",
       "9              310.369965                 810.291935   \n",
       "\n",
       "   desp_recp_saude_pc_mun_def  \n",
       "0                  183.023838  \n",
       "1                  280.676624  \n",
       "2                  259.057266  \n",
       "3                  259.340321  \n",
       "4                  221.927472  \n",
       "5                  228.493684  \n",
       "6                  215.160925  \n",
       "7                  206.197410  \n",
       "8                  272.680000  \n",
       "9                  291.950175  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar um novo DataFrame com as linhas para 2021 e 2022\n",
    "novas_linhas = pd.DataFrame({'ano': [2022],\n",
    "                              'pct_desp_recp_saude_mun': [valor_2022_pct_desp_recp_saude_mun_estimado],\n",
    "                                'desp_tot_saude_pc_mun': [valor_2022_desp_tot_saude_pc_mun_estimado],\n",
    "                                  'desp_recp_saude_pc_mun': [valor_2022_desp_recp_saude_pc_muno_estimado],\n",
    "                                    'desp_tot_saude_pc_mun_def': [valor_2022_desp_tot_saude_pc_mun_def_estimado],\n",
    "                                      'desp_recp_saude_pc_mun_def': [valor_2022_desp_recp_saude_pc_mun_def_estimado]})\n",
    "novas_linhas = transforma_coluna_em_datetime(novas_linhas, 'ano')\n",
    "\n",
    "# Concatenar as novas linhas ao DataFrame original\n",
    "df_saude_convertido = pd.concat([df_saude_dados_convertido, novas_linhas], ignore_index=True)\n",
    "df_saude_convertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saude_convertido = cria_colunas_tempo(df_saude_convertido, 'ano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ano                         10 non-null     object \n",
      " 1   pct_desp_recp_saude_mun     10 non-null     float64\n",
      " 2   desp_tot_saude_pc_mun       10 non-null     float64\n",
      " 3   desp_recp_saude_pc_mun      10 non-null     float64\n",
      " 4   desp_tot_saude_pc_mun_def   10 non-null     float64\n",
      " 5   desp_recp_saude_pc_mun_def  10 non-null     float64\n",
      " 6   ano_mes                     10 non-null     object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 692.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_saude_convertido.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun_def</th>\n",
       "      <th>desp_recp_saude_pc_mun_def</th>\n",
       "      <th>ano_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "      <td>2013-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>448.730000</td>\n",
       "      <td>186.190000</td>\n",
       "      <td>676.448904</td>\n",
       "      <td>280.676624</td>\n",
       "      <td>2014-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>22.480000</td>\n",
       "      <td>468.650000</td>\n",
       "      <td>190.190000</td>\n",
       "      <td>638.346852</td>\n",
       "      <td>259.057266</td>\n",
       "      <td>2015-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>21.230000</td>\n",
       "      <td>439.370000</td>\n",
       "      <td>202.370000</td>\n",
       "      <td>563.059529</td>\n",
       "      <td>259.340321</td>\n",
       "      <td>2016-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>468.370000</td>\n",
       "      <td>178.280000</td>\n",
       "      <td>583.038871</td>\n",
       "      <td>221.927472</td>\n",
       "      <td>2017-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>705.230000</td>\n",
       "      <td>190.430000</td>\n",
       "      <td>846.193355</td>\n",
       "      <td>228.493684</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>16.130000</td>\n",
       "      <td>559.080000</td>\n",
       "      <td>187.040000</td>\n",
       "      <td>643.136068</td>\n",
       "      <td>215.160925</td>\n",
       "      <td>2019-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>16.230000</td>\n",
       "      <td>668.070000</td>\n",
       "      <td>187.350000</td>\n",
       "      <td>735.277842</td>\n",
       "      <td>206.197410</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>19.020000</td>\n",
       "      <td>790.590000</td>\n",
       "      <td>272.680000</td>\n",
       "      <td>790.590000</td>\n",
       "      <td>272.680000</td>\n",
       "      <td>2021-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "      <td>2022-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano  pct_desp_recp_saude_mun  desp_tot_saude_pc_mun  \\\n",
       "0  2013                16.560000             464.300000   \n",
       "1  2014                23.400000             448.730000   \n",
       "2  2015                22.480000             468.650000   \n",
       "3  2016                21.230000             439.370000   \n",
       "4  2017                18.600000             468.370000   \n",
       "5  2018                18.260000             705.230000   \n",
       "6  2019                16.130000             559.080000   \n",
       "7  2020                16.230000             668.070000   \n",
       "8  2021                19.020000             790.590000   \n",
       "9  2022                19.584458             858.896682   \n",
       "\n",
       "   desp_recp_saude_pc_mun  desp_tot_saude_pc_mun_def  \\\n",
       "0              114.100000                 744.767465   \n",
       "1              186.190000                 676.448904   \n",
       "2              190.190000                 638.346852   \n",
       "3              202.370000                 563.059529   \n",
       "4              178.280000                 583.038871   \n",
       "5              190.430000                 846.193355   \n",
       "6              187.040000                 643.136068   \n",
       "7              187.350000                 735.277842   \n",
       "8              272.680000                 790.590000   \n",
       "9              310.369965                 810.291935   \n",
       "\n",
       "   desp_recp_saude_pc_mun_def  ano_mes  \n",
       "0                  183.023838  2013-01  \n",
       "1                  280.676624  2014-01  \n",
       "2                  259.057266  2015-01  \n",
       "3                  259.340321  2016-01  \n",
       "4                  221.927472  2017-01  \n",
       "5                  228.493684  2018-01  \n",
       "6                  215.160925  2019-01  \n",
       "7                  206.197410  2020-01  \n",
       "8                  272.680000  2021-01  \n",
       "9                  291.950175  2022-01  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_saude_convertido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparo dos df para implementação dos modelos de RN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados das despesas + população + idhm/educacao + saude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_populacao_dados_convertidos.drop(columns=['porcentagem_variacao_anual', 'porcentagem_aceleracao_variacao_anual','ano_mes'], inplace=True)\n",
    "df_idhm_convertido.drop(columns=['ano_mes'], inplace=True)\n",
    "df_saude_convertido.drop(columns=['ano_mes'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_fato</th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>2911694.0</td>\n",
       "      <td>5120.00</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120.00</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>6950.00</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6950.00</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.00</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>400.00</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.00</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>600.00</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.00</td>\n",
       "      <td>2013-12</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86836</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25673.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25673.02</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86837</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23333.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23333.43</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86838</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17920.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17920.75</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86839</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3842.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3842.60</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86840</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22970.00</td>\n",
       "      <td>22970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22970.00</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72498 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       data_fato  valor_fixado  valor_empenhado  valor_liquidado  valor_pago  \\\n",
       "0     2013-12-31     2911694.0          5120.00           5120.0         0.0   \n",
       "1     2013-12-31      107000.0          6950.00           6950.0         0.0   \n",
       "2     2013-12-31      107000.0           800.00            800.0         0.0   \n",
       "3     2013-12-31      107000.0           400.00            400.0         0.0   \n",
       "4     2013-12-31      107000.0           600.00            600.0         0.0   \n",
       "...          ...           ...              ...              ...         ...   \n",
       "86836 2022-12-30           0.0         25673.02              0.0         0.0   \n",
       "86837 2022-12-30           0.0         23333.43              0.0         0.0   \n",
       "86838 2022-12-30           0.0         17920.75              0.0         0.0   \n",
       "86839 2022-12-30           0.0          3842.60              0.0         0.0   \n",
       "86840 2022-12-30           0.0         22970.00          22970.0         0.0   \n",
       "\n",
       "          saldo  ano_mes   ano  \n",
       "0       5120.00  2013-12  2013  \n",
       "1       6950.00  2013-12  2013  \n",
       "2        800.00  2013-12  2013  \n",
       "3        400.00  2013-12  2013  \n",
       "4        600.00  2013-12  2013  \n",
       "...         ...      ...   ...  \n",
       "86836  25673.02  2022-12  2022  \n",
       "86837  23333.43  2022-12  2022  \n",
       "86838  17920.75  2022-12  2022  \n",
       "86839   3842.60  2022-12  2022  \n",
       "86840  22970.00  2022-12  2022  \n",
       "\n",
       "[72498 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas_sem_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>idhm</th>\n",
       "      <th>pct_desp_recp_saude_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun</th>\n",
       "      <th>desp_recp_saude_pc_mun</th>\n",
       "      <th>desp_tot_saude_pc_mun_def</th>\n",
       "      <th>desp_recp_saude_pc_mun_def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>247407589.0</td>\n",
       "      <td>297815.13</td>\n",
       "      <td>297955.53</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>474.84</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-02</td>\n",
       "      <td>196115092.0</td>\n",
       "      <td>557228.16</td>\n",
       "      <td>558786.56</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>619.48</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-03</td>\n",
       "      <td>174505126.0</td>\n",
       "      <td>892748.46</td>\n",
       "      <td>892748.46</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>255197.26</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>198742858.0</td>\n",
       "      <td>736807.15</td>\n",
       "      <td>736807.15</td>\n",
       "      <td>732833.15</td>\n",
       "      <td>3974.00</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-05</td>\n",
       "      <td>179036644.0</td>\n",
       "      <td>823679.15</td>\n",
       "      <td>823679.15</td>\n",
       "      <td>800601.05</td>\n",
       "      <td>23078.10</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>464.300000</td>\n",
       "      <td>114.100000</td>\n",
       "      <td>744.767465</td>\n",
       "      <td>183.023838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2232184.97</td>\n",
       "      <td>1803049.33</td>\n",
       "      <td>1034448.16</td>\n",
       "      <td>751928.83</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4418410.62</td>\n",
       "      <td>3887346.43</td>\n",
       "      <td>1140401.16</td>\n",
       "      <td>2983092.26</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2091722.58</td>\n",
       "      <td>1169256.62</td>\n",
       "      <td>748572.06</td>\n",
       "      <td>1259961.80</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2203597.48</td>\n",
       "      <td>1688218.71</td>\n",
       "      <td>665162.97</td>\n",
       "      <td>1327660.60</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5841193.52</td>\n",
       "      <td>4401476.75</td>\n",
       "      <td>851121.10</td>\n",
       "      <td>4606375.17</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>5.246951</td>\n",
       "      <td>5.270346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>19.584458</td>\n",
       "      <td>858.896682</td>\n",
       "      <td>310.369965</td>\n",
       "      <td>810.291935</td>\n",
       "      <td>291.950175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ano  ano_mes  valor_fixado  valor_empenhado  valor_liquidado  \\\n",
       "0    2013  2013-01   247407589.0        297815.13        297955.53   \n",
       "1    2013  2013-02   196115092.0        557228.16        558786.56   \n",
       "2    2013  2013-03   174505126.0        892748.46        892748.46   \n",
       "3    2013  2013-04   198742858.0        736807.15        736807.15   \n",
       "4    2013  2013-05   179036644.0        823679.15        823679.15   \n",
       "..    ...      ...           ...              ...              ...   \n",
       "115  2022  2022-08           0.0       2232184.97       1803049.33   \n",
       "116  2022  2022-09           0.0       4418410.62       3887346.43   \n",
       "117  2022  2022-10           0.0       2091722.58       1169256.62   \n",
       "118  2022  2022-11           0.0       2203597.48       1688218.71   \n",
       "119  2022  2022-12           0.0       5841193.52       4401476.75   \n",
       "\n",
       "     valor_pago       saldo  populacao  variacao_anual  \\\n",
       "0     297340.29      474.84      60612            1482   \n",
       "1     556608.68      619.48      60612            1482   \n",
       "2     637551.20   255197.26      60612            1482   \n",
       "3     732833.15     3974.00      60612            1482   \n",
       "4     800601.05    23078.10      60612            1482   \n",
       "..          ...         ...        ...             ...   \n",
       "115  1034448.16   751928.83      63239             663   \n",
       "116  1140401.16  2983092.26      63239             663   \n",
       "117   748572.06  1259961.80      63239             663   \n",
       "118   665162.97  1327660.60      63239             663   \n",
       "119   851121.10  4606375.17      63239             663   \n",
       "\n",
       "     aceleracao_variacao_anual  ideb_5ano  ideb_9ano   idhm  \\\n",
       "0                         1146   4.100000   2.800000  0.679   \n",
       "1                         1146   4.100000   2.800000  0.679   \n",
       "2                         1146   4.100000   2.800000  0.679   \n",
       "3                         1146   4.100000   2.800000  0.679   \n",
       "4                         1146   4.100000   2.800000  0.679   \n",
       "..                         ...        ...        ...    ...   \n",
       "115                        376   5.246951   5.270346  0.679   \n",
       "116                        376   5.246951   5.270346  0.679   \n",
       "117                        376   5.246951   5.270346  0.679   \n",
       "118                        376   5.246951   5.270346  0.679   \n",
       "119                        376   5.246951   5.270346  0.679   \n",
       "\n",
       "     pct_desp_recp_saude_mun  desp_tot_saude_pc_mun  desp_recp_saude_pc_mun  \\\n",
       "0                  16.560000             464.300000              114.100000   \n",
       "1                  16.560000             464.300000              114.100000   \n",
       "2                  16.560000             464.300000              114.100000   \n",
       "3                  16.560000             464.300000              114.100000   \n",
       "4                  16.560000             464.300000              114.100000   \n",
       "..                       ...                    ...                     ...   \n",
       "115                19.584458             858.896682              310.369965   \n",
       "116                19.584458             858.896682              310.369965   \n",
       "117                19.584458             858.896682              310.369965   \n",
       "118                19.584458             858.896682              310.369965   \n",
       "119                19.584458             858.896682              310.369965   \n",
       "\n",
       "     desp_tot_saude_pc_mun_def  desp_recp_saude_pc_mun_def  \n",
       "0                   744.767465                  183.023838  \n",
       "1                   744.767465                  183.023838  \n",
       "2                   744.767465                  183.023838  \n",
       "3                   744.767465                  183.023838  \n",
       "4                   744.767465                  183.023838  \n",
       "..                         ...                         ...  \n",
       "115                 810.291935                  291.950175  \n",
       "116                 810.291935                  291.950175  \n",
       "117                 810.291935                  291.950175  \n",
       "118                 810.291935                  291.950175  \n",
       "119                 810.291935                  291.950175  \n",
       "\n",
       "[120 rows x 18 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas_agrupado = df_despesas_sem_outliers.groupby(['ano', 'ano_mes'])[['valor_fixado', 'valor_empenhado', 'valor_liquidado', 'valor_pago', 'saldo']].sum().reset_index()\n",
    "df_despesas_agrupado = pd.merge(df_despesas_agrupado, df_populacao_dados_convertidos, on='ano', how='left')\n",
    "df_despesas_agrupado = pd.merge(df_despesas_agrupado, df_idhm_convertido, on='ano', how='left')\n",
    "df_despesas_agrupado = pd.merge(df_despesas_agrupado, df_saude_convertido, on='ano', how='left')\n",
    "df_despesas_agrupado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elaborando metadados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA(12)</th>\n",
       "      <th>SMA(6)</th>\n",
       "      <th>SMA(3)</th>\n",
       "      <th>SMA(2)</th>\n",
       "      <th>lag(12)</th>\n",
       "      <th>lag(6)</th>\n",
       "      <th>lag(4)</th>\n",
       "      <th>lag(3)</th>\n",
       "      <th>lag(2)</th>\n",
       "      <th>lag(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>247407589.0</td>\n",
       "      <td>297815.13</td>\n",
       "      <td>297955.53</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>474.84</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-02</td>\n",
       "      <td>196115092.0</td>\n",
       "      <td>557228.16</td>\n",
       "      <td>558786.56</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>619.48</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>426974.485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297340.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-03</td>\n",
       "      <td>174505126.0</td>\n",
       "      <td>892748.46</td>\n",
       "      <td>892748.46</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>255197.26</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>497166.723333</td>\n",
       "      <td>597079.940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>198742858.0</td>\n",
       "      <td>736807.15</td>\n",
       "      <td>736807.15</td>\n",
       "      <td>732833.15</td>\n",
       "      <td>3974.00</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>642331.010000</td>\n",
       "      <td>685192.175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-05</td>\n",
       "      <td>179036644.0</td>\n",
       "      <td>823679.15</td>\n",
       "      <td>823679.15</td>\n",
       "      <td>800601.05</td>\n",
       "      <td>23078.10</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>723661.800000</td>\n",
       "      <td>766717.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>732833.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano  ano_mes  valor_fixado  valor_empenhado  valor_liquidado  valor_pago  \\\n",
       "0  2013  2013-01   247407589.0        297815.13        297955.53   297340.29   \n",
       "1  2013  2013-02   196115092.0        557228.16        558786.56   556608.68   \n",
       "2  2013  2013-03   174505126.0        892748.46        892748.46   637551.20   \n",
       "3  2013  2013-04   198742858.0        736807.15        736807.15   732833.15   \n",
       "4  2013  2013-05   179036644.0        823679.15        823679.15   800601.05   \n",
       "\n",
       "       saldo  populacao  variacao_anual  aceleracao_variacao_anual  ...  \\\n",
       "0     474.84      60612            1482                       1146  ...   \n",
       "1     619.48      60612            1482                       1146  ...   \n",
       "2  255197.26      60612            1482                       1146  ...   \n",
       "3    3974.00      60612            1482                       1146  ...   \n",
       "4   23078.10      60612            1482                       1146  ...   \n",
       "\n",
       "   SMA(12)  SMA(6)         SMA(3)      SMA(2)  lag(12)  lag(6)     lag(4)  \\\n",
       "0      NaN     NaN            NaN         NaN      NaN     NaN        NaN   \n",
       "1      NaN     NaN            NaN  426974.485      NaN     NaN        NaN   \n",
       "2      NaN     NaN  497166.723333  597079.940      NaN     NaN        NaN   \n",
       "3      NaN     NaN  642331.010000  685192.175      NaN     NaN        NaN   \n",
       "4      NaN     NaN  723661.800000  766717.100      NaN     NaN  297340.29   \n",
       "\n",
       "      lag(3)     lag(2)     lag(1)  \n",
       "0        NaN        NaN        NaN  \n",
       "1        NaN        NaN  297340.29  \n",
       "2        NaN  297340.29  556608.68  \n",
       "3  297340.29  556608.68  637551.20  \n",
       "4  556608.68  637551.20  732833.15  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample dos dados para as despesas mensais do município\n",
    "df_despesas_agrupado['SMA(12)_fixado'] = df_despesas_agrupado['valor_fixado'].rolling(window=12).mean()\n",
    "df_despesas_agrupado['SMA(6)_fixado'] = df_despesas_agrupado['valor_fixado'].rolling(window=6).mean()\n",
    "df_despesas_agrupado['SMA(3)_fixado'] = df_despesas_agrupado['valor_fixado'].rolling(window=3).mean()\n",
    "df_despesas_agrupado['SMA(2)_fixado'] = df_despesas_agrupado['valor_fixado'].rolling(window=2).mean()\n",
    "df_despesas_agrupado['lag(12)_fixado'] = df_despesas_agrupado['valor_fixado'].shift(12)\n",
    "df_despesas_agrupado['lag(6)_fixado'] = df_despesas_agrupado['valor_fixado'].shift(6)\n",
    "df_despesas_agrupado['lag(4)_fixado'] = df_despesas_agrupado['valor_fixado'].shift(4)\n",
    "df_despesas_agrupado['lag(3)_fixado'] = df_despesas_agrupado['valor_fixado'].shift(3)\n",
    "df_despesas_agrupado['lag(2)_fixado'] = df_despesas_agrupado['valor_fixado'].shift(2)\n",
    "df_despesas_agrupado['lag(1)_fixado'] = df_despesas_agrupado['valor_fixado'].shift(1)\n",
    "df_despesas_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dos dados para as despesas mensais do município\n",
    "df_despesas_agrupado['SMA(12)_empenhado'] = df_despesas_agrupado['valor_empenhado'].rolling(window=12).mean()\n",
    "df_despesas_agrupado['SMA(6)_empenhado'] = df_despesas_agrupado['valor_empenhado'].rolling(window=6).mean()\n",
    "df_despesas_agrupado['SMA(3)_empenhado'] = df_despesas_agrupado['valor_empenhado'].rolling(window=3).mean()\n",
    "df_despesas_agrupado['SMA(2)_empenhado'] = df_despesas_agrupado['valor_empenhado'].rolling(window=2).mean()\n",
    "df_despesas_agrupado['lag(12)_empenhado'] = df_despesas_agrupado['valor_empenhado'].shift(12)\n",
    "df_despesas_agrupado['lag(6)_empenhado'] = df_despesas_agrupado['valor_empenhado'].shift(6)\n",
    "df_despesas_agrupado['lag(4)_empenhado'] = df_despesas_agrupado['valor_empenhado'].shift(4)\n",
    "df_despesas_agrupado['lag(3)_empenhado'] = df_despesas_agrupado['valor_empenhado'].shift(3)\n",
    "df_despesas_agrupado['lag(2)_empenhado'] = df_despesas_agrupado['valor_empenhado'].shift(2)\n",
    "df_despesas_agrupado['lag(1)_empenhado'] = df_despesas_agrupado['valor_empenhado'].shift(1)\n",
    "df_despesas_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dos dados para as despesas mensais do município\n",
    "df_despesas_agrupado['SMA(12)_liquidado'] = df_despesas_agrupado['valor_liquidado'].rolling(window=12).mean()\n",
    "df_despesas_agrupado['SMA(6)_liquidado'] = df_despesas_agrupado['valor_liquidado'].rolling(window=6).mean()\n",
    "df_despesas_agrupado['SMA(3)_liquidado'] = df_despesas_agrupado['valor_liquidado'].rolling(window=3).mean()\n",
    "df_despesas_agrupado['SMA(2)_liquidado'] = df_despesas_agrupado['valor_liquidado'].rolling(window=2).mean()\n",
    "df_despesas_agrupado['lag(12)_liquidado'] = df_despesas_agrupado['valor_liquidado'].shift(12)\n",
    "df_despesas_agrupado['lag(6)_liquidado'] = df_despesas_agrupado['valor_liquidado'].shift(6)\n",
    "df_despesas_agrupado['lag(4)_liquidado'] = df_despesas_agrupado['valor_liquidado'].shift(4)\n",
    "df_despesas_agrupado['lag(3)_liquidado'] = df_despesas_agrupado['valor_liquidado'].shift(3)\n",
    "df_despesas_agrupado['lag(2)_liquidado'] = df_despesas_agrupado['valor_liquidado'].shift(2)\n",
    "df_despesas_agrupado['lag(1)_liquidado'] = df_despesas_agrupado['valor_liquidado'].shift(1)\n",
    "df_despesas_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dos dados para as despesas mensais do município\n",
    "df_despesas_agrupado['SMA(12)_pago'] = df_despesas_agrupado['valor_pago'].rolling(window=12).mean()\n",
    "df_despesas_agrupado['SMA(6)_pago'] = df_despesas_agrupado['valor_pago'].rolling(window=6).mean()\n",
    "df_despesas_agrupado['SMA(3)_pago'] = df_despesas_agrupado['valor_pago'].rolling(window=3).mean()\n",
    "df_despesas_agrupado['SMA(2)_pago'] = df_despesas_agrupado['valor_pago'].rolling(window=2).mean()\n",
    "df_despesas_agrupado['lag(12)_pago'] = df_despesas_agrupado['valor_pago'].shift(12)\n",
    "df_despesas_agrupado['lag(6)_pago'] = df_despesas_agrupado['valor_pago'].shift(6)\n",
    "df_despesas_agrupado['lag(4)_pago'] = df_despesas_agrupado['valor_pago'].shift(4)\n",
    "df_despesas_agrupado['lag(3)_pago'] = df_despesas_agrupado['valor_pago'].shift(3)\n",
    "df_despesas_agrupado['lag(2)_pago'] = df_despesas_agrupado['valor_pago'].shift(2)\n",
    "df_despesas_agrupado['lag(1)_pago'] = df_despesas_agrupado['valor_pago'].shift(1)\n",
    "df_despesas_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dos dados para as despesas mensais do município\n",
    "df_despesas_agrupado['SMA(12)_saldo'] = df_despesas_agrupado['saldo'].rolling(window=12).mean()\n",
    "df_despesas_agrupado['SMA(6)_saldo'] = df_despesas_agrupado['saldo'].rolling(window=6).mean()\n",
    "df_despesas_agrupado['SMA(3)_saldo'] = df_despesas_agrupado['saldo'].rolling(window=3).mean()\n",
    "df_despesas_agrupado['SMA(2)_saldo'] = df_despesas_agrupado['saldo'].rolling(window=2).mean()\n",
    "df_despesas_agrupado['lag(12)_saldo'] = df_despesas_agrupado['saldo'].shift(12)\n",
    "df_despesas_agrupado['lag(6)_saldo'] = df_despesas_agrupado['saldo'].shift(6)\n",
    "df_despesas_agrupado['lag(4)_saldo'] = df_despesas_agrupado['saldo'].shift(4)\n",
    "df_despesas_agrupado['lag(3)_saldo'] = df_despesas_agrupado['saldo'].shift(3)\n",
    "df_despesas_agrupado['lag(2)_saldo'] = df_despesas_agrupado['saldo'].shift(2)\n",
    "df_despesas_agrupado['lag(1)_saldo'] = df_despesas_agrupado['saldo'].shift(1)\n",
    "df_despesas_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA(12)</th>\n",
       "      <th>SMA(6)</th>\n",
       "      <th>SMA(3)</th>\n",
       "      <th>SMA(2)</th>\n",
       "      <th>lag(12)</th>\n",
       "      <th>lag(6)</th>\n",
       "      <th>lag(4)</th>\n",
       "      <th>lag(3)</th>\n",
       "      <th>lag(2)</th>\n",
       "      <th>lag(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>247407589.0</td>\n",
       "      <td>297815.13</td>\n",
       "      <td>297955.53</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>474.84</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-02</td>\n",
       "      <td>196115092.0</td>\n",
       "      <td>557228.16</td>\n",
       "      <td>558786.56</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>619.48</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>426974.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-03</td>\n",
       "      <td>174505126.0</td>\n",
       "      <td>892748.46</td>\n",
       "      <td>892748.46</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>255197.26</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497166.723333</td>\n",
       "      <td>597079.940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>198742858.0</td>\n",
       "      <td>736807.15</td>\n",
       "      <td>736807.15</td>\n",
       "      <td>732833.15</td>\n",
       "      <td>3974.00</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>642331.010000</td>\n",
       "      <td>685192.175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013-05</td>\n",
       "      <td>179036644.0</td>\n",
       "      <td>823679.15</td>\n",
       "      <td>823679.15</td>\n",
       "      <td>800601.05</td>\n",
       "      <td>23078.10</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723661.800000</td>\n",
       "      <td>766717.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>732833.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano  ano_mes  valor_fixado  valor_empenhado  valor_liquidado  valor_pago  \\\n",
       "0  2013  2013-01   247407589.0        297815.13        297955.53   297340.29   \n",
       "1  2013  2013-02   196115092.0        557228.16        558786.56   556608.68   \n",
       "2  2013  2013-03   174505126.0        892748.46        892748.46   637551.20   \n",
       "3  2013  2013-04   198742858.0        736807.15        736807.15   732833.15   \n",
       "4  2013  2013-05   179036644.0        823679.15        823679.15   800601.05   \n",
       "\n",
       "       saldo  populacao  variacao_anual  aceleracao_variacao_anual  ...  \\\n",
       "0     474.84      60612            1482                       1146  ...   \n",
       "1     619.48      60612            1482                       1146  ...   \n",
       "2  255197.26      60612            1482                       1146  ...   \n",
       "3    3974.00      60612            1482                       1146  ...   \n",
       "4   23078.10      60612            1482                       1146  ...   \n",
       "\n",
       "   SMA(12)  SMA(6)         SMA(3)      SMA(2)  lag(12)  lag(6)     lag(4)  \\\n",
       "0      0.0     0.0       0.000000       0.000      0.0     0.0       0.00   \n",
       "1      0.0     0.0       0.000000  426974.485      0.0     0.0       0.00   \n",
       "2      0.0     0.0  497166.723333  597079.940      0.0     0.0       0.00   \n",
       "3      0.0     0.0  642331.010000  685192.175      0.0     0.0       0.00   \n",
       "4      0.0     0.0  723661.800000  766717.100      0.0     0.0  297340.29   \n",
       "\n",
       "      lag(3)     lag(2)     lag(1)  \n",
       "0       0.00       0.00       0.00  \n",
       "1       0.00       0.00  297340.29  \n",
       "2       0.00  297340.29  556608.68  \n",
       "3  297340.29  556608.68  637551.20  \n",
       "4  556608.68  637551.20  732833.15  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas_agrupado.fillna(0, inplace=True)\n",
    "df_despesas_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor_fixado</th>\n",
       "      <th>valor_empenhado</th>\n",
       "      <th>valor_liquidado</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>saldo</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>ideb_5ano</th>\n",
       "      <th>ideb_9ano</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA(6)</th>\n",
       "      <th>SMA(3)</th>\n",
       "      <th>SMA(2)</th>\n",
       "      <th>lag(12)</th>\n",
       "      <th>lag(6)</th>\n",
       "      <th>lag(4)</th>\n",
       "      <th>lag(3)</th>\n",
       "      <th>lag(2)</th>\n",
       "      <th>lag(1)</th>\n",
       "      <th>ano_mes_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>247407589.0</td>\n",
       "      <td>297815.13</td>\n",
       "      <td>297955.53</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>474.84</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>734869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196115092.0</td>\n",
       "      <td>557228.16</td>\n",
       "      <td>558786.56</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>619.48</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>426974.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>734900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174505126.0</td>\n",
       "      <td>892748.46</td>\n",
       "      <td>892748.46</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>255197.26</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497166.723333</td>\n",
       "      <td>597079.940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>734928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198742858.0</td>\n",
       "      <td>736807.15</td>\n",
       "      <td>736807.15</td>\n",
       "      <td>732833.15</td>\n",
       "      <td>3974.00</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>642331.010000</td>\n",
       "      <td>685192.175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>734959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>179036644.0</td>\n",
       "      <td>823679.15</td>\n",
       "      <td>823679.15</td>\n",
       "      <td>800601.05</td>\n",
       "      <td>23078.10</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723661.800000</td>\n",
       "      <td>766717.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297340.29</td>\n",
       "      <td>556608.68</td>\n",
       "      <td>637551.20</td>\n",
       "      <td>732833.15</td>\n",
       "      <td>734989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   valor_fixado  valor_empenhado  valor_liquidado  valor_pago      saldo  \\\n",
       "0   247407589.0        297815.13        297955.53   297340.29     474.84   \n",
       "1   196115092.0        557228.16        558786.56   556608.68     619.48   \n",
       "2   174505126.0        892748.46        892748.46   637551.20  255197.26   \n",
       "3   198742858.0        736807.15        736807.15   732833.15    3974.00   \n",
       "4   179036644.0        823679.15        823679.15   800601.05   23078.10   \n",
       "\n",
       "   populacao  variacao_anual  aceleracao_variacao_anual  ideb_5ano  ideb_9ano  \\\n",
       "0      60612            1482                       1146        4.1        2.8   \n",
       "1      60612            1482                       1146        4.1        2.8   \n",
       "2      60612            1482                       1146        4.1        2.8   \n",
       "3      60612            1482                       1146        4.1        2.8   \n",
       "4      60612            1482                       1146        4.1        2.8   \n",
       "\n",
       "   ...  SMA(6)         SMA(3)      SMA(2)  lag(12)  lag(6)     lag(4)  \\\n",
       "0  ...     0.0       0.000000       0.000      0.0     0.0       0.00   \n",
       "1  ...     0.0       0.000000  426974.485      0.0     0.0       0.00   \n",
       "2  ...     0.0  497166.723333  597079.940      0.0     0.0       0.00   \n",
       "3  ...     0.0  642331.010000  685192.175      0.0     0.0       0.00   \n",
       "4  ...     0.0  723661.800000  766717.100      0.0     0.0  297340.29   \n",
       "\n",
       "      lag(3)     lag(2)     lag(1)  ano_mes_ordinal  \n",
       "0       0.00       0.00       0.00           734869  \n",
       "1       0.00       0.00  297340.29           734900  \n",
       "2       0.00  297340.29  556608.68           734928  \n",
       "3  297340.29  556608.68  637551.20           734959  \n",
       "4  556608.68  637551.20  732833.15           734989  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_despesas_agrupado.drop(columns=['ano'], inplace=True)\n",
    "df_despesas_agrupado = transforma_data_em_ordinal(df_despesas_agrupado, 'ano_mes')\n",
    "df_despesas_agrupado.drop(columns=['ano_mes'], inplace=True)\n",
    "df_despesas_agrupado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of train data:  (96, 27)\n",
      "Dimension of test data:  (24, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_series_data(df_despesas_agrupado, 'valor_pago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_despesas_agrupado.to_csv('../../data/dados_despesas.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelagem dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df_despesas_agrupado) * 0.75)\n",
    "train_dataset, test_dataset = df_despesas_agrupado.iloc[:train_size], df_despesas_agrupado.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.drop(['valor_fixado','valor_empenhado','valor_liquidado','valor_pago','saldo'], axis=1)\n",
    "y_train = train_dataset.loc[:, ['valor_fixado','valor_empenhado','valor_liquidado','valor_pago','saldo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_dataset.drop(['valor_fixado','valor_empenhado','valor_liquidado','valor_pago','saldo'], axis=1)\n",
    "y_test = test_dataset.loc[:, ['valor_fixado','valor_empenhado','valor_liquidado','valor_pago','saldo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_x = MinMaxScaler(feature_range=(0,1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scaler = scaler_x.fit(X_train)\n",
    "output_scaler = scaler_y.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizando os dados de treino e teste\n",
    "train_y_norm = output_scaler.transform(y_train)\n",
    "train_x_norm = input_scaler.transform(X_train)\n",
    "\n",
    "test_y_norm = output_scaler.transform(y_test)\n",
    "test_x_norm = input_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_x_norm.reshape((test_x_norm.shape[0], 1, test_x_norm.shape[1]))\n",
    "X_train = train_x_norm.reshape((train_x_norm.shape[0], 1, train_x_norm.shape[1]))\n",
    "y_test = test_y_norm.reshape((test_y_norm.shape[0], 1))\n",
    "y_train = train_y_norm.reshape((train_y_norm.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste no modelo com 32, 64 e 128 neurônios para verficação do mais adequado para a aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 125ms/step - loss: 0.2092 - val_loss: 0.0517\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0977 - val_loss: 0.0177\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0437 - val_loss: 0.0502\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0359 - val_loss: 0.0293\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0374 - val_loss: 0.0258\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0356 - val_loss: 0.0257\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.0216\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0306 - val_loss: 0.0182\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0268 - val_loss: 0.0150\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0278 - val_loss: 0.0147\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0252 - val_loss: 0.0135\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0219 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0226 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0107\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0109\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0108\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0207 - val_loss: 0.0108\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0111\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0113\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0108\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0109\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0108\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0110\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0106\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0103\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0101\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0100\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0098\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0098\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0096\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0125\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0098\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0094\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0093\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0096\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0090\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0111\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0139\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0092\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0092\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0111\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0095\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0098\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0107\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0094\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0094\n",
      ">Neurons=32, Score=5.672363564372063\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 94ms/step - loss: 0.2053 - val_loss: 0.0555\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0970 - val_loss: 0.0160\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0424 - val_loss: 0.0418\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0365 - val_loss: 0.0256\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0326 - val_loss: 0.0193\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0333 - val_loss: 0.0200\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0300 - val_loss: 0.0164\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0326 - val_loss: 0.0137\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0140\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0226 - val_loss: 0.0117\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0238 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0127\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0123\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0125\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0121\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0092\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0093\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0094\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0094\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0092\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0090\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0082\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0074\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0076\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0077\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0078\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0082\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0074\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0092\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0071\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0090\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0095\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0067\n",
      ">Neurons=32, Score=1.6147186979651451\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 86ms/step - loss: 0.1924 - val_loss: 0.0391\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0749 - val_loss: 0.0291\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0428 - val_loss: 0.0415\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0352 - val_loss: 0.0218\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0357 - val_loss: 0.0238\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0328 - val_loss: 0.0204\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0331 - val_loss: 0.0158\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0277 - val_loss: 0.0144\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0267 - val_loss: 0.0122\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0239 - val_loss: 0.0115\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.0103\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0103\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0103\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0110\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0106\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0109\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0111\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0105\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0108\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0106\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0096\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0101\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0154 - val_loss: 0.0083\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0124\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0092\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0080\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0093\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0085\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0165\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0075\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0069\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0123\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0139\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0098\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0111\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0156\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0152\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0112\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0116\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0124\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0127\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0091\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0154\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0160\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0117\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0172\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0096\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0116\n",
      ">Neurons=32, Score=5.6682489812374115\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 75ms/step - loss: 0.2083 - val_loss: 0.0482\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0888 - val_loss: 0.0225\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0563 - val_loss: 0.0435\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0394 - val_loss: 0.0259\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0396 - val_loss: 0.0256\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0236\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0344 - val_loss: 0.0217\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0187\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0300 - val_loss: 0.0170\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0337 - val_loss: 0.0154\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0322 - val_loss: 0.0139\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0273 - val_loss: 0.0130\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.0122\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0124\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0128\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0130\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0135\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0131\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0133\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0131\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0139\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0128\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0128\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0128\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0125\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0124\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0122\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0120\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0113\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0095\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0092\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0090\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0093\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0093\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0087\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0092\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0088\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      ">Neurons=32, Score=1.4403642155230045\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 77ms/step - loss: 0.2067 - val_loss: 0.0473\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0904 - val_loss: 0.0227\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0471 - val_loss: 0.0420\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.0235\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0373 - val_loss: 0.0241\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0356 - val_loss: 0.0207\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0319 - val_loss: 0.0170\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0283 - val_loss: 0.0179\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0279 - val_loss: 0.0143\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0264 - val_loss: 0.0134\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0272 - val_loss: 0.0124\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0132\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0138\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0124\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0140\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0141\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0161\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0154\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0160\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0170\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0171\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0194\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0220\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0151\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0149\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0178\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0157\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0178\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0160\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0177\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0144\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0168\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0146\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0182\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0169\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0155\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0166\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0184\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0181\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0159\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0173\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0217\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0178\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0154\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0173\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0215\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0209\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0219\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0214\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0153\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0182\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0220\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0229\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0202\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0173\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0208\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0209\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0156\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0191\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0206\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0279\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0211\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0199\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0199\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0164\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0181\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0220\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0220\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0310\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0188\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0225\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0210\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0171\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0225\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0211\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0166\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0209\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0297\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0275\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0202\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0208\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0258\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0197\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0250\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0271\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0224\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0198\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0252\n",
      ">Neurons=32, Score=9.120629727840424\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 82ms/step - loss: 0.2127 - val_loss: 0.0618\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0997 - val_loss: 0.0154\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0479 - val_loss: 0.0416\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0361 - val_loss: 0.0214\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0331 - val_loss: 0.0191\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0327 - val_loss: 0.0182\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0301 - val_loss: 0.0144\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0122\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0239 - val_loss: 0.0111\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0207 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0129\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0112\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0120\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0118\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0138\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0117\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0128\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0131\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0110\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0145\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0162\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0157\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0119\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0135\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0156\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0173\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0142\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0086\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0180\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0154\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0126\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0194\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0176\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0155\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0158\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0134\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0195\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0218\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0177\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0164\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0183\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0176\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0133\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0145\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0173\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0112\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0155\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0160\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0153\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0171\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0102\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0132\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0165\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0156\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0166\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0166\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0175\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0128\n",
      ">Neurons=32, Score=5.450265109539032\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 82ms/step - loss: 0.2131 - val_loss: 0.0534\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0817 - val_loss: 0.0211\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0426 - val_loss: 0.0343\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0364 - val_loss: 0.0211\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0294 - val_loss: 0.0190\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0302 - val_loss: 0.0176\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0283 - val_loss: 0.0152\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.0133\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0237 - val_loss: 0.0120\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0117\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0112\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0238 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0111\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0115\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0132\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0124\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0120\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0125\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0117\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0129\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0126\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0120\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0115\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0122\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0134\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0141\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0195\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0120\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0141\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0169\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0151\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0143\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0124\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0156\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0163\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0132\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0132\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0155\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0159\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0135\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0166\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0147\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0129\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0137\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0128\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0150\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0172\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0154\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0162\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0166\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0112\n",
      ">Neurons=32, Score=3.42954657971859\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 92ms/step - loss: 0.2086 - val_loss: 0.0480\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0932 - val_loss: 0.0213\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0459 - val_loss: 0.0546\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0380 - val_loss: 0.0270\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0372 - val_loss: 0.0251\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0311 - val_loss: 0.0205\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0157\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0139\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0267 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0268 - val_loss: 0.0113\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0196 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0210 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0117\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0119\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0123\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0133\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0124\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0133\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0126\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0137\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0140\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0118\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0172\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0129\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0127\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0158\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0147\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0137\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0153\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0140\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0155\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0140\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0140\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0084\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0146\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0060 - val_loss: 0.0111\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0103\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0106\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0145\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0131\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0098\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0102\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0137\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0122\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0117\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0117\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0087\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0134\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0092\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0087\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0081\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0072\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      ">Neurons=32, Score=1.4438476413488388\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 85ms/step - loss: 0.2232 - val_loss: 0.0673\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1079 - val_loss: 0.0157\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0502 - val_loss: 0.0399\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0241\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0383 - val_loss: 0.0211\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0355 - val_loss: 0.0194\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0343 - val_loss: 0.0186\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0307 - val_loss: 0.0159\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0313 - val_loss: 0.0139\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0306 - val_loss: 0.0144\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0287 - val_loss: 0.0125\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.0110\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 0.0110\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0108\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0108\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0108\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0196 - val_loss: 0.0108\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0113\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0108\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0108\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0109\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0116\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0110\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0106\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0106\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0105\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0104\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0100\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0105\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0106\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0090\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0104\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0094\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0092\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0107\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0087\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0096\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0084\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0087\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0102\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0083\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0100\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0131\n",
      ">Neurons=32, Score=4.566820710897446\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 82ms/step - loss: 0.1906 - val_loss: 0.0395\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0789 - val_loss: 0.0285\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0467 - val_loss: 0.0458\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0412 - val_loss: 0.0262\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0362 - val_loss: 0.0256\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0374 - val_loss: 0.0251\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0340 - val_loss: 0.0198\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0290 - val_loss: 0.0147\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0291 - val_loss: 0.0135\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0245 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.0125\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0131\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0131\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0128\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0142\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0127\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0132\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0139\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0124\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0138\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0130\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0132\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0160\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0155\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0165\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0148\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0104\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0113\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0087\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0127\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0118\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0121\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0108\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0110\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0125\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0115\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0128\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0080\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0140\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0123\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0112\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0108\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0102\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0093\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0106\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0117\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0072\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0082\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0180\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0139\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0074\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0094\n",
      ">Neurons=32, Score=13.49465548992157\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 76ms/step - loss: 0.1841 - val_loss: 0.0267\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0553 - val_loss: 0.0486\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.0213\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0351 - val_loss: 0.0194\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0341 - val_loss: 0.0170\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0282 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0215 - val_loss: 0.0108\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0108\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0104\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0104\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0105\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0104\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0101\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0096\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0095\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0099\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0093\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0093\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0092\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0093\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0091\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0087\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0091\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0088\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0082\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0211 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0094\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0089\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0083\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0084\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0077\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0110\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0079\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0071\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0072\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0073\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0085\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0074\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0089\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0098\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0108\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0101\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0076\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0094\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0069\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0075\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0102\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0100\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0105\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0105\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0098\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0101\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0090\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0099\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0116\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0104\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0079\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0066\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      ">Neurons=60, Score=8.89650359749794\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 85ms/step - loss: 0.2073 - val_loss: 0.0395\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0672 - val_loss: 0.0466\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0410 - val_loss: 0.0177\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0369 - val_loss: 0.0202\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0168\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0147\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0292 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0125\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0246 - val_loss: 0.0115\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0122\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0125\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0125\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0126\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0128\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0130\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0111\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0135\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0106\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0132\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0116\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0137\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0122\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0111\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0115\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0116\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0117\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0130\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0117\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0103\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0117\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0115\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0094\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0111\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0153\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0095\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.0138\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0229 - val_loss: 0.0139\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0164\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0111\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0124\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0115\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0115\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0132\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0134\n",
      ">Neurons=60, Score=5.359985306859016\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 11s 219ms/step - loss: 0.1908 - val_loss: 0.0251\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0655 - val_loss: 0.0631\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0413 - val_loss: 0.0282\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0378 - val_loss: 0.0246\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0348 - val_loss: 0.0220\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0312 - val_loss: 0.0198\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0280 - val_loss: 0.0145\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0259 - val_loss: 0.0131\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0257 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0115\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0212 - val_loss: 0.0116\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0199 - val_loss: 0.0117\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0158 - val_loss: 0.0119\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0109\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0108\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0103\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0219 - val_loss: 0.0100\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0168\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0099\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0102\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0094\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0092\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0080 - val_loss: 0.0089\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0085\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0086\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0099\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0093\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0095\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0088\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0083\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0093\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0090\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0077\n",
      ">Neurons=60, Score=2.0847585052251816\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 89ms/step - loss: 0.2005 - val_loss: 0.0303\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0370 - val_loss: 0.0252\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0382 - val_loss: 0.0206\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0315 - val_loss: 0.0200\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.0155\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0145\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0255 - val_loss: 0.0118\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0122\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0188 - val_loss: 0.0112\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0113\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0106\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0111\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0134\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0110\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0114\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0109\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0117\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0092\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0091\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0092\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0140\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0096\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0106\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0096\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0105\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0111\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0106\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0063 - val_loss: 0.0110\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0096\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0092\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0089\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0113\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0134\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0098\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0108\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0151\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0105\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0110\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0120\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0117\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0092\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0080\n",
      ">Neurons=60, Score=1.773475669324398\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 74ms/step - loss: 0.1799 - val_loss: 0.0220\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0612 - val_loss: 0.0577\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0385 - val_loss: 0.0225\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0364 - val_loss: 0.0228\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0313 - val_loss: 0.0192\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0160\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0124\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0224 - val_loss: 0.0117\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0224 - val_loss: 0.0108\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0111\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0113\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0110\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0111\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0104\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0109\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0101\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0097\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0158\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0116\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0103\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0104\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0097\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0100\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0093\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0090\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0134\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0092\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0145\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0115\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0086\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0152\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0115\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0097\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0127\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0077\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0145\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0126\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0103\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0072\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0068\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0106\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0073\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0061 - val_loss: 0.0102\n",
      ">Neurons=60, Score=5.718584358692169\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 86ms/step - loss: 0.1899 - val_loss: 0.0245\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0601 - val_loss: 0.0595\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0355 - val_loss: 0.0235\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0349 - val_loss: 0.0237\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0290 - val_loss: 0.0186\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0265 - val_loss: 0.0155\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0256 - val_loss: 0.0125\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.0109\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0115\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0116\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0112\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0112\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0133\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0121\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0137\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0130\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0121\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0137\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0120\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0125\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0108\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0129\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0095\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0169\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0107\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0144\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0135\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0160\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0138\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0109\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0122\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0139\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0140\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0119\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0146\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0089\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0093\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0220\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0136\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0142\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0147\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0153\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0121\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0136\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0151\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0193\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0172\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0127\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0105\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0145\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0182\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0130\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0126\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0174\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0158\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      ">Neurons=60, Score=5.088987201452255\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 101ms/step - loss: 0.1782 - val_loss: 0.0249\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0525 - val_loss: 0.0443\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0337 - val_loss: 0.0196\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0336 - val_loss: 0.0179\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0325 - val_loss: 0.0167\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0324 - val_loss: 0.0150\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0263 - val_loss: 0.0128\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0215 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0228 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0116\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0199 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0129\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0138\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0144\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0163\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0144\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0132\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0176\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0181\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0120\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0133\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0159\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0126\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0137\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0151\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0169\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0158\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0152\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0203\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0142\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0174\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0187\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0179\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0146\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0173\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0162\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0145\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0143\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0170\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0145\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0146\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0151\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0155\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0216\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0199\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0156\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0232 - val_loss: 0.0094\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0247\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0149\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0141\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0188\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0237\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0195\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0178\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0146\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0196\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0206\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0167\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0183\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0150\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0187\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0227\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0215\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0200\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0184\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0172\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0091\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0178\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0241\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0257\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.0204\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0169\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0234\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0204\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0161\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0061 - val_loss: 0.0203\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0217\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0245\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0187\n",
      ">Neurons=60, Score=9.114816784858704\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 86ms/step - loss: 0.1880 - val_loss: 0.0255\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0631 - val_loss: 0.0615\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0355 - val_loss: 0.0267\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0350 - val_loss: 0.0258\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0307 - val_loss: 0.0223\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0277 - val_loss: 0.0163\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0160\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0120\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0113\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0206 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0114\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0120\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0120\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0109\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0114\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0143\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0097\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0123\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0127\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0116\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0120\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0143\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0117\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0117\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0119\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0115\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0117\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0132\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0083\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0108\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0129\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0081 - val_loss: 0.0140\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0099\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0134\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 0.0117\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0064 - val_loss: 0.0108\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.0114\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0133\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0171\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0090\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0101\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0088\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0151\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0077\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0073 - val_loss: 0.0163\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0141\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0139\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0121\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0114\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0129\n",
      ">Neurons=60, Score=5.672546103596687\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 91ms/step - loss: 0.1956 - val_loss: 0.0233\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0646 - val_loss: 0.0631\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0376 - val_loss: 0.0291\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0387 - val_loss: 0.0267\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0346 - val_loss: 0.0242\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0320 - val_loss: 0.0192\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0264 - val_loss: 0.0164\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0262 - val_loss: 0.0138\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0128\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0108\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0111\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0112\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0113\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0111\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0113\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0104\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0110\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0129\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0111 - val_loss: 0.0093\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0092\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.0105\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0090\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0087\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0120\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0266 - val_loss: 0.0154\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0084\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0224 - val_loss: 0.0139\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0124\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0094\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0107\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0097\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0098\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0087\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0086\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0136\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      ">Neurons=60, Score=4.059556871652603\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 97ms/step - loss: 0.1877 - val_loss: 0.0246\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0538 - val_loss: 0.0496\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0344 - val_loss: 0.0199\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0339 - val_loss: 0.0177\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0334 - val_loss: 0.0167\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0287 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0254 - val_loss: 0.0125\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.0118\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0114\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0195 - val_loss: 0.0115\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0183 - val_loss: 0.0115\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0204 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0189 - val_loss: 0.0115\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0112\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0110\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0106\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0096\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0102\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0106\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0097\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0096\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0110\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0094\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0092\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0085\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0117\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0114\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0092\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0111\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0091\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0105\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0088\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0093\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0085\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0086\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0168\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0121\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0143\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0084\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0129\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0135\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0077\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.0114\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0140\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0098\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0104\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0103\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0092\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0119\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0072 - val_loss: 0.0119\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0119\n",
      ">Neurons=60, Score=8.344908058643341\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 89ms/step - loss: 0.1780 - val_loss: 0.0217\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0551 - val_loss: 0.0450\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0331 - val_loss: 0.0211\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0382 - val_loss: 0.0198\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0290 - val_loss: 0.0155\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0314 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0112\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0112\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0113\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0112\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0115\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0103\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0108\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0099\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0101\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0103\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0100\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0096\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0116\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0127\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0089\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0081\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0129\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0107\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0117\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0109\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0100\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0119\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0094\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0091\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0120\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0076\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0074\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0092\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0111\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0088\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0117\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0119\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0113\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0102\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0114\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0072\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0108\n",
      ">Neurons=64, Score=7.338289171457291\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 85ms/step - loss: 0.1881 - val_loss: 0.0226\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0611 - val_loss: 0.0602\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0364 - val_loss: 0.0230\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0338 - val_loss: 0.0238\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0327 - val_loss: 0.0171\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0290 - val_loss: 0.0151\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0120\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0112\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0122\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0129\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0134\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0119\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0119\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0123\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0149\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0117\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0148\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0148\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0134\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0146\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0125\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0218\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0107\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0134\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0121\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0148\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0167\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0128\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0129\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0139\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0146\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0132\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0152\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0143\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0150\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0187\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0141\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0127\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0154\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0137\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0134\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0126\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0142\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0147\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0148\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0137\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0139\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0193\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0177\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0137\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0134\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0131\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0061 - val_loss: 0.0147\n",
      ">Neurons=64, Score=4.469933360815048\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 88ms/step - loss: 0.1650 - val_loss: 0.0166\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0533 - val_loss: 0.0467\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0345 - val_loss: 0.0191\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0331 - val_loss: 0.0197\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0135\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0242 - val_loss: 0.0113\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0104\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0102\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0105\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0104\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0142\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0111\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0100\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0103\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0092\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0095\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0175 - val_loss: 0.0089\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0136\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0097\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0113\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0093\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0094\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0101\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0083\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0125\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0146\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0084\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0165\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0099\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.0113\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0114\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0118\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0098\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0099\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0097\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0114\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0140\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0103\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0106\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0126\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0103\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0102\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0120\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0139\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0128\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0116\n",
      ">Neurons=64, Score=6.642527878284454\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 78ms/step - loss: 0.1905 - val_loss: 0.0201\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0692 - val_loss: 0.0743\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0386 - val_loss: 0.0309\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0402 - val_loss: 0.0300\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0241\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0309 - val_loss: 0.0192\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0276 - val_loss: 0.0160\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0120\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0112\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0112\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0110\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0115\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0111\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0109\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0129\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0094\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0093\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0092\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0089\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0086\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0091\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0088\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0092\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0138\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0087\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0094\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0119\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0109\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0092\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0099\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0091\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0122\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0094\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0099\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0074\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0075\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0128\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0075\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0135\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0117\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 0.0108\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0102\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0110\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0136\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0102\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0075\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0138\n",
      ">Neurons=64, Score=9.335146099328995\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 90ms/step - loss: 0.1558 - val_loss: 0.0154\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0552 - val_loss: 0.0550\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0349 - val_loss: 0.0216\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0358 - val_loss: 0.0245\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0298 - val_loss: 0.0171\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0142\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0115\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0216 - val_loss: 0.0109\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0201 - val_loss: 0.0112\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0112\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0110\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0107\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0106\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0100\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0096\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0097\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0105\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0093\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0092\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0093\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0116\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0088\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0088\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0082\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0099\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0081\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0180 - val_loss: 0.0092\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.0095\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0093\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0097\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0084\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0068\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0084\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0133\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0082\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0096\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0092\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0089\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0072\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0063\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0064\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0142\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0083\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0089\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0110\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0099\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      ">Neurons=64, Score=5.616345256567001\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 104ms/step - loss: 0.1709 - val_loss: 0.0169\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0481 - val_loss: 0.0401\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0342 - val_loss: 0.0213\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0326 - val_loss: 0.0204\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0294 - val_loss: 0.0150\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0294 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0252 - val_loss: 0.0118\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0224 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0115\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0207 - val_loss: 0.0116\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0185 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0128\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0117\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0227 - val_loss: 0.0115\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0121\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0114\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0101\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0102\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0101\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0121\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0097\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0102\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0097\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0113\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0096\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0113\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0094\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0098\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      ">Neurons=64, Score=2.3226553574204445\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 109ms/step - loss: 0.1811 - val_loss: 0.0189\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0564 - val_loss: 0.0557\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0335 - val_loss: 0.0190\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0355 - val_loss: 0.0223\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0280 - val_loss: 0.0162\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0275 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0249 - val_loss: 0.0116\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0220 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0222 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0195 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0115\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0109\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0105\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0219 - val_loss: 0.0143\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0117\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0095\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0097\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0099\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0113\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0095\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0090\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0096\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0090\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.0085\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0116\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0079\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0084\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0085 - val_loss: 0.0123\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0071 - val_loss: 0.0097\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0105\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0100\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0080\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0109\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0072 - val_loss: 0.0111\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0056 - val_loss: 0.0107\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0093\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0107\n",
      ">Neurons=64, Score=5.106941610574722\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 84ms/step - loss: 0.1680 - val_loss: 0.0176\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0516 - val_loss: 0.0492\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0325 - val_loss: 0.0196\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0327 - val_loss: 0.0198\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0278 - val_loss: 0.0168\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0234 - val_loss: 0.0139\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.0129\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0109\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0108\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0110\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0128\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0110\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0103\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0109\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0177 - val_loss: 0.0103\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0106\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0144\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0127\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0112\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0109\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0134\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0091\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0138\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0162\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0135\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0098\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0137\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0130\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0114\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0117\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0113\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0119\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0141\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0089\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0156\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0143\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0093\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0155\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0154\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0165\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0115\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0101\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0134\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0158\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0138\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0123\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0113\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0109\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0149\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0130\n",
      ">Neurons=64, Score=4.743320122361183\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 86ms/step - loss: 0.1982 - val_loss: 0.0285\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0648 - val_loss: 0.0615\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0371 - val_loss: 0.0212\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0393 - val_loss: 0.0229\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0341 - val_loss: 0.0208\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0309 - val_loss: 0.0164\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0277 - val_loss: 0.0152\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0235 - val_loss: 0.0126\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0120\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 0.0122\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0127\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0113\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0114\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0125\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0109\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0107\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0113\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0111\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0119\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0114\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0231 - val_loss: 0.0104\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0091\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0256 - val_loss: 0.0117\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0126\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0114\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0106\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0120\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0116\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0152\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0135\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0126\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0084\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0120\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0124\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0090\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0128\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0153\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0098\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0090\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0108\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0141\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0119\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0123\n",
      ">Neurons=64, Score=3.8926422595977783\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 120ms/step - loss: 0.1856 - val_loss: 0.0209\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0599 - val_loss: 0.0679\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0385 - val_loss: 0.0266\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0350 - val_loss: 0.0266\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0338 - val_loss: 0.0220\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0301 - val_loss: 0.0174\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0264 - val_loss: 0.0129\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0120\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0125\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0124\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0122 - val_loss: 0.0128\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0198 - val_loss: 0.0113\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0174 - val_loss: 0.0103\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0139\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0139\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0123 - val_loss: 0.0137\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0129\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0090 - val_loss: 0.0127\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0084 - val_loss: 0.0145\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0143\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0111\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0140\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0082 - val_loss: 0.0126\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0122\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0152\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0090\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0208\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0165\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0172\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0130\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.0137\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0160\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0124\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0069 - val_loss: 0.0134\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0116\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0123\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0133\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0173\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0130\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0185\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0148\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0150\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0174\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0150\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0164\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0172\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0181\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0153\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0124\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0154\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0146\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0176\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0170\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0130\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0206\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0230\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0085\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0151\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0209\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0154\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0059 - val_loss: 0.0149\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0155\n",
      ">Neurons=64, Score=6.342935562133789\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 107ms/step - loss: 0.1684 - val_loss: 0.0163\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0588 - val_loss: 0.0635\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0352 - val_loss: 0.0269\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0350 - val_loss: 0.0291\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0325 - val_loss: 0.0240\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0313 - val_loss: 0.0189\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0255 - val_loss: 0.0144\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0129\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0182 - val_loss: 0.0115\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0117\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0125\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0120\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0126\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0123\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0115\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0119\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0126\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0125\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0155 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0112\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0118\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0114\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0109\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0158\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0150\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0130\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0129\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 0.0116\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0126\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0140\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0139\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0227 - val_loss: 0.0189\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0191 - val_loss: 0.0104\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0128\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0115\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0134\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0139\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0143\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0118\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0137\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0138\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0141\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0160\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0196\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0095\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0140\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0074 - val_loss: 0.0151\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0120\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0137\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0169\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0146\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0132\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0169\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0156\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0097\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0160\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0162\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0146\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0133\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0214\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0166\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0131\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0141\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0178\n",
      ">Neurons=65, Score=5.150559917092323\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 112ms/step - loss: 0.1855 - val_loss: 0.0222\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0566 - val_loss: 0.0558\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0355 - val_loss: 0.0239\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0345 - val_loss: 0.0234\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0331 - val_loss: 0.0177\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0318 - val_loss: 0.0163\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0260 - val_loss: 0.0135\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0256 - val_loss: 0.0128\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0230 - val_loss: 0.0112\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0210 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0199 - val_loss: 0.0111\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0163 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0117\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0131\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0133\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0108\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0173 - val_loss: 0.0122\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0141\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0132\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0111\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0119\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0120\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0138\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0124\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0102\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0123\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0159\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0078 - val_loss: 0.0122\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0126\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0139\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0138\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0081 - val_loss: 0.0125\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0126\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0139\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0120\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0183\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0144\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0094\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0166\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0171\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0127\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0170\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0158\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0131\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0106\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0123\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0123\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0127\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0130\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0134\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0165\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0177\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0124\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0134\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0170\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0155\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0126\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0170\n",
      ">Neurons=65, Score=5.320939049124718\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 177ms/step - loss: 0.1714 - val_loss: 0.0163\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0527 - val_loss: 0.0576\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0357 - val_loss: 0.0218\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0342 - val_loss: 0.0259\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0297 - val_loss: 0.0187\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0291 - val_loss: 0.0180\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0257 - val_loss: 0.0134\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0233 - val_loss: 0.0132\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0223 - val_loss: 0.0119\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0199 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0111\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0187 - val_loss: 0.0113\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0169 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0155 - val_loss: 0.0119\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0111\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0104\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0110\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0111\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0118\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0111\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0110\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0092\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0125\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0176 - val_loss: 0.0095\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0098\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0104\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0109\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0145\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0091\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0096\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0116\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0103\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0091\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0129\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0078\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0103\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0102\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0134\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0112\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0119\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0108\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0116\n",
      ">Neurons=65, Score=3.886830061674118\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 118ms/step - loss: 0.1778 - val_loss: 0.0173\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0547 - val_loss: 0.0537\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0341 - val_loss: 0.0240\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0341 - val_loss: 0.0228\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0322 - val_loss: 0.0164\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0146\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0115\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0110\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0219 - val_loss: 0.0108\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0206 - val_loss: 0.0108\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0111\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0115\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0115\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0122\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0128\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0156 - val_loss: 0.0101\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0108\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0115\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0107\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0130\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0099\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0127\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0141\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0096\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0123\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0152\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0145\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0156\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0110\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0125\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0171\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0138\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0176\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0134\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0120\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0062 - val_loss: 0.0141\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0160\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0136\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0157\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0204\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0108\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0112\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0146\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0134\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0143\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0123\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0205\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0182\n",
      ">Neurons=65, Score=9.686536341905594\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 90ms/step - loss: 0.1738 - val_loss: 0.0184\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0508 - val_loss: 0.0581\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0332 - val_loss: 0.0211\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0338 - val_loss: 0.0221\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0289 - val_loss: 0.0179\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0265 - val_loss: 0.0142\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0251 - val_loss: 0.0117\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0111\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0113\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0128\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0126\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0112\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0122\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0121\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0111\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0109\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0142\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0121\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0140\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0172\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0098\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0215 - val_loss: 0.0162\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0123\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0142\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0109\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0137\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0150\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0150\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0138\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0124\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0096\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0180\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0171\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0136\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0165\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0123\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0126\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0125\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0146\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0162\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0144\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0141\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0227\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0192\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0143\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0061 - val_loss: 0.0164\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0156\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0142\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0135\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0157\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0160\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0169\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0145\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0171\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0167\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0142\n",
      ">Neurons=65, Score=3.902699798345566\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 103ms/step - loss: 0.2125 - val_loss: 0.0401\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0651 - val_loss: 0.0451\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0369 - val_loss: 0.0214\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0327 - val_loss: 0.0187\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0279 - val_loss: 0.0158\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0265 - val_loss: 0.0128\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0225 - val_loss: 0.0116\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0228 - val_loss: 0.0113\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0193 - val_loss: 0.0112\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0173 - val_loss: 0.0117\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0182 - val_loss: 0.0115\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0152 - val_loss: 0.0115\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0200 - val_loss: 0.0117\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0157 - val_loss: 0.0130\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.0106\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0103\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0122\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0077 - val_loss: 0.0110\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0149\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0103\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0133\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0084\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0078 - val_loss: 0.0094\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0165\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0124\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0140\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0092\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0105\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0114\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0072 - val_loss: 0.0112\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0115\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0098\n",
      ">Neurons=65, Score=3.8598813116550446\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 133ms/step - loss: 0.1922 - val_loss: 0.0236\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0609 - val_loss: 0.0600\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0355 - val_loss: 0.0250\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0343 - val_loss: 0.0252\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0305 - val_loss: 0.0215\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0289 - val_loss: 0.0192\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0263 - val_loss: 0.0145\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0227 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0134\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0115\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0191 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0125\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0165 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0141 - val_loss: 0.0128\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0115\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0110\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0107\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0102\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0101\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0100\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0105\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0092\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0088\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0095\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0099\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0090\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0094\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0088\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0085\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0090\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0097\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0091\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0104\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0088\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0094\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0093\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0093\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0115\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0065 - val_loss: 0.0104\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0095\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0099\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0095\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0101\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0092\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0094\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0115\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0114\n",
      ">Neurons=65, Score=2.5146933272480965\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 125ms/step - loss: 0.1823 - val_loss: 0.0198\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0533 - val_loss: 0.0582\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0351 - val_loss: 0.0241\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0338 - val_loss: 0.0207\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0317 - val_loss: 0.0184\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0310 - val_loss: 0.0142\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0124\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0118\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0217 - val_loss: 0.0120\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0201 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0119\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0120\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0110\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0101\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0106\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0103\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0100\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0128\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0127\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0112\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0101\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0119\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0109\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.0113\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0115\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0106\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0137\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0111\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0102\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0101\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0086\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0084\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0154 - val_loss: 0.0192\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0175\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0089\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0136\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0123\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0135\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0108\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0062 - val_loss: 0.0111\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.0131\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0060 - val_loss: 0.0114\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0109\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0115\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0118\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0096\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0122\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0159\n",
      ">Neurons=65, Score=8.695437014102936\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 100ms/step - loss: 0.1799 - val_loss: 0.0188\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0570 - val_loss: 0.0573\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0363 - val_loss: 0.0243\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0356 - val_loss: 0.0209\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0326 - val_loss: 0.0188\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0150\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0123\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.0111\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0198 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0192 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0113\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0116\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0103\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0128\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0099\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0111\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0108\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0096\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0091\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0085\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0085\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0125\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0113\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0094\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0124\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0119\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0098\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0085\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0095\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0115\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0111\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0105\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0108\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0113\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0079\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0136\n",
      ">Neurons=65, Score=5.5364590138196945\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 89ms/step - loss: 0.1636 - val_loss: 0.0153\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0536 - val_loss: 0.0511\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0352 - val_loss: 0.0210\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0333 - val_loss: 0.0187\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0301 - val_loss: 0.0142\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0259 - val_loss: 0.0121\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0236 - val_loss: 0.0110\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0231 - val_loss: 0.0108\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0107\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0183 - val_loss: 0.0107\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0171 - val_loss: 0.0097\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0247 - val_loss: 0.0101\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0096\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0137\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0100\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0160 - val_loss: 0.0104\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0098\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0097\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0098\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0095\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0091\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0092\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0084\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0107\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0090\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0122\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0092\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0130\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0084\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0107\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0107\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.0110\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0077\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0137\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0126\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0088\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0089\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0072\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      ">Neurons=65, Score=5.154946818947792\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 101ms/step - loss: 0.1859 - val_loss: 0.0189\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0577 - val_loss: 0.0617\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0366 - val_loss: 0.0301\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0314 - val_loss: 0.0218\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0163\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0241 - val_loss: 0.0133\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0119\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0199 - val_loss: 0.0120\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0195 - val_loss: 0.0125\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0127\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0126\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0129\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0128\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0125\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0186 - val_loss: 0.0127\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0182 - val_loss: 0.0131\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0142\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0123\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0130\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0116\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0116\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0156\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0125\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0155\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0126\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0121\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0142\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0144\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0133\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0129\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0085 - val_loss: 0.0132\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0118\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0156\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0146\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0184 - val_loss: 0.0171\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0132 - val_loss: 0.0139\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0204 - val_loss: 0.0115\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0144\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0148\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0125\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0136\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0156\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0128\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0131\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0161\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0140\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0153\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0137\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0141\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0136\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0080 - val_loss: 0.0150\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0156\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0148\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0122\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0177\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0139\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0136\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0144\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0187\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0146\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0140\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0171\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0159\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0186\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0099 - val_loss: 0.0161\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      ">Neurons=70, Score=2.979215793311596\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 103ms/step - loss: 0.1529 - val_loss: 0.0149\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0459 - val_loss: 0.0300\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0351 - val_loss: 0.0165\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0322 - val_loss: 0.0143\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0282 - val_loss: 0.0127\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0252 - val_loss: 0.0112\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0111\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0208 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0112\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0111\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0165 - val_loss: 0.0106\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0101\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0105\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0117\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0113\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0155 - val_loss: 0.0090\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0094\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0180 - val_loss: 0.0096\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0092\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0093\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0105\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0108\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0087\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0100\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0097\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0200 - val_loss: 0.0135\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0173\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0091\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0135\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0121\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0108\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0099\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0117\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0072 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0132\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0126\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0116\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0083\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0165\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0123\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0138\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0124\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0104\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0062 - val_loss: 0.0127\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0092\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0080\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0110\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0114\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0119\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0113\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0112\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0066 - val_loss: 0.0117\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0129\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0120\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0079\n",
      ">Neurons=70, Score=5.2272118628025055\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 96ms/step - loss: 0.1938 - val_loss: 0.0234\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0636 - val_loss: 0.0600\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0360 - val_loss: 0.0247\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0358 - val_loss: 0.0233\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0330 - val_loss: 0.0215\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0306 - val_loss: 0.0152\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0287 - val_loss: 0.0134\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0249 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0196 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0219 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0173 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0145 - val_loss: 0.0109\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0228 - val_loss: 0.0149\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0104\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0172 - val_loss: 0.0129\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0099\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0104\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0131\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0115\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0096\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0081\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0084\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0084\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0134\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0136\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0094\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0084\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0127\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0099\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0062 - val_loss: 0.0102\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0115\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0093\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0076\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0076\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0125\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0104\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0065 - val_loss: 0.0099\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0059 - val_loss: 0.0095\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0092\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0093\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0088\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0093\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      ">Neurons=70, Score=4.374272003769875\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 106ms/step - loss: 0.1905 - val_loss: 0.0230\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0604 - val_loss: 0.0625\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0345 - val_loss: 0.0262\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0355 - val_loss: 0.0245\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0299 - val_loss: 0.0216\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0268 - val_loss: 0.0168\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0264 - val_loss: 0.0142\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0243 - val_loss: 0.0126\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0204 - val_loss: 0.0114\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0112\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0112\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0112\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0107\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0103\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0170 - val_loss: 0.0106\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0181 - val_loss: 0.0123\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0101\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0133 - val_loss: 0.0094\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0095\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0095\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0095\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0102\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0098\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0109\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0090\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0093\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0110\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0098\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0083\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0084\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0087\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0155 - val_loss: 0.0087\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0217 - val_loss: 0.0175\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0095\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0108\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0098\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0101\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0114\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0110\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0125\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.0088\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0120\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0119\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0101\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0211 - val_loss: 0.0079\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0163\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0129\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0110\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0134\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0147\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0103\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0084 - val_loss: 0.0155\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0085\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0095\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0112\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0136\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0076 - val_loss: 0.0098\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0060 - val_loss: 0.0094\n",
      ">Neurons=70, Score=3.4019730985164642\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 103ms/step - loss: 0.1765 - val_loss: 0.0169\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0552 - val_loss: 0.0513\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0347 - val_loss: 0.0209\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0332 - val_loss: 0.0210\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0303 - val_loss: 0.0147\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0273 - val_loss: 0.0124\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0241 - val_loss: 0.0114\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0119\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0119\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0119\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0126\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0124\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0110\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0113\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0109\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0132\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0122\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0125\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0137\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0126\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0128\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0137\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0097\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0100\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0113\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0110\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0095\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0148\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0097\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0116\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0168\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0137\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0108\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0145\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0144\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0117\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0125\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0183\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0148\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0121\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0080 - val_loss: 0.0121\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0149\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0165\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0141\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0130\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0073 - val_loss: 0.0132\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0144\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0152\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0089\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0120\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0167\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0110\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0109\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0156\n",
      ">Neurons=70, Score=5.113505572080612\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 87ms/step - loss: 0.1879 - val_loss: 0.0211\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0588 - val_loss: 0.0550\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0368 - val_loss: 0.0190\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0354 - val_loss: 0.0202\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0145\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0124\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0114\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0207 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0180 - val_loss: 0.0112\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0117\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0120\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0114\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0112\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0114\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0123\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0126\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0112\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0129\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0096\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0127 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0139\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0096\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0104\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0094\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0207 - val_loss: 0.0146\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0122\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0092\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0094\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0111\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0105\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0106\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0094\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0082 - val_loss: 0.0090\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0118\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0138\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0154 - val_loss: 0.0130\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0096\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0127\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0109\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0090\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0114\n",
      ">Neurons=70, Score=4.9021851271390915\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 91ms/step - loss: 0.1648 - val_loss: 0.0165\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0547 - val_loss: 0.0482\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0334 - val_loss: 0.0211\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0341 - val_loss: 0.0228\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0300 - val_loss: 0.0172\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0267 - val_loss: 0.0152\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0115\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0180 - val_loss: 0.0117\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0113\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0111\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0113\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0108\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0129\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0102\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0171 - val_loss: 0.0102\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0125\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0123\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0100\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0132\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0133\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0123\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0119\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0146\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0114\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0142\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0139\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0143\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0150\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0149\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0161\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0109\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0138\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0113\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0138\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 0.0134\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0145\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0066 - val_loss: 0.0110\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0116\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0089\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0187\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0137\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.0131\n",
      ">Neurons=70, Score=9.581097960472107\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 96ms/step - loss: 0.1631 - val_loss: 0.0160\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0477 - val_loss: 0.0352\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0321 - val_loss: 0.0182\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0313 - val_loss: 0.0181\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0133\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0266 - val_loss: 0.0119\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0254 - val_loss: 0.0113\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0223 - val_loss: 0.0113\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0189 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0171 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0164 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0115\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0110\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0117\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0205 - val_loss: 0.0113\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0106\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.0194\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0101\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0121\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0136\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0116\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0133\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0161\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0144\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0155 - val_loss: 0.0090\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0116\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0224 - val_loss: 0.0100\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0175 - val_loss: 0.0103\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0138\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0131\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0072 - val_loss: 0.0120\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0143\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0120\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0124\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0133\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0116\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0120\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0126\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0093\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.0100\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0203 - val_loss: 0.0094\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0102\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0207\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0096\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0123\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0158\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0136\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0124\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0115\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0122\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0145\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0111\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0137\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0148\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0164\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0173\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0144\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0114\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0115\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0158\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0139\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0093\n",
      ">Neurons=70, Score=5.748538300395012\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 85ms/step - loss: 0.1916 - val_loss: 0.0251\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0605 - val_loss: 0.0516\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0394 - val_loss: 0.0202\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0325 - val_loss: 0.0215\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0301 - val_loss: 0.0169\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0303 - val_loss: 0.0148\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0280 - val_loss: 0.0119\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0259 - val_loss: 0.0118\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0224 - val_loss: 0.0112\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0113\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0113\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0128\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0108\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.0125\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0131\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0139\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0143\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0149\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0131\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0158\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0139\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0125\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0155\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0152\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0155\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0141\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0135\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0139\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0144\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0140\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0152\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0153\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0111\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0162\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0199\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0164\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0126\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0175\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0183\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0156\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0177\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0143\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0159\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0176\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0222\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0193\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0198\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0149\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0128\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0213\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0219\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0176\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0168\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.0174\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0205\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0168\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0153\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0148\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0158\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0179\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0207\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0105\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0194\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0190\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0147\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0168\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0222\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0186\n",
      ">Neurons=70, Score=8.060239255428314\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 90ms/step - loss: 0.1762 - val_loss: 0.0168\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0566 - val_loss: 0.0474\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0364 - val_loss: 0.0210\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0343 - val_loss: 0.0224\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0291 - val_loss: 0.0157\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0282 - val_loss: 0.0149\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0257 - val_loss: 0.0118\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0220 - val_loss: 0.0116\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0114\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0130\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0131\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0136\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0234 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0180\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0132\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0139\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0121\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0143\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0133\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.0168\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0105\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0150\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0198\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0119\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0137\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0158\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0139\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0178\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0156\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0136\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0127\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0141\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0159\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0160\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0100 - val_loss: 0.0139\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0082 - val_loss: 0.0137\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0147\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0139\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0129\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0183\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0198\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0095\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0159\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0172\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0160\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0174\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0143\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0197\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0152\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0128\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0081 - val_loss: 0.0163\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0174\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0147\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0171\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0200\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0116\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0147\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0161\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0176\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0144\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0153\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0192\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0207\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0152\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0130\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0208\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0206\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0153\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0160\n",
      ">Neurons=70, Score=5.567954480648041\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 84ms/step - loss: 0.1757 - val_loss: 0.0167\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0523 - val_loss: 0.0589\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0377 - val_loss: 0.0234\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0318 - val_loss: 0.0274\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0297 - val_loss: 0.0175\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0268 - val_loss: 0.0165\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0237 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0216 - val_loss: 0.0131\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0211 - val_loss: 0.0121\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0196 - val_loss: 0.0117\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.0140\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0166 - val_loss: 0.0133\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0127\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0129\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0129\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0175 - val_loss: 0.0118\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0214 - val_loss: 0.0109\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0154\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0103\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0108\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0107\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0105\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0099\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0095\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0071 - val_loss: 0.0104\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0106\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0105\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0085\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0094\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0270 - val_loss: 0.0110\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0106\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0162\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0123\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0097\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0103\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0092\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0098\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0107\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0093\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0140\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0133\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0092\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0094\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0117\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0088\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0065 - val_loss: 0.0112\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0121\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0114\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0073 - val_loss: 0.0104\n",
      ">Neurons=75, Score=3.058912977576256\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 143ms/step - loss: 0.1616 - val_loss: 0.0166\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0475 - val_loss: 0.0402\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0302 - val_loss: 0.0204\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0326 - val_loss: 0.0172\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0284 - val_loss: 0.0134\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0249 - val_loss: 0.0122\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0112\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0194 - val_loss: 0.0117\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0115\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0125\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0108\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0198 - val_loss: 0.0106\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0211 - val_loss: 0.0117\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0204 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0195 - val_loss: 0.0130\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0159 - val_loss: 0.0136\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0180 - val_loss: 0.0094\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0171 - val_loss: 0.0163\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0109\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0100\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0112\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0102\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0097\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0117\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0105\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0087\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0135\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0086\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0098\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0136\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0103\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0098\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0110\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0120\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0125\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0117\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0113\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      ">Neurons=75, Score=2.874145470559597\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 82ms/step - loss: 0.1569 - val_loss: 0.0171\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0477 - val_loss: 0.0384\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0371 - val_loss: 0.0198\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0341 - val_loss: 0.0200\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0301 - val_loss: 0.0148\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0257 - val_loss: 0.0130\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0115\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0197 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 0.0103\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0186 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0137\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0123\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0126\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0150\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0108\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0142\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0143\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0095\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0147\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0151\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0126\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0128\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0080 - val_loss: 0.0134\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0138\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0119\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0123\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0142\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0115\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0156 - val_loss: 0.0132\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0099\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0154\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0094 - val_loss: 0.0145\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0162\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0134\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0135\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0123\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0158\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0170\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0129\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0198\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0144\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0116\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0128\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0146\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0165\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0133\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0131\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0173\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0150\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0123\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0134\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0136\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0161\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0164\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0135\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0162\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0189\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0090 - val_loss: 0.0174\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0115\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0169\n",
      ">Neurons=75, Score=7.901310175657272\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 105ms/step - loss: 0.1639 - val_loss: 0.0156\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0484 - val_loss: 0.0419\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0340 - val_loss: 0.0193\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0318 - val_loss: 0.0194\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0287 - val_loss: 0.0143\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0259 - val_loss: 0.0130\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0235 - val_loss: 0.0122\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0204 - val_loss: 0.0117\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0126\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0127\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0126\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0116\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0121\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0201 - val_loss: 0.0139\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0126\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0122\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0123\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0124\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0108\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0176\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0127\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0121\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0124\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0113\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0111\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0123\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0129\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0121\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0113\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0122\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0136\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0154\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0137\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0141\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0106\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0137\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0141\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0121\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0126\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.0125\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0130\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0111\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0118\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0145\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0176\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.0138\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0156\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0128\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0129\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0110\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0099\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0195\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0119\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0154\n",
      ">Neurons=75, Score=5.551619455218315\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 89ms/step - loss: 0.1526 - val_loss: 0.0149\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0456 - val_loss: 0.0362\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0345 - val_loss: 0.0211\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0326 - val_loss: 0.0203\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0306 - val_loss: 0.0158\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0287 - val_loss: 0.0136\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0231 - val_loss: 0.0118\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0238 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0115\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0201 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0155 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0114\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0123\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0138\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0142\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0136\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0125\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0143\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0140\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0222 - val_loss: 0.0113\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0102\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0231 - val_loss: 0.0115\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0128\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0117\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0136\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0153\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0130\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0133\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0108\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0132\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0115\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0096\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0152\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0092\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0135\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0176\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0134\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0134\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0130\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0111\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0139\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0162\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0147\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0117\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0131\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0091\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0123\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0149\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0144\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0125\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0072 - val_loss: 0.0123\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.0142\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0144\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0140\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0143\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0124\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0155\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0131\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0141\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0115\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0145\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0140\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0127\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0104\n",
      ">Neurons=75, Score=7.5530849397182465\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 108ms/step - loss: 0.1562 - val_loss: 0.0159\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0481 - val_loss: 0.0349\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0374 - val_loss: 0.0236\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0340 - val_loss: 0.0207\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0296 - val_loss: 0.0159\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0254 - val_loss: 0.0136\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0223 - val_loss: 0.0120\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0204 - val_loss: 0.0113\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0119\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0193 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0128\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0110\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0104\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0141\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0102\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0099\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0101\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0096\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0095\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0144 - val_loss: 0.0098\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0093\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0108\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0104\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0150 - val_loss: 0.0098\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0097\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0070 - val_loss: 0.0101\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0125\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0091\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0107\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0101\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0099\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0091\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0098\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0142\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0090\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0065 - val_loss: 0.0112\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0127\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0100\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0066 - val_loss: 0.0102\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0062 - val_loss: 0.0107\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0059 - val_loss: 0.0115\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.0097\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0062 - val_loss: 0.0097\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0067 - val_loss: 0.0125\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0109\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0110\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      ">Neurons=75, Score=5.861740931868553\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 102ms/step - loss: 0.1928 - val_loss: 0.0213\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0630 - val_loss: 0.0661\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0329 - val_loss: 0.0225\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0336 - val_loss: 0.0238\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0294 - val_loss: 0.0181\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0268 - val_loss: 0.0145\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0241 - val_loss: 0.0125\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0203 - val_loss: 0.0109\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0183 - val_loss: 0.0112\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.0112\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0106\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0115\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0129\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0103\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0123\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0135\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0127\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0100\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0155\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0123\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0100\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0142\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0157\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0132\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0111\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0125\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0149\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0117\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0153\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0137\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0077 - val_loss: 0.0115\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0115\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0148\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0060 - val_loss: 0.0127\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0064 - val_loss: 0.0139\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0141\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0143\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0067 - val_loss: 0.0132\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0070 - val_loss: 0.0102\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0112\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 0.0118\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0150\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0141\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0157\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0149 - val_loss: 0.0082\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 0.0188\n",
      ">Neurons=75, Score=10.41593998670578\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 85ms/step - loss: 0.1636 - val_loss: 0.0160\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0506 - val_loss: 0.0473\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0352 - val_loss: 0.0222\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0333 - val_loss: 0.0236\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0281 - val_loss: 0.0179\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0264 - val_loss: 0.0130\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0242 - val_loss: 0.0125\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0199 - val_loss: 0.0110\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0112\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0115\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0115\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0115\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0113\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0114\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0108\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0115\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0160 - val_loss: 0.0114\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0116\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0119\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0117\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0117\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0133\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0093\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0213 - val_loss: 0.0141\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0112\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0104\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0099\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0098\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0150 - val_loss: 0.0125\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0188\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0143\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0118\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0113\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0107\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0122\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0104\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0106\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0123\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0131\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0055 - val_loss: 0.0111\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0091\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0109\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0144\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0136\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0078\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.0087\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0313 - val_loss: 0.0193\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0123\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0115\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 0.0115\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0055 - val_loss: 0.0116\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0107\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0130\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0121\n",
      ">Neurons=75, Score=6.96827620267868\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 90ms/step - loss: 0.1704 - val_loss: 0.0167\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0503 - val_loss: 0.0445\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0358 - val_loss: 0.0202\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0340 - val_loss: 0.0205\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0315 - val_loss: 0.0150\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0282 - val_loss: 0.0132\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 0.0108\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0207 - val_loss: 0.0104\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0103\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.0111\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0163 - val_loss: 0.0107\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0241 - val_loss: 0.0125\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0102\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0105\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0115\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0127\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0096\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0087\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0192 - val_loss: 0.0155\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0090\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0149\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0109\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0128\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0113\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0116\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0116\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0123\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0097\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0142\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0241 - val_loss: 0.0144\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0104\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0129\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0134\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0112\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0122\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0110\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0111\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.0124\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0099\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0115\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0088\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0111\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0175\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0157\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0128\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0130\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0129\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0086\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0127\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0148\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0102\n",
      ">Neurons=75, Score=4.068382829427719\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 99ms/step - loss: 0.1539 - val_loss: 0.0149\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0487 - val_loss: 0.0394\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0336 - val_loss: 0.0191\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0322 - val_loss: 0.0191\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0274 - val_loss: 0.0157\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0118\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0258 - val_loss: 0.0115\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0105\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0108\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0182 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0122\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0126\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0174 - val_loss: 0.0105\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0124\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0107\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0105\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0144\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0124\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0097\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0098\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0099\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0102\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0097\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0096\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0098\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0097\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0108\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0095\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0093\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0101\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0108\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0092\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0152\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0093\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0059 - val_loss: 0.0113\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.0103\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0093\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.0088\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0092\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0110\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.0093\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0083\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0116\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0167 - val_loss: 0.0086\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0168\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      ">Neurons=75, Score=3.9674513041973114\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 123ms/step - loss: 0.1614 - val_loss: 0.0163\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0526 - val_loss: 0.0443\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0372 - val_loss: 0.0225\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0352 - val_loss: 0.0216\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0303 - val_loss: 0.0165\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0275 - val_loss: 0.0134\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0254 - val_loss: 0.0117\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0110\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0125\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0115\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0211 - val_loss: 0.0107\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0253 - val_loss: 0.0162\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0164 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0133\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0107\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0115\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0109\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0124\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0098\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0100\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0111\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0111\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0125\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0095\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0086\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0091\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0146\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0137\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0105\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0112\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0114\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0097\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0109\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0104\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0109\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0092\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0113\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0123\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0086\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0092\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0140\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0070 - val_loss: 0.0130\n",
      ">Neurons=80, Score=6.082064658403397\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 130ms/step - loss: 0.1633 - val_loss: 0.0167\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0483 - val_loss: 0.0498\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0373 - val_loss: 0.0243\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0328 - val_loss: 0.0268\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0278 - val_loss: 0.0161\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0258 - val_loss: 0.0140\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0279 - val_loss: 0.0112\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0198 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0175 - val_loss: 0.0119\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0169 - val_loss: 0.0128\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0180 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0129\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0183 - val_loss: 0.0126\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0124\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0179 - val_loss: 0.0130\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0137\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0130\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0122 - val_loss: 0.0105\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0143 - val_loss: 0.0129\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0138\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0116\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0100\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0093\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0096\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0151\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0109\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0112\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0117\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0129\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0141\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0117\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0160\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0103\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0110\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0134\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0130\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0118\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0138\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0169\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0083\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0175\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0159\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0123\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0131\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 0.0138\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0106\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0094\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.0114\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0122\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0116\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      ">Neurons=80, Score=6.9239117205142975\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 94ms/step - loss: 0.1505 - val_loss: 0.0174\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0466 - val_loss: 0.0360\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0367 - val_loss: 0.0207\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0314 - val_loss: 0.0187\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0265 - val_loss: 0.0136\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0119\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0193 - val_loss: 0.0110\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0129\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0120\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0170 - val_loss: 0.0118\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0136\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0140\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0128\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0136\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0129\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0141\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0161 - val_loss: 0.0154\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0143\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0143\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0119\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0118\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0152\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0149\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0133\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0154\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0143\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0124\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0083 - val_loss: 0.0134\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0158\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0129\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0126\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 0.0209\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0096\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0140\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0182\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0146\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0160\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0151\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0159\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0162\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0156\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0177\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0153\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0139\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0150\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0168\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0198\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0177\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0097\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0121\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0094\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0132\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0139\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0187\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0151\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0136\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0154\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0170\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0178\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0163\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0155\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0146\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0149\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0161\n",
      ">Neurons=80, Score=9.830983728170395\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 94ms/step - loss: 0.1594 - val_loss: 0.0161\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0506 - val_loss: 0.0353\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0360 - val_loss: 0.0225\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0333 - val_loss: 0.0231\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0150\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0270 - val_loss: 0.0140\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0113\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0217 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0109\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0113\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0157 - val_loss: 0.0112\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0107\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0148 - val_loss: 0.0103\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0222 - val_loss: 0.0132\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0111\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0101\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0093\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0128\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0104\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0116\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0135\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0141\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0133\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0131\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0178\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0121\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0158\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0131\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0130\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0118\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0116\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0118\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0137\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0115\n",
      ">Neurons=80, Score=3.3549580723047256\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 94ms/step - loss: 0.1602 - val_loss: 0.0166\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0486 - val_loss: 0.0450\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0368 - val_loss: 0.0227\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0358 - val_loss: 0.0224\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0286 - val_loss: 0.0161\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0264 - val_loss: 0.0122\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0249 - val_loss: 0.0110\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0202 - val_loss: 0.0110\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0183 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0123\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0221 - val_loss: 0.0132\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0118\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0142\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0123\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0113\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0171\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0120\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0081 - val_loss: 0.0126\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0126\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0129\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0115\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0098\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0161 - val_loss: 0.0099\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0155\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0142\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0115\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0122\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0126\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0114\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0127\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0109\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0128\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0124\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0149\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0150\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0114\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0137\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0131\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0121\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0174\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0134\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0142\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0089\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0151\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0161\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0111\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.0117\n",
      ">Neurons=80, Score=6.1789024621248245\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 104ms/step - loss: 0.1611 - val_loss: 0.0182\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0518 - val_loss: 0.0560\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0387 - val_loss: 0.0269\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0362 - val_loss: 0.0266\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0281 - val_loss: 0.0195\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0282 - val_loss: 0.0153\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0241 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0224 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0189 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0197 - val_loss: 0.0109\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0165 - val_loss: 0.0110\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0111\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.0112\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0106\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0182 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0108\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0127\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0127 - val_loss: 0.0101\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0099\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0093\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0096\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0134\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0120\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0109\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0090\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0117\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0104\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0107\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0107\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0111\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0142\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0113\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0139\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0092\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0095\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0127\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0116\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.0107\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0118\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0126\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0154\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      ">Neurons=80, Score=4.460448399186134\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 97ms/step - loss: 0.1785 - val_loss: 0.0154\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0527 - val_loss: 0.0553\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0340 - val_loss: 0.0226\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0330 - val_loss: 0.0252\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0308 - val_loss: 0.0166\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0274 - val_loss: 0.0163\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0248 - val_loss: 0.0135\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0254 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0209 - val_loss: 0.0115\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0112\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0185 - val_loss: 0.0111\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0112\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0111\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0111\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0099\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0106\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0103\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0100\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0103\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0103\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0135\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0128\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0107\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0175\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0084 - val_loss: 0.0105\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0125\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0118\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0102\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0107\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0106\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0142\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0114\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0139\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0103\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0136\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0106\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0132\n",
      ">Neurons=80, Score=4.581701382994652\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 6s 89ms/step - loss: 0.1635 - val_loss: 0.0150\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0511 - val_loss: 0.0365\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0193\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0332 - val_loss: 0.0183\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0271 - val_loss: 0.0133\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0123\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0227 - val_loss: 0.0108\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0113\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0121\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0172 - val_loss: 0.0118\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0155 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0123\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0105\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0120\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0133\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0135 - val_loss: 0.0115\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0129\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0129\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0155 - val_loss: 0.0104\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0155\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0153\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0119\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0167 - val_loss: 0.0149\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0143\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0147\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0141\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0089 - val_loss: 0.0129\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0144\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0172\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0114\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0129\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0171\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0174\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0134\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0167\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0130\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0109\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0152\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0165\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0143\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0130\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0143\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0135\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0151\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0141\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0170 - val_loss: 0.0086\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0197\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0146\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0118\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0183\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0078 - val_loss: 0.0181\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0124\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0146\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.0169\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0148\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0128\n",
      ">Neurons=80, Score=8.200272917747498\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 100ms/step - loss: 0.1720 - val_loss: 0.0170\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0502 - val_loss: 0.0513\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0358 - val_loss: 0.0209\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0334 - val_loss: 0.0203\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0314 - val_loss: 0.0156\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0287 - val_loss: 0.0135\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0252 - val_loss: 0.0117\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0169 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0186 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0174 - val_loss: 0.0129\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0130\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0135\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0116\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0122\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0184 - val_loss: 0.0120\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0161\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0130\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0115\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0156\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0121\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0107\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0130\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0178\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0139\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0142\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0169\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0166\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0165\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0144\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0164\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0148\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0159\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0170\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0142\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0140\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0154\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0107\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0136\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0138\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0141\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0126\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0141\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0131\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0158\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0129\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0190\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0161\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0128\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0170\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0192\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0129\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0131\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0137\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0082 - val_loss: 0.0155\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0148\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0142\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0179\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0170\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0098\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      ">Neurons=80, Score=5.921440944075584\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 102ms/step - loss: 0.1559 - val_loss: 0.0185\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0479 - val_loss: 0.0394\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0361 - val_loss: 0.0218\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0351 - val_loss: 0.0241\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0266 - val_loss: 0.0166\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0268 - val_loss: 0.0134\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0223 - val_loss: 0.0118\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0222 - val_loss: 0.0109\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0109\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0181 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0113\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0159 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0109\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0102\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0098\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0106\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0120\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0202 - val_loss: 0.0152\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0176 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0177 - val_loss: 0.0101\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0107\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0175 - val_loss: 0.0154\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0095 - val_loss: 0.0121\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0115\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0092 - val_loss: 0.0129\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0112\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0118\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0089\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0168 - val_loss: 0.0091\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0140\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0147\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0102\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0087 - val_loss: 0.0113\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0166\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0122 - val_loss: 0.0152\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0074 - val_loss: 0.0158\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0156\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0138\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0123\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0151\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0086 - val_loss: 0.0130\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0071 - val_loss: 0.0111\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0153\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0082 - val_loss: 0.0111\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0123\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0135\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0153\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0151\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0193\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0071 - val_loss: 0.0122\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0169\n",
      ">Neurons=80, Score=10.03054827451706\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 118ms/step - loss: 0.1653 - val_loss: 0.0159\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0473 - val_loss: 0.0369\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0358 - val_loss: 0.0207\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0306 - val_loss: 0.0196\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0289 - val_loss: 0.0148\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0238 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0233 - val_loss: 0.0114\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0201 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0186 - val_loss: 0.0112\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0180 - val_loss: 0.0120\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0159 - val_loss: 0.0118\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0142 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0109\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0179 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0192 - val_loss: 0.0124\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0189 - val_loss: 0.0120\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0143 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0106\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0159 - val_loss: 0.0102\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0084 - val_loss: 0.0122\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0106\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0109\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0116\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0140 - val_loss: 0.0095\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0103 - val_loss: 0.0139\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0141\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0128\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0131\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0070 - val_loss: 0.0128\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0114\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0058 - val_loss: 0.0107\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0116\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0122\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0131\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0115\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0135\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0108\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0070 - val_loss: 0.0116\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0118\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0095 - val_loss: 0.0131\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0163\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0147\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0175\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0078 - val_loss: 0.0108\n",
      ">Neurons=85, Score=6.328816711902618\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 146ms/step - loss: 0.1469 - val_loss: 0.0182\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0459 - val_loss: 0.0280\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0375 - val_loss: 0.0208\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0306 - val_loss: 0.0210\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0298 - val_loss: 0.0146\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0259 - val_loss: 0.0124\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0238 - val_loss: 0.0111\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0205 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0200 - val_loss: 0.0114\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0120\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0148\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0163\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0214 - val_loss: 0.0111\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0108\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0222 - val_loss: 0.0133\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0108\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0145\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0137\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0101 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0134\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0104\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0102\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 0.0131\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0099\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0125\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0131\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0115\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0109\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0129\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0149\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0121\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0118\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0139\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0112\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0232 - val_loss: 0.0197\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0173 - val_loss: 0.0135\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0136\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0129\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0130\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0123\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0115\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 0.0115\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0123\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0126\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0124\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0065 - val_loss: 0.0116\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0087 - val_loss: 0.0124\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0186 - val_loss: 0.0191\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0091\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0127 - val_loss: 0.0090\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0132\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0076 - val_loss: 0.0148\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0163\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0130\n",
      ">Neurons=85, Score=5.799375474452972\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 100ms/step - loss: 0.1543 - val_loss: 0.0155\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0441 - val_loss: 0.0300\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0324 - val_loss: 0.0205\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0311 - val_loss: 0.0189\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0279 - val_loss: 0.0144\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0223 - val_loss: 0.0123\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0211 - val_loss: 0.0112\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0187 - val_loss: 0.0113\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0161 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0232 - val_loss: 0.0096\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0273 - val_loss: 0.0125\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0227 - val_loss: 0.0149\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0136\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0099\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0218 - val_loss: 0.0101\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 0.0092\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0209 - val_loss: 0.0153\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0107\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0103\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0097\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0101\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0098\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0081 - val_loss: 0.0094\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0093\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0097\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0129\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0193 - val_loss: 0.0104\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0134\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0086 - val_loss: 0.0098\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0090\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0084 - val_loss: 0.0122\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0098\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0110\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0083 - val_loss: 0.0092\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0153 - val_loss: 0.0087\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0140\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0128 - val_loss: 0.0086\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0094\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0109\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0071 - val_loss: 0.0111\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0104\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0098\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0113\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0059 - val_loss: 0.0095\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0105\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0044 - val_loss: 0.0108\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0064 - val_loss: 0.0091\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0108\n",
      ">Neurons=85, Score=5.837889388203621\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 143ms/step - loss: 0.1698 - val_loss: 0.0154\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0503 - val_loss: 0.0455\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0365 - val_loss: 0.0239\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0337 - val_loss: 0.0241\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0280 - val_loss: 0.0168\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0261 - val_loss: 0.0143\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0228 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0218 - val_loss: 0.0107\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0200 - val_loss: 0.0109\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0182 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0165 - val_loss: 0.0113\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0110\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0174 - val_loss: 0.0110\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0178 - val_loss: 0.0105\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0179 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0232 - val_loss: 0.0153\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0199 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0158 - val_loss: 0.0130\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0176 - val_loss: 0.0102\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0151 - val_loss: 0.0099\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0218 - val_loss: 0.0117\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0159 - val_loss: 0.0118\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0117\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0108\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0138 - val_loss: 0.0097\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0163 - val_loss: 0.0117\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0142 - val_loss: 0.0099\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0107\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0095\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0110\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0107\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0070 - val_loss: 0.0102\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0196 - val_loss: 0.0155\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0137 - val_loss: 0.0085\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0165 - val_loss: 0.0109\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0084 - val_loss: 0.0105\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0145\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0115\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0075 - val_loss: 0.0114\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0068 - val_loss: 0.0118\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0104\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0116\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0071 - val_loss: 0.0116\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0110\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0109\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0125\n",
      ">Neurons=85, Score=5.913881212472916\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 118ms/step - loss: 0.1547 - val_loss: 0.0184\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0475 - val_loss: 0.0370\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0386 - val_loss: 0.0229\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0323 - val_loss: 0.0215\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0298 - val_loss: 0.0148\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0279 - val_loss: 0.0130\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0253 - val_loss: 0.0115\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0206 - val_loss: 0.0109\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0208 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0195 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0167 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0165 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0142 - val_loss: 0.0108\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0112\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0106\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0216 - val_loss: 0.0101\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0216 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0210 - val_loss: 0.0131\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0125\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0183 - val_loss: 0.0099\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0195 - val_loss: 0.0123\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0123 - val_loss: 0.0096\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0148 - val_loss: 0.0113\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0081 - val_loss: 0.0092\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0100\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0109\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0090\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0176 - val_loss: 0.0144\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0084\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0142\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0068 - val_loss: 0.0125\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0070 - val_loss: 0.0115\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0108\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0122\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0065 - val_loss: 0.0140\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0062 - val_loss: 0.0116\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0061 - val_loss: 0.0100\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0068 - val_loss: 0.0109\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0096\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0057 - val_loss: 0.0105\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0121\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0108\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0109\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0128 - val_loss: 0.0135\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0131 - val_loss: 0.0080\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0112 - val_loss: 0.0083\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0087\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0091\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0118\n",
      ">Neurons=85, Score=7.584789395332336\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 158ms/step - loss: 0.1460 - val_loss: 0.0190\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0442 - val_loss: 0.0292\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0374 - val_loss: 0.0203\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0335 - val_loss: 0.0180\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0255 - val_loss: 0.0112\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0210 - val_loss: 0.0110\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0186 - val_loss: 0.0110\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0172 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0154 - val_loss: 0.0115\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0170 - val_loss: 0.0110\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0211 - val_loss: 0.0125\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0181 - val_loss: 0.0112\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0153 - val_loss: 0.0127\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0184 - val_loss: 0.0102\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0187 - val_loss: 0.0093\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0141 - val_loss: 0.0124\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0123 - val_loss: 0.0093\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0125 - val_loss: 0.0094\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 0.0123\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0103\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0083\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0084 - val_loss: 0.0123\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0145\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0079 - val_loss: 0.0098\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0088 - val_loss: 0.0110\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0086 - val_loss: 0.0118\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0086 - val_loss: 0.0111\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0130 - val_loss: 0.0079\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 0.0118\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0071 - val_loss: 0.0141\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 0.0147\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0070 - val_loss: 0.0112\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0073 - val_loss: 0.0090\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0068 - val_loss: 0.0128\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0110\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0109\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0077 - val_loss: 0.0106\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0116\n",
      ">Neurons=85, Score=5.495918169617653\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 139ms/step - loss: 0.1569 - val_loss: 0.0158\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0487 - val_loss: 0.0310\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0378 - val_loss: 0.0194\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0311 - val_loss: 0.0183\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0294 - val_loss: 0.0145\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0238 - val_loss: 0.0128\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0250 - val_loss: 0.0109\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0205 - val_loss: 0.0111\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0200 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0169 - val_loss: 0.0115\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0154 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0261 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0181 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0238 - val_loss: 0.0148\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0200 - val_loss: 0.0135\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0141 - val_loss: 0.0110\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0120\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0108\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0099\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0105\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0093 - val_loss: 0.0121\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.0101 - val_loss: 0.0123\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0116\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 0.0135\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0065 - val_loss: 0.0108\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0064 - val_loss: 0.0108\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0065 - val_loss: 0.0130\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0125\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0077 - val_loss: 0.0117\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0100\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0123 - val_loss: 0.0127\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.0099\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0169 - val_loss: 0.0099\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0170\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0127\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0076 - val_loss: 0.0142\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0147\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0125\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0072 - val_loss: 0.0125\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0062 - val_loss: 0.0113\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0064 - val_loss: 0.0111\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0136\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0071 - val_loss: 0.0117\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0064 - val_loss: 0.0131\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0070 - val_loss: 0.0115\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0130\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0116\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0144 - val_loss: 0.0169\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0156 - val_loss: 0.0094\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0152\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0145\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0057 - val_loss: 0.0123\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0156\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0061 - val_loss: 0.0158\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0134\n",
      ">Neurons=85, Score=3.5472191870212555\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 176ms/step - loss: 0.1684 - val_loss: 0.0157\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0527 - val_loss: 0.0372\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0386 - val_loss: 0.0202\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0362 - val_loss: 0.0204\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0309 - val_loss: 0.0136\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0250 - val_loss: 0.0126\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0227 - val_loss: 0.0111\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0217 - val_loss: 0.0111\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0201 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0179 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0168 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0141 - val_loss: 0.0128\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0141 - val_loss: 0.0113\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0162 - val_loss: 0.0106\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0183 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0215 - val_loss: 0.0136\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0165 - val_loss: 0.0107\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0186 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0104\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0097 - val_loss: 0.0114\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0154 - val_loss: 0.0109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0220 - val_loss: 0.0133\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0105\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0217 - val_loss: 0.0111\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0123 - val_loss: 0.0153\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0129\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0124\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0091 - val_loss: 0.0150\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0146\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0140\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0143 - val_loss: 0.0138\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0208 - val_loss: 0.0183\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0186 - val_loss: 0.0090\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0144 - val_loss: 0.0089\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 0.0146\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0121\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0145\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0146\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0084 - val_loss: 0.0123\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0076 - val_loss: 0.0149\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0084 - val_loss: 0.0136\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0140\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0169\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0142\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0083 - val_loss: 0.0121\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0155\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0141\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.0151\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 0.0149\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0167\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0071 - val_loss: 0.0125\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0075 - val_loss: 0.0157\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0160\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0124\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0164\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0182\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0082\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0219\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0067 - val_loss: 0.0180\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.0120\n",
      ">Neurons=85, Score=7.498051226139069\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 109ms/step - loss: 0.1687 - val_loss: 0.0159\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0473 - val_loss: 0.0359\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0350 - val_loss: 0.0212\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0300 - val_loss: 0.0188\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0279 - val_loss: 0.0141\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0257 - val_loss: 0.0121\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0234 - val_loss: 0.0115\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0188 - val_loss: 0.0117\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0183 - val_loss: 0.0120\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0168 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0151 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0148 - val_loss: 0.0131\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0159 - val_loss: 0.0127\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0124\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0118\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0164 - val_loss: 0.0116\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0178 - val_loss: 0.0127\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0116\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0110\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0184 - val_loss: 0.0123\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0160 - val_loss: 0.0105\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 0.0112\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0130\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0126\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0135\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0165\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0100\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0108 - val_loss: 0.0139\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0107\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0159\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0138 - val_loss: 0.0184\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0143\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0160\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0162\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0135\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0136\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0124\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0165\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0139\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0138\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0126\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0145\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0177\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0147 - val_loss: 0.0095\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0172\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0201\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0148\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0154\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0080 - val_loss: 0.0189\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0066 - val_loss: 0.0180\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0068 - val_loss: 0.0146\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0065 - val_loss: 0.0146\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0142\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0163\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0167\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0115\n",
      ">Neurons=85, Score=6.669246405363083\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 110ms/step - loss: 0.1606 - val_loss: 0.0154\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0476 - val_loss: 0.0419\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0315 - val_loss: 0.0232\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0306 - val_loss: 0.0234\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0284 - val_loss: 0.0161\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0273 - val_loss: 0.0133\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0242 - val_loss: 0.0111\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0206 - val_loss: 0.0109\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0196 - val_loss: 0.0113\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0167 - val_loss: 0.0119\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0130\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0184 - val_loss: 0.0103\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0173 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0226 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0237 - val_loss: 0.0108\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0177 - val_loss: 0.0137\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0189 - val_loss: 0.0150\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0123\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0138\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0136\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 0.0136\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0136 - val_loss: 0.0119\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0198 - val_loss: 0.0120\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0176 - val_loss: 0.0109\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0218 - val_loss: 0.0199\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0154 - val_loss: 0.0099\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0143\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0147\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0136\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0092 - val_loss: 0.0146\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.0162\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0141\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0125\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0159\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0172\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0108 - val_loss: 0.0195\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0173\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0135\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0137\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0146\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0177\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0126\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0201\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0177\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0131\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0083 - val_loss: 0.0134\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0141\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0149\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0067 - val_loss: 0.0163\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0152\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0162\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0193\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0082 - val_loss: 0.0183\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0155\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0160\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0125 - val_loss: 0.0172\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.0144 - val_loss: 0.0165\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0266 - val_loss: 0.0237\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0180 - val_loss: 0.0087\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0080 - val_loss: 0.0169\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0186\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0188\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0166\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0061 - val_loss: 0.0197\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0206\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0165\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0057 - val_loss: 0.0173\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0198\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0069 - val_loss: 0.0187\n",
      ">Neurons=85, Score=8.385687321424484\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 132ms/step - loss: 0.1573 - val_loss: 0.0193\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0466 - val_loss: 0.0351\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0380 - val_loss: 0.0210\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0341 - val_loss: 0.0193\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0289 - val_loss: 0.0140\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0260 - val_loss: 0.0119\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0241 - val_loss: 0.0114\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0226 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0185 - val_loss: 0.0114\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0193 - val_loss: 0.0116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0124\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0159 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0194 - val_loss: 0.0119\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0225 - val_loss: 0.0108\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0224 - val_loss: 0.0129\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0292 - val_loss: 0.0187\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0201 - val_loss: 0.0124\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0098\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 0.0095\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0208 - val_loss: 0.0087\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0225 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0218 - val_loss: 0.0106\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0209 - val_loss: 0.0114\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0097\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0074 - val_loss: 0.0090\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0142 - val_loss: 0.0088\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0137\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0094\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0068 - val_loss: 0.0096\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0078 - val_loss: 0.0090\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0098\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0099\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0102\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0086\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0127\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0111\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0097\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0103\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0085\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0065 - val_loss: 0.0114\n",
      ">Neurons=90, Score=7.683179527521133\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 102ms/step - loss: 0.1592 - val_loss: 0.0169\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0463 - val_loss: 0.0276\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0364 - val_loss: 0.0197\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0319 - val_loss: 0.0182\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0272 - val_loss: 0.0135\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0256 - val_loss: 0.0124\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0240 - val_loss: 0.0111\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0203 - val_loss: 0.0109\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0191 - val_loss: 0.0109\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0111\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0113\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0126\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0098\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0191 - val_loss: 0.0107\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0113\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0239 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0171 - val_loss: 0.0144\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0107\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0096\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0137\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0091\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0110\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0084\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0089\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.0123\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0108\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0081 - val_loss: 0.0093\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.0109\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0095\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0086\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0139 - val_loss: 0.0091\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0080\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0140 - val_loss: 0.0083\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0113 - val_loss: 0.0150\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0093\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0126\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0096\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0098\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0063 - val_loss: 0.0094\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0099\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 0.0103\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0067 - val_loss: 0.0107\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0079 - val_loss: 0.0094\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0128 - val_loss: 0.0100\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0158 - val_loss: 0.0076\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0092 - val_loss: 0.0140\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0152\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 0.0112\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0114\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0073 - val_loss: 0.0111\n",
      ">Neurons=90, Score=12.151893228292465\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 101ms/step - loss: 0.1632 - val_loss: 0.0144\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0474 - val_loss: 0.0293\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0380 - val_loss: 0.0195\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0315 - val_loss: 0.0162\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0260 - val_loss: 0.0122\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0245 - val_loss: 0.0105\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0218 - val_loss: 0.0104\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0208 - val_loss: 0.0105\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0167 - val_loss: 0.0109\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0170 - val_loss: 0.0110\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0109\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0181 - val_loss: 0.0106\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0152 - val_loss: 0.0100\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0233 - val_loss: 0.0099\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0191 - val_loss: 0.0103\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0212 - val_loss: 0.0163\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0100\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0100\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0101\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0143 - val_loss: 0.0096\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0169 - val_loss: 0.0098\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0104\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0084 - val_loss: 0.0090\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0095\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0089\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0087\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0149 - val_loss: 0.0086\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0096\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0190 - val_loss: 0.0125\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0087\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0084 - val_loss: 0.0119\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0070 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0095\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0096\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0096\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0090\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0089\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0065 - val_loss: 0.0102\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0082\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0090\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0219 - val_loss: 0.0190\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0093\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0095\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0108\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 0.0103\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0059 - val_loss: 0.0115\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0118\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0065 - val_loss: 0.0115\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0058 - val_loss: 0.0109\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0112\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0062 - val_loss: 0.0103\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0060 - val_loss: 0.0101\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 0.0107\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0134\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0065 - val_loss: 0.0105\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      ">Neurons=90, Score=5.776393413543701\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 102ms/step - loss: 0.1510 - val_loss: 0.0208\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0469 - val_loss: 0.0319\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0392 - val_loss: 0.0234\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0311 - val_loss: 0.0234\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0295 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0276 - val_loss: 0.0125\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0225 - val_loss: 0.0117\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0199 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0187 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0185 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0166 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0128\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0182 - val_loss: 0.0107\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0152 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0198 - val_loss: 0.0111\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 0.0108\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0205 - val_loss: 0.0129\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0131\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0164 - val_loss: 0.0109\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.0118\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.0105\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0098\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0091 - val_loss: 0.0131\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0144\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0123\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0107\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0138\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0125 - val_loss: 0.0126\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0167 - val_loss: 0.0134\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0142\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0179 - val_loss: 0.0088\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0150\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0110 - val_loss: 0.0147\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0135\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0083 - val_loss: 0.0135\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0134\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0126\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 0.0113\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0114\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0124\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0121\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0123\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0110\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0125\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0183 - val_loss: 0.0086\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0167\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0122\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0158\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0147\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0125\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0070 - val_loss: 0.0126\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0144\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0063 - val_loss: 0.0159\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.0139\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0109\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0077 - val_loss: 0.0123\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0079 - val_loss: 0.0127\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 0.0148\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0140\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0138\n",
      ">Neurons=90, Score=6.935671716928482\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 112ms/step - loss: 0.1474 - val_loss: 0.0251\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0449 - val_loss: 0.0288\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0386 - val_loss: 0.0255\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0315 - val_loss: 0.0223\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0280 - val_loss: 0.0151\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0245 - val_loss: 0.0128\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0204 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0210 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0175 - val_loss: 0.0121\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0161 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0164 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0195 - val_loss: 0.0109\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0147 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0227 - val_loss: 0.0114\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0108\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0228 - val_loss: 0.0149\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0109\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0165 - val_loss: 0.0112\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0104\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0104\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0139\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0136\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0117\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0124\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0127\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0119\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0117\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0121\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0127\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0099\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0125\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0154\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0160\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0116\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0150\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0162\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0143\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0108\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0069 - val_loss: 0.0143\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0132\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0117\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0134\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0144\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.0153\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0110 - val_loss: 0.0125\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0132 - val_loss: 0.0105\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0143 - val_loss: 0.0095\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0150\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0162\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0115\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0157\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0153\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0140\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0119\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0132\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0161\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0179\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0106\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0122\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0177\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0164\n",
      ">Neurons=90, Score=7.040657103061676\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 131ms/step - loss: 0.1529 - val_loss: 0.0177\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0466 - val_loss: 0.0306\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0373 - val_loss: 0.0220\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0327 - val_loss: 0.0178\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0317 - val_loss: 0.0141\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0258 - val_loss: 0.0127\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0264 - val_loss: 0.0119\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0221 - val_loss: 0.0122\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0220 - val_loss: 0.0124\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0177 - val_loss: 0.0126\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0184 - val_loss: 0.0128\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0174 - val_loss: 0.0128\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0145 - val_loss: 0.0127\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0141\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0136 - val_loss: 0.0119\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0292 - val_loss: 0.0135\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0250 - val_loss: 0.0147\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0114 - val_loss: 0.0141\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0127\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0108 - val_loss: 0.0154\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0111 - val_loss: 0.0143\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0110 - val_loss: 0.0136\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0122\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0127\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0133\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0213 - val_loss: 0.0163\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0205 - val_loss: 0.0108\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0182\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0132\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0125 - val_loss: 0.0130\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0162\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0169\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0118\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0144\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0133\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0126\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0146\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0160\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0146\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0158\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0121\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0177\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0174\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0171\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0175\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0159\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0136\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0170\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0186\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0072 - val_loss: 0.0143\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.0173\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0167\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0186\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.0171\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0180\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0101\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0185\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0178\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0124\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0191\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0199\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0170\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0070 - val_loss: 0.0167\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0148\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0215\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0173\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0188\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0158 - val_loss: 0.0195\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0134 - val_loss: 0.0135\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0194\n",
      ">Neurons=90, Score=10.091125220060349\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 98ms/step - loss: 0.1681 - val_loss: 0.0163\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0565 - val_loss: 0.0376\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0422 - val_loss: 0.0219\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0329 - val_loss: 0.0238\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0313 - val_loss: 0.0164\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0282 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0267 - val_loss: 0.0120\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0217 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0200 - val_loss: 0.0114\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0182 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0117\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0181 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0177 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0190 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0178 - val_loss: 0.0113\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0203 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0186 - val_loss: 0.0126\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0175 - val_loss: 0.0125\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0097\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0116 - val_loss: 0.0120\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0153 - val_loss: 0.0124\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0099\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0124\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0141 - val_loss: 0.0092\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0092\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0094\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0113\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0095\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0098 - val_loss: 0.0144\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0092\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0112\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0113\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0114\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0117\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0097\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0083\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.0097\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0128\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0093 - val_loss: 0.0089\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0084 - val_loss: 0.0133\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0073 - val_loss: 0.0125\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0076 - val_loss: 0.0109\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0122\n",
      ">Neurons=90, Score=4.521359503269196\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 113ms/step - loss: 0.1718 - val_loss: 0.0149\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0505 - val_loss: 0.0376\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0345 - val_loss: 0.0223\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0307 - val_loss: 0.0192\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0264 - val_loss: 0.0145\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0241 - val_loss: 0.0124\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0221 - val_loss: 0.0111\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0208 - val_loss: 0.0110\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0193 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0184 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0131 - val_loss: 0.0108\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0106\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0099\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0262 - val_loss: 0.0094\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0207 - val_loss: 0.0101\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0323 - val_loss: 0.0206\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0099\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0097\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0178 - val_loss: 0.0092\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0140 - val_loss: 0.0093\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0091\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0092\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0102\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0133 - val_loss: 0.0090\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0100\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0084\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0098 - val_loss: 0.0136\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0107\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0112 - val_loss: 0.0083\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.0098\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0124\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0119 - val_loss: 0.0082\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0078 - val_loss: 0.0146\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 0.0093\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0103\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0132\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0114\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0113\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0084 - val_loss: 0.0093\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0093\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0136\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0095\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0076 - val_loss: 0.0132\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0155\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0095\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0121\n",
      ">Neurons=90, Score=6.57094269990921\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 106ms/step - loss: 0.1567 - val_loss: 0.0178\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0483 - val_loss: 0.0333\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0360 - val_loss: 0.0230\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0298 - val_loss: 0.0201\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0301 - val_loss: 0.0155\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0256 - val_loss: 0.0127\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0235 - val_loss: 0.0115\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0198 - val_loss: 0.0113\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0194 - val_loss: 0.0115\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0176 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0169 - val_loss: 0.0118\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0127\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0124\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0235 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0170 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0236 - val_loss: 0.0143\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0167 - val_loss: 0.0125\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0144 - val_loss: 0.0132\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0133\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0168 - val_loss: 0.0099\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0189 - val_loss: 0.0103\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0210 - val_loss: 0.0104\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0116\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0168 - val_loss: 0.0143\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0114\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0136\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0120\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0122\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0152\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0128\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0188 - val_loss: 0.0100\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0147\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0176 - val_loss: 0.0133\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0096\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0100 - val_loss: 0.0140\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0086 - val_loss: 0.0128\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0083 - val_loss: 0.0112\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0122\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0132\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0133\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0125\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0080 - val_loss: 0.0128\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0126\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0144 - val_loss: 0.0095\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0160 - val_loss: 0.0090\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0182\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0138\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0078 - val_loss: 0.0139\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0133\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0082 - val_loss: 0.0166\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0079 - val_loss: 0.0144\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0135\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0118\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0122\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0148\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0125\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0165\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0140\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0121\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0140\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0167\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0119\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0128\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.0139\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0168\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0131\n",
      ">Neurons=90, Score=5.230271816253662\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 104ms/step - loss: 0.1518 - val_loss: 0.0177\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0488 - val_loss: 0.0287\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0373 - val_loss: 0.0208\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0326 - val_loss: 0.0189\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0306 - val_loss: 0.0163\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0265 - val_loss: 0.0129\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0273 - val_loss: 0.0120\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0237 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0191 - val_loss: 0.0117\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0201 - val_loss: 0.0118\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0178 - val_loss: 0.0123\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0148 - val_loss: 0.0123\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0128\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0137\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0261 - val_loss: 0.0119\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0115\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0252 - val_loss: 0.0134\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0110 - val_loss: 0.0125\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0121\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0217 - val_loss: 0.0125\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0163 - val_loss: 0.0113\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0188 - val_loss: 0.0117\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0140\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0084 - val_loss: 0.0118\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0102 - val_loss: 0.0166\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.0137\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0098\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0117 - val_loss: 0.0160\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0119\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0125\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0140\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0133\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0126\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0146\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0112\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0097\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0144\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0128\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0162\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0171\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0157\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0095 - val_loss: 0.0174\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0082 - val_loss: 0.0134\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0083 - val_loss: 0.0124\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0133\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0146\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0064 - val_loss: 0.0145\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0068 - val_loss: 0.0154\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0065 - val_loss: 0.0143\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0195\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0115\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0177 - val_loss: 0.0095\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0200\n",
      ">Neurons=90, Score=8.100592344999313\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 11s 158ms/step - loss: 0.1325 - val_loss: 0.0463\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0398 - val_loss: 0.0151\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0357 - val_loss: 0.0196\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0278 - val_loss: 0.0128\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0255 - val_loss: 0.0117\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0231 - val_loss: 0.0111\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0202 - val_loss: 0.0122\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0187 - val_loss: 0.0122\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0184 - val_loss: 0.0121\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0146 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0139\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0180 - val_loss: 0.0176\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0150 - val_loss: 0.0131\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0289 - val_loss: 0.0105\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0316 - val_loss: 0.0146\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0350 - val_loss: 0.0193\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0191 - val_loss: 0.0118\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0117 - val_loss: 0.0135\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0139\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0156\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0133 - val_loss: 0.0191\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0291 - val_loss: 0.0115\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0229 - val_loss: 0.0120\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0318 - val_loss: 0.0160\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0116 - val_loss: 0.0142\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0143\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0130\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0147\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0137\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0142\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0126\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0155\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0138\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0131\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 0.0143\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0136\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0123\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0175\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0188\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0191 - val_loss: 0.0095\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0150 - val_loss: 0.0101\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0142\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 0.0172\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0163\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0156\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0143\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0157\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0140\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0144\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0101 - val_loss: 0.0183\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0177\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0131 - val_loss: 0.0191\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0113 - val_loss: 0.0157\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0164 - val_loss: 0.0110\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0113\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0223\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0128 - val_loss: 0.0191\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0189\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0193\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0144\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0072 - val_loss: 0.0167\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0182\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0179\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0070 - val_loss: 0.0164\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0084 - val_loss: 0.0144\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0171\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0186\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0212\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0149\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0154\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0205\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0176\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0185\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0128\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0163\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0078 - val_loss: 0.0152\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0195\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0167\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0179\n",
      ">Neurons=128, Score=7.93929249048233\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 7s 107ms/step - loss: 0.1485 - val_loss: 0.0316\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0420 - val_loss: 0.0186\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0409 - val_loss: 0.0257\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0301 - val_loss: 0.0152\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0269 - val_loss: 0.0146\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0239 - val_loss: 0.0114\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0192 - val_loss: 0.0117\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0193 - val_loss: 0.0117\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0119\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0133\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0185 - val_loss: 0.0145\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0217 - val_loss: 0.0112\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0257 - val_loss: 0.0119\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0374 - val_loss: 0.0173\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0243 - val_loss: 0.0135\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0165 - val_loss: 0.0124\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0176 - val_loss: 0.0103\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0100\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0186 - val_loss: 0.0111\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0116\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 0.0099\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0141 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0155 - val_loss: 0.0103\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0122 - val_loss: 0.0104\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0127\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0123\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0086 - val_loss: 0.0108\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0091 - val_loss: 0.0117\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0104\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0125 - val_loss: 0.0092\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0088 - val_loss: 0.0109\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0131\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 0.0144\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0084 - val_loss: 0.0114\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0114\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0115\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0117\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0129\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0134\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0067 - val_loss: 0.0138\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 0.0129\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0119\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0124\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0148\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      ">Neurons=128, Score=5.123430490493774\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 113ms/step - loss: 0.1407 - val_loss: 0.0395\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0362 - val_loss: 0.0166\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0375 - val_loss: 0.0260\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0282 - val_loss: 0.0132\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0258 - val_loss: 0.0128\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0216 - val_loss: 0.0109\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0216 - val_loss: 0.0114\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0182 - val_loss: 0.0116\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0163 - val_loss: 0.0113\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0169 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0154 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0192 - val_loss: 0.0139\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0385 - val_loss: 0.0161\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0192 - val_loss: 0.0108\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0221 - val_loss: 0.0167\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0134 - val_loss: 0.0109\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0140 - val_loss: 0.0128\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0211 - val_loss: 0.0115\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0222 - val_loss: 0.0131\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0152 - val_loss: 0.0104\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0141 - val_loss: 0.0128\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0111\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0098 - val_loss: 0.0123\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0100\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0155 - val_loss: 0.0099\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0118\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0186 - val_loss: 0.0145\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0144 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0111\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0142\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0151\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0135\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0125\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0085 - val_loss: 0.0142\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0123\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0133\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0165\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0164\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0080 - val_loss: 0.0128\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0129\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0115 - val_loss: 0.0179\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0175\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0104\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0153\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0168\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0121\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0122\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0064 - val_loss: 0.0146\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0148\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0163\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0111\n",
      ">Neurons=128, Score=6.372909992933273\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 169ms/step - loss: 0.1413 - val_loss: 0.0466\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0420 - val_loss: 0.0210\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0415 - val_loss: 0.0259\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0308 - val_loss: 0.0159\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0265 - val_loss: 0.0130\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0226 - val_loss: 0.0110\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0197 - val_loss: 0.0109\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0187 - val_loss: 0.0110\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0172 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0162 - val_loss: 0.0112\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0152 - val_loss: 0.0111\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0103\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0169 - val_loss: 0.0108\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0325 - val_loss: 0.0107\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0267 - val_loss: 0.0104\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0305 - val_loss: 0.0191\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0159 - val_loss: 0.0112\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0141 - val_loss: 0.0103\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0194 - val_loss: 0.0104\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0159 - val_loss: 0.0101\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0187 - val_loss: 0.0155\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0154 - val_loss: 0.0147\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0150 - val_loss: 0.0098\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0123\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0118\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 0.0116\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0138 - val_loss: 0.0118\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0215 - val_loss: 0.0177\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0171 - val_loss: 0.0094\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0169 - val_loss: 0.0096\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0083 - val_loss: 0.0113\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0145\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0133\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0136\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 0.0134\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0083 - val_loss: 0.0140\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0145\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0070 - val_loss: 0.0128\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0071 - val_loss: 0.0126\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0123\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0116\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 0.0148\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0146\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0154\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 0.0097\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0140 - val_loss: 0.0092\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0117\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0170\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.0171\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0128\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0148\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0158\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0114\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0120\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.0155\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0166\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0089 - val_loss: 0.0148\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0130\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0150\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0145\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0126\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0157\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0170\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0135\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0120\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0158\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0080 - val_loss: 0.0183\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0163\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0123\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0132\n",
      ">Neurons=128, Score=8.30233171582222\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s 132ms/step - loss: 0.1315 - val_loss: 0.0473\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0411 - val_loss: 0.0164\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0397 - val_loss: 0.0240\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0283 - val_loss: 0.0143\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0252 - val_loss: 0.0128\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0234 - val_loss: 0.0114\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0211 - val_loss: 0.0114\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0185 - val_loss: 0.0124\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0121\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0153 - val_loss: 0.0126\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0171 - val_loss: 0.0119\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0189 - val_loss: 0.0110\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0165 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0260 - val_loss: 0.0116\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0188 - val_loss: 0.0114\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0208 - val_loss: 0.0130\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0184 - val_loss: 0.0115\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0171 - val_loss: 0.0111\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0129 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0178 - val_loss: 0.0117\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0165 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0213 - val_loss: 0.0119\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0223 - val_loss: 0.0164\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0194 - val_loss: 0.0107\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0117\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0127\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0121\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0095 - val_loss: 0.0125\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0126\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0088 - val_loss: 0.0135\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0126\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0121\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0141\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0122\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0229 - val_loss: 0.0157\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0094\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0193 - val_loss: 0.0128\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0123\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0161\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0086 - val_loss: 0.0132\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0077 - val_loss: 0.0124\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0140\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0137\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0122\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0135\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0108\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0128\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 0.0156\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.0148\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0222 - val_loss: 0.0163\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0212 - val_loss: 0.0111\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0211 - val_loss: 0.0134\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0150\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0059 - val_loss: 0.0139\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0146\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0150\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0146\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0134\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0138\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0068 - val_loss: 0.0154\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0070 - val_loss: 0.0141\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0076 - val_loss: 0.0127\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0146\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0129\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0123\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0089 - val_loss: 0.0121\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0082 - val_loss: 0.0156\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0108 - val_loss: 0.0146\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0130\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0076 - val_loss: 0.0118\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0158\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0169\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0155\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0112 - val_loss: 0.0170\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0128\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0124\n",
      ">Neurons=128, Score=6.1579205095767975\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 142ms/step - loss: 0.1386 - val_loss: 0.0389\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0412 - val_loss: 0.0155\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0397 - val_loss: 0.0234\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0299 - val_loss: 0.0121\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0243 - val_loss: 0.0115\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0205 - val_loss: 0.0114\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0191 - val_loss: 0.0116\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0168 - val_loss: 0.0139\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0157 - val_loss: 0.0126\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0227 - val_loss: 0.0108\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0164 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0251 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0188 - val_loss: 0.0110\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0242 - val_loss: 0.0150\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0187 - val_loss: 0.0137\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0191 - val_loss: 0.0111\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0141 - val_loss: 0.0113\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0138\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0152\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0166 - val_loss: 0.0112\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0106 - val_loss: 0.0136\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0173\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0123\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0101 - val_loss: 0.0138\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0146\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0143\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0141\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0101 - val_loss: 0.0154\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0191\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0091 - val_loss: 0.0148\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0138\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0135\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0101 - val_loss: 0.0151\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0162\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 0.0092 - val_loss: 0.0124\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0129\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0172\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0176\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0154\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.0175\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0150\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0132 - val_loss: 0.0164\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0112\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0117 - val_loss: 0.0132\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0175\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0183\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0139\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.0166\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0192\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0090 - val_loss: 0.0162\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0126\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0096 - val_loss: 0.0162\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0187\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0064 - val_loss: 0.0172\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0080 - val_loss: 0.0190\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0066 - val_loss: 0.0174\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0085 - val_loss: 0.0155\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0156\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0076 - val_loss: 0.0172\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0110 - val_loss: 0.0171\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0157\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0270\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0086 - val_loss: 0.0207\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0079 - val_loss: 0.0130\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0071 - val_loss: 0.0152\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0196\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0202\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0063 - val_loss: 0.0176\n",
      ">Neurons=128, Score=9.265728294849396\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 13s 167ms/step - loss: 0.1384 - val_loss: 0.0474\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0396 - val_loss: 0.0165\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0371 - val_loss: 0.0247\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0279 - val_loss: 0.0129\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0257 - val_loss: 0.0123\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0228 - val_loss: 0.0110\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0214 - val_loss: 0.0113\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0173 - val_loss: 0.0119\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 0.0121\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0141 - val_loss: 0.0120\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0144 - val_loss: 0.0123\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0146 - val_loss: 0.0118\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0193 - val_loss: 0.0145\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0183 - val_loss: 0.0117\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0306 - val_loss: 0.0124\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0304 - val_loss: 0.0157\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0305 - val_loss: 0.0174\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0161 - val_loss: 0.0104\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0134 - val_loss: 0.0112\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0168 - val_loss: 0.0101\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0180 - val_loss: 0.0100\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0199 - val_loss: 0.0168\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0143 - val_loss: 0.0107\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0174 - val_loss: 0.0102\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0130\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0145\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0079 - val_loss: 0.0133\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0129\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0167\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0092\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0172 - val_loss: 0.0097\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0134 - val_loss: 0.0177\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0078 - val_loss: 0.0130\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0138\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0099 - val_loss: 0.0157\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0142\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0170\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0133\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0151\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0135 - val_loss: 0.0178\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0097\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 0.0127\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0107 - val_loss: 0.0168\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0086 - val_loss: 0.0145\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0127\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0142\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0095 - val_loss: 0.0151\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0126\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0138\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0088 - val_loss: 0.0161\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0106 - val_loss: 0.0167\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0124\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0083 - val_loss: 0.0145\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0164\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0119\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0185\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0158\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0079 - val_loss: 0.0134\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0068 - val_loss: 0.0162\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0163\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0161\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 0.0123\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0144\n",
      ">Neurons=128, Score=5.620399489998817\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 13s 171ms/step - loss: 0.1341 - val_loss: 0.0406\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0423 - val_loss: 0.0150\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0385 - val_loss: 0.0233\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0274 - val_loss: 0.0127\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0246 - val_loss: 0.0114\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0202 - val_loss: 0.0110\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0172 - val_loss: 0.0113\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0180 - val_loss: 0.0115\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.0161 - val_loss: 0.0113\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0162 - val_loss: 0.0119\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0229 - val_loss: 0.0112\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.0161 - val_loss: 0.0107\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0324 - val_loss: 0.0159\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0197 - val_loss: 0.0106\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0202 - val_loss: 0.0142\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0119 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0121 - val_loss: 0.0139\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0160 - val_loss: 0.0163\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0223 - val_loss: 0.0111\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0215 - val_loss: 0.0120\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0232 - val_loss: 0.0127\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0116 - val_loss: 0.0141\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.0114 - val_loss: 0.0142\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 2s 103ms/step - loss: 0.0098 - val_loss: 0.0133\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0148 - val_loss: 0.0132\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0098 - val_loss: 0.0139\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0096 - val_loss: 0.0130\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0118\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0142\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0136\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0129 - val_loss: 0.0111\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0100 - val_loss: 0.0141\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0094 - val_loss: 0.0121\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.0149\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0147\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0098 - val_loss: 0.0126\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0076 - val_loss: 0.0142\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0083 - val_loss: 0.0140\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0079 - val_loss: 0.0151\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0091 - val_loss: 0.0148\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0093 - val_loss: 0.0130\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0078 - val_loss: 0.0147\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0150 - val_loss: 0.0089\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0130 - val_loss: 0.0103\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0094 - val_loss: 0.0151\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0116 - val_loss: 0.0176\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0096 - val_loss: 0.0126\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0145\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0179\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0076 - val_loss: 0.0148\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0076 - val_loss: 0.0153\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0066 - val_loss: 0.0149\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0172\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0067 - val_loss: 0.0133\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0067 - val_loss: 0.0153\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0148\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0187\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0083 - val_loss: 0.0148\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0106\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0143 - val_loss: 0.0088\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0145\n",
      ">Neurons=128, Score=10.52643433213234\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 20s 181ms/step - loss: 0.1366 - val_loss: 0.0388\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0423 - val_loss: 0.0163\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0400 - val_loss: 0.0255\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0299 - val_loss: 0.0132\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0285 - val_loss: 0.0126\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0190 - val_loss: 0.0122\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0182 - val_loss: 0.0123\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0173 - val_loss: 0.0124\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0159 - val_loss: 0.0117\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0145 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0139 - val_loss: 0.0136\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0185 - val_loss: 0.0159\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0175 - val_loss: 0.0144\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0222 - val_loss: 0.0136\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0279 - val_loss: 0.0177\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0261 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0206 - val_loss: 0.0114\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0136\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0140\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0143\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0109 - val_loss: 0.0137\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0155\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0140\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 0.0121\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0112\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0137 - val_loss: 0.0186\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0175 - val_loss: 0.0166\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.0137\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0316 - val_loss: 0.0206\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0208 - val_loss: 0.0098\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0165 - val_loss: 0.0105\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0094 - val_loss: 0.0150\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0153\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0092 - val_loss: 0.0145\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 0.0141\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 0.0145\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 0.0144\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0082 - val_loss: 0.0145\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0146\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0132\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0163\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0161\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0133\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0159\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0194 - val_loss: 0.0120\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0171 - val_loss: 0.0137\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0224 - val_loss: 0.0265\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0161 - val_loss: 0.0129\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0086 - val_loss: 0.0154\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0084 - val_loss: 0.0185\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0078 - val_loss: 0.0157\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0139\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0168\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0092 - val_loss: 0.0168\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0079 - val_loss: 0.0151\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0148\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0152\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0180\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0158\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0143\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0161\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0151\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0139 - val_loss: 0.0175\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0114\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0155\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0222\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0111 - val_loss: 0.0159\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0151\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0217\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0080 - val_loss: 0.0178\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.0155\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0186\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0208\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0158\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0131\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0141\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0188\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0195\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0094 - val_loss: 0.0154\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0107 - val_loss: 0.0177\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0082 - val_loss: 0.0175\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0223\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0152\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0158\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.0187\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0204\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0169\n",
      ">Neurons=128, Score=8.182083815336227\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 126ms/step - loss: 0.1375 - val_loss: 0.0377\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0425 - val_loss: 0.0158\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0398 - val_loss: 0.0241\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0319 - val_loss: 0.0135\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0268 - val_loss: 0.0128\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0237 - val_loss: 0.0111\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0206 - val_loss: 0.0110\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0180 - val_loss: 0.0112\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0150 - val_loss: 0.0114\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0201 - val_loss: 0.0106\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0164 - val_loss: 0.0106\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0285 - val_loss: 0.0113\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0280 - val_loss: 0.0123\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0214 - val_loss: 0.0152\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0128\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0142 - val_loss: 0.0107\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0117\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0177 - val_loss: 0.0114\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0177 - val_loss: 0.0101\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0121\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0123\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0110\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0096 - val_loss: 0.0125\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0126 - val_loss: 0.0139\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0095 - val_loss: 0.0112\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0137\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0125\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0114\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0119 - val_loss: 0.0153\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0123\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0130\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0077 - val_loss: 0.0112\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0074 - val_loss: 0.0136\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0083 - val_loss: 0.0124\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0084 - val_loss: 0.0124\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0129\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0090\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0170\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0147\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0073 - val_loss: 0.0135\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0065 - val_loss: 0.0132\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0135\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0073 - val_loss: 0.0152\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0108\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0106\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0127\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0089 - val_loss: 0.0129\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0177\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0118\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      ">Neurons=128, Score=3.9115488529205322\n",
      "[[5.672363564372063, 1.6147186979651451, 5.6682489812374115, 1.4403642155230045, 9.120629727840424, 5.450265109539032, 3.42954657971859, 1.4438476413488388, 4.566820710897446, 13.49465548992157], [8.89650359749794, 5.359985306859016, 2.0847585052251816, 1.773475669324398, 5.718584358692169, 5.088987201452255, 9.114816784858704, 5.672546103596687, 4.059556871652603, 8.344908058643341], [7.338289171457291, 4.469933360815048, 6.642527878284454, 9.335146099328995, 5.616345256567001, 2.3226553574204445, 5.106941610574722, 4.743320122361183, 3.8926422595977783, 6.342935562133789], [5.150559917092323, 5.320939049124718, 3.886830061674118, 9.686536341905594, 3.902699798345566, 3.8598813116550446, 2.5146933272480965, 8.695437014102936, 5.5364590138196945, 5.154946818947792], [2.979215793311596, 5.2272118628025055, 4.374272003769875, 3.4019730985164642, 5.113505572080612, 4.9021851271390915, 9.581097960472107, 5.748538300395012, 8.060239255428314, 5.567954480648041], [3.058912977576256, 2.874145470559597, 7.901310175657272, 5.551619455218315, 7.5530849397182465, 5.861740931868553, 10.41593998670578, 6.96827620267868, 4.068382829427719, 3.9674513041973114], [6.082064658403397, 6.9239117205142975, 9.830983728170395, 3.3549580723047256, 6.1789024621248245, 4.460448399186134, 4.581701382994652, 8.200272917747498, 5.921440944075584, 10.03054827451706], [6.328816711902618, 5.799375474452972, 5.837889388203621, 5.913881212472916, 7.584789395332336, 5.495918169617653, 3.5472191870212555, 7.498051226139069, 6.669246405363083, 8.385687321424484], [7.683179527521133, 12.151893228292465, 5.776393413543701, 6.935671716928482, 7.040657103061676, 10.091125220060349, 4.521359503269196, 6.57094269990921, 5.230271816253662, 8.100592344999313], [7.93929249048233, 5.123430490493774, 6.372909992933273, 8.30233171582222, 6.1579205095767975, 9.265728294849396, 5.620399489998817, 10.52643433213234, 8.182083815336227, 3.9115488529205322]] [32, 60, 64, 65, 70, 75, 80, 85, 90, 128]\n",
      "Param=32, Mean=5.190, Std=3.596\n",
      "Param=60, Mean=5.611, Std=2.459\n",
      "Param=64, Mean=5.581, Std=1.858\n",
      "Param=65, Mean=5.371, Std=2.112\n",
      "Param=70, Mean=5.496, Std=1.894\n",
      "Param=75, Mean=5.822, Std=2.295\n",
      "Param=80, Mean=6.557, Std=2.120\n",
      "Param=85, Mean=6.306, Std=1.281\n",
      "Param=90, Mean=7.410, Std=2.169\n",
      "Param=128, Mean=7.140, Std=1.934\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, neurons):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=4, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=4)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # resumindo a média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = np.mean(scores[i]), np.std(scores[i])\n",
    "        print(f'Param={params[i]}, Mean={m:.3f}, Std={s:.3f}')\n",
    "    # boxplot das pontuações\n",
    "    plt.boxplot(scores, labels=params)\n",
    "    plt.savefig('../../src/static/images/despesas/figura[0].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repetindo o experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            score = score * 100.0\n",
    "            scores.append(score)\n",
    "            print(f'>Neurons={p}, Score={score}')\n",
    "        all_scores.append(scores)\n",
    "    # resumindo os resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = [32, 60, 64, 65, 70, 75, 80, 85, 90, 128]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste de modelo com tamanho do lote 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 e 12, para verificação do mais adequado para a aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 8s 32ms/step - loss: 0.0782 - val_loss: 0.0149\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0318 - val_loss: 0.0126\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0151\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0217\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0117\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0107\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0103\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0102\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0207\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0136\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0123\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0099 - val_loss: 0.0269\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0163\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0180\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0291\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0415\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0265\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0512\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0407\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0428\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0648\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0488\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0432\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0536\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0493\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0746\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0490\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0669\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0076 - val_loss: 0.0519\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0074 - val_loss: 0.0576\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0588\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0210\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0541\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0468\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0556\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0400\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0583\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0400\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0568\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0660\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.0589\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0333\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0398\n",
      ">p=1: 1, Score=10.008285939693451\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 7s 29ms/step - loss: 0.0725 - val_loss: 0.0151\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0319 - val_loss: 0.0129\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0203 - val_loss: 0.0149\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0314\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0219\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0107\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0134\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0106\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0137\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0231\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0225\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0152\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0088\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0212\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0103 - val_loss: 0.0167\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0300\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0282\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0101 - val_loss: 0.0386\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0274\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.0221\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0083 - val_loss: 0.0446\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0093 - val_loss: 0.0211\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0256\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0315\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0146\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0091\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0161\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0187\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0143\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0519\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0457\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0522\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0778\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0076 - val_loss: 0.0947\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0720\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0534\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0476\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.0532\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0346\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0083 - val_loss: 0.0231\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0155\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0209\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0236\n",
      ">p=1: 2, Score=10.408152639865875\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 8s 24ms/step - loss: 0.0732 - val_loss: 0.0158\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0338 - val_loss: 0.0129\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0268 - val_loss: 0.0136\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0116\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0104\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0153\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0119 - val_loss: 0.0222\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.0166\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0216\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0097 - val_loss: 0.0134\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0214\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0187\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0188\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0241\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0601\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0431\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0385\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0333\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0273\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0235\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0260\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0165\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0360\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0486\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0081 - val_loss: 0.0399\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0479\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0212\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0270\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0055 - val_loss: 0.0421\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0298\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0461\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0358\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0606\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0077 - val_loss: 0.0587\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0599\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0633\n",
      ">p=1: 3, Score=22.148998081684113\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 6s 24ms/step - loss: 0.0776 - val_loss: 0.0164\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0321 - val_loss: 0.0128\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0250 - val_loss: 0.0115\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0116\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0125\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0127\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0141\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0303\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0167\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0134\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0238\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0197\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0255\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0435\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0263\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0091 - val_loss: 0.0133\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0211\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0135 - val_loss: 0.0161\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0080 - val_loss: 0.0136\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0181\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0153\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0570\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0407\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0083 - val_loss: 0.0523\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0776\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0089 - val_loss: 0.0534\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0608\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0410\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0540\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0395\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0545\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0246\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0595\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0279\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0516\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0380\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0538\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0053 - val_loss: 0.0374\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0731\n",
      ">p=1: 4, Score=23.787890374660492\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 11s 33ms/step - loss: 0.0787 - val_loss: 0.0159\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0332 - val_loss: 0.0129\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0122\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0217 - val_loss: 0.0196\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0204 - val_loss: 0.0149\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0115\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0136\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0113\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0179\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0113 - val_loss: 0.0227\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0208\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0144\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0113 - val_loss: 0.0169\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0151\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0220\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0194\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0171\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0346\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0209\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0185\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.0186\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0148\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0296\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0457\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0637\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0475\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0591\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0513\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0542\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0392\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0479\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0463\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0470\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0276\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0056 - val_loss: 0.0211\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0299\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0420\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0846\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.1075\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0642\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0079 - val_loss: 0.0584\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0472\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0251\n",
      ">p=1: 5, Score=10.526014864444733\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 8s 33ms/step - loss: 0.0741 - val_loss: 0.0141\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0314 - val_loss: 0.0123\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0239 - val_loss: 0.0149\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0203\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0133\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0109\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0106\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0134 - val_loss: 0.0166\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0201\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0332\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0382\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0725\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0315\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0425\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0238\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0196\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0103 - val_loss: 0.0160\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0173\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0193\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0396\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0506\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0536\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0407\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0599\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0108 - val_loss: 0.0726\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0089 - val_loss: 0.0337\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0360\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0302\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0324\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0196\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0077 - val_loss: 0.0352\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0053 - val_loss: 0.0406\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0426\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0173\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0353\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0249\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0206\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0294\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0263\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0308\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0551\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0345\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0284\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0267\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0559\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0570\n",
      ">p=1: 6, Score=20.20866721868515\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 8s 28ms/step - loss: 0.0773 - val_loss: 0.0153\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0333 - val_loss: 0.0128\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0269 - val_loss: 0.0117\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0215 - val_loss: 0.0125\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0134\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0111\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0175 - val_loss: 0.0113\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0173 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0132 - val_loss: 0.0130\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0166\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0268\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0314\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0112 - val_loss: 0.0167\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0188\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0162 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0106 - val_loss: 0.0220\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0107 - val_loss: 0.0154\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0100 - val_loss: 0.0249\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0117 - val_loss: 0.0293\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0100 - val_loss: 0.0316\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0289\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0087 - val_loss: 0.0430\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0109 - val_loss: 0.0358\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0082 - val_loss: 0.0198\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0191\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0211\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0079 - val_loss: 0.0261\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0237\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0168\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0174\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0058 - val_loss: 0.0243\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0237\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0078 - val_loss: 0.0282\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0087 - val_loss: 0.0498\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0084 - val_loss: 0.0664\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0266\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0117 - val_loss: 0.0253\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0197\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0207\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0056 - val_loss: 0.0146\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0157\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0150\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0066\n",
      ">p=1: 7, Score=1.7686773091554642\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 6s 23ms/step - loss: 0.0760 - val_loss: 0.0149\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0320 - val_loss: 0.0123\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0149\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0204\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0319\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0116\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0103\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0106\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0161 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0131\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0273\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0224\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0113 - val_loss: 0.0439\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.0225\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0113 - val_loss: 0.0166\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0169\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0123 - val_loss: 0.0088\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0140\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0192\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0090 - val_loss: 0.0281\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0076 - val_loss: 0.0293\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0332\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0676\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0469\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0328\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0228\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0089 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0069\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0203\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0290\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0296\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0567\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0694\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0800\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0856\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.1112\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.0593\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0527\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0407\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0307\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0271\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0200\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0326\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0176\n",
      ">p=1: 8, Score=10.360205918550491\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 7s 27ms/step - loss: 0.0769 - val_loss: 0.0153\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0331 - val_loss: 0.0125\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0229 - val_loss: 0.0175\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0186\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0185\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0115\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0103\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0139\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0139\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0233\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0220\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0273\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0209\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0119 - val_loss: 0.0205\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0117 - val_loss: 0.0091\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0103 - val_loss: 0.0166\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0141\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0243\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0098 - val_loss: 0.0152\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0226\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0093 - val_loss: 0.0308\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0258\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0311\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0414\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0335\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0293\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0167\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0271\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0169\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0409\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0094 - val_loss: 0.0423\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0440\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0410\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0089 - val_loss: 0.0266\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0466\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0076 - val_loss: 0.0526\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0409\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0389\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0531\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0492\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0074 - val_loss: 0.0516\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0631\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0707\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0520\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0613\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0091 - val_loss: 0.0451\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0383\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0113\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0107\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0121\n",
      ">p=1: 9, Score=11.193948239088058\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 7s 29ms/step - loss: 0.0759 - val_loss: 0.0167\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0340 - val_loss: 0.0124\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0252 - val_loss: 0.0116\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0121\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0116\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0104\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0099\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0115 - val_loss: 0.0080\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0089\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0089\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0107 - val_loss: 0.0217\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0191\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0288\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0399\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0289\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0106 - val_loss: 0.0143\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0197\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0162\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0120\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0215\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0062 - val_loss: 0.0311\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0464\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0506\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0392\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0419\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0525\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0086 - val_loss: 0.0640\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0266\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0208\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0190\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0184\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0177\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0134\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0207\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0262\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0350\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0316\n",
      ">p=1: 10, Score=6.501810252666473\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 7s 61ms/step - loss: 0.1218 - val_loss: 0.0362\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0353 - val_loss: 0.0146\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0304 - val_loss: 0.0120\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0112\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0109\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0110\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0156\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0127\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0085\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0095\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0182\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 0.0207\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0256\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0295\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0420\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0359\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0187\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0207\n",
      ">p=2: 1, Score=10.47384962439537\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 7s 54ms/step - loss: 0.1082 - val_loss: 0.0213\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0282 - val_loss: 0.0129\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0123\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0120\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0131\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0141\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0140\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0150\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0135\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0159\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0131\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0128\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0139\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0136\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0160\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0095\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0081\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0085\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0148\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0123\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0167\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0223\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0309\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0121\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0170\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0094 - val_loss: 0.0124\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0196\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0115\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0120\n",
      ">p=2: 2, Score=5.188873782753944\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 7s 49ms/step - loss: 0.1100 - val_loss: 0.0265\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0350 - val_loss: 0.0133\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0279 - val_loss: 0.0118\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0110\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.0112\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0124\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0138\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0107\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0163\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0197\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0249\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0259\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0200\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0104\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0177\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0167\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0164\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0166\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0196\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0130\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0165\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0201\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0267\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0194\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0147\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0217\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0150\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0185\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0196\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0144\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0169\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0144\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0137\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0321\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0150\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0137\n",
      ">p=2: 3, Score=7.026178389787674\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 9s 54ms/step - loss: 0.1270 - val_loss: 0.0357\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0342 - val_loss: 0.0166\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0278 - val_loss: 0.0129\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0114\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0113\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0134\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0113\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0110\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0090\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0084\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0093\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0094\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0183\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0089\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      ">p=2: 4, Score=1.359060127288103\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 7s 47ms/step - loss: 0.1185 - val_loss: 0.0320\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0153\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0132\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0276 - val_loss: 0.0121\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.0117\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0121\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0137\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0108\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0128\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0161\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0147\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0162\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0156\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0239\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0229\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0105\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0121\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0207\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0137\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0290\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0163\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0137\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0189\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0164\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0171\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0127\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0148\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0145\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0147\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0101\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0181\n",
      ">p=2: 5, Score=6.324540078639984\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 7s 46ms/step - loss: 0.1102 - val_loss: 0.0258\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0133\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0303 - val_loss: 0.0120\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0114\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0113\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0132\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0129\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0117\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0166\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0084\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0214\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0222\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0329\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0352\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0336\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0321\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0473\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0241\n",
      ">p=2: 6, Score=15.890179574489594\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 7s 44ms/step - loss: 0.1073 - val_loss: 0.0274\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0341 - val_loss: 0.0155\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0279 - val_loss: 0.0123\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0110\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0108\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0113\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0192 - val_loss: 0.0124\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0119\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0136\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0129\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0130\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0135\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0137\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0183\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0092\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0135\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0167\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0133\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0172\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0149\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0161\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0095\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0162\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0203\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0302\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0063\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0070\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0088\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0082\n",
      ">p=2: 7, Score=2.708166651427746\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 6s 45ms/step - loss: 0.1090 - val_loss: 0.0294\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0341 - val_loss: 0.0140\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0298 - val_loss: 0.0126\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0115\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0112\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0113\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0112\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0112\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0135\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0109\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0109\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0103\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0095\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0105\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0104\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0089\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0084 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0077\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0132\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0081\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0142\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0080\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0128\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0155\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0188\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0164\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0063\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0083\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      ">p=2: 8, Score=5.282311886548996\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 7s 47ms/step - loss: 0.1162 - val_loss: 0.0336\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0351 - val_loss: 0.0143\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0301 - val_loss: 0.0127\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0273 - val_loss: 0.0116\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0114\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0112\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0113\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0119\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0136\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0091\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0089\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0127\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0172\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0084\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0076\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0107\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0135\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0055\n",
      ">p=2: 9, Score=4.251116141676903\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 8s 64ms/step - loss: 0.1232 - val_loss: 0.0342\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0314 - val_loss: 0.0140\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0280 - val_loss: 0.0127\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.0122\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.0111\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.0111\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0112\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0140\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0103\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0095\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0140\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0189\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0122\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0245\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0111\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0208\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0166\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0140\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0179\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0225\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0126\n",
      ">p=2: 10, Score=9.529805183410645\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 7s 75ms/step - loss: 0.1461 - val_loss: 0.0332\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0419 - val_loss: 0.0197\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0412 - val_loss: 0.0245\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0144\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0122\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0113\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0202 - val_loss: 0.0115\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0124\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0123\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0154\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0173\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0359 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0220 - val_loss: 0.0123\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0132\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0145\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0142\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0160\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0212\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0209\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0106\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0109\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0129\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0105\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0120\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0127\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0139\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0139\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0165\n",
      ">p=3: 1, Score=5.373033508658409\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 6s 71ms/step - loss: 0.1463 - val_loss: 0.0341\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0440 - val_loss: 0.0225\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0411 - val_loss: 0.0294\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0318 - val_loss: 0.0181\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.0148\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0246 - val_loss: 0.0125\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0125\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0221 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0123\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0125\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0128\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0126\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0137\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0155\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0111\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0127\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0109\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0123\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      ">p=3: 2, Score=3.1323738396167755\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 7s 98ms/step - loss: 0.1354 - val_loss: 0.0327\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0416 - val_loss: 0.0161\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0406 - val_loss: 0.0229\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0281 - val_loss: 0.0136\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0259 - val_loss: 0.0118\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0111\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.0112\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0124\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0140\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0132\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0202\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0270\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0147\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0106\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0133\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0150\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0198\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0167\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0143\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0169\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0192\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0135\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0100\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0135\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.0133\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0200 - val_loss: 0.0124\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0147\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0163\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0138\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0173\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0192\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0156\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0147\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0178\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0182\n",
      ">p=3: 3, Score=6.38791099190712\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 7s 70ms/step - loss: 0.1383 - val_loss: 0.0391\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0163\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0405 - val_loss: 0.0256\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0137\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0115\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0110\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0116\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0116\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0182\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0160\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0133\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0107\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0375 - val_loss: 0.0106\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0106\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.0127\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0111\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.0189 - val_loss: 0.0160\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0143\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0125\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0115\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0109\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0142\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0159\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0168\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0195\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0162\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0109\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0106\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      ">p=3: 4, Score=4.257103428244591\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 7s 67ms/step - loss: 0.1408 - val_loss: 0.0404\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0463 - val_loss: 0.0223\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0410 - val_loss: 0.0282\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0168\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0275 - val_loss: 0.0139\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0113\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 0.0111\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0112\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0136\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0125\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0106\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0263 - val_loss: 0.0132\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0107\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0110\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0252 - val_loss: 0.0109\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.0171 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.0171 - val_loss: 0.0109\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0107\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0108\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0106\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0100\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0107\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0100\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0118\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0153\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      ">p=3: 5, Score=6.988023221492767\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 7s 94ms/step - loss: 0.1376 - val_loss: 0.0454\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0378 - val_loss: 0.0182\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0392 - val_loss: 0.0226\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0293 - val_loss: 0.0135\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0261 - val_loss: 0.0114\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0113\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0201 - val_loss: 0.0108\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0186 - val_loss: 0.0110\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0171 - val_loss: 0.0177\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0252\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0161\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0097\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0291 - val_loss: 0.0107\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0226 - val_loss: 0.0107\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0105\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0146\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0096\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0133\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0123\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0142\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0156\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0160\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0126\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0125\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0140\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0155\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0141\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0108\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0136\n",
      ">p=3: 6, Score=6.305281072854996\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 6s 67ms/step - loss: 0.1404 - val_loss: 0.0422\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.0200\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0404 - val_loss: 0.0238\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0283 - val_loss: 0.0164\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0122\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0113\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0110\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0109\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0108\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0128\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0098\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0131\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0136\n",
      ">p=3: 7, Score=5.4221101105213165\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 7s 82ms/step - loss: 0.1377 - val_loss: 0.0349\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0396 - val_loss: 0.0212\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0384 - val_loss: 0.0265\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0319 - val_loss: 0.0152\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0271 - val_loss: 0.0117\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0111\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0113\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0135\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0136\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0188\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0152\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0330 - val_loss: 0.0100\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0102\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.0108\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0111\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0160\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0098\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.0098\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0113\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0105\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0103\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0125\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0122\n",
      ">p=3: 8, Score=5.296016111969948\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 7s 61ms/step - loss: 0.1252 - val_loss: 0.0404\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0153\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0387 - val_loss: 0.0183\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0123\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.0116\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0114\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.0119\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0131\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0148\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0252\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0274\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0226 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0102\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0225 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0107\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0107\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0146\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0138\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0163\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0130\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0199\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0208\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0161\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0112\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0181\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0160\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0133\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0196\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0196\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0139\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0133\n",
      ">p=3: 9, Score=5.180847644805908\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 6s 66ms/step - loss: 0.1320 - val_loss: 0.0368\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0378 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0351 - val_loss: 0.0187\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0287 - val_loss: 0.0120\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0112\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0135\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0123\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0128\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0130\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0144\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0182\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.0267\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0337\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.0196\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0332 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0314 - val_loss: 0.0171\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0107\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0136\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0158\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0155\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0139\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0192\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0148\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0151\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0135\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0174\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0200\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0210\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0111\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0130\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0247\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0222\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0155\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0166\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0137\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0132\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0163\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0185\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0200\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0197\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0183\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0207\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0186\n",
      ">p=3: 10, Score=13.130475580692291\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 7s 91ms/step - loss: 0.1699 - val_loss: 0.0161\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0537 - val_loss: 0.0484\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0372 - val_loss: 0.0237\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0356 - val_loss: 0.0228\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0298 - val_loss: 0.0161\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0288 - val_loss: 0.0153\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0122\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0120\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0200 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0106\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0228 - val_loss: 0.0106\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0144\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0111\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0108\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.0108\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0110\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      ">p=4: 1, Score=3.6312203854322433\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 8s 117ms/step - loss: 0.1653 - val_loss: 0.0151\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0458 - val_loss: 0.0311\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.0181\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0329 - val_loss: 0.0157\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0126\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0235 - val_loss: 0.0110\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0109\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 0.0120\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0165 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0126\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0133\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0131\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0119\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0196 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0166\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0165\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0107\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0160\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0159\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0118\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0147\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0164\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0155\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0124\n",
      ">p=4: 2, Score=4.762069880962372\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 6s 94ms/step - loss: 0.1559 - val_loss: 0.0172\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0503 - val_loss: 0.0423\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0364 - val_loss: 0.0230\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0349 - val_loss: 0.0223\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0298 - val_loss: 0.0170\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0275 - val_loss: 0.0137\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0116\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0112\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.0112\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0123\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0160\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0109\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0118\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0132\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0107\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0143\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0130\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0136\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0144\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0173\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0147\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0178\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0130\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0143\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0112\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0166\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0162\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0143\n",
      ">p=4: 3, Score=7.247413694858551\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 6s 82ms/step - loss: 0.1770 - val_loss: 0.0163\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0504 - val_loss: 0.0397\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0344 - val_loss: 0.0175\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0322 - val_loss: 0.0187\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0144\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0272 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0116\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0123\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.0142\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0099\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0106\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0127\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0156\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      ">p=4: 4, Score=2.6485757902264595\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 8s 127ms/step - loss: 0.1437 - val_loss: 0.0204\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0444 - val_loss: 0.0281\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0394 - val_loss: 0.0237\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0353 - val_loss: 0.0204\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0150\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.0130\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0229 - val_loss: 0.0112\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0159 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0235 - val_loss: 0.0120\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0111\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0149\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0136\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0136\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0106\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0182 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0137\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0138\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0136\n",
      ">p=4: 5, Score=6.752236187458038\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 7s 86ms/step - loss: 0.1617 - val_loss: 0.0169\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0486 - val_loss: 0.0394\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0381 - val_loss: 0.0225\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0333 - val_loss: 0.0219\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0299 - val_loss: 0.0161\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0269 - val_loss: 0.0130\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0243 - val_loss: 0.0113\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0227 - val_loss: 0.0109\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0196\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0181 - val_loss: 0.0104\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0122\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0128\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0151\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0143\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0099\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0115\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0140\n",
      ">p=4: 6, Score=6.007843464612961\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 6s 82ms/step - loss: 0.1677 - val_loss: 0.0156\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0512 - val_loss: 0.0430\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0348 - val_loss: 0.0209\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0335 - val_loss: 0.0188\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0278 - val_loss: 0.0136\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0118\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0247 - val_loss: 0.0111\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0113\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0133\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0194 - val_loss: 0.0111\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0215 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 0.0110\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0172\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0160\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0121\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0137\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0123\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0130\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0134\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0136\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0145\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0142\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0108\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0169\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0135\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0146\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0156\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0148\n",
      ">p=4: 7, Score=5.744945630431175\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 7s 118ms/step - loss: 0.1710 - val_loss: 0.0157\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0512 - val_loss: 0.0403\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0349 - val_loss: 0.0208\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0323 - val_loss: 0.0212\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0288 - val_loss: 0.0174\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.0146\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0240 - val_loss: 0.0120\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0211 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.0105\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0209 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0108\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0210 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0107\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0115\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0100\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      ">p=4: 8, Score=2.8157707303762436\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 7s 98ms/step - loss: 0.1636 - val_loss: 0.0154\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0527 - val_loss: 0.0408\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0373 - val_loss: 0.0219\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0354 - val_loss: 0.0237\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0173\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0269 - val_loss: 0.0137\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0211 - val_loss: 0.0105\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0221 - val_loss: 0.0106\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0107\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0111\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0107\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0101\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0104\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0111\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.0127\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0102\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0139\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0125\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0151\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0140\n",
      ">p=4: 9, Score=8.038640767335892\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 7s 106ms/step - loss: 0.1652 - val_loss: 0.0152\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0468 - val_loss: 0.0396\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0336 - val_loss: 0.0208\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0199\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0138\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0248 - val_loss: 0.0127\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0212 - val_loss: 0.0111\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0196 - val_loss: 0.0110\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0113\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0111\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0224 - val_loss: 0.0109\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0193 - val_loss: 0.0139\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0101\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0175 - val_loss: 0.0121\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0121\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0107\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0104\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0096\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0103\n",
      ">p=4: 10, Score=4.543391615152359\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 144ms/step - loss: 0.1701 - val_loss: 0.0164\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0540 - val_loss: 0.0532\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0292 - val_loss: 0.0187\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0325 - val_loss: 0.0200\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0278 - val_loss: 0.0146\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0289 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0255 - val_loss: 0.0112\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0109\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0117\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0110\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0194 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0186 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0109\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0107\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0170 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0139\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0115\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0149\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0211 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0132\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0123\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0145\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0135\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0128\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0129\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0125\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0141\n",
      ">p=5: 1, Score=2.753355912864208\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 113ms/step - loss: 0.1921 - val_loss: 0.0234\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0548 - val_loss: 0.0562\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0322 - val_loss: 0.0187\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0338 - val_loss: 0.0194\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0307 - val_loss: 0.0157\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0289 - val_loss: 0.0140\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0241 - val_loss: 0.0122\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 0.0119\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0216 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0193 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0171 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.0149 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0142 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0155 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.0223 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0225 - val_loss: 0.0163\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0120\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0132\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0117\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0122\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0119\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0121\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0098\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0180 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0193 - val_loss: 0.0157\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0128\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0119\n",
      ">p=5: 2, Score=2.7110151946544647\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 9s 144ms/step - loss: 0.1758 - val_loss: 0.0172\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0564 - val_loss: 0.0530\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0336 - val_loss: 0.0195\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0361 - val_loss: 0.0195\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0330 - val_loss: 0.0162\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0293 - val_loss: 0.0130\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0288 - val_loss: 0.0127\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0252 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0119\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0235 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0131\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0154 - val_loss: 0.0125\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0130\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0129\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0245 - val_loss: 0.0156\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0143\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.0126\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0154\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0149\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0144\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0149\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0163\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0138\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.0153 - val_loss: 0.0118\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.0163 - val_loss: 0.0114\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0135 - val_loss: 0.0179\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.0109 - val_loss: 0.0154\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      ">p=5: 3, Score=1.988792046904564\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 10s 116ms/step - loss: 0.1741 - val_loss: 0.0175\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0502 - val_loss: 0.0545\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0357 - val_loss: 0.0207\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0336 - val_loss: 0.0194\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0316 - val_loss: 0.0158\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0276 - val_loss: 0.0124\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0263 - val_loss: 0.0112\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0218 - val_loss: 0.0108\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0221 - val_loss: 0.0109\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0180 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0143 - val_loss: 0.0130\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0167 - val_loss: 0.0125\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0129\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0182 - val_loss: 0.0120\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0123\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0110\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0139\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0109\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0113\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0112\n",
      ">p=5: 4, Score=2.126128412783146\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 10s 139ms/step - loss: 0.1813 - val_loss: 0.0176\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0614 - val_loss: 0.0746\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0388 - val_loss: 0.0257\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0380 - val_loss: 0.0222\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0331 - val_loss: 0.0211\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0307 - val_loss: 0.0145\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0279 - val_loss: 0.0129\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0258 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0239 - val_loss: 0.0109\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0212 - val_loss: 0.0110\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0185 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0181 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0164 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0154 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0238 - val_loss: 0.0147\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0100\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0186 - val_loss: 0.0138\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0124\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0098 - val_loss: 0.0138\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0097 - val_loss: 0.0141\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0076 - val_loss: 0.0110\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0092 - val_loss: 0.0126\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 0.0131\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0084 - val_loss: 0.0113\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      ">p=5: 5, Score=5.0308071076869965\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 10s 109ms/step - loss: 0.1858 - val_loss: 0.0183\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0583 - val_loss: 0.0622\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0356 - val_loss: 0.0236\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0338 - val_loss: 0.0200\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0292 - val_loss: 0.0189\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0268 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 0.0122\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0222 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0110\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0167 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0131\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0143\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0132\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0146\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0127\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0147\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0127\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0131\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0183\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0130\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0148\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0120\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0133\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0142\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0114\n",
      ">p=5: 6, Score=3.908773884177208\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 119ms/step - loss: 0.1778 - val_loss: 0.0205\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0507 - val_loss: 0.0545\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0352 - val_loss: 0.0182\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0331 - val_loss: 0.0182\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0299 - val_loss: 0.0168\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0297 - val_loss: 0.0135\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0243 - val_loss: 0.0116\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0236 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0223 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0183 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0184 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0160 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0170 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0107\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0099\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0087\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0155\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0095\n",
      ">p=5: 7, Score=3.1979724764823914\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 105ms/step - loss: 0.1857 - val_loss: 0.0202\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0612 - val_loss: 0.0584\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0351 - val_loss: 0.0198\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0375 - val_loss: 0.0196\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0325 - val_loss: 0.0172\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0271 - val_loss: 0.0126\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0266 - val_loss: 0.0118\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0116\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0124\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0134\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0138\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0145\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0135\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0126\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0135\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0136\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0180\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0138\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0141\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0168\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0147\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0166\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0141\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0148\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0142\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0133\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0145\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0166\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0187\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0176\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0158\n",
      ">p=5: 8, Score=5.322062969207764\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 9s 187ms/step - loss: 0.1943 - val_loss: 0.0259\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0564 - val_loss: 0.0503\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0379 - val_loss: 0.0175\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0355 - val_loss: 0.0171\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0312 - val_loss: 0.0163\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0295 - val_loss: 0.0130\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0273 - val_loss: 0.0125\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0112\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0238 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0233 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0183 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0133\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0123\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0187 - val_loss: 0.0119\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0199 - val_loss: 0.0124\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0143\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      ">p=5: 9, Score=4.544321075081825\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 10s 230ms/step - loss: 0.1682 - val_loss: 0.0159\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0518 - val_loss: 0.0510\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0319 - val_loss: 0.0171\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0332 - val_loss: 0.0200\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0257 - val_loss: 0.0137\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0243 - val_loss: 0.0116\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0242 - val_loss: 0.0105\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0201 - val_loss: 0.0110\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0195 - val_loss: 0.0107\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0161 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0197 - val_loss: 0.0140\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0124\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0160 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0106\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0178 - val_loss: 0.0140\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 0.0140\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0113\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0117\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0114\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0113\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0077 - val_loss: 0.0106\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      ">p=5: 10, Score=4.6980176120996475\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 7s 182ms/step - loss: 0.1973 - val_loss: 0.0379\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0681 - val_loss: 0.0463\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0443 - val_loss: 0.0330\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0331 - val_loss: 0.0171\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0352 - val_loss: 0.0207\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0312 - val_loss: 0.0166\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0259 - val_loss: 0.0137\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0250 - val_loss: 0.0131\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0219 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0171 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0178 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0167 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0159 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0109\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0105\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0111\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0126\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0090\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0088\n",
      ">p=6: 1, Score=2.460463158786297\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 8s 144ms/step - loss: 0.1940 - val_loss: 0.0312\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0676 - val_loss: 0.0629\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0411 - val_loss: 0.0338\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0347 - val_loss: 0.0205\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0321 - val_loss: 0.0237\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0290 - val_loss: 0.0158\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0283 - val_loss: 0.0130\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0226 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0126\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0142 - val_loss: 0.0126\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0138\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0078 - val_loss: 0.0107\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0107\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0117\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0108 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0090\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0091\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0117\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      ">p=6: 2, Score=2.8016185387969017\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 8s 145ms/step - loss: 0.1927 - val_loss: 0.0333\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0691 - val_loss: 0.0468\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0439 - val_loss: 0.0354\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0348 - val_loss: 0.0184\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0344 - val_loss: 0.0232\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0334 - val_loss: 0.0171\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0282 - val_loss: 0.0147\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0256 - val_loss: 0.0132\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0222 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0220 - val_loss: 0.0114\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0116\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0091\n",
      ">p=6: 3, Score=3.7221841514110565\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 8s 141ms/step - loss: 0.2006 - val_loss: 0.0317\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0701 - val_loss: 0.0661\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0429 - val_loss: 0.0407\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0348 - val_loss: 0.0204\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0388 - val_loss: 0.0256\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0332 - val_loss: 0.0192\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0295 - val_loss: 0.0148\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0266 - val_loss: 0.0126\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0255 - val_loss: 0.0113\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0225 - val_loss: 0.0108\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0106\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0106\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0108\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0101\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0095\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      ">p=6: 4, Score=2.0564408972859383\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 7s 126ms/step - loss: 0.1956 - val_loss: 0.0333\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0670 - val_loss: 0.0557\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0433 - val_loss: 0.0411\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0351 - val_loss: 0.0207\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0218\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0296 - val_loss: 0.0171\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0147\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0249 - val_loss: 0.0124\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0112\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0131\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0105\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0105\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0100\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0087\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0108\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      ">p=6: 5, Score=3.5401981323957443\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 6s 125ms/step - loss: 0.2015 - val_loss: 0.0339\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0677 - val_loss: 0.0589\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0430 - val_loss: 0.0347\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0351 - val_loss: 0.0183\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0352 - val_loss: 0.0237\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0292 - val_loss: 0.0176\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0276 - val_loss: 0.0135\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0248 - val_loss: 0.0133\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0108\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0112\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0110\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0110\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0169\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0113\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0163\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0120\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0141\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0152\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0136\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0195\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0121\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0092 - val_loss: 0.0133\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0163\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0116\n",
      ">p=6: 6, Score=3.009364940226078\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 6s 127ms/step - loss: 0.1801 - val_loss: 0.0218\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0622 - val_loss: 0.0779\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0407 - val_loss: 0.0335\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0374 - val_loss: 0.0227\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0335 - val_loss: 0.0289\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0294 - val_loss: 0.0204\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0276 - val_loss: 0.0153\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0242 - val_loss: 0.0141\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0184 - val_loss: 0.0109\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0111\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0135 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0098\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0118\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0080\n",
      ">p=6: 7, Score=2.345559187233448\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 7s 142ms/step - loss: 0.1876 - val_loss: 0.0307\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0581 - val_loss: 0.0530\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0395 - val_loss: 0.0253\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0345 - val_loss: 0.0163\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0315 - val_loss: 0.0207\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0265 - val_loss: 0.0151\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0262 - val_loss: 0.0137\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0106\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0103\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0104\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0107\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0101\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0104\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0092\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0090\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0081\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0097\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0080\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0216\n",
      ">p=6: 8, Score=9.449076652526855\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 7s 133ms/step - loss: 0.1790 - val_loss: 0.0226\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0587 - val_loss: 0.0689\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0436 - val_loss: 0.0304\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0362 - val_loss: 0.0180\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0340 - val_loss: 0.0241\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0289 - val_loss: 0.0178\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0264 - val_loss: 0.0141\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0252 - val_loss: 0.0119\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0110\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0125\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0129\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0141\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0172\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0089\n",
      ">p=6: 9, Score=2.0515529438853264\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 6s 125ms/step - loss: 0.2064 - val_loss: 0.0363\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0767 - val_loss: 0.0504\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0433 - val_loss: 0.0544\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0352 - val_loss: 0.0227\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0346 - val_loss: 0.0278\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0307 - val_loss: 0.0244\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0299 - val_loss: 0.0162\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0275 - val_loss: 0.0151\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0251 - val_loss: 0.0128\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0229 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0209 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0111\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0099\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0118\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0087\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0091\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0095\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      ">p=6: 10, Score=1.7299599945545197\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 8s 135ms/step - loss: 0.1962 - val_loss: 0.0346\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0700 - val_loss: 0.0450\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0398 - val_loss: 0.0348\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0317 - val_loss: 0.0162\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0351 - val_loss: 0.0168\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0284 - val_loss: 0.0163\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0261 - val_loss: 0.0126\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0241 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0217 - val_loss: 0.0108\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 0.0115\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0144 - val_loss: 0.0130\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0131\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0132\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0129\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0143\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0129\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0135 - val_loss: 0.0179\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0170\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0168\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0134\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0143\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 0.0124\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0131\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0138\n",
      ">p=7: 1, Score=3.8704313337802887\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 11s 234ms/step - loss: 0.1970 - val_loss: 0.0299\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0695 - val_loss: 0.0536\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0428 - val_loss: 0.0399\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0332 - val_loss: 0.0183\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0355 - val_loss: 0.0199\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0301 - val_loss: 0.0186\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0266 - val_loss: 0.0149\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0254 - val_loss: 0.0124\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0238 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0230 - val_loss: 0.0110\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0215 - val_loss: 0.0109\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0111\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0177 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0148 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0154 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0153 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0128\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0140 - val_loss: 0.0138\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0107\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      ">p=7: 2, Score=2.751162461936474\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 8s 139ms/step - loss: 0.2025 - val_loss: 0.0333\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0784 - val_loss: 0.0498\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0445 - val_loss: 0.0518\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0328 - val_loss: 0.0232\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0364 - val_loss: 0.0236\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0330 - val_loss: 0.0225\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0313 - val_loss: 0.0180\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0297 - val_loss: 0.0145\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0237 - val_loss: 0.0128\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0107\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0112\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0110\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0120\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0107\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0144\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0103\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0121\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      ">p=7: 3, Score=2.976303920149803\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 8s 140ms/step - loss: 0.2037 - val_loss: 0.0366\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0736 - val_loss: 0.0373\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0430 - val_loss: 0.0402\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0320 - val_loss: 0.0176\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0346 - val_loss: 0.0179\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0285 - val_loss: 0.0163\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0272 - val_loss: 0.0124\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0224 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0210 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0112\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0185 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0181 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0132 - val_loss: 0.0137\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0158 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0138\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0132\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0127\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0126\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0111\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0117\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      ">p=7: 4, Score=1.8907131627202034\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 150ms/step - loss: 0.1835 - val_loss: 0.0292\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0675 - val_loss: 0.0463\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0427 - val_loss: 0.0324\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0347 - val_loss: 0.0151\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0351 - val_loss: 0.0172\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0297 - val_loss: 0.0151\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0290 - val_loss: 0.0117\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0262 - val_loss: 0.0109\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0225 - val_loss: 0.0110\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0191 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0202 - val_loss: 0.0151\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0180 - val_loss: 0.0138\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.0149\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0141\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0168 - val_loss: 0.0135\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0145\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0150\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0135\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0193\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0143\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0188\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0095 - val_loss: 0.0162\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0169\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0151\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0202\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0155\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0206\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0124\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0202\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0250\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0123\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0133\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0139\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0163\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0084 - val_loss: 0.0190\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0160\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0135\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0202\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0141\n",
      ">p=7: 5, Score=7.591589540243149\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 8s 140ms/step - loss: 0.2184 - val_loss: 0.0499\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0909 - val_loss: 0.0273\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0478 - val_loss: 0.0569\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0360 - val_loss: 0.0214\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0366 - val_loss: 0.0200\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0305 - val_loss: 0.0226\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0300 - val_loss: 0.0185\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0244 - val_loss: 0.0134\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.0109\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0109\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0112\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0125\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0126\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0108\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0111\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0132\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0114\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0104\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0148\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0112\n",
      ">p=7: 6, Score=4.508638009428978\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 9s 161ms/step - loss: 0.2292 - val_loss: 0.0528\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.1002 - val_loss: 0.0235\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0504 - val_loss: 0.0609\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0339 - val_loss: 0.0238\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0374 - val_loss: 0.0194\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0332 - val_loss: 0.0198\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0301 - val_loss: 0.0166\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0263 - val_loss: 0.0132\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0119\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0203 - val_loss: 0.0110\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0194 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0179 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0177 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0158 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0139\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0125\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0122\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0127\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      ">p=7: 7, Score=2.344803139567375\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 144ms/step - loss: 0.2054 - val_loss: 0.0424\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0737 - val_loss: 0.0312\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0424 - val_loss: 0.0361\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0322 - val_loss: 0.0165\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0352 - val_loss: 0.0169\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0316 - val_loss: 0.0168\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0290 - val_loss: 0.0130\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0276 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0260 - val_loss: 0.0119\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0233 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0216 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0222 - val_loss: 0.0125\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0195 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0198 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0189 - val_loss: 0.0129\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0179 - val_loss: 0.0136\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0175 - val_loss: 0.0141\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0139\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0133\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0133\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0129\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0163\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0125 - val_loss: 0.0126\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0142\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0117\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0151\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0170\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0126\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0078 - val_loss: 0.0146\n",
      ">p=7: 8, Score=4.802713543176651\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 8s 154ms/step - loss: 0.2060 - val_loss: 0.0420\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0809 - val_loss: 0.0351\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0466 - val_loss: 0.0496\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0343 - val_loss: 0.0174\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0374 - val_loss: 0.0186\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0319 - val_loss: 0.0202\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0313 - val_loss: 0.0138\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0276 - val_loss: 0.0126\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0266 - val_loss: 0.0117\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0217 - val_loss: 0.0112\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0218 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0228 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0171 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0161 - val_loss: 0.0129\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0124\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0154\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0104\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0117\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0132\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0161\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0113\n",
      ">p=7: 9, Score=3.699546307325363\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 8s 163ms/step - loss: 0.1826 - val_loss: 0.0255\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0625 - val_loss: 0.0588\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0377 - val_loss: 0.0356\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0343 - val_loss: 0.0186\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0334 - val_loss: 0.0211\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0324 - val_loss: 0.0204\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0298 - val_loss: 0.0144\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0301 - val_loss: 0.0137\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0240 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0239 - val_loss: 0.0106\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0214 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0107\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0110\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0109\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0156 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0128\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0127\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0164\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0135\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0133\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0131\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0136\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0122\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0116\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0133\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0122\n",
      ">p=7: 10, Score=5.305995792150497\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 280ms/step - loss: 0.2179 - val_loss: 0.0509\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0951 - val_loss: 0.0195\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0504 - val_loss: 0.0762\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0374 - val_loss: 0.0357\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0318 - val_loss: 0.0207\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0361 - val_loss: 0.0212\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0303 - val_loss: 0.0221\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0287 - val_loss: 0.0190\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0272 - val_loss: 0.0152\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0258 - val_loss: 0.0135\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0249 - val_loss: 0.0121\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0185 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0160 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0125\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0116\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      ">p=8: 1, Score=2.0816007629036903\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 196ms/step - loss: 0.1879 - val_loss: 0.0404\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0748 - val_loss: 0.0250\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0463 - val_loss: 0.0645\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0358 - val_loss: 0.0244\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0343 - val_loss: 0.0162\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0348 - val_loss: 0.0192\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0313 - val_loss: 0.0186\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0300 - val_loss: 0.0139\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0259 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0243 - val_loss: 0.0114\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.0107\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0104\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0104\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0108\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0109\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0180 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0159 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0136\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      ">p=8: 2, Score=2.5470660999417305\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 170ms/step - loss: 0.2403 - val_loss: 0.0754\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1193 - val_loss: 0.0164\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0492 - val_loss: 0.0543\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0401 - val_loss: 0.0363\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0342 - val_loss: 0.0179\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0357 - val_loss: 0.0174\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0311 - val_loss: 0.0194\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0296 - val_loss: 0.0180\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0280 - val_loss: 0.0144\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0249 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0248 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0244 - val_loss: 0.0112\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0237 - val_loss: 0.0107\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0226 - val_loss: 0.0105\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0104\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.0106\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0106\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0109\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0102\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0096\n",
      ">p=8: 3, Score=4.717385768890381\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 222ms/step - loss: 0.2052 - val_loss: 0.0539\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0942 - val_loss: 0.0179\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0468 - val_loss: 0.0612\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0367 - val_loss: 0.0291\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0337 - val_loss: 0.0182\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0341 - val_loss: 0.0190\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0316 - val_loss: 0.0185\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0287 - val_loss: 0.0167\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0265 - val_loss: 0.0139\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0239 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0232 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0208 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.0222 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0197 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0120\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0121\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0105\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      ">p=8: 4, Score=3.4487824887037277\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 196ms/step - loss: 0.2100 - val_loss: 0.0530\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0945 - val_loss: 0.0198\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0503 - val_loss: 0.0679\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.0404 - val_loss: 0.0323\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0343 - val_loss: 0.0197\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0370 - val_loss: 0.0199\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0317 - val_loss: 0.0219\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0304 - val_loss: 0.0186\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0296 - val_loss: 0.0150\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0136\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0252 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0226 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0209 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.0233 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0211 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0193 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0175 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0179 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0167 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0166 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0118\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0124\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0092\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      ">p=8: 5, Score=6.169049441814423\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 202ms/step - loss: 0.2171 - val_loss: 0.0560\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1068 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0533 - val_loss: 0.0773\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0457 - val_loss: 0.0405\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0344 - val_loss: 0.0200\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0373 - val_loss: 0.0217\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0333 - val_loss: 0.0280\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0315 - val_loss: 0.0235\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0293 - val_loss: 0.0172\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0276 - val_loss: 0.0153\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0242 - val_loss: 0.0153\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0240 - val_loss: 0.0130\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0218 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0200 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0183 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0125\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0132\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0136\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0129\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0136\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0126\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0139\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0131\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0135\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0127\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0122\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0144\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0124\n",
      ">p=8: 6, Score=3.0905889347195625\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 166ms/step - loss: 0.2218 - val_loss: 0.0570\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1105 - val_loss: 0.0162\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0556 - val_loss: 0.0708\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0397 - val_loss: 0.0426\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0328 - val_loss: 0.0220\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0318 - val_loss: 0.0218\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0218\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0289 - val_loss: 0.0177\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0144\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0250 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0113\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0221 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0109\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0103\n",
      ">p=8: 7, Score=1.979626901447773\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 168ms/step - loss: 0.2168 - val_loss: 0.0633\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1018 - val_loss: 0.0164\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0471 - val_loss: 0.0610\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0398 - val_loss: 0.0310\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0325 - val_loss: 0.0173\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0333 - val_loss: 0.0177\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0319 - val_loss: 0.0198\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0279 - val_loss: 0.0166\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0264 - val_loss: 0.0134\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0258 - val_loss: 0.0121\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0251 - val_loss: 0.0113\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0231 - val_loss: 0.0109\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0226 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0211 - val_loss: 0.0109\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0185 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0132\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0129\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0132\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0133\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0138\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0133\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0121\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0137\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0135\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0082 - val_loss: 0.0114\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      ">p=8: 8, Score=3.935065120458603\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 185ms/step - loss: 0.2200 - val_loss: 0.0554\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1051 - val_loss: 0.0169\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0474 - val_loss: 0.0711\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0442 - val_loss: 0.0440\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0337 - val_loss: 0.0222\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0362 - val_loss: 0.0212\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0335 - val_loss: 0.0250\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0313 - val_loss: 0.0213\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0293 - val_loss: 0.0161\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0284 - val_loss: 0.0143\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0248 - val_loss: 0.0135\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0247 - val_loss: 0.0122\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0229 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0214 - val_loss: 0.0111\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0182 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0125\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0143\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0122\n",
      ">p=8: 9, Score=6.931819766759872\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 186ms/step - loss: 0.2002 - val_loss: 0.0466\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0901 - val_loss: 0.0192\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0472 - val_loss: 0.0724\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0392 - val_loss: 0.0336\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0322 - val_loss: 0.0177\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0337 - val_loss: 0.0187\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0312 - val_loss: 0.0195\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0274 - val_loss: 0.0155\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0259 - val_loss: 0.0130\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0226 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0211 - val_loss: 0.0111\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0202 - val_loss: 0.0113\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 0.0130\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0135\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0122\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0132\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0148\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0150\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0147\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0099 - val_loss: 0.0140\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0147\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.0096 - val_loss: 0.0148\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.0153\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0162\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0122\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0146\n",
      ">p=8: 10, Score=5.553416907787323\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 194ms/step - loss: 0.2162 - val_loss: 0.0618\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1039 - val_loss: 0.0152\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0455 - val_loss: 0.0595\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0430 - val_loss: 0.0370\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0320 - val_loss: 0.0176\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0352 - val_loss: 0.0173\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0319 - val_loss: 0.0200\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0308 - val_loss: 0.0174\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0288 - val_loss: 0.0142\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0249 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0249 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0208 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0236 - val_loss: 0.0113\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0182 - val_loss: 0.0112\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0180 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0169 - val_loss: 0.0131\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0137\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0144\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0129\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0114\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0146\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0115\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0127\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0107\n",
      ">p=9: 1, Score=3.8831807672977448\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 237ms/step - loss: 0.2181 - val_loss: 0.0552\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1085 - val_loss: 0.0167\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0493 - val_loss: 0.0833\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0446 - val_loss: 0.0552\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0337 - val_loss: 0.0251\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0370 - val_loss: 0.0221\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0361 - val_loss: 0.0262\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0306 - val_loss: 0.0246\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0323 - val_loss: 0.0191\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0281 - val_loss: 0.0159\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0280 - val_loss: 0.0148\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0213 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0105\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0130\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0123\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0096\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0098\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0125\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0094\n",
      ">p=9: 2, Score=2.1963434293866158\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 205ms/step - loss: 0.2171 - val_loss: 0.0586\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1088 - val_loss: 0.0159\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0500 - val_loss: 0.0660\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0443 - val_loss: 0.0445\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0334 - val_loss: 0.0206\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0353 - val_loss: 0.0188\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0316 - val_loss: 0.0223\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0303 - val_loss: 0.0213\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0270 - val_loss: 0.0157\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0260 - val_loss: 0.0129\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0245 - val_loss: 0.0125\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0221 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.0113\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0182 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0164 - val_loss: 0.0129\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0125\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0124\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0127\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0140\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0115\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0216\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0109\n",
      ">p=9: 3, Score=2.335452474653721\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 198ms/step - loss: 0.2051 - val_loss: 0.0529\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1012 - val_loss: 0.0159\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0502 - val_loss: 0.0696\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0420 - val_loss: 0.0441\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0349 - val_loss: 0.0198\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0372 - val_loss: 0.0177\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0303 - val_loss: 0.0203\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0293 - val_loss: 0.0184\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0263 - val_loss: 0.0146\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0260 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0252 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0222 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0222 - val_loss: 0.0110\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0215 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0230 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0186 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0175 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0176 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0122\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0152 - val_loss: 0.0125\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0110 - val_loss: 0.0121\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0115\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0115\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0140\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0126\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0080 - val_loss: 0.0133\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0109\n",
      ">p=9: 4, Score=5.701271444559097\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 196ms/step - loss: 0.2163 - val_loss: 0.0645\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1094 - val_loss: 0.0164\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0521 - val_loss: 0.0648\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0479 - val_loss: 0.0424\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0365 - val_loss: 0.0199\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0373 - val_loss: 0.0185\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.0335 - val_loss: 0.0218\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0326 - val_loss: 0.0212\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0290 - val_loss: 0.0170\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0296 - val_loss: 0.0154\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0276 - val_loss: 0.0144\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0270 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0249 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0231 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0213 - val_loss: 0.0109\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0195 - val_loss: 0.0109\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0198 - val_loss: 0.0108\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0110\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0109\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0113\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0082 - val_loss: 0.0088\n",
      ">p=9: 5, Score=2.341539040207863\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 210ms/step - loss: 0.2079 - val_loss: 0.0577\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1038 - val_loss: 0.0163\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0522 - val_loss: 0.0624\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0457 - val_loss: 0.0383\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0364 - val_loss: 0.0182\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0382 - val_loss: 0.0169\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0325 - val_loss: 0.0198\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0297 - val_loss: 0.0193\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0288 - val_loss: 0.0141\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0266 - val_loss: 0.0128\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0232 - val_loss: 0.0121\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0223 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0227 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0205 - val_loss: 0.0123\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0129\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0131\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0186 - val_loss: 0.0127\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0131\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0138\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0132\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0141\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0129 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0122\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0127\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0125\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0105\n",
      ">p=9: 6, Score=2.0239369943737984\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 194ms/step - loss: 0.2142 - val_loss: 0.0576\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1074 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0485 - val_loss: 0.0732\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0463 - val_loss: 0.0478\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0326 - val_loss: 0.0216\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0351 - val_loss: 0.0199\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0328 - val_loss: 0.0243\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0303 - val_loss: 0.0221\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0276 - val_loss: 0.0163\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0266 - val_loss: 0.0137\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0239 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0205 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0108\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0170 - val_loss: 0.0109\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0110\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0178 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0179 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0145 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 0.0140 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      ">p=9: 7, Score=2.630610018968582\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 11s 274ms/step - loss: 0.2280 - val_loss: 0.0654\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1170 - val_loss: 0.0164\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0527 - val_loss: 0.0606\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0482 - val_loss: 0.0487\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0376 - val_loss: 0.0215\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0368 - val_loss: 0.0188\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0311 - val_loss: 0.0231\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0331 - val_loss: 0.0230\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0308 - val_loss: 0.0166\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0281 - val_loss: 0.0142\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0252 - val_loss: 0.0142\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0266 - val_loss: 0.0126\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0234 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0214 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0217 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0203 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0190 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0177 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0127\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      ">p=9: 8, Score=4.217850789427757\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 9s 253ms/step - loss: 0.2178 - val_loss: 0.0597\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1081 - val_loss: 0.0155\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0481 - val_loss: 0.0690\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0469 - val_loss: 0.0470\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0327 - val_loss: 0.0219\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0349 - val_loss: 0.0200\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0319 - val_loss: 0.0247\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0294 - val_loss: 0.0239\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0269 - val_loss: 0.0162\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0240 - val_loss: 0.0136\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0239 - val_loss: 0.0132\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 0.0124\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0219 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0089\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0097\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0106\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      ">p=9: 9, Score=1.9413281232118607\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 206ms/step - loss: 0.2248 - val_loss: 0.0681\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1206 - val_loss: 0.0175\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0527 - val_loss: 0.0533\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0502 - val_loss: 0.0424\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0319 - val_loss: 0.0190\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0335 - val_loss: 0.0178\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0325 - val_loss: 0.0209\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0296 - val_loss: 0.0195\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0266 - val_loss: 0.0149\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0256 - val_loss: 0.0136\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0234 - val_loss: 0.0126\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0195 - val_loss: 0.0114\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0204 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0192 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0183 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0165 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0127\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0111\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0092\n",
      ">p=9: 10, Score=2.341194823384285\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 187ms/step - loss: 0.2427 - val_loss: 0.0741\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1382 - val_loss: 0.0203\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0593 - val_loss: 0.0451\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0456 - val_loss: 0.0598\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0369 - val_loss: 0.0247\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0390 - val_loss: 0.0171\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0371 - val_loss: 0.0189\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0325 - val_loss: 0.0212\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0273 - val_loss: 0.0176\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0274 - val_loss: 0.0133\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0264 - val_loss: 0.0123\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0232 - val_loss: 0.0122\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0224 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0183 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0191 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0177 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0130\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.0129\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0135\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0184 - val_loss: 0.0136\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0147\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0140\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0133\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0131\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0131\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0127\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0139\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0100 - val_loss: 0.0127\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0123\n",
      ">p=10: 1, Score=3.521456941962242\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 8s 225ms/step - loss: 0.2249 - val_loss: 0.0705\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1234 - val_loss: 0.0186\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0490 - val_loss: 0.0402\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0423 - val_loss: 0.0366\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0358 - val_loss: 0.0177\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0340 - val_loss: 0.0143\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0327 - val_loss: 0.0153\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0295 - val_loss: 0.0162\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0264 - val_loss: 0.0132\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0255 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0255 - val_loss: 0.0113\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0243 - val_loss: 0.0111\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0220 - val_loss: 0.0113\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0200 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0169 - val_loss: 0.0125\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0163 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0131\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0139\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0138\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0134\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0140\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0146 - val_loss: 0.0139\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0139\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0134\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0143\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0133 - val_loss: 0.0140\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0144\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0147\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0152\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0140\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0163\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0138\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0127\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0168\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0147\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0153\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0101 - val_loss: 0.0184\n",
      ">p=10: 2, Score=5.3479742258787155\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 182ms/step - loss: 0.2291 - val_loss: 0.0648\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1270 - val_loss: 0.0163\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0545 - val_loss: 0.0604\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0447 - val_loss: 0.0455\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0351 - val_loss: 0.0215\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0355 - val_loss: 0.0180\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0348 - val_loss: 0.0200\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0287 - val_loss: 0.0186\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0292 - val_loss: 0.0134\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0266 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0239 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0222 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0186 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0190 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0161 - val_loss: 0.0125\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0126\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0156\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0107\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      ">p=10: 3, Score=4.052921757102013\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 182ms/step - loss: 0.2209 - val_loss: 0.0564\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1049 - val_loss: 0.0148\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0461 - val_loss: 0.0525\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0416 - val_loss: 0.0302\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0332 - val_loss: 0.0150\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0365 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0322 - val_loss: 0.0181\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0300 - val_loss: 0.0161\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0257 - val_loss: 0.0136\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0261 - val_loss: 0.0131\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0255 - val_loss: 0.0123\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0232 - val_loss: 0.0113\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0243 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0218 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0200 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0186 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0131\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0146 - val_loss: 0.0131\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0130\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0129\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0139\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0146\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0123\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0126\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.0123\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0127\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0168\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0108\n",
      ">p=10: 4, Score=1.993114873766899\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 182ms/step - loss: 0.2233 - val_loss: 0.0617\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1157 - val_loss: 0.0166\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 0.0480 - val_loss: 0.0573\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0487 - val_loss: 0.0384\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0344 - val_loss: 0.0179\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0374 - val_loss: 0.0163\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0328 - val_loss: 0.0193\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0188\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0275 - val_loss: 0.0152\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0280 - val_loss: 0.0135\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0233 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0226 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0197 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0186 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.0132\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0130\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0134\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0134\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0143 - val_loss: 0.0137\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0134\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0133\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0129\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0126\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0137 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0123\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0121\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0118\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0122\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      ">p=10: 5, Score=2.5283312425017357\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 192ms/step - loss: 0.2290 - val_loss: 0.0630\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1208 - val_loss: 0.0166\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0539 - val_loss: 0.0548\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0419 - val_loss: 0.0439\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0350 - val_loss: 0.0201\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0374 - val_loss: 0.0170\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0335 - val_loss: 0.0207\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0303 - val_loss: 0.0210\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0294 - val_loss: 0.0153\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0286 - val_loss: 0.0125\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0254 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0243 - val_loss: 0.0108\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0238 - val_loss: 0.0108\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0210 - val_loss: 0.0109\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0200 - val_loss: 0.0114\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0178 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0170 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0127\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0127\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0134\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0148\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0137 - val_loss: 0.0144\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0138\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0135\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0136\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0138\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0140\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0133\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0136\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0151\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0126\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0143\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0130\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0149\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0131\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0079 - val_loss: 0.0127\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0084 - val_loss: 0.0128\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0146\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0156\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0126\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0145\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0077 - val_loss: 0.0136\n",
      ">p=10: 6, Score=5.0873056054115295\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 8s 208ms/step - loss: 0.2231 - val_loss: 0.0629\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1162 - val_loss: 0.0164\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0519 - val_loss: 0.0500\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0478 - val_loss: 0.0363\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0342 - val_loss: 0.0165\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0361 - val_loss: 0.0154\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0335 - val_loss: 0.0177\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0304 - val_loss: 0.0164\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0302 - val_loss: 0.0132\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0261 - val_loss: 0.0125\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0261 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0251 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0221 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0197 - val_loss: 0.0124\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 0.0132\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0171 - val_loss: 0.0137\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 0.0148\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0138\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0138 - val_loss: 0.0158\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.0143\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0138\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0134\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0161 - val_loss: 0.0140\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0139 - val_loss: 0.0134\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0134\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0123\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0116\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0078 - val_loss: 0.0110\n",
      ">p=10: 7, Score=2.5250840932130814\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 8s 199ms/step - loss: 0.2272 - val_loss: 0.0662\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1255 - val_loss: 0.0164\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0551 - val_loss: 0.0545\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0461 - val_loss: 0.0453\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0335 - val_loss: 0.0199\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0331 - val_loss: 0.0179\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0314 - val_loss: 0.0182\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0299 - val_loss: 0.0146\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0266 - val_loss: 0.0130\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0257 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0253 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0231 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0226 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0211 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0194 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0131\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 0.0135\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0191 - val_loss: 0.0138\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0170 - val_loss: 0.0138\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0139\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0160 - val_loss: 0.0139\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0141\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0138\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0136\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0150 - val_loss: 0.0133\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0132\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0136 - val_loss: 0.0133\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0132\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0136\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0127\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0128\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0129\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0124\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      ">p=10: 8, Score=2.4428728967905045\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 182ms/step - loss: 0.2311 - val_loss: 0.0646\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1315 - val_loss: 0.0174\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0556 - val_loss: 0.0584\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0457 - val_loss: 0.0522\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0374 - val_loss: 0.0227\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0407 - val_loss: 0.0175\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0380 - val_loss: 0.0196\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0344 - val_loss: 0.0206\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0302 - val_loss: 0.0184\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0297 - val_loss: 0.0149\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0268 - val_loss: 0.0131\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0230 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0226 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0211 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0205 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0124\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 0.0131\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0136\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0165 - val_loss: 0.0139\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0165 - val_loss: 0.0138\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0162 - val_loss: 0.0145\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 0.0142\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0159 - val_loss: 0.0150\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0140\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0139\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0138\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0138\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0136\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0137\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0141\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0135\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0131\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0127\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0133\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0128\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0126\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0127\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      ">p=10: 9, Score=2.727704495191574\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 189ms/step - loss: 0.2157 - val_loss: 0.0562\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1093 - val_loss: 0.0150\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0448 - val_loss: 0.0513\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0387 - val_loss: 0.0320\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0313 - val_loss: 0.0166\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0339 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0324 - val_loss: 0.0164\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0277 - val_loss: 0.0151\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0273 - val_loss: 0.0120\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0259 - val_loss: 0.0114\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0232 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0218 - val_loss: 0.0108\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0218 - val_loss: 0.0108\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0212 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0171 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0171 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0122\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0127\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 0.0130\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0106\n",
      ">p=10: 10, Score=5.730830505490303\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 215ms/step - loss: 0.2273 - val_loss: 0.0687\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1321 - val_loss: 0.0192\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0588 - val_loss: 0.0428\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0489 - val_loss: 0.0743\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0381 - val_loss: 0.0307\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0335 - val_loss: 0.0181\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0334 - val_loss: 0.0192\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0329 - val_loss: 0.0246\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0271 - val_loss: 0.0222\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0265 - val_loss: 0.0166\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0266 - val_loss: 0.0151\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0264 - val_loss: 0.0147\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0243 - val_loss: 0.0132\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0225 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0195 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0200 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0179 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0188 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0156 - val_loss: 0.0125\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0150 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0156 - val_loss: 0.0131\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0146 - val_loss: 0.0132\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0140 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0135\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0127\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0125\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0120\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0116 - val_loss: 0.0141\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0114\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0092 - val_loss: 0.0111\n",
      ">p=11: 1, Score=6.477124989032745\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 212ms/step - loss: 0.2355 - val_loss: 0.0719\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1355 - val_loss: 0.0200\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0590 - val_loss: 0.0387\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0495 - val_loss: 0.0704\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0392 - val_loss: 0.0329\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0326 - val_loss: 0.0186\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0335 - val_loss: 0.0188\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 0.0330 - val_loss: 0.0237\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0310 - val_loss: 0.0241\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0291 - val_loss: 0.0181\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0255 - val_loss: 0.0152\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0268 - val_loss: 0.0143\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0223 - val_loss: 0.0133\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0207 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0184 - val_loss: 0.0109\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0196 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0178 - val_loss: 0.0111\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0178 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0113\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0108\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0069 - val_loss: 0.0091\n",
      ">p=11: 2, Score=2.5328047573566437\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 247ms/step - loss: 0.2210 - val_loss: 0.0633\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1277 - val_loss: 0.0181\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0589 - val_loss: 0.0469\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0543 - val_loss: 0.0660\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0380 - val_loss: 0.0295\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0351 - val_loss: 0.0185\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0382 - val_loss: 0.0191\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0352 - val_loss: 0.0228\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0336 - val_loss: 0.0217\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0290 - val_loss: 0.0164\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0283 - val_loss: 0.0143\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0256 - val_loss: 0.0134\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0226 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0218 - val_loss: 0.0111\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0230 - val_loss: 0.0110\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0216 - val_loss: 0.0108\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0216 - val_loss: 0.0109\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0172 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0170 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0158 - val_loss: 0.0120\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0150 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0175 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0117\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0123\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0130\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0124\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0134\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0156\n",
      ">p=11: 3, Score=10.667908936738968\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 265ms/step - loss: 0.2331 - val_loss: 0.0697\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1400 - val_loss: 0.0206\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0635 - val_loss: 0.0417\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0522 - val_loss: 0.0787\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0389 - val_loss: 0.0366\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0349 - val_loss: 0.0208\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0362 - val_loss: 0.0212\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0310 - val_loss: 0.0265\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0252\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0268 - val_loss: 0.0164\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0273 - val_loss: 0.0160\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0233 - val_loss: 0.0140\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0213 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0193 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0200 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0178 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0169 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0107\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      ">p=11: 4, Score=2.179325371980667\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 8s 216ms/step - loss: 0.2343 - val_loss: 0.0703\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1312 - val_loss: 0.0186\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0582 - val_loss: 0.0457\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0521 - val_loss: 0.0680\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0391 - val_loss: 0.0300\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0365 - val_loss: 0.0191\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0341 - val_loss: 0.0195\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0332 - val_loss: 0.0218\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0300 - val_loss: 0.0207\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0286 - val_loss: 0.0161\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0276 - val_loss: 0.0134\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0268 - val_loss: 0.0126\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0243 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0246 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0214 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0206 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0126\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0159 - val_loss: 0.0127\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0152 - val_loss: 0.0133\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0141 - val_loss: 0.0126\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0132\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0125\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0120\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0122\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0118\n",
      ">p=11: 5, Score=4.576750844717026\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 8s 277ms/step - loss: 0.2263 - val_loss: 0.0694\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1268 - val_loss: 0.0180\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0521 - val_loss: 0.0502\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0523 - val_loss: 0.0685\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0350 - val_loss: 0.0272\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0327 - val_loss: 0.0170\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0341 - val_loss: 0.0182\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0301 - val_loss: 0.0235\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0279 - val_loss: 0.0219\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0280 - val_loss: 0.0159\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0240 - val_loss: 0.0139\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0244 - val_loss: 0.0128\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0234 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0197 - val_loss: 0.0108\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0186 - val_loss: 0.0108\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0155 - val_loss: 0.0125\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0124\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0129\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0124 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0122\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0094 - val_loss: 0.0120\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0121\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0111\n",
      ">p=11: 6, Score=5.217188969254494\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 214ms/step - loss: 0.2474 - val_loss: 0.0856\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1541 - val_loss: 0.0293\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0691 - val_loss: 0.0254\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0505 - val_loss: 0.0669\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0419 - val_loss: 0.0298\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0334 - val_loss: 0.0158\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0379 - val_loss: 0.0154\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0339 - val_loss: 0.0195\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0295 - val_loss: 0.0213\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0281 - val_loss: 0.0167\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0244 - val_loss: 0.0137\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0258 - val_loss: 0.0132\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0254 - val_loss: 0.0128\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0217 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0115\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0187 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0179 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0174 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0163 - val_loss: 0.0126\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0154 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0155 - val_loss: 0.0126\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0125\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0125\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0128\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0123\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0125\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0130\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0129\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0117\n",
      ">p=11: 7, Score=2.9726263135671616\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 9s 257ms/step - loss: 0.2254 - val_loss: 0.0679\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1277 - val_loss: 0.0185\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0600 - val_loss: 0.0503\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0524 - val_loss: 0.0658\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0375 - val_loss: 0.0270\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0353 - val_loss: 0.0177\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0358 - val_loss: 0.0198\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0317 - val_loss: 0.0247\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0283 - val_loss: 0.0213\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0265 - val_loss: 0.0152\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0270 - val_loss: 0.0134\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0240 - val_loss: 0.0133\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0252 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0208 - val_loss: 0.0112\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0211 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0215 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0180 - val_loss: 0.0113\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0186 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0162 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0166 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0150 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      ">p=11: 8, Score=4.462387412786484\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 215ms/step - loss: 0.2190 - val_loss: 0.0590\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1161 - val_loss: 0.0156\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0507 - val_loss: 0.0640\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0498 - val_loss: 0.0656\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0322 - val_loss: 0.0261\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0324 - val_loss: 0.0179\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0326 - val_loss: 0.0209\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0285 - val_loss: 0.0239\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0273 - val_loss: 0.0206\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0288 - val_loss: 0.0158\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0249 - val_loss: 0.0142\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0243 - val_loss: 0.0133\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0212 - val_loss: 0.0126\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0214 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0200 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0173 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0169 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0160 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0120\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0133 - val_loss: 0.0137\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      ">p=11: 9, Score=2.6028338819742203\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 9s 316ms/step - loss: 0.2357 - val_loss: 0.0654\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1384 - val_loss: 0.0186\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0613 - val_loss: 0.0459\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0498 - val_loss: 0.0821\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0390 - val_loss: 0.0370\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0353 - val_loss: 0.0207\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0343 - val_loss: 0.0211\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0333 - val_loss: 0.0267\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0288 - val_loss: 0.0254\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0279 - val_loss: 0.0198\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0263 - val_loss: 0.0167\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0243 - val_loss: 0.0168\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0233 - val_loss: 0.0160\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0222 - val_loss: 0.0125\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0207 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0175 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0170 - val_loss: 0.0116\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0157 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0146 - val_loss: 0.0128\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0176 - val_loss: 0.0132\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0117\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      ">p=11: 10, Score=2.7757422998547554\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 267ms/step - loss: 0.2470 - val_loss: 0.0933\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1663 - val_loss: 0.0440\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0953 - val_loss: 0.0156\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0474 - val_loss: 0.0417\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0457 - val_loss: 0.0666\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0413 - val_loss: 0.0367\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0325 - val_loss: 0.0200\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0342 - val_loss: 0.0161\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0353 - val_loss: 0.0170\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0293 - val_loss: 0.0199\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0289 - val_loss: 0.0180\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0250 - val_loss: 0.0138\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0231 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0198 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0215 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0207 - val_loss: 0.0113\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0184 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0194 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0171 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0174 - val_loss: 0.0120\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0124\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0171 - val_loss: 0.0122\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0134\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0172 - val_loss: 0.0122\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0143 - val_loss: 0.0132\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0127\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0125\n",
      ">p=12: 1, Score=5.152953788638115\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 315ms/step - loss: 0.2371 - val_loss: 0.0797\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1519 - val_loss: 0.0294\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0790 - val_loss: 0.0201\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0499 - val_loss: 0.0681\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0539 - val_loss: 0.0602\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0401 - val_loss: 0.0295\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0366 - val_loss: 0.0198\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0361 - val_loss: 0.0193\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0317 - val_loss: 0.0230\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0310 - val_loss: 0.0251\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0300 - val_loss: 0.0208\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0293 - val_loss: 0.0170\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0268 - val_loss: 0.0153\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0246 - val_loss: 0.0143\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0272 - val_loss: 0.0130\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0225 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0231 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0204 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0187 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0174 - val_loss: 0.0113\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0177 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0150 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0154 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0106\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0102\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      ">p=12: 2, Score=6.735513359308243\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 7s 248ms/step - loss: 0.2199 - val_loss: 0.0731\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1385 - val_loss: 0.0273\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0691 - val_loss: 0.0202\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0427 - val_loss: 0.0604\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0438 - val_loss: 0.0517\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0366 - val_loss: 0.0253\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0346 - val_loss: 0.0168\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0348 - val_loss: 0.0161\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0296 - val_loss: 0.0182\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0291 - val_loss: 0.0195\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0270 - val_loss: 0.0171\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0242 - val_loss: 0.0144\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0258 - val_loss: 0.0126\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0257 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0223 - val_loss: 0.0115\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0211 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0203 - val_loss: 0.0113\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0180 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0163 - val_loss: 0.0120\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0167 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0127\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.0126\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0124\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0126\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 0.0127\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0137\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0132\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 0.0116\n",
      ">p=12: 3, Score=4.110966995358467\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 251ms/step - loss: 0.2470 - val_loss: 0.0926\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1720 - val_loss: 0.0462\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1000 - val_loss: 0.0162\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0482 - val_loss: 0.0387\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0473 - val_loss: 0.0680\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0414 - val_loss: 0.0397\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0335 - val_loss: 0.0204\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0320 - val_loss: 0.0168\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0326 - val_loss: 0.0181\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0302 - val_loss: 0.0201\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0300 - val_loss: 0.0189\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0255 - val_loss: 0.0162\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0228 - val_loss: 0.0140\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0249 - val_loss: 0.0126\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0234 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0220 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0204 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0195 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0181 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0177 - val_loss: 0.0120\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0185 - val_loss: 0.0122\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0174 - val_loss: 0.0122\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0161 - val_loss: 0.0129\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0122\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0158 - val_loss: 0.0125\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0151 - val_loss: 0.0120\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0156 - val_loss: 0.0120\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      ">p=12: 4, Score=2.9133664444088936\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 254ms/step - loss: 0.2435 - val_loss: 0.0742\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1567 - val_loss: 0.0265\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0810 - val_loss: 0.0242\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0476 - val_loss: 0.0864\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0473 - val_loss: 0.0874\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0386 - val_loss: 0.0444\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0333 - val_loss: 0.0257\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0359 - val_loss: 0.0232\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0339 - val_loss: 0.0266\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0331 - val_loss: 0.0295\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0281 - val_loss: 0.0246\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0285 - val_loss: 0.0192\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0245 - val_loss: 0.0162\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0255 - val_loss: 0.0163\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0234 - val_loss: 0.0151\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0237 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0197 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0204 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0173 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0186 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0175 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0158 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.0120\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      ">p=12: 5, Score=3.9915766566991806\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 7s 296ms/step - loss: 0.2448 - val_loss: 0.0867\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1608 - val_loss: 0.0372\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0879 - val_loss: 0.0163\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0486 - val_loss: 0.0526\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0480 - val_loss: 0.0647\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0399 - val_loss: 0.0354\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0352 - val_loss: 0.0214\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0341 - val_loss: 0.0193\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0315 - val_loss: 0.0223\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0294 - val_loss: 0.0259\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0334 - val_loss: 0.0243\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0311 - val_loss: 0.0194\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0276 - val_loss: 0.0158\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0285 - val_loss: 0.0146\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0248 - val_loss: 0.0139\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0207 - val_loss: 0.0133\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0213 - val_loss: 0.0125\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0196 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0204 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0194 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0183 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0169 - val_loss: 0.0118\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0187 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0163 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0176 - val_loss: 0.0121\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0175 - val_loss: 0.0121\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0161 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0119\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0138 - val_loss: 0.0118\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      ">p=12: 6, Score=4.038573428988457\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 288ms/step - loss: 0.2161 - val_loss: 0.0599\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1287 - val_loss: 0.0184\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0605 - val_loss: 0.0370\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0496 - val_loss: 0.0848\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0387 - val_loss: 0.0576\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0346 - val_loss: 0.0309\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0342 - val_loss: 0.0223\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0331 - val_loss: 0.0234\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0340 - val_loss: 0.0277\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0311 - val_loss: 0.0269\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0276 - val_loss: 0.0228\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0257 - val_loss: 0.0181\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0261 - val_loss: 0.0160\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0249 - val_loss: 0.0150\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0236 - val_loss: 0.0145\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0200 - val_loss: 0.0135\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0208 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0213 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0214 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0183 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0168 - val_loss: 0.0119\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0166 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0163 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0171 - val_loss: 0.0120\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0166 - val_loss: 0.0124\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0164 - val_loss: 0.0122\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0126\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0125\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0094 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      ">p=12: 7, Score=4.035813361406326\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 270ms/step - loss: 0.2302 - val_loss: 0.0714\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1469 - val_loss: 0.0254\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0730 - val_loss: 0.0231\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0462 - val_loss: 0.0773\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0476 - val_loss: 0.0658\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0351 - val_loss: 0.0316\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0335 - val_loss: 0.0205\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0355 - val_loss: 0.0205\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0303 - val_loss: 0.0240\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0321 - val_loss: 0.0255\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0287 - val_loss: 0.0213\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0263 - val_loss: 0.0163\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0265 - val_loss: 0.0140\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0236 - val_loss: 0.0138\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0221 - val_loss: 0.0128\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0219 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0184 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0182 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0176 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0158 - val_loss: 0.0126\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0166 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0134\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      ">p=12: 8, Score=4.0985021740198135\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 7s 253ms/step - loss: 0.2419 - val_loss: 0.0849\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1577 - val_loss: 0.0341\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0835 - val_loss: 0.0175\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0491 - val_loss: 0.0587\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0516 - val_loss: 0.0646\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0379 - val_loss: 0.0358\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0352 - val_loss: 0.0222\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0354 - val_loss: 0.0206\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0344 - val_loss: 0.0232\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0336 - val_loss: 0.0255\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0320 - val_loss: 0.0233\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0308 - val_loss: 0.0195\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0293 - val_loss: 0.0167\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0263 - val_loss: 0.0148\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0260 - val_loss: 0.0139\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0255 - val_loss: 0.0131\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0231 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0199 - val_loss: 0.0116\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0212 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0162 - val_loss: 0.0123\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 0.0130\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0154 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0148 - val_loss: 0.0126\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0122\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0136 - val_loss: 0.0132\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0152\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0116 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0133\n",
      ">p=12: 9, Score=5.335303023457527\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 6s 259ms/step - loss: 0.2298 - val_loss: 0.0742\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1484 - val_loss: 0.0278\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0782 - val_loss: 0.0209\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0498 - val_loss: 0.0744\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0536 - val_loss: 0.0639\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0348 - val_loss: 0.0313\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0341 - val_loss: 0.0211\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0354 - val_loss: 0.0209\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0326 - val_loss: 0.0247\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0296 - val_loss: 0.0262\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0295 - val_loss: 0.0223\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0265 - val_loss: 0.0179\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0260 - val_loss: 0.0141\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0252 - val_loss: 0.0130\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0221 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0219 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0180 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0188 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0184 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0171 - val_loss: 0.0115\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0115\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0109\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      ">p=12: 10, Score=2.4448467418551445\n",
      "[[10.008285939693451, 10.408152639865875, 22.148998081684113, 23.787890374660492, 10.526014864444733, 20.20866721868515, 1.7686773091554642, 10.360205918550491, 11.193948239088058, 6.501810252666473], [10.47384962439537, 5.188873782753944, 7.026178389787674, 1.359060127288103, 6.324540078639984, 15.890179574489594, 2.708166651427746, 5.282311886548996, 4.251116141676903, 9.529805183410645], [5.373033508658409, 3.1323738396167755, 6.38791099190712, 4.257103428244591, 6.988023221492767, 6.305281072854996, 5.4221101105213165, 5.296016111969948, 5.180847644805908, 13.130475580692291], [3.6312203854322433, 4.762069880962372, 7.247413694858551, 2.6485757902264595, 6.752236187458038, 6.007843464612961, 5.744945630431175, 2.8157707303762436, 8.038640767335892, 4.543391615152359], [2.753355912864208, 2.7110151946544647, 1.988792046904564, 2.126128412783146, 5.0308071076869965, 3.908773884177208, 3.1979724764823914, 5.322062969207764, 4.544321075081825, 4.6980176120996475], [2.460463158786297, 2.8016185387969017, 3.7221841514110565, 2.0564408972859383, 3.5401981323957443, 3.009364940226078, 2.345559187233448, 9.449076652526855, 2.0515529438853264, 1.7299599945545197], [3.8704313337802887, 2.751162461936474, 2.976303920149803, 1.8907131627202034, 7.591589540243149, 4.508638009428978, 2.344803139567375, 4.802713543176651, 3.699546307325363, 5.305995792150497], [2.0816007629036903, 2.5470660999417305, 4.717385768890381, 3.4487824887037277, 6.169049441814423, 3.0905889347195625, 1.979626901447773, 3.935065120458603, 6.931819766759872, 5.553416907787323], [3.8831807672977448, 2.1963434293866158, 2.335452474653721, 5.701271444559097, 2.341539040207863, 2.0239369943737984, 2.630610018968582, 4.217850789427757, 1.9413281232118607, 2.341194823384285], [3.521456941962242, 5.3479742258787155, 4.052921757102013, 1.993114873766899, 2.5283312425017357, 5.0873056054115295, 2.5250840932130814, 2.4428728967905045, 2.727704495191574, 5.730830505490303], [6.477124989032745, 2.5328047573566437, 10.667908936738968, 2.179325371980667, 4.576750844717026, 5.217188969254494, 2.9726263135671616, 4.462387412786484, 2.6028338819742203, 2.7757422998547554], [5.152953788638115, 6.735513359308243, 4.110966995358467, 2.9133664444088936, 3.9915766566991806, 4.038573428988457, 4.035813361406326, 4.0985021740198135, 5.335303023457527, 2.4448467418551445]] [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Param=1, Mean=12.691, Std=6.719\n",
      "Param=2, Mean=6.803, Std=4.020\n",
      "Param=3, Mean=6.147, Std=2.550\n",
      "Param=4, Mean=5.219, Std=1.757\n",
      "Param=5, Mean=3.628, Std=1.168\n",
      "Param=6, Mean=3.317, Std=2.135\n",
      "Param=7, Mean=3.974, Std=1.594\n",
      "Param=8, Mean=4.045, Std=1.650\n",
      "Param=9, Mean=2.961, Std=1.171\n",
      "Param=10, Mean=3.596, Std=1.304\n",
      "Param=11, Mean=4.446, Std=2.462\n",
      "Param=12, Mean=4.286, Std=1.158\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = 80, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.LSTM(units = 80))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=batch_size, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=batch_size)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # resumindo a média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = np.mean(scores[i]), np.std(scores[i])\n",
    "        print(f'Param={params[i]}, Mean={m:.3f}, Std={s:.3f}')\n",
    "    # boxplot das pontuações\n",
    "    plt.boxplot(scores, labels=params)\n",
    "    plt.savefig('../../src/static/images/despesas/figura[1].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repetindo o experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            score = score * 100.0\n",
    "            scores.append(score)\n",
    "            print(f'>p={p}: {r+1}, Score={score}')\n",
    "        all_scores.append(scores)\n",
    "    # resumindo os resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = np.arange(1, 13)\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste no modelo com diluição - dropout - 0.05, 0.1, 0.2, 0.3, para verficação do mais adequado para a aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 129ms/step - loss: 0.1969 - val_loss: 0.0276\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0626 - val_loss: 0.0566\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0363 - val_loss: 0.0220\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0347 - val_loss: 0.0175\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0321 - val_loss: 0.0163\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0281 - val_loss: 0.0130\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0271 - val_loss: 0.0120\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0119\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0123\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0137\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0129\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0132\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0127\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0134\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0128\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0120\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0155\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0140\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0120\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0143\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0133\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0120\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0124\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0124\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0156\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0129\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0134\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0285 - val_loss: 0.0256\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0096\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0133\n",
      ">p=0.05: 1, Score=0.05209779739379883\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 101ms/step - loss: 0.1903 - val_loss: 0.0191\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0572 - val_loss: 0.0687\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0306 - val_loss: 0.0219\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0340 - val_loss: 0.0211\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0291 - val_loss: 0.0188\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0261 - val_loss: 0.0131\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0235 - val_loss: 0.0119\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0112\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0199 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0251 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0106\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0232 - val_loss: 0.0148\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0102\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0111\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0107\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0111\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0095\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0096\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0165\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      ">p=0.05: 2, Score=0.048340439796447754\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 115ms/step - loss: 0.1952 - val_loss: 0.0237\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0568 - val_loss: 0.0564\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0330 - val_loss: 0.0190\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0332 - val_loss: 0.0177\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0284 - val_loss: 0.0153\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0274 - val_loss: 0.0121\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0163 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0124\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0125\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0130\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0132\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0115\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0128\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0112\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0112\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0173\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0145\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0111\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0151\n",
      ">p=0.05: 3, Score=0.03740783408284187\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 9s 121ms/step - loss: 0.1832 - val_loss: 0.0214\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0565 - val_loss: 0.0545\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0304 - val_loss: 0.0200\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0328 - val_loss: 0.0187\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0283 - val_loss: 0.0154\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0266 - val_loss: 0.0130\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.0113\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.0108\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0110\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0113\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0111\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0110\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0122\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0119\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0101\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0098\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0107\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0142\n",
      ">p=0.05: 4, Score=0.061193838715553284\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 110ms/step - loss: 0.1726 - val_loss: 0.0205\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0493 - val_loss: 0.0393\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0360 - val_loss: 0.0147\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0336 - val_loss: 0.0149\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0288 - val_loss: 0.0127\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0270 - val_loss: 0.0115\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0112\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0130\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0143 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0137\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0131\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0154\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0166\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0174\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0154\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0143\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0144\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0122\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0144\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0143\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0181\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0169\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0202\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0140\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0141\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0216\n",
      ">p=0.05: 5, Score=0.07177538424730301\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 128ms/step - loss: 0.1856 - val_loss: 0.0219\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0563 - val_loss: 0.0554\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0337 - val_loss: 0.0194\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0353 - val_loss: 0.0181\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0320 - val_loss: 0.0180\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0265 - val_loss: 0.0132\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0245 - val_loss: 0.0123\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0239 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0113\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0165 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0186 - val_loss: 0.0123\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0156 - val_loss: 0.0126\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0129\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0132\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0120\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0141\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0110\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0130\n",
      ">p=0.05: 6, Score=0.032215435057878494\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 106ms/step - loss: 0.1815 - val_loss: 0.0176\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0572 - val_loss: 0.0661\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0319 - val_loss: 0.0217\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0363 - val_loss: 0.0210\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0197\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0288 - val_loss: 0.0147\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0256 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0116\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0127\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0127\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0126\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0207 - val_loss: 0.0136\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0126\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0124\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0126\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0130\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0115\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0219 - val_loss: 0.0113\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0125\n",
      ">p=0.05: 7, Score=0.033384304493665695\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 113ms/step - loss: 0.1838 - val_loss: 0.0192\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0554 - val_loss: 0.0574\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0337 - val_loss: 0.0195\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0348 - val_loss: 0.0203\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0296 - val_loss: 0.0162\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0273 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0257 - val_loss: 0.0118\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0110\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0217 - val_loss: 0.0109\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0123\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0133\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0125\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0118\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0104\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0145\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0099\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0130\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0108\n",
      ">p=0.05: 8, Score=0.023327847942709923\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 9s 105ms/step - loss: 0.1743 - val_loss: 0.0178\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0592 - val_loss: 0.0585\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0350 - val_loss: 0.0222\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0355 - val_loss: 0.0231\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0326 - val_loss: 0.0202\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0311 - val_loss: 0.0155\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0134\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0121\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0229 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 0.0121\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0129\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0130\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0131\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0129\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0129\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0268 - val_loss: 0.0156\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0106\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 0.0169\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0117\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0117\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0124\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0111\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0113\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0128\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0221 - val_loss: 0.0129\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      ">p=0.05: 9, Score=0.02211633510887623\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 127ms/step - loss: 0.1811 - val_loss: 0.0194\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0584 - val_loss: 0.0599\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0357 - val_loss: 0.0234\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0366 - val_loss: 0.0201\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0333 - val_loss: 0.0183\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0294 - val_loss: 0.0132\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0263 - val_loss: 0.0117\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.0108\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0110\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0111\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0115\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0133\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0118\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0161\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0120\n",
      ">p=0.05: 10, Score=0.06753332167863846\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 105ms/step - loss: 0.1952 - val_loss: 0.0307\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0572 - val_loss: 0.0502\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0390 - val_loss: 0.0198\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0341 - val_loss: 0.0191\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0330 - val_loss: 0.0193\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0290 - val_loss: 0.0148\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0283 - val_loss: 0.0140\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0286 - val_loss: 0.0118\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0232 - val_loss: 0.0113\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0194 - val_loss: 0.0122\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0157 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0125\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0115\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0125 - val_loss: 0.0132\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0134\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0108\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0176\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0162\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0112\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0115\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0136\n",
      ">p=0.1: 1, Score=0.06142815575003624\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 105ms/step - loss: 0.1843 - val_loss: 0.0207\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0544 - val_loss: 0.0514\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0330 - val_loss: 0.0193\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0342 - val_loss: 0.0188\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0273 - val_loss: 0.0142\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0286 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0261 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0110\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0125\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0184 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0173 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0124\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0130\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0124\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0121\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0116\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0136\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0156\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0123\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0116\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0146\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0147\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0194\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0128\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0146\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0142\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0129\n",
      ">p=0.1: 2, Score=0.04001408815383911\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 103ms/step - loss: 0.1798 - val_loss: 0.0208\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0565 - val_loss: 0.0484\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0357 - val_loss: 0.0176\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0351 - val_loss: 0.0182\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0299 - val_loss: 0.0158\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0298 - val_loss: 0.0129\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0252 - val_loss: 0.0119\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0228 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0224 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0191 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0126\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0158 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0113\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0142\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0125\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0133\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0129\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0136\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0165 - val_loss: 0.0101\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0154\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0139\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0134\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0120\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0117\n",
      ">p=0.1: 3, Score=0.04586941376328468\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 115ms/step - loss: 0.1879 - val_loss: 0.0198\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0542 - val_loss: 0.0690\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0354 - val_loss: 0.0209\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0329 - val_loss: 0.0234\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0301 - val_loss: 0.0206\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0283 - val_loss: 0.0156\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0288 - val_loss: 0.0137\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0221 - val_loss: 0.0118\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0227 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0109\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0123\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0100\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0324 - val_loss: 0.0137\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0091\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0128\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0093\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0098\n",
      ">p=0.1: 4, Score=0.018407141789793968\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 114ms/step - loss: 0.1825 - val_loss: 0.0182\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0569 - val_loss: 0.0637\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0362 - val_loss: 0.0223\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0343 - val_loss: 0.0235\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0301 - val_loss: 0.0189\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0268 - val_loss: 0.0155\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0129\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0238 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0213 - val_loss: 0.0109\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0124\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0176 - val_loss: 0.0117\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0132\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0226 - val_loss: 0.0111\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0145\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0106\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0130\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      ">p=0.1: 5, Score=0.036636631935834885\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 104ms/step - loss: 0.1754 - val_loss: 0.0181\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0517 - val_loss: 0.0536\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0337 - val_loss: 0.0169\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0345 - val_loss: 0.0187\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0293 - val_loss: 0.0174\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0124\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0124\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.0112\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0198 - val_loss: 0.0114\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0123\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0155 - val_loss: 0.0128\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0131\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0133\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0126\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0125\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0182 - val_loss: 0.0138\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0115\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 0.0117\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0146\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0113\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0117\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0118\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0089 - val_loss: 0.0125\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0112\n",
      ">p=0.1: 6, Score=0.024406349286437035\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 117ms/step - loss: 0.1953 - val_loss: 0.0207\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0625 - val_loss: 0.0674\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0355 - val_loss: 0.0267\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0379 - val_loss: 0.0263\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0337 - val_loss: 0.0237\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0297 - val_loss: 0.0210\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0287 - val_loss: 0.0159\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0219 - val_loss: 0.0140\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0126\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0180 - val_loss: 0.0132\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0123\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0130\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0136\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0127\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0131\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0108\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0125\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0151\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0108\n",
      ">p=0.1: 7, Score=0.04839835315942764\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 102ms/step - loss: 0.1993 - val_loss: 0.0284\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0647 - val_loss: 0.0595\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0387 - val_loss: 0.0253\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0395 - val_loss: 0.0206\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0311 - val_loss: 0.0229\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0283 - val_loss: 0.0165\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0139\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0227 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0207 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0123\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0122\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0119\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0161 - val_loss: 0.0126\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0116\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0111\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0134\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      ">p=0.1: 8, Score=0.041103001683950424\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 103ms/step - loss: 0.1789 - val_loss: 0.0191\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0561 - val_loss: 0.0589\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0370 - val_loss: 0.0208\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0340 - val_loss: 0.0205\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0311 - val_loss: 0.0171\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0265 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0244 - val_loss: 0.0123\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0204 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0214 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0117\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0124\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0130\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0125\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0140\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0126\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0122\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0228 - val_loss: 0.0142\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0107\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0126\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0117\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0115\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0111\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0108\n",
      ">p=0.1: 9, Score=0.02491574175655842\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 141ms/step - loss: 0.1849 - val_loss: 0.0223\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0560 - val_loss: 0.0504\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0328 - val_loss: 0.0184\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0330 - val_loss: 0.0177\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0305 - val_loss: 0.0151\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0130\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0247 - val_loss: 0.0116\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0256 - val_loss: 0.0110\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0206 - val_loss: 0.0110\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0112\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0165 - val_loss: 0.0118\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0129\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0162 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0161 - val_loss: 0.0131\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 0.0123\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0115\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0139 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0125\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0136\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0117\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0115\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0108\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      ">p=0.1: 10, Score=0.05596113204956055\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 107ms/step - loss: 0.1915 - val_loss: 0.0239\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0524 - val_loss: 0.0611\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0368 - val_loss: 0.0202\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0337 - val_loss: 0.0169\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0292 - val_loss: 0.0170\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0279 - val_loss: 0.0138\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0122\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0213 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0199 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0213 - val_loss: 0.0114\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0228 - val_loss: 0.0119\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0193 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0203 - val_loss: 0.0134\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0112\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 0.0130\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0129\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0145\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0141\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0181\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0137\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0146\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0097\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0153\n",
      ">p=0.2: 1, Score=0.049160186201334\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 103ms/step - loss: 0.2081 - val_loss: 0.0355\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0629 - val_loss: 0.0558\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0412 - val_loss: 0.0199\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0383 - val_loss: 0.0173\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0354 - val_loss: 0.0188\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0302 - val_loss: 0.0141\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0248 - val_loss: 0.0135\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0231 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0219 - val_loss: 0.0108\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0232 - val_loss: 0.0107\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0108\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0110\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0113\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0113\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0165 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0108\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0190 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0104\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0098\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0126\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0149\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0105\n",
      ">p=0.2: 2, Score=0.03398884832859039\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 110ms/step - loss: 0.1825 - val_loss: 0.0245\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0567 - val_loss: 0.0529\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0406 - val_loss: 0.0202\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0380 - val_loss: 0.0182\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0342 - val_loss: 0.0206\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0338 - val_loss: 0.0143\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0282 - val_loss: 0.0137\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 0.0115\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0218 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0204 - val_loss: 0.0115\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0195 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0132\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0171 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0125\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0110\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0136\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0120\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0118\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0108\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0178 - val_loss: 0.0107\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0102\n",
      ">p=0.2: 3, Score=0.04363931342959404\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 128ms/step - loss: 0.1700 - val_loss: 0.0168\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0483 - val_loss: 0.0512\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0328 - val_loss: 0.0179\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0342 - val_loss: 0.0170\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0284 - val_loss: 0.0153\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0240 - val_loss: 0.0124\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0227 - val_loss: 0.0113\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0216 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0128\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0130\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0132\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0140 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0126\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0129\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.0127\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0130\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0135\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0124\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0123\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0141\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 0.0149\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0109\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0109\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0158\n",
      ">p=0.2: 4, Score=0.047689396888017654\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 105ms/step - loss: 0.1885 - val_loss: 0.0231\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0604 - val_loss: 0.0579\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0336 - val_loss: 0.0206\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0381 - val_loss: 0.0209\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0336 - val_loss: 0.0188\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0281 - val_loss: 0.0138\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0302 - val_loss: 0.0142\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0118\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0234 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0232 - val_loss: 0.0107\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0227 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0110\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0181 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0161 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0165 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0119\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0142 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0138\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0136\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0108\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0131\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0201 - val_loss: 0.0101\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0102\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0202\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0160\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0117\n",
      ">p=0.2: 5, Score=0.051790859550237656\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 106ms/step - loss: 0.1534 - val_loss: 0.0158\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0516 - val_loss: 0.0609\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0382 - val_loss: 0.0209\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0399 - val_loss: 0.0190\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0345 - val_loss: 0.0184\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0322 - val_loss: 0.0161\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0282 - val_loss: 0.0130\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0244 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0250 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.0109\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0217 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0227 - val_loss: 0.0112\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0211 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0122\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0123\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0161 - val_loss: 0.0120\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0186\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0140\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0162\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0125\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0134\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0148\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0120\n",
      ">p=0.2: 6, Score=0.03493581712245941\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 105ms/step - loss: 0.1832 - val_loss: 0.0197\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0593 - val_loss: 0.0674\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0380 - val_loss: 0.0272\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0335 - val_loss: 0.0218\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0364 - val_loss: 0.0201\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0304 - val_loss: 0.0148\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0300 - val_loss: 0.0134\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0257 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0226 - val_loss: 0.0116\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 0.0110\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0166 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0126\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0156 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0146 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0122\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0115\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0112\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0114\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0167 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0214 - val_loss: 0.0092\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0188 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0192\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      ">p=0.2: 7, Score=0.03219658508896828\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 116ms/step - loss: 0.1905 - val_loss: 0.0230\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0635 - val_loss: 0.0662\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0329 - val_loss: 0.0301\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0408 - val_loss: 0.0222\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0345 - val_loss: 0.0202\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0296 - val_loss: 0.0153\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0249 - val_loss: 0.0156\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0267 - val_loss: 0.0121\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0236 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0183 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0199 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0182 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0162 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0194 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0119\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0116\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0122\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0137\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0126\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0178 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 0.0140\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      ">p=0.2: 8, Score=0.05444246530532837\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 105ms/step - loss: 0.1897 - val_loss: 0.0231\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0553 - val_loss: 0.0548\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0386 - val_loss: 0.0199\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0342 - val_loss: 0.0203\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0331 - val_loss: 0.0163\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0295 - val_loss: 0.0148\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0258 - val_loss: 0.0133\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0250 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0247 - val_loss: 0.0122\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0119\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0119\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0127\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0182 - val_loss: 0.0135\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0134\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0131\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0129\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0114\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0146\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0160 - val_loss: 0.0109\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0160 - val_loss: 0.0108\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0114\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0111\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0109\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0110\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0111\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0097\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0095\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      ">p=0.2: 9, Score=0.022590482607483864\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 104ms/step - loss: 0.1956 - val_loss: 0.0244\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0573 - val_loss: 0.0583\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0403 - val_loss: 0.0224\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0388 - val_loss: 0.0179\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0311 - val_loss: 0.0213\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0302 - val_loss: 0.0157\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0278 - val_loss: 0.0126\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0126\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0257 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0251 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0236 - val_loss: 0.0113\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0111\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0213 - val_loss: 0.0113\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0178 - val_loss: 0.0116\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0117\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0199 - val_loss: 0.0117\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0128\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0111\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0121\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0165 - val_loss: 0.0116\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0154 - val_loss: 0.0114\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0100\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0099\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0126\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0128\n",
      ">p=0.2: 10, Score=0.043063413351774216\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 109ms/step - loss: 0.1959 - val_loss: 0.0263\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0638 - val_loss: 0.0496\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0366 - val_loss: 0.0228\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0382 - val_loss: 0.0177\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0362 - val_loss: 0.0175\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0316 - val_loss: 0.0145\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0329 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0251 - val_loss: 0.0119\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0292 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0277 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0242 - val_loss: 0.0112\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0112\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0249 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0220 - val_loss: 0.0128\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0120\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0156\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0135\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0189 - val_loss: 0.0132\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0192 - val_loss: 0.0124\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0126\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0121\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0121\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0135\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0216 - val_loss: 0.0158\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0188 - val_loss: 0.0113\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0193\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0168\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0165\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0141 - val_loss: 0.0127\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0171\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0140\n",
      ">p=0.3: 1, Score=0.038148414343595505\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 107ms/step - loss: 0.1788 - val_loss: 0.0207\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0591 - val_loss: 0.0514\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0387 - val_loss: 0.0243\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0425 - val_loss: 0.0182\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0330 - val_loss: 0.0217\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0282 - val_loss: 0.0147\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0272 - val_loss: 0.0120\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0275 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0239 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0251 - val_loss: 0.0114\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0214 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0208 - val_loss: 0.0120\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0206 - val_loss: 0.0119\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0214 - val_loss: 0.0117\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0194 - val_loss: 0.0170\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0159 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0174 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0164 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.0162 - val_loss: 0.0122\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0187 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0182 - val_loss: 0.0139\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0112\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0127\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0163 - val_loss: 0.0140\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0171 - val_loss: 0.0114\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0233 - val_loss: 0.0159\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0098\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0113\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      ">p=0.3: 2, Score=0.05988004058599472\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 127ms/step - loss: 0.1931 - val_loss: 0.0279\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0648 - val_loss: 0.0555\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0416 - val_loss: 0.0280\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0395 - val_loss: 0.0180\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0398 - val_loss: 0.0196\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0321 - val_loss: 0.0169\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0264 - val_loss: 0.0146\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0291 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0126\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0240 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0240 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0222 - val_loss: 0.0116\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0240 - val_loss: 0.0121\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0228 - val_loss: 0.0139\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0124\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0120\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0119\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 0.0130\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0121\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 0.0136\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0180 - val_loss: 0.0117\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0118\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0121\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0134\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0132\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0123\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0200 - val_loss: 0.0149\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0115\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0106\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0106\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0104\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 0.0108\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0104\n",
      ">p=0.3: 3, Score=0.02585066482424736\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 123ms/step - loss: 0.1986 - val_loss: 0.0261\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0628 - val_loss: 0.0621\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0434 - val_loss: 0.0265\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0416 - val_loss: 0.0202\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0387 - val_loss: 0.0254\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0354 - val_loss: 0.0168\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0367 - val_loss: 0.0144\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0315 - val_loss: 0.0149\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0288 - val_loss: 0.0119\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0271 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0228 - val_loss: 0.0124\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0235 - val_loss: 0.0122\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0227 - val_loss: 0.0130\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0216 - val_loss: 0.0119\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.0119\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0119\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0129\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0155 - val_loss: 0.0132\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0122\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0122\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0126\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0155\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0127\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0127\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.0125\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 0.0160\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0166 - val_loss: 0.0111\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0132\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0109\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0181 - val_loss: 0.0115\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0158 - val_loss: 0.0120\n",
      ">p=0.3: 4, Score=0.02493997849524021\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 9s 149ms/step - loss: 0.1820 - val_loss: 0.0168\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0655 - val_loss: 0.0711\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0410 - val_loss: 0.0319\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0389 - val_loss: 0.0245\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0344 - val_loss: 0.0220\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0295 - val_loss: 0.0190\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0310 - val_loss: 0.0140\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0279 - val_loss: 0.0120\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0270 - val_loss: 0.0127\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0255 - val_loss: 0.0116\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0218 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0237 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 0.0122\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0125\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0128\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0127\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0124\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0175 - val_loss: 0.0132\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0129\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0139\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0129\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0119\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0115\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 0.0136\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0161\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0131\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0132\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.0154 - val_loss: 0.0127\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0170 - val_loss: 0.0125\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0152 - val_loss: 0.0120\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0176 - val_loss: 0.0205\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.0106\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      ">p=0.3: 5, Score=0.043039798736572266\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 106ms/step - loss: 0.1739 - val_loss: 0.0165\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0559 - val_loss: 0.0535\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0383 - val_loss: 0.0209\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0401 - val_loss: 0.0195\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0365 - val_loss: 0.0199\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.0141\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0345 - val_loss: 0.0145\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0272 - val_loss: 0.0114\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0236 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0252 - val_loss: 0.0107\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0224 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 0.0107\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0192 - val_loss: 0.0109\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0112\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0216 - val_loss: 0.0122\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0228 - val_loss: 0.0109\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0166 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0213 - val_loss: 0.0116\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0107\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0129\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0110\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0177 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0106\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0095\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0280 - val_loss: 0.0153\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0096\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0101\n",
      ">p=0.3: 6, Score=0.022370675578713417\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 154ms/step - loss: 0.1867 - val_loss: 0.0243\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0635 - val_loss: 0.0421\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0355 - val_loss: 0.0261\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0327 - val_loss: 0.0192\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0338 - val_loss: 0.0179\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0154\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0322 - val_loss: 0.0133\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0234 - val_loss: 0.0117\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0259 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0194 - val_loss: 0.0123\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0127\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0130\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0124\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0123\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0165 - val_loss: 0.0125\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0209 - val_loss: 0.0131\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0213 - val_loss: 0.0125\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0123\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0134\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0140 - val_loss: 0.0128\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0143\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0146\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0127\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0132\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0128\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0135\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0156\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0115\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0151\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0145\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0170\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0182\n",
      ">p=0.3: 7, Score=0.05679154768586159\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 7s 109ms/step - loss: 0.1861 - val_loss: 0.0224\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0569 - val_loss: 0.0526\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0422 - val_loss: 0.0192\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0392 - val_loss: 0.0166\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0337 - val_loss: 0.0166\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0254 - val_loss: 0.0135\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0277 - val_loss: 0.0124\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0252 - val_loss: 0.0118\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0220 - val_loss: 0.0109\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0232 - val_loss: 0.0107\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0231 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0205 - val_loss: 0.0109\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0110\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0177 - val_loss: 0.0111\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0111\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0114\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0117\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0221 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0107\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0111\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0105\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0102\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0157 - val_loss: 0.0101\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0136\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0099\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0102\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0113\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0141\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0106\n",
      ">p=0.3: 8, Score=0.027515845373272896\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 8s 117ms/step - loss: 0.1896 - val_loss: 0.0283\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0629 - val_loss: 0.0580\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0428 - val_loss: 0.0231\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0382 - val_loss: 0.0174\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0351 - val_loss: 0.0193\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0358 - val_loss: 0.0163\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0339 - val_loss: 0.0137\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0303 - val_loss: 0.0121\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0229 - val_loss: 0.0114\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0241 - val_loss: 0.0111\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0220 - val_loss: 0.0111\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0220 - val_loss: 0.0112\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0195 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0195 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0227 - val_loss: 0.0118\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0131\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0142\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0191 - val_loss: 0.0155\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0123\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0163 - val_loss: 0.0119\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0126\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0147\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0173 - val_loss: 0.0126\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0202\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0114\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0139\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0136\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0130\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0140\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0133\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0137\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0133\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0107\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0152 - val_loss: 0.0135\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      ">p=0.3: 9, Score=0.058982182294130325\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 9s 101ms/step - loss: 0.1834 - val_loss: 0.0211\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0577 - val_loss: 0.0641\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0320 - val_loss: 0.0281\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0367 - val_loss: 0.0231\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0238\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0307 - val_loss: 0.0178\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0281 - val_loss: 0.0160\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0239 - val_loss: 0.0155\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0254 - val_loss: 0.0112\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0116\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0125\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0205 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0165 - val_loss: 0.0115\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0185 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0123\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0114\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0181 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0114\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0147\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0114\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0115\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0144\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0161 - val_loss: 0.0119\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0111\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0140\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0110\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0112\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0128\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0106\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0105\n",
      ">p=0.3: 10, Score=0.021230032667517662\n",
      "[[0.05209779739379883, 0.048340439796447754, 0.03740783408284187, 0.061193838715553284, 0.07177538424730301, 0.032215435057878494, 0.033384304493665695, 0.023327847942709923, 0.02211633510887623, 0.06753332167863846], [0.06142815575003624, 0.04001408815383911, 0.04586941376328468, 0.018407141789793968, 0.036636631935834885, 0.024406349286437035, 0.04839835315942764, 0.041103001683950424, 0.02491574175655842, 0.05596113204956055], [0.049160186201334, 0.03398884832859039, 0.04363931342959404, 0.047689396888017654, 0.051790859550237656, 0.03493581712245941, 0.03219658508896828, 0.05444246530532837, 0.022590482607483864, 0.043063413351774216], [0.038148414343595505, 0.05988004058599472, 0.02585066482424736, 0.02493997849524021, 0.043039798736572266, 0.022370675578713417, 0.05679154768586159, 0.027515845373272896, 0.058982182294130325, 0.021230032667517662]] [0.05, 0.1, 0.2, 0.3]\n",
      "Param=0.05, Mean=0.045:, Std=0.017\n",
      "Param=0.1, Mean=0.040:, Std=0.013\n",
      "Param=0.2, Mean=0.041:, Std=0.010\n",
      "Param=0.3, Mean=0.038:, Std=0.015\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, dropout):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = 80, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units = 80))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=5, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=5)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # resumindo a média e desvio padrão\n",
    "    for i in range(len(scores)):\n",
    "        m, s = np.mean(scores[i]), np.std(scores[i])\n",
    "        print(f'Param={params[i]}, Mean={m:.3f}:, Std={s:.3f}')\n",
    "    # boxplot das pontuações\n",
    "    plt.boxplot(scores, labels=params)\n",
    "    plt.savefig('../../src/static/images/despesas/figura[2].png')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(params, repeats = 10):\n",
    "    # Testando cada parâmetro\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repetindo o experimento\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(X_train, y_train, X_test, y_test, p)\n",
    "            score = score\n",
    "            scores.append(score)\n",
    "            print(f'>p={p}: {r+1}, Score={score}')\n",
    "        all_scores.append(scores)\n",
    "    # resumindo os resultados\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# Rodando o experimento\n",
    "n_params = [0.05, 0.1, 0.2, 0.3]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando o modelo com os padrões mais adequados visualizados nos testes anteriores.\n",
    "<p>Neurônios = 85</p>\n",
    "<p>Tamanho do lote/batch = 6</p>\n",
    "<p>Dopout = 0.2</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = \n",
    "batch_size = \n",
    "dropout = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 9s 184ms/step - loss: 0.1985 - val_loss: 0.0353\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0685 - val_loss: 0.0492\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0372 - val_loss: 0.0210\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0343 - val_loss: 0.0247\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0331 - val_loss: 0.0171\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0302 - val_loss: 0.0139\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0253 - val_loss: 0.0128\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0112\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.0109\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0113\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0195 - val_loss: 0.0111\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0124\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.0126\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0115\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0113\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0111\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0139\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0115\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0100\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0138\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0124\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0092\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0105\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0092\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0086\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0091\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0176\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0079\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0125\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0088\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0127\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0111\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0154\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0169\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0075\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0093\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0134\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0120\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0099\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0147\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0096\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0179\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0102\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0120\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0096\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0106\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0105\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0106\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0103\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0170\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0057\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0211\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0171\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0061\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0122\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0100\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0104\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0127\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0145\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0107\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0074\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0130\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0140\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0074\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0108\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0100\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0147\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0188\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0064\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0120\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0127\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0126\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 0.0118\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0129\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0125\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0131\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0129\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0126\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0160\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0116\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0097\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0145\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0197\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0061 - val_loss: 0.0161\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0088\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0151\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0085\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0086\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0096\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0119\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0092\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0091\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0131\n",
      ">1: Score=0.1296929568052292\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 9s 184ms/step - loss: 0.1879 - val_loss: 0.0262\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0630 - val_loss: 0.0591\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0420 - val_loss: 0.0350\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0355 - val_loss: 0.0197\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0328 - val_loss: 0.0235\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0286 - val_loss: 0.0184\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0254 - val_loss: 0.0152\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0117\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0241 - val_loss: 0.0115\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0195 - val_loss: 0.0107\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0110\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0112\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0112\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0111\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0107\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0107\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0127\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0164\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0087\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0127\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0079\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0102\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0116\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0210 - val_loss: 0.0206\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0094\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0107\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0108\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0088\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0184\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0068\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0094\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0129\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0105\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0135\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0142\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0093\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0058\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0147\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0100\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0094\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0066\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0089\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0195\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0059\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0113\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0121\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0074\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0094\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0077\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0133\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0081\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0112\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0078\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0107\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0046\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0047\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0163\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0104\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0094\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.0105\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0109\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0094\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0055 - val_loss: 0.0148\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0085\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0068\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0132\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0034\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0127\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0162\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0126\n",
      ">2: Score=0.10430700331926346\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 10s 204ms/step - loss: 0.1764 - val_loss: 0.0184\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0608 - val_loss: 0.0805\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0361 - val_loss: 0.0292\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0328 - val_loss: 0.0206\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0337 - val_loss: 0.0216\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0273 - val_loss: 0.0152\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0272 - val_loss: 0.0124\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0228 - val_loss: 0.0114\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0123\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0221 - val_loss: 0.0135\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0120\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0127\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0121\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0126\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0120\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0131\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0115\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0188 - val_loss: 0.0134\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 0.0112\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0139\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0141\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0130\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0127\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0196\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0117\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0104\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0126\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0127\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0089\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0172\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0207\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0159\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0079\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0185\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0146\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0126\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0132\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0146\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0140\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0149\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0093\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0210\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0067\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0142\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0155\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0109\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0092\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0105\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0123\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0096\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0097\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0137\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0062\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0248\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0060\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0152\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0141\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0114\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0093\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0091\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0128\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.0108\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0157\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0127\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0173\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0108\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0113\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0291\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0084\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0053\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0145\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0137\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0143\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0094\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0141\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0114\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.0112\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0105\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0116\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0129\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0129\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0100\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0116\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0047 - val_loss: 0.0107\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0126\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0089\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0046\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0163\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0180 - val_loss: 0.0257\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0075\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0095\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0140\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0106\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0123\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0128\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 0.0108\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0129\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0135\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0111\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0041\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0119\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0053 - val_loss: 0.0196\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0109\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0113\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0096\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0096\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0182\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0099\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0083\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.0116\n",
      ">3: Score=0.20145462453365326\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 9s 179ms/step - loss: 0.1922 - val_loss: 0.0264\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0611 - val_loss: 0.0626\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0368 - val_loss: 0.0325\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0317 - val_loss: 0.0190\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0341 - val_loss: 0.0215\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0267 - val_loss: 0.0150\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0279 - val_loss: 0.0129\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.0120\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.0108\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.0107\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.0110\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0110\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0113\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0111\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0117\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0110\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0116\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0117\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0102\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0119\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0094\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0173\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0086\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0089\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0111\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0116\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0135\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0091\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0077\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0087\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0215\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0079\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0152\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0127\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0073\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0175\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0115\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0096\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0117\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0105\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0109\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0131\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0113\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0120\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0075\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0226\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0104\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0123\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0111\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0093\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0107\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0096\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0128\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0089\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0077\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0108\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0085\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0109\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0106\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0129\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0194\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0174\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0063\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0105\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0193\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0136\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0083\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.0130\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0042 - val_loss: 0.0080\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0132\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0169\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0055 - val_loss: 0.0111\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0084\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0131\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0130\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0133\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0231\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0051\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0126\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0043 - val_loss: 0.0104\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0146\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0122\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0104\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0119\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0125\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0082\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0094\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0109\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0081\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0106\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0107\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0086\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0218\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.0055\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0059\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0201\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0109\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0127\n",
      ">4: Score=0.12147221714258194\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 9s 176ms/step - loss: 0.1895 - val_loss: 0.0286\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0591 - val_loss: 0.0597\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0413 - val_loss: 0.0358\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0310 - val_loss: 0.0173\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0329 - val_loss: 0.0205\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0334 - val_loss: 0.0144\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0116\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0235 - val_loss: 0.0110\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0229 - val_loss: 0.0108\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0109\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0180 - val_loss: 0.0115\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0131\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0120\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0164 - val_loss: 0.0125\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0158\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0112\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0142\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0163\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0149\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0083\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0126\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0081\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0097\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0140\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0133\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0120\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0166\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0125\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0169\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0118\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0129\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0113\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0128\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0059\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0162\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0072\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0147\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0134\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0189\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0128\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0128\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0136\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0103\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0132\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0156\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0063\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0097\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0195\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0164\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0061\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0094\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0155\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0151\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0125\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0099\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 0.0129\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0062\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0266\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0054\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0095\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0120\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0117\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0156\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0111\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0113\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0118\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0106\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0131\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0194\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 0.0056\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0200\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0252\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0097\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0118\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0124\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0149\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0193\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0074\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.0116\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0097\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0150\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0230\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0126\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0038\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 0.0162\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0144\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0083\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0151\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0125\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0107\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0098\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0055 - val_loss: 0.0151\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      ">5: Score=0.06472686678171158\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 9s 187ms/step - loss: 0.2036 - val_loss: 0.0366\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0757 - val_loss: 0.0458\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0486 - val_loss: 0.0387\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0403 - val_loss: 0.0187\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0357 - val_loss: 0.0232\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0325 - val_loss: 0.0176\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0273 - val_loss: 0.0133\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0137\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0114\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0113\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0141\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0120\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0184 - val_loss: 0.0120\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0124\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0122\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0138\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0103\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0113\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0120\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0093\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0158\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0160\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0113\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0132\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.0099\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.0100\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0129\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0130\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0140\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0080\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0110\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0184\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0089\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0116\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0112\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0080 - val_loss: 0.0149\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0086\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0110\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0073\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0140\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0137\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0146\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0151\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0159\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0132\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0116\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0201\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0063\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0117\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0225\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0091\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0166\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0091\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0130\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0161\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0148\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0165\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0065\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0192\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0108\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 0.0123\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0087\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0128\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0127\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0147\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0135\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0152\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0141\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0114\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0119\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0080\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0106\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0171\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0183\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0074\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0055\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0262\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0140\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0059\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0145\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0126\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0134\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0141\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0165\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0140\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0106\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0168\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0118\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0103 - val_loss: 0.0040\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0128\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0157\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0055 - val_loss: 0.0084\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0090\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0190\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0113\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0077\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0103\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0112\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0102\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0085\n",
      ">6: Score=0.10483448952436447\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 9s 188ms/step - loss: 0.1869 - val_loss: 0.0277\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0620 - val_loss: 0.0563\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0404 - val_loss: 0.0238\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0343 - val_loss: 0.0167\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0358 - val_loss: 0.0201\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0282 - val_loss: 0.0143\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0285 - val_loss: 0.0125\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0118\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0113\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0113\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0198 - val_loss: 0.0115\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0120\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.0117\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0125\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0126\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0107\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0133\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0115\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0102\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0109\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0128\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0099\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0146 - val_loss: 0.0098\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0116\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0092\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0083\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0154\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0082\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0112\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0089\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0082\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0078\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0071\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0124\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0116\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0103\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0149\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0070\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0100\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0148\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0089\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0092\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0101\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0086\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0093\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0145\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0104\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0084\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0083\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0072\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0095\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0141\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0085\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0115\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0076\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0095\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0106\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0077\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0107\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0134\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0156\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0137\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0110\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0113\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0074\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0134\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0123\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0128\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0078\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0091\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0093\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0050 - val_loss: 0.0084\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0062 - val_loss: 0.0096\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0047\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0306\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0053\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0086\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0078\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0085\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0094\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0092\n",
      ">7: Score=0.09236350655555725\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 9s 182ms/step - loss: 0.1927 - val_loss: 0.0351\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0663 - val_loss: 0.0466\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0391 - val_loss: 0.0291\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0378 - val_loss: 0.0163\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0325 - val_loss: 0.0205\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0317 - val_loss: 0.0152\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0298 - val_loss: 0.0130\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0281 - val_loss: 0.0125\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0253 - val_loss: 0.0115\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0214 - val_loss: 0.0112\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0243 - val_loss: 0.0127\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 0.0115\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0129\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0116\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0200 - val_loss: 0.0121\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0125\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 0.0118\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0183 - val_loss: 0.0139\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0184\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0115\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0125\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0189\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0109\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0106\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0149\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0141\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0150\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0139\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0151\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0190\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0087\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.0084\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0195\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0154\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0169\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0107\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0121\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0106\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0118\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0123\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0083\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0153\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0185\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0147\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0182\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0177\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0072\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0146\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0189\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0127\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0184\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0125\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0169\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0150\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0172\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0153\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0067\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0108\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0159\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0158\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0110\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0181\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0145\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0150\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0123\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0166\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0102\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0106\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 0.0171\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0210\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0255\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0142\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0189\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.0170\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0089\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0060 - val_loss: 0.0112\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0194\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0128\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.0093\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0094\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.0093\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0146\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0129\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0114\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0032 - val_loss: 0.0131\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0140\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0141\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0063 - val_loss: 0.0146\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0100\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0151\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0112\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0071\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0139\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0053 - val_loss: 0.0115\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.0136\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0143\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0085\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0155\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0095\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0085\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0135\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0176\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0140\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.0153\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0190\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0111\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0240\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0165\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0041 - val_loss: 0.0120\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0214\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0149\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0113\n",
      ">8: Score=0.1148119792342186\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 9s 186ms/step - loss: 0.2004 - val_loss: 0.0357\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0710 - val_loss: 0.0448\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0483 - val_loss: 0.0380\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0330 - val_loss: 0.0196\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0351 - val_loss: 0.0233\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0280 - val_loss: 0.0214\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0275 - val_loss: 0.0141\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0253 - val_loss: 0.0124\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0120\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0238 - val_loss: 0.0110\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.0110\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0124\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0185 - val_loss: 0.0116\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 0.0165\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0116\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0155 - val_loss: 0.0118\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0115\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.0120\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0114\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0138\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.0139\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0109\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0101\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0098\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0094\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0145\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0098\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0148\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0093\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0113\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0142\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 0.0095\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0110\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0098\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0141\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0163\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0132\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0075\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0069\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0172\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0204\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0109\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0111\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0101\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0146\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0113\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0070 - val_loss: 0.0117\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0147\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0165\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0120\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0062\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0122\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0167\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0114\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0149\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0120\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0114\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0164\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0063\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0052\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0215\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0089\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0104\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0114\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0120\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0097\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0108\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0199\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0050\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0110\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0191\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0081\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0143\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0098\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0102\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0129\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0115\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0127\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0081\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0047 - val_loss: 0.0149\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0129\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0131\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0088\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0042 - val_loss: 0.0138\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0233\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0138\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0071\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0103\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0124\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0086\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0166\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0112\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0096\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0184\n",
      ">9: Score=0.22688980400562286\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 10s 160ms/step - loss: 0.2017 - val_loss: 0.0317\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0659 - val_loss: 0.0614\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0458 - val_loss: 0.0403\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0350 - val_loss: 0.0195\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0358 - val_loss: 0.0233\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0296 - val_loss: 0.0206\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0271 - val_loss: 0.0155\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0274 - val_loss: 0.0139\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0246 - val_loss: 0.0115\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0215 - val_loss: 0.0113\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0104\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0194 - val_loss: 0.0105\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0106\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0189 - val_loss: 0.0107\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0109\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0104\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0145 - val_loss: 0.0105\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0098\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0101\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0092\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0119\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0087\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0105\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0079\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0103\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0075\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0072\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0072\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0135\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0088\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0073\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0087\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0059\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0122\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0065\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0116\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0055 - val_loss: 0.0117\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0085\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0064\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0057\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0073\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0099\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0087\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0085\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0053\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0078\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0068\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0070\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0081\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0082\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0040\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0141\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0084\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0095\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0095\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      ">10: Score=0.037940606474876404\n",
      "[0.1296929568052292, 0.10430700331926346, 0.20145462453365326, 0.12147221714258194, 0.06472686678171158, 0.10483448952436447, 0.09236350655555725, 0.1148119792342186, 0.22688980400562286, 0.037940606474876404]\n",
      "Loss: Mean = 0.120, Std = 0.054\n"
     ]
    }
   ],
   "source": [
    "# Ajustando e validando o modelo\n",
    "def evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units = neurons))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # ajustando o modelo\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=batch_size, validation_split = 0.2, shuffle=False)\n",
    "    # avaliando o modelo\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0, batch_size=5)\n",
    "    return loss\n",
    "\n",
    "# Resumindo as pontuações\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = np.mean(scores), np.std(scores)\n",
    "    print(f'Loss: Mean = {m:.3f}, Std = {s:.3f}')\n",
    "\n",
    "# Rodando um experimento\n",
    "def run_experiment(repeats = 10):\n",
    "    # repetindo o experimento\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(X_train, y_train, X_test, y_test)\n",
    "        score = score\n",
    "        scores.append(score)\n",
    "        print(f'>{r+1}: Score={score}')\n",
    "    # resumindo os resultados\n",
    "    summarize_results(scores)\n",
    "\n",
    "# Rodando o experimento\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(units, dropout):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=units, return_sequences = True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.LSTM(units = units))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(units = 1))\n",
    "    # compilando o modelo\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, batch_size):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    history = model.fit(X_train, y_train, epochs=150, batch_size=batch_size, validation_split = 0.2, shuffle=False, callbacks=[early_stop])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "15/15 [==============================] - 11s 149ms/step - loss: 0.1799 - val_loss: 0.0208\n",
      "Epoch 2/150\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0557 - val_loss: 0.0450\n",
      "Epoch 3/150\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0347 - val_loss: 0.0176\n",
      "Epoch 4/150\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0322 - val_loss: 0.0176\n",
      "Epoch 5/150\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0324 - val_loss: 0.0156\n",
      "Epoch 6/150\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0253 - val_loss: 0.0129\n",
      "Epoch 7/150\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0251 - val_loss: 0.0128\n",
      "Epoch 8/150\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0281 - val_loss: 0.0114\n",
      "Epoch 9/150\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0218 - val_loss: 0.0110\n",
      "Epoch 10/150\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0216 - val_loss: 0.0109\n",
      "Epoch 11/150\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0188 - val_loss: 0.0109\n",
      "Epoch 12/150\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0114\n",
      "Epoch 13/150\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0210 - val_loss: 0.0110\n",
      "Epoch 14/150\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0179 - val_loss: 0.0110\n",
      "Epoch 15/150\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 16/150\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0112\n",
      "Epoch 17/150\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.0109\n",
      "Epoch 18/150\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 19/150\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 0.0117\n",
      "Epoch 20/150\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0154 - val_loss: 0.0113\n",
      "Epoch 21/150\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0110\n"
     ]
    }
   ],
   "source": [
    "model_lstm = create_model(neurons, dropout)\n",
    "history_lstm = fit_model(model_lstm, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: despesas_2013_2022\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: despesas_2013_2022\\assets\n"
     ]
    }
   ],
   "source": [
    "model_lstm.save('despesas_2013_2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga do modelo salvo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = tf.keras.models.load_model('despesas_2013_2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-processamento e predição da base de testes com a utilização do modelo carregado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_future(prediction, y_test):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    range_future = len(prediction)\n",
    "    plt.plot(np.arange(range_future), np.array(y_test), label='Dados reais')\n",
    "    plt.plot(np.arange(range_future), np.array(prediction),label='Predição')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Período')\n",
    "    plt.ylabel('Valor Arrecadado')\n",
    "    plt.title('Predição de Receitas - LSTM')\n",
    "    plt.savefig('../../src/static/images/despesas/figura[3].png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_test = scaler_y.inverse_transform(y_test)\n",
    "y_train = scaler_y.inverse_transform(y_train)\n",
    "\n",
    "prediction_lstm = prediction(model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_future(prediction_lstm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo do erro médio absoluto e raiz quadrática média:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(prediction_lstm, actual, model_name):\n",
    "    errors = prediction_lstm - actual\n",
    "    mse = np.square(errors).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.abs(errors).mean()\n",
    "    print(f'{model_name}:')\n",
    "    print(f'MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n",
      "MSE: 43651126111.95, RMSE: 208928.52, MAE: 159481.68\n"
     ]
    }
   ],
   "source": [
    "evaluate_prediction(prediction_lstm, y_test, 'LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-processamento dos dados e aplicação do modelo em toda a base de dados (treino + teste):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_future(prediction, y):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    range_future = len(prediction)\n",
    "    plt.plot(np.arange(range_future), np.array(y), label='Dados reais')\n",
    "    plt.plot(np.arange(range_future), np.array(prediction),label='Predição')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Período')\n",
    "    plt.ylabel('Valor Arrecadado')\n",
    "    plt.title('Predição de Receitas - LSTM')\n",
    "    plt.savefig('../../src/static/images/despesas/figura[4].png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df_despesas_agrupado.drop(['valor_fixado','valor_empenhado','valor_liquidado','valor_pago','saldo'], axis=1)\n",
    "y = df_despesas_agrupado.loc[:, ['valor_fixado','valor_empenhado','valor_liquidado','valor_pago','saldo']]\n",
    "\n",
    "y_norm = output_scaler.transform(y)\n",
    "X_norm = input_scaler.transform(X)\n",
    "\n",
    "X = X_norm.reshape((X_norm.shape[0], 1, X_norm.shape[1]))\n",
    "y = y_norm.reshape((y_norm.shape[0], 1))\n",
    "\n",
    "y = scaler_y.inverse_transform(y)\n",
    "\n",
    "prediction_lstm = prediction(model_lstm)\n",
    "\n",
    "plot_future(prediction_lstm, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo do erro médio percentual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro médio percentual: -6.08%\n"
     ]
    }
   ],
   "source": [
    "real = y.flatten()\n",
    "previsto = prediction_lstm.flatten()\n",
    "\n",
    "tabela = pd.DataFrame([real, previsto]).T\n",
    "tabela = tabela.rename(columns={0: 'Real', 1: 'Previsto'})\n",
    "tabela['Diferenca'] = 1 - (tabela['Real'] / tabela['Previsto'])\n",
    "media_tabela = tabela['Diferenca'].mean() * 100\n",
    "print(f'Erro médio percentual: {media_tabela:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribuição de erros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(data=tabela, x='Diferenca', kde=True).set_title('Distribuição dos erros percentuais').get_figure().savefig('../../src/static/images/despesas/figura[5].png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relizando previsões com os dados e modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['valor_fixado', 'valor_empenhado', 'valor_liquidado', 'valor_pago',\n",
       "       'saldo', 'populacao', 'variacao_anual', 'aceleracao_variacao_anual',\n",
       "       'ideb_5ano', 'ideb_9ano', 'idhm', 'pct_desp_recp_saude_mun',\n",
       "       'desp_tot_saude_pc_mun', 'desp_recp_saude_pc_mun',\n",
       "       'desp_tot_saude_pc_mun_def', 'desp_recp_saude_pc_mun_def', 'SMA(12)',\n",
       "       'SMA(6)', 'SMA(3)', 'SMA(2)', 'lag(12)', 'lag(6)', 'lag(4)', 'lag(3)',\n",
       "       'lag(2)', 'lag(1)', 'ano_mes_ordinal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao = df_despesas_agrupado\n",
    "\n",
    "previsao.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 182ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allys\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano_mes_ordinal</th>\n",
       "      <th>valor_receita</th>\n",
       "      <th>SMA(12)</th>\n",
       "      <th>SMA(6)</th>\n",
       "      <th>SMA(3)</th>\n",
       "      <th>SMA(2)</th>\n",
       "      <th>lag(12)</th>\n",
       "      <th>lag(6)</th>\n",
       "      <th>lag(4)</th>\n",
       "      <th>lag(3)</th>\n",
       "      <th>lag(2)</th>\n",
       "      <th>lag(1)</th>\n",
       "      <th>populacao</th>\n",
       "      <th>variacao_anual</th>\n",
       "      <th>aceleracao_variacao_anual</th>\n",
       "      <th>valor_pib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>734869</td>\n",
       "      <td>160122.33000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>770339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>734900</td>\n",
       "      <td>125630.52000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142876.425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160122.33</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>770339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734928</td>\n",
       "      <td>169281.06000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151677.97</td>\n",
       "      <td>147455.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160122.33</td>\n",
       "      <td>125630.52</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>770339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734959</td>\n",
       "      <td>161371.68000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152094.42</td>\n",
       "      <td>165326.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160122.33</td>\n",
       "      <td>125630.52</td>\n",
       "      <td>169281.06</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>770339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>734989</td>\n",
       "      <td>158982.66000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163211.8</td>\n",
       "      <td>160177.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160122.33</td>\n",
       "      <td>125630.52</td>\n",
       "      <td>169281.06</td>\n",
       "      <td>161371.68</td>\n",
       "      <td>60612</td>\n",
       "      <td>1482</td>\n",
       "      <td>1146</td>\n",
       "      <td>770339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>738494</td>\n",
       "      <td>344189.31250</td>\n",
       "      <td>269196.078958</td>\n",
       "      <td>271339.344583</td>\n",
       "      <td>318566.729167</td>\n",
       "      <td>331790.21875</td>\n",
       "      <td>222432.57</td>\n",
       "      <td>185469.57</td>\n",
       "      <td>279195.09</td>\n",
       "      <td>292119.75</td>\n",
       "      <td>319710.8125</td>\n",
       "      <td>343869.625</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>1393868.928021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>738495</td>\n",
       "      <td>369864.71875</td>\n",
       "      <td>279342.474167</td>\n",
       "      <td>297792.635</td>\n",
       "      <td>335923.25</td>\n",
       "      <td>344029.46875</td>\n",
       "      <td>321259.43</td>\n",
       "      <td>207671.22</td>\n",
       "      <td>292119.75</td>\n",
       "      <td>319710.8125</td>\n",
       "      <td>343869.625</td>\n",
       "      <td>344189.3125</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>1393868.928021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>738496</td>\n",
       "      <td>383960.03125</td>\n",
       "      <td>283392.914896</td>\n",
       "      <td>324824.884792</td>\n",
       "      <td>352641.21875</td>\n",
       "      <td>357027.015625</td>\n",
       "      <td>347717.77</td>\n",
       "      <td>279195.09</td>\n",
       "      <td>319710.8125</td>\n",
       "      <td>343869.625</td>\n",
       "      <td>344189.3125</td>\n",
       "      <td>369864.71875</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>1393868.928021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>738497</td>\n",
       "      <td>388267.00000</td>\n",
       "      <td>286413.103333</td>\n",
       "      <td>342285.708333</td>\n",
       "      <td>366004.6875</td>\n",
       "      <td>376912.375</td>\n",
       "      <td>280317.33</td>\n",
       "      <td>292119.75</td>\n",
       "      <td>343869.625</td>\n",
       "      <td>344189.3125</td>\n",
       "      <td>369864.71875</td>\n",
       "      <td>383960.03125</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>1393868.928021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>738498</td>\n",
       "      <td>397414.25000</td>\n",
       "      <td>295408.909167</td>\n",
       "      <td>358310.25</td>\n",
       "      <td>380697.25</td>\n",
       "      <td>386113.515625</td>\n",
       "      <td>232355.13</td>\n",
       "      <td>319710.8125</td>\n",
       "      <td>344189.3125</td>\n",
       "      <td>369864.71875</td>\n",
       "      <td>383960.03125</td>\n",
       "      <td>388267.0</td>\n",
       "      <td>63239</td>\n",
       "      <td>663</td>\n",
       "      <td>376</td>\n",
       "      <td>1393868.928021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano_mes_ordinal  valor_receita        SMA(12)         SMA(6)  \\\n",
       "0            734869   160122.33000            0.0            0.0   \n",
       "1            734900   125630.52000            0.0            0.0   \n",
       "2            734928   169281.06000            0.0            0.0   \n",
       "3            734959   161371.68000            0.0            0.0   \n",
       "4            734989   158982.66000            0.0            0.0   \n",
       "..              ...            ...            ...            ...   \n",
       "171          738494   344189.31250  269196.078958  271339.344583   \n",
       "172          738495   369864.71875  279342.474167     297792.635   \n",
       "173          738496   383960.03125  283392.914896  324824.884792   \n",
       "174          738497   388267.00000  286413.103333  342285.708333   \n",
       "175          738498   397414.25000  295408.909167      358310.25   \n",
       "\n",
       "            SMA(3)         SMA(2)    lag(12)       lag(6)       lag(4)  \\\n",
       "0              0.0            0.0        0.0          0.0          0.0   \n",
       "1              0.0     142876.425        0.0          0.0          0.0   \n",
       "2        151677.97      147455.79        0.0          0.0          0.0   \n",
       "3        152094.42      165326.37        0.0          0.0          0.0   \n",
       "4         163211.8      160177.17        0.0          0.0    160122.33   \n",
       "..             ...            ...        ...          ...          ...   \n",
       "171  318566.729167   331790.21875  222432.57    185469.57    279195.09   \n",
       "172      335923.25   344029.46875  321259.43    207671.22    292119.75   \n",
       "173   352641.21875  357027.015625  347717.77    279195.09  319710.8125   \n",
       "174    366004.6875     376912.375  280317.33    292119.75   343869.625   \n",
       "175      380697.25  386113.515625  232355.13  319710.8125  344189.3125   \n",
       "\n",
       "           lag(3)        lag(2)        lag(1) populacao variacao_anual  \\\n",
       "0             0.0           0.0           0.0     60612           1482   \n",
       "1             0.0           0.0     160122.33     60612           1482   \n",
       "2             0.0     160122.33     125630.52     60612           1482   \n",
       "3       160122.33     125630.52     169281.06     60612           1482   \n",
       "4       125630.52     169281.06     161371.68     60612           1482   \n",
       "..            ...           ...           ...       ...            ...   \n",
       "171     292119.75   319710.8125    343869.625     63239            663   \n",
       "172   319710.8125    343869.625   344189.3125     63239            663   \n",
       "173    343869.625   344189.3125  369864.71875     63239            663   \n",
       "174   344189.3125  369864.71875  383960.03125     63239            663   \n",
       "175  369864.71875  383960.03125      388267.0     63239            663   \n",
       "\n",
       "    aceleracao_variacao_anual       valor_pib  \n",
       "0                        1146        770339.0  \n",
       "1                        1146        770339.0  \n",
       "2                        1146        770339.0  \n",
       "3                        1146        770339.0  \n",
       "4                        1146        770339.0  \n",
       "..                        ...             ...  \n",
       "171                       376  1393868.928021  \n",
       "172                       376  1393868.928021  \n",
       "173                       376  1393868.928021  \n",
       "174                       376  1393868.928021  \n",
       "175                       376  1393868.928021  \n",
       "\n",
       "[176 rows x 16 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "periodo = 8  # escolha o período de previsão à frente será executado\n",
    "\n",
    "for i in range(periodo):\n",
    "    # Crie uma nova linha de dados vazia\n",
    "    row = pd.DataFrame(columns=previsao.columns)\n",
    "\n",
    "    # Calcule as médias e valores de atraso\n",
    "    row.loc[0, 'SMA(12)'] = previsao['valor_pago'].iloc[-12:].mean()\n",
    "    row.loc[0, 'SMA(6)'] = previsao['valor_pago'].iloc[-6:].mean()\n",
    "    row.loc[0, 'SMA(3)'] = previsao['valor_pago'].iloc[-3:].mean()\n",
    "    row.loc[0, 'SMA(2)'] = previsao['valor_pago'].iloc[-2:].mean()\n",
    "    row.loc[0, 'lag(12)'] = previsao['valor_pago'].iloc[-12]\n",
    "    row.loc[0, 'lag(6)'] = previsao['valor_pago'].iloc[-6]\n",
    "    row.loc[0, 'lag(4)'] = previsao['valor_pago'].iloc[-4]\n",
    "    row.loc[0, 'lag(3)'] = previsao['valor_pago'].iloc[-3]\n",
    "    row.loc[0, 'lag(2)'] = previsao['valor_pago'].iloc[-2]\n",
    "    row.loc[0, 'lag(1)'] = previsao['valor_pago'].iloc[-1]\n",
    "    row.loc[0, 'populacao'] = previsao['populacao'].iloc[-1]\n",
    "    row.loc[0, 'variacao_anual'] = previsao['variacao_anual'].iloc[-1]\n",
    "    row.loc[0, 'aceleracao_variacao_anual'] = previsao['aceleracao_variacao_anual'].iloc[-1]\n",
    "    row.loc[0, 'valor_pib'] = previsao['valor_pib'].iloc[-1]\n",
    "\n",
    "\n",
    "    # Incremente a data\n",
    "    row.loc[0, 'ano_mes_ordinal'] = previsao['ano_mes_ordinal'].iloc[-1]+1\n",
    "    \n",
    "    # Excluindo a coluna de valor arrecadado\n",
    "    row = row.drop(columns={'valor_receita'})\n",
    "    \n",
    "    # Transforme a linha em um array e normalize\n",
    "    row = np.array(row.iloc[-1]).reshape(1, -1)\n",
    "    row_norm = input_scaler.transform(row)\n",
    "\n",
    "    # Preveja usando o modelo LSTM\n",
    "    to_prev = row_norm.reshape((row_norm.shape[0], 1, row_norm.shape[1]))\n",
    "    prev = model_lstm.predict(to_prev)\n",
    "    prev = scaler_y.inverse_transform(prev)\n",
    "\n",
    "    # Crie um DataFrame com a previsão e adicione ao DataFrame principal\n",
    "    row_ = pd.DataFrame(row, columns = ['valor_fixado', 'valor_empenhado', 'valor_liquidado', 'valor_pago',\n",
    "       'saldo', 'populacao', 'variacao_anual', 'aceleracao_variacao_anual',\n",
    "       'ideb_5ano', 'ideb_9ano', 'idhm', 'pct_desp_recp_saude_mun',\n",
    "       'desp_tot_saude_pc_mun', 'desp_recp_saude_pc_mun',\n",
    "       'desp_tot_saude_pc_mun_def', 'desp_recp_saude_pc_mun_def', 'SMA(12)',\n",
    "       'SMA(6)', 'SMA(3)', 'SMA(2)', 'lag(12)', 'lag(6)', 'lag(4)', 'lag(3)',\n",
    "       'lag(2)', 'lag(1)', 'ano_mes_ordinal'])\n",
    "    row_.loc[0, 'valor_receita'] = prev[0]\n",
    "    previsao = pd.concat([previsao, row_], ignore_index=True)\n",
    "\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
